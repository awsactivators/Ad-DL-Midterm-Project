{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSprop optimizer\n",
    "\n",
    "RMSprop (Root Mean Square Propagation) is an optimization algorithm commonly used in training artificial neural networks (ANNs). It is particularly effective in scenarios where other optimization algorithms like vanilla stochastic gradient descent (SGD) may struggle due to problems such as vanishing or exploding gradients.\n",
    "\n",
    "## Details of RMSprop Algorithm\n",
    "\n",
    "RMSprop is an adaptive learning rate optimization algorithm proposed by Geoffrey Hinton in his course on Neural Networks for Machine Learning. The algorithm is designed to adaptively adjust the learning rates for different parameters during training.\n",
    "\n",
    "Summary of how RMSprop works:\n",
    "\n",
    "1. Compute Squared Gradients: RMSprop maintains a moving average of the squared gradients for each parameter. This is similar to AdaGrad but with a decaying average.\n",
    "\n",
    "2. Update Parameters: The update rule adjusts the learning rate for each parameter based on the average of the squared gradients.\n",
    "\n",
    "3. Adaptive Learning Rates: RMSprop divides the learning rate by the square root of the exponentially decaying average of squared gradients for each parameter. This helps to normalize the learning rates and overcome the problems of vanishing or exploding gradients.\n",
    "\n",
    "\n",
    "## Pros of RMSprop optimizer\n",
    "\n",
    "1. Adaptive Learning Rates: RMSprop adapts the learning rates for each parameter individually based on the magnitude of their gradients. This helps converge faster and more efficiently, especially in deep neural networks.\n",
    "\n",
    "2. Stability: It helps to stabilize the learning process by mitigating the issues of vanishing and exploding gradients.\n",
    "\n",
    "3. Simple Implementation: RMSprop is relatively easy to implement and widely used in practice.\n",
    "\n",
    "## Cons of RMSprop optimizer\n",
    "\n",
    "1. Hyperparameter Sensitivity: RMSprop, like other adaptive methods, has hyperparameters that need to be tuned, such as the learning rate and the decay rate. Improper tuning can lead to suboptimal performance.\n",
    "\n",
    "2. Memory Usage: RMSprop maintains a moving average of squared gradients for each parameter, which can require additional memory, especially for large models with many parameters.\n",
    "\n",
    "\n",
    "## References\n",
    "- https://keras.io/api/optimizers/rmsprop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fashionmnist_model import FMM\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X_train, y_train, X_test, y_test = FMM.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "X_train, X_test = FMM.reshape_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with RMSprop optimizer...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 21:57:28.520599: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 8s 9ms/step - loss: 0.5365 - accuracy: 0.8064 - val_loss: 0.4039 - val_accuracy: 0.8533\n",
      "Epoch 2/30\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.3824 - accuracy: 0.8605 - val_loss: 0.4039 - val_accuracy: 0.8507\n",
      "Epoch 3/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.3430 - accuracy: 0.8755 - val_loss: 0.3505 - val_accuracy: 0.8787\n",
      "Epoch 4/30\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.3222 - accuracy: 0.8814 - val_loss: 0.3341 - val_accuracy: 0.8807\n",
      "Epoch 5/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.3020 - accuracy: 0.8887 - val_loss: 0.3283 - val_accuracy: 0.8879\n",
      "Epoch 6/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2900 - accuracy: 0.8941 - val_loss: 0.3921 - val_accuracy: 0.8685\n",
      "Epoch 7/30\n",
      "750/750 [==============================] - 6s 9ms/step - loss: 0.2800 - accuracy: 0.8966 - val_loss: 0.3268 - val_accuracy: 0.8894\n",
      "Epoch 8/30\n",
      "750/750 [==============================] - 6s 9ms/step - loss: 0.2703 - accuracy: 0.8997 - val_loss: 0.3566 - val_accuracy: 0.8817\n",
      "Epoch 9/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2596 - accuracy: 0.9041 - val_loss: 0.3501 - val_accuracy: 0.8841\n",
      "Epoch 10/30\n",
      "750/750 [==============================] - 6s 9ms/step - loss: 0.2542 - accuracy: 0.9069 - val_loss: 0.3819 - val_accuracy: 0.8863\n",
      "Epoch 11/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2492 - accuracy: 0.9075 - val_loss: 0.3601 - val_accuracy: 0.8820\n",
      "Epoch 12/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2407 - accuracy: 0.9125 - val_loss: 0.3708 - val_accuracy: 0.8871\n",
      "Epoch 13/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2375 - accuracy: 0.9130 - val_loss: 0.3704 - val_accuracy: 0.8913\n",
      "Epoch 14/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2303 - accuracy: 0.9155 - val_loss: 0.3869 - val_accuracy: 0.8898\n",
      "Epoch 15/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2238 - accuracy: 0.9175 - val_loss: 0.4201 - val_accuracy: 0.8800\n",
      "Epoch 16/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2228 - accuracy: 0.9184 - val_loss: 0.4284 - val_accuracy: 0.8811\n",
      "Epoch 17/30\n",
      "750/750 [==============================] - 6s 9ms/step - loss: 0.2183 - accuracy: 0.9198 - val_loss: 0.3650 - val_accuracy: 0.8936\n",
      "Epoch 18/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2143 - accuracy: 0.9221 - val_loss: 0.3720 - val_accuracy: 0.8925\n",
      "Epoch 19/30\n",
      "750/750 [==============================] - 6s 9ms/step - loss: 0.2102 - accuracy: 0.9249 - val_loss: 0.4748 - val_accuracy: 0.8769\n",
      "Epoch 20/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2061 - accuracy: 0.9251 - val_loss: 0.4120 - val_accuracy: 0.8892\n",
      "Epoch 21/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2068 - accuracy: 0.9258 - val_loss: 0.4749 - val_accuracy: 0.8902\n",
      "Epoch 22/30\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.2004 - accuracy: 0.9275 - val_loss: 0.4433 - val_accuracy: 0.8863\n",
      "Epoch 23/30\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.1989 - accuracy: 0.9285 - val_loss: 0.4436 - val_accuracy: 0.8888\n",
      "Epoch 24/30\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.1954 - accuracy: 0.9299 - val_loss: 0.4643 - val_accuracy: 0.8926\n",
      "Epoch 25/30\n",
      "750/750 [==============================] - 7s 10ms/step - loss: 0.1955 - accuracy: 0.9302 - val_loss: 0.5480 - val_accuracy: 0.8802\n",
      "Epoch 26/30\n",
      "750/750 [==============================] - 7s 10ms/step - loss: 0.1902 - accuracy: 0.9315 - val_loss: 0.5170 - val_accuracy: 0.8891\n",
      "Epoch 27/30\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.1879 - accuracy: 0.9328 - val_loss: 0.5035 - val_accuracy: 0.8873\n",
      "Epoch 28/30\n",
      "750/750 [==============================] - 7s 10ms/step - loss: 0.1857 - accuracy: 0.9333 - val_loss: 0.5173 - val_accuracy: 0.8903\n",
      "Epoch 29/30\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.1832 - accuracy: 0.9340 - val_loss: 0.5823 - val_accuracy: 0.8841\n",
      "Epoch 30/30\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.1824 - accuracy: 0.9353 - val_loss: 0.5478 - val_accuracy: 0.8894\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop()\n",
    "model = FMM.create_model_v1()\n",
    "print(f\"Training with {optimizer.__class__.__name__} optimizer...\")\n",
    "history = FMM.compile_and_train(\n",
    "    model, X_train, y_train, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.6033 - accuracy: 0.8822 - 2s/epoch - 7ms/step\n",
      "\n",
      "Training accuracy : 0.9353125095367432\n",
      "Validation accuracy : 0.8894166946411133\n",
      "Loss : 0.6032505631446838\n",
      "Accuracy : 0.8822000026702881\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/UAAAIhCAYAAAAPY5p0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3gU1dfA8e9m0yshnZZQQ+iQ0AVEkI6gIkWqgIoogtjghyggio1iA1+VIqCCig1BKQJKFYyE3lsoCSEBEtLbvH/c7CYhhZRNNuV8nmefncxOubuEzJ65556r0zRNQwghhBBCCCGEEOWOhbkbIIQQQgghhBBCiKKRoF4IIYQQQgghhCinJKgXQgghhBBCCCHKKQnqhRBCCCGEEEKIckqCeiGEEEIIIYQQopySoF4IIYQQQgghhCinJKgXQgghhBBCCCHKKQnqhRBCCCGEEEKIckqCeiGEEEIIIYQQopySoF6IErZixQp0Oh06nY4dO3bkeF3TNOrVq4dOp+P+++836bl1Oh2zZs0q9H4XL15Ep9OxYsWKAu9z5MgRdDodVlZWhIWFFfqcQgghhFAq8ncHw3YffPBB0RoohMhBgnohSomTkxNLly7Nsf6vv/7i3LlzODk5maFVpvPll18CkJqaysqVK83cGiGEEKL8q+jfHYQQpiFBvRClZMiQIaxbt46YmJhs65cuXUr79u2pVauWmVpWfElJSXz99dc0b96c6tWrs2zZMnM3KU8JCQlommbuZgghhBD3VJG/OwghTEeCeiFKybBhwwD49ttvjeuio6NZt24dY8eOzXWfmzdvMnHiRKpXr461tTV16tRhxowZJCUlZdsuJiaGJ598Ejc3NxwdHenVqxenT5/O9Zhnzpzh8ccfx9PTExsbGwICAvj000+L9d5+/vlnoqKiGD9+PKNHj+b06dPs2rUrx3ZJSUnMmTOHgIAAbG1tcXNzo2vXruzZs8e4TXp6Oh9//DEtWrTAzs6OKlWq0K5dO3799VfjNnmlBvr5+TFmzBjjz4b0xc2bNzN27Fg8PDywt7cnKSmJs2fP8sQTT1C/fn3s7e2pXr06/fv358iRIzmOe/v2bV588UXq1KmDjY0Nnp6e9OnTh5MnT6JpGvXr16dnz5459ouNjcXFxYVnn322kJ+oEEIIUbG/O9xLaGgoI0aMyHbO+fPnk56enm27JUuW0Lx5cxwdHXFycqJhw4b873//M74eHx/PSy+9RO3atbG1taVq1aoEBQVl+0yFKO8szd0AISoLZ2dnBg0axLJly3j66acBdZG2sLBgyJAhLFq0KNv2iYmJdO3alXPnzjF79myaNWvGzp07mTdvHiEhIWzYsAFQ4+oGDhzInj17eP3112ndujW7d++md+/eOdpw/PhxOnToQK1atZg/fz7e3t5s2rSJ559/nsjISN54440ivbelS5diY2PD8OHDuXnzJvPmzWPp0qXcd999xm1SU1Pp3bs3O3fuZMqUKTzwwAOkpqayb98+QkND6dChAwBjxoxh9erVjBs3jjlz5mBtbc1///3HxYsXi9Q2gLFjx9K3b19WrVpFXFwcVlZWXLt2DTc3N9555x08PDy4efMmX331FW3btuXgwYP4+/sDcOfOHe677z4uXrzIq6++Stu2bYmNjeXvv/8mLCyMhg0bMmnSJKZMmcKZM2eoX7++8bwrV64kJiZGgnohhBBFUpG/O+Tnxo0bdOjQgeTkZN588038/Pz47bffeOmllzh37hyLFy8GYM2aNUycOJFJkybxwQcfYGFhwdmzZzl+/LjxWFOnTmXVqlXMnTuXli1bEhcXx9GjR4mKijJ5u4UwG00IUaKWL1+uAdqBAwe07du3a4B29OhRTdM0rXXr1tqYMWM0TdO0xo0ba126dDHu99lnn2mA9t1332U73rvvvqsB2ubNmzVN07Tff/9dA7QPP/ww23ZvvfWWBmhvvPGGcV3Pnj21GjVqaNHR0dm2fe655zRbW1vt5s2bmqZp2oULFzRAW758+T3f38WLFzULCwtt6NChxnVdunTRHBwctJiYGOO6lStXaoD2xRdf5Hmsv//+WwO0GTNm5HvOu9+Xga+vrzZ69Gjjz4bPftSoUfd8H6mpqVpycrJWv3597YUXXjCunzNnjgZoW7ZsyXPfmJgYzcnJSZs8eXK29Y0aNdK6du16z3MLIYQQWVXk7w6G7d5///08t5k2bZoGaP/880+29c8884ym0+m0U6dOGdtQpUqVfM/XpEkTbeDAgfluI0R5J+n3QpSiLl26ULduXZYtW8aRI0c4cOBAnulz27Ztw8HBgUGDBmVbb0gv//PPPwHYvn07AMOHD8+23eOPP57t58TERP78808efvhh7O3tSU1NNT769OlDYmIi+/btK/R7Wr58Oenp6dnex9ixY4mLi2Pt2rXGdb///ju2trZ5vl/DNoDJe7YfffTRHOtSU1N5++23adSoEdbW1lhaWmJtbc2ZM2c4ceJEtjY1aNCA7t2753l8JycnnnjiCVasWEFcXByg/v2OHz/Oc889Z9L3IoQQonKpiN8d7mXbtm00atSINm3a5Hgfmqaxbds2ANq0acPt27cZNmwYv/zyC5GRkTmO1aZNG37//XemTZvGjh07SEhIMHl7hTA3CeqFKEU6nY4nnniC1atX89lnn9GgQQM6deqU67ZRUVF4e3uj0+myrff09MTS0tKYNhYVFYWlpSVubm7ZtvP29s5xvNTUVD7++GOsrKyyPfr06QOQ68UwP+np6axYsYJq1aoRGBjI7du3uX37Nt27d8fBwSFbxd4bN25QrVo1LCzy/rNz48YN9Hp9jrYXl4+PT451U6dOZebMmQwcOJD169fzzz//cODAAZo3b57tgn/jxg1q1Khxz3NMmjSJO3fu8PXXXwPwySefUKNGDQYMGGC6NyKEEKLSqWjfHQoiKioq12t3tWrVjK8DjBw5kmXLlnHp0iUeffRRPD09adu2LVu2bDHu89FHH/Hqq6/y888/07VrV6pWrcrAgQM5c+aMydsthLlIUC9EKRszZgyRkZF89tlnPPHEE3lu5+bmxvXr13NUao+IiCA1NRV3d3fjdqmpqTnGhoWHh2f72dXVFb1ez5gxYzhw4ECuD8MFuqC2bt3KpUuXjOPTXV1dcXV1pXr16sTFxbFv3z7juDYPDw+uXbuWo8BNVh4eHqSlpeVo+91sbGxyFPwB8hwfd/eXG4DVq1czatQo3n77bXr27EmbNm0ICgrK8eXEw8ODK1eu5NsegHr16tG7d28+/fRTLl++zK+//sqECRPQ6/X33FcIIYTIT0X67lAQbm5uhIWF5Vh/7do1AOP7AHjiiSfYs2cP0dHRbNiwAU3T6NevH5cuXQLAwcGB2bNnc/LkScLDw1myZAn79u2jf//+Jm+3EOYiQb0Qpax69eq8/PLL9O/fn9GjR+e5Xbdu3YiNjeXnn3/Ott4wB3y3bt0A6Nq1K4Cxh9jgm2++yfazvb09Xbt25eDBgzRr1oygoKAcj7vv2N/L0qVLsbCw4Oeff2b79u3ZHqtWrQIwTm/Xu3dvEhMTWbFiRZ7HMxToWbJkSb7n9fPz4/Dhw9nWbdu2jdjY2AK3XafTYWNjk23dhg0buHr1ao42nT592pjql5/Jkydz+PBhRo8ejV6v58knnyxwe4QQQoi8VKTvDgXRrVs3jh8/zn///Zfjfeh0OmP7s3JwcKB3797MmDGD5ORkjh07lmMbLy8vxowZw7Bhwzh16hTx8fEmb7sQ5iDV74Uwg3feeeee24waNYpPP/2U0aNHc/HiRZo2bcquXbt4++236dOnj3GMd48ePejcuTOvvPIKcXFxBAUFsXv3bmNQndWHH37IfffdR6dOnXjmmWfw8/Pjzp07nD17lvXr1xcocDWIioril19+oWfPnnmmmC9cuJCVK1cyb948hg0bxvLly5kwYQKnTp2ia9eupKen888//xAQEMDQoUPp1KkTI0eOZO7cuVy/fp1+/fphY2PDwYMHsbe3Z9KkSYBKt5s5cyavv/46Xbp04fjx43zyySe4uLgUuP39+vVjxYoVNGzYkGbNmhEcHMz777+fI9V+ypQprF27lgEDBjBt2jTatGlDQkICf/31F/369cv2xeLBBx+kUaNGbN++3TgNjxBCCGEKFeG7Q1ZHjhzhhx9+yLG+devWvPDCC6xcuZK+ffsyZ84cfH192bBhA4sXL+aZZ56hQYMGADz55JPY2dnRsWNHfHx8CA8PZ968ebi4uNC6dWsA2rZtS79+/WjWrBmurq6cOHGCVatW0b59e+zt7YvUdiHKHPPW6ROi4stawTY/d1ew1TRNi4qK0iZMmKD5+PholpaWmq+vrzZ9+nQtMTEx23a3b9/Wxo4dq1WpUkWzt7fXHnzwQe3kyZO5Vom/cOGCNnbsWK169eqalZWV5uHhoXXo0EGbO3dutm24RwXbRYsWaYD2888/57mNoQrvunXrNE3TtISEBO3111/X6tevr1lbW2tubm7aAw88oO3Zs8e4T1pamrZw4UKtSZMmmrW1tebi4qK1b99eW79+vXGbpKQk7ZVXXtFq1qyp2dnZaV26dNFCQkLyrH6f22d/69Ytbdy4cZqnp6dmb2+v3XfffdrOnTu1Ll265Ph3uHXrljZ58mStVq1ampWVlebp6an17dtXO3nyZI7jzpo1SwO0ffv25fm5CCGEEPmpqN8dsm6X18Ow/6VLl7THH39cc3Nz06ysrDR/f3/t/fff19LS0ozH+uqrr7SuXbtqXl5emrW1tVatWjVt8ODB2uHDh43bTJs2TQsKCtJcXV01GxsbrU6dOtoLL7ygRUZG5ttOIcoTnabdNehGCCFEkQUFBaHT6Thw4IC5myKEEEIIISoBSb8XQohiiomJ4ejRo/z2228EBwfz008/mbtJQgghhBCikpCgXgghium///6ja9euuLm58cYbbzBw4EBzN0kIIYQQQlQSkn4vhBBCCCGEEEKUUzKlnRBCCCGEEEIIUU5JUC+EEEIIIYQQQpRTEtQLIYQQosQtXryY2rVrY2trS2BgIDt37sx3+6SkJGbMmIGvry82NjbUrVuXZcuWZdtm3bp1NGrUCBsbGxo1aiRFKoUQQlRKUigvF+np6Vy7dg0nJyd0Op25myOEEEKgaRp37tyhWrVqWFiUr3vya9euZcqUKSxevJiOHTvyf//3f/Tu3Zvjx49Tq1atXPcZPHgw169fZ+nSpdSrV4+IiAhSU1ONr+/du5chQ4bw5ptv8vDDD/PTTz8xePBgdu3aRdu2bQvULrneCyGEKEuKeq2XQnm5uHLlCjVr1jR3M4QQQogcLl++TI0aNczdjEJp27YtrVq1YsmSJcZ1AQEBDBw4kHnz5uXY/o8//mDo0KGcP3+eqlWr5nrMIUOGEBMTw++//25c16tXL1xdXfn2228L1C653gshhCiLCnutl576XDg5OQHqw3R2djZza4QQQgiIiYmhZs2axmtUeZGcnExwcDDTpk3Ltr5Hjx7s2bMn131+/fVXgoKCeO+991i1ahUODg489NBDvPnmm9jZ2QGqp/6FF17Itl/Pnj1ZtGhRnm1JSkoiKSnJ+LOhX0Ou90IIIcqCol7rzR7UL168mPfff5+wsDAaN27MokWL6NSpU57bf/rpp3zyySdcvHiRWrVqMWPGDEaNGpXrtmvWrGHYsGEMGDCAn3/+ucBtMqTgOTs7y0VeCCFEmVLe0sQjIyNJS0vDy8sr23ovLy/Cw8Nz3ef8+fPs2rULW1tbfvrpJyIjI5k4cSI3b940jqsPDw8v1DEB5s2bx+zZs3Osl+u9EEKIsqSw13qzDsozjLGbMWMGBw8epFOnTvTu3ZvQ0NBct1+yZAnTp09n1qxZHDt2jNmzZ/Pss8+yfv36HNteunSJl156Kd8bBEIIIYQoHXd/QdE0Lc8vLenp6eh0Or7++mvatGlDnz59WLBgAStWrCAhIaFIxwSYPn060dHRxsfly5eL8Y6EEEKIssGsQf2CBQsYN24c48ePJyAggEWLFlGzZs1sY+6yWrVqFU8//TRDhgyhTp06DB06lHHjxvHuu+9m2y4tLY3hw4cze/Zs6tSpc892JCUlERMTk+0hhBBCiOJzd3dHr9fn6EGPiIjI0dNu4OPjQ/Xq1XFxcTGuCwgIQNM0rly5AoC3t3ehjglgY2Nj7JWX3nkhhBAVhdmCesMYux49emRbn98Yu6SkJGxtbbOts7OzY//+/aSkpBjXzZkzBw8PD8aNG1egtsybNw8XFxfjQ4rmCCGEEKZhbW1NYGAgW7ZsybZ+y5YtdOjQIdd9OnbsyLVr14iNjTWuO336NBYWFsbCQe3bt89xzM2bN+d5TCGEEKKiMtuY+qKMsevZsydffvklAwcOpFWrVgQHB7Ns2TJSUlKIjIzEx8eH3bt3s3TpUkJCQgrclunTpzN16lTjz4YCBfnRNI3U1FTS0tIKfB4hygu9Xo+lpWW5G7srhCibpk6dysiRIwkKCqJ9+/Z8/vnnhIaGMmHCBEBdh69evcrKlSsBePzxx3nzzTd54oknmD17NpGRkbz88suMHTvWWChv8uTJdO7cmXfffZcBAwbwyy+/sHXrVnbt2mWydsu1XpQUuc4KIUzJ7IXyCjMebubMmYSHh9OuXTs0TcPLy4sxY8bw3nvvodfruXPnDiNGjOCLL77A3d29wG2wsbHBxsamwNsnJycTFhZGfHx8gfcRoryxt7fHx8cHa2trczdFCFHODRkyhKioKObMmUNYWBhNmjRh48aN+Pr6AhAWFpatno6joyNbtmxh0qRJBAUF4ebmxuDBg5k7d65xmw4dOrBmzRpee+01Zs6cSd26dVm7dm2B56i/F7nWi5Im11khhKmYbZ765ORk7O3t+f7773n44YeN6ydPnkxISAh//fVXnvumpKRw/fp1fHx8+Pzzz3n11Ve5ffs2hw8fpmXLluj1euO26enpAFhYWHDq1Cnq1q17z7bFxMTg4uJCdHR0jvF26enpnDlzBr1ej4eHB9bW1nKXVVQomqaRnJzMjRs3SEtLo379+lhYmLX8hhCC/K9Nomjy+kzlWi9KklxnhRB5Keq13mw99VnH2GUN6rds2cKAAQPy3dfKyso4pm7NmjX069cPCwsLGjZsyJEjR7Jt+9prr3Hnzh0+/PBDk4yVT05OJj09nZo1a2Jvb1/s4wlRFtnZ2WFlZcWlS5dITk7OUctCCCEqMrnWi5Im11khhCmZNf2+sGPsTp8+zf79+2nbti23bt1iwYIFHD16lK+++goAW1tbmjRpku0cVapUAcixvrjkjqqo6OR3XAhR2cnfQVGS5PdLCGEqZg3qCzvGLi0tjfnz53Pq1CmsrKzo2rUre/bswc/Pz0zvQAghhBBCCCGEMB+zF8qbOHEiEydOzPW1FStWZPs5ICCAgwcPFur4dx9DCCGEEEIIIYSoKCTvRxTL/fffz5QpUwq8/cWLF9HpdIWaclAIIYQQ5iPXeiGEKNskqK8kdDpdvo8xY8YU6bg//vgjb775ZoG3r1mzpnGoRWnp0aMHer2effv2ldo5hRBCiNJW2a71cvNACCEUs6ffi9IRFhZmXF67di2vv/46p06dMq6zs7PLtn1KSgpWVlb3PG7VqlUL1Q69Xo+3t3eh9imO0NBQ9u7dy3PPPcfSpUtp165dqZ07NwX9XIUQQojCqqzXeiGEqOykp94ENE0jPjnVLA9N0wrURm9vb+PDxcUFnU5n/DkxMZEqVarw3Xffcf/992Nra8vq1auJiopi2LBh1KhRA3t7e5o2bcq3336b7bh3p+T5+fnx9ttvM3bsWJycnKhVqxaff/658fW776rv2LEDnU7Hn3/+SVBQEPb29nTo0CHblxCAuXPn4unpiZOTE+PHj2fatGm0aNHinu97+fLl9OvXj2eeeYa1a9cSFxeX7fXbt2/z1FNP4eXlZZw94bfffjO+vnv3brp06YK9vT2urq707NmTW7duGd/rokWLsh2vRYsWzJo1y/izTqfjs88+Y8CAATg4ODB37lzS0tIYN24ctWvXxs7ODn9/fz788MMcbV+2bBmNGzfGxsYGHx8fnnvuOQDGjh1Lv379sm2bmpqKt7c3y5Ytu+dnIoQQovDkWj/F+HNZu9bnJSkpieeffx5PT09sbW257777OHDggPH1W7duMXz4cDw8PLCzs6N+/fosX74cUNMaPvfcc/j4+GBra4ufnx/z5s0rcluEEKIkSU+9CSSkpNHo9U1mOffxOT2xtzbNP+Orr77K/PnzWb58OTY2NiQmJhIYGMirr76Ks7MzGzZsYOTIkdSpU4e2bdvmeZz58+fz5ptv8r///Y8ffviBZ555hs6dO9OwYcM895kxYwbz58/Hw8ODCRMmMHbsWHbv3g3A119/zVtvvcXixYvp2LEja9asYf78+dSuXTvf96NpGsuXL+fTTz+lYcOGNGjQgO+++44nnngCgPT0dHr37s2dO3dYvXo1devW5fjx4+j1egBCQkLo1q0bY8eO5aOPPsLS0pLt27eTlpZWqM/1jTfeYN68eSxcuBC9Xk96ejo1atTgu+++w93dnT179vDUU0/h4+PD4MGDAViyZAlTp07lnXfeoXfv3kRHRxs/j/Hjx9O5c2fCwsLw8fEBYOPGjcTGxhr3F0IIYVpyrc+urFzr8/PKK6+wbt06vvrqK3x9fXnvvffo2bMnZ8+epWrVqsycOZPjx4/z+++/4+7uztmzZ0lISADgo48+4tdff+W7776jVq1aXL58mcuXLxe5LUIIUZIkqBdGU6ZM4ZFHHsm27qWXXjIuT5o0iT/++IPvv/8+3wt9nz59jDMavPrqqyxcuJAdO3bke6F/66236NKlCwDTpk2jb9++JCYmYmtry8cff8y4ceOMwfjrr7/O5s2biY2Nzff9bN26lfj4eHr27AnAiBEjWLp0qfE4W7duZf/+/Zw4cYIGDRoAUKdOHeP+7733HkFBQSxevNi4rnHjxvmeMzePP/44Y8eOzbZu9uzZxuXatWuzZ88evvvuO2NQPnfuXF588UUmT55s3K5169YAdOjQAX9/f1atWsUrr7wCqIyExx57DEdHx0K3TwghROVR0a71eYmLi2PJkiWsWLGC3r17A/DFF1+wZcsWli5dyssvv0xoaCgtW7YkKCgIINsUyaGhodSvX5/77rsPnU5nnG5ZCCHKIgnqTcDOSs/xOT3Ndm5TMVzUDNLS0njnnXdYu3YtV69eJSkpiaSkJBwcHPI9TrNmzYzLhtS/iIiIAu9j6H2OiIigVq1anDp1Kse0h23atGHbtm35HnPp0qUMGTIES0v1az5s2DBefvllTp06hb+/PyEhIdSoUcMY0N8tJCSExx57LN9zFMTdnyvAZ599xpdffsmlS5dISEggOTnZmGIYERHBtWvX6NatW57HHD9+PJ9//jmvvPIKERERbNiwgT///LPYbRVCmE5KWjq7z0aSrmk80NDL3M0RxSTX+uzKyrU+L+fOnSMlJYWOHTsa11lZWdGmTRtOnDgBwDPPPMOjjz7Kf//9R48ePRg4cCAdOnQAYMyYMTz44IP4+/vTq1cv+vXrR48ePYrUFiFEORJxEhw8wMHN3C0pFAnqTUCn05ksLc6c7r6Az58/n4ULF7Jo0SKaNm2Kg4MDU6ZMITk5Od/j3F10R6fTkZ6eXuB9dDodQLZ9DOsM7jW+8ObNm/z888+kpKSwZMkS4/q0tDSWLVvGu+++m6Ng0N3u9bqFhUWOdqSkpOTY7u7P9bvvvuOFF15g/vz5tG/fHicnJ95//33++eefAp0XYNSoUUybNo29e/eyd+9e/Pz86NSp0z33E0KULEMgv+FwGJuPXyc6IYUAH2cJ6isAudZnVxau9fkx7JvbMQ3revfuzaVLl9iwYQNbt26lW7duPPvss3zwwQe0atWKCxcu8Pvvv7N161YGDx5M9+7d+eGHH4rcJiFEGXfjNCzpAN5N4akdcNffj7JMCuWJPO3cuZMBAwYwYsQImjdvTp06dThz5kypt8Pf35/9+/dnW/fvv//mu8/XX39NjRo1OHToECEhIcbHokWL+Oqrr0hNTaVZs2ZcuXKF06dP53qMZs2a5dv77eHhka3ScExMDBcuXLjn+9m5cycdOnRg4sSJtGzZknr16nHu3Dnj605OTvj5+eV7bjc3NwYOHMjy5ctZvny5MV1RCFH6klPT2X4qgpe/P0TQ3K2MWX6A74OvEJ2QgrujNYG+VUhOzT/YEcJcyvO1Pj/16tXD2tqaXbt2GdelpKTw77//EhAQYFzn4eHBmDFjWL16NYsWLcpW8M/Z2ZkhQ4bwxRdfsHbtWtatW8fNmzeL3CYhRBl3aRdoaRAWAtcOmrs1hVL+bzmLElOvXj3WrVvHnj17cHV1ZcGCBYSHh2e7GJaGSZMm8eSTTxIUFESHDh1Yu3Ythw8fzjb+/W5Lly5l0KBBOebI9fX15dVXX2XDhg0MGDCAzp078+ijj7JgwQLq1avHyZMn0el09OrVi+nTp9O0aVMmTpzIhAkTsLa2Zvv27Tz22GO4u7vzwAMPsGLFCvr374+rqyszZ840FtnLT7169Vi5ciWbNm2idu3arFq1igMHDmQrBjRr1iwmTJiAp6ensZjf7t27mTRpknGb8ePH069fP9LS0hg9enQRPlkhRFElp6az+1wkG7P0yBu4O9rQu4k3fZr60KZ2VfQW5edOv6h8yvO13uDuKvoAjRo14plnnuHll1+matWq1KpVi/fee4/4+HjGjRsHqHH7gYGBNG7cmKSkJH777Tfj+164cCE+Pj60aNECCwsLvv/+e7y9valSpYpJ37cQogwJO5S5fHgtVG9lvrYUkgT1Ik8zZ87kwoUL9OzZE3t7e5566ikGDhxIdHR0qbZj+PDhnD9/npdeeonExEQGDx7MmDFjctzRNwgODubQoUN88cUXOV5zcnKiR48eLF26lAEDBrBu3Tpeeuklhg0bRlxcHPXq1eOdd94BoEGDBmzevJn//e9/tGnTBjs7O9q2bcuwYcMAmD59OufPn6dfv364uLjw5ptvFqinfsKECYSEhDBkyBB0Oh3Dhg1j4sSJ/P7778ZtRo8eTWJiIgsXLuSll17C3d2dQYMGZTtO9+7d8fHxoXHjxlSrVq3An6cQomiyBvKbjoUTk5hqfM0QyPdt5kNrPwnkRflRXq/1WQ0dOjTHugsXLvDOO++Qnp7OyJEjuXPnDkFBQWzatAlXV1cArK2tmT59OhcvXsTOzo5OnTqxZs0aABwdHXn33Xc5c+YMer2e1q1bs3HjRiwsJMlViAora1B/5AfoMRf0VnlvX4botOIMWKqgYmJicHFxITo6Gmdn52yvJSYmcuHCBWrXro2tra2ZWigefPBBvL29WbVqlbmbYjbx8fFUq1aNZcuW5ahkbAryuy4qK03TuHEniTMRsZy5foczEbGcjYjleFgMd7IE8h5OmT3ypRHI53dtEkWT12cqf//Khop+rZffMyHKkLQUeLs6pCWBlT2kxMOwteDfq1SbUdRrvfTUizIvPj6ezz77jJ49e6LX6/n222/ZunUrW7ZsMXfTzCI9PZ3w8HDmz5+Pi4sLDz30kLmbJES5pGkaYdGJxuD9bESscTlrL3xWhkC+b1MfgqRHXgiTkWu9EMKsbpxSAb2NC7R4HP5ZAoe+LfWgvqgkqBdlnk6nY+PGjcydO5ekpCT8/f1Zt24d3bt3N3fTzCI0NJTatWtTo0YNVqxYYZyyTwiRXXq6RmRcEmG3EwmLTuDa7UTCYxK5djuByzfjORsRS1xyWq77WujAz82Bep6O1PdypL6nE/U8HQnwcZZAXogSINd6IYRZGVLvvZtC86EqqD/1OyTcBrsq5mxZgUg0IMo8Ozs7tm7dau5mlBl+fn7FmuZHiIrkyq14ToTdyQzaoxO4Fq2C+OvRSSSn5V913tJCR213B+p7OVLP04n6GUG8n5sDtiacG1wIkT+51gshzCr8sHr2aa4eHgFw4wQc/wUCy35BagnqhRBClCuXb8az8UgYG4+EcehK/sW8dDrwdLLBx8WOalVs8XGxw8fFlupV7Kjv5YivmwNWeil8JYQQQlRqhp56n+bqy0PzIbB1FhxaI0G9EEIIYQp5BfIWOmhUzZnqVeyMAbtPFTuqZTx7OtlI0C6EEEKIvKWnQ/gRtezTXD03HQxbZ0PoHrh1EVz9zNW6ApGgXgghRJlkCOQ3HAnj8F2BfLs6bvRp6kOvJt64O9qYsZVCCCGEKNdunofkWLC0A/f6ap1LdajdGS78BYe/gy6vmLeN9yBBvRBCiDLj8s14NmT0yEsgL4QQQogSFxainr2bgEWWejrNh6qg/tAa6PyySssvoySoF0IIYVbnb8Tyx7Fw/jganmsg37eZDz0bSyAvhBBCiBKQdTx9VgH9YcOLcPMcXA2GGkGl37YCkqBeCCFEqdI0jZPhd/j9aDibjoZz6vod42sWOmhfV/XISyAvhBBCiBJnqHzv3Sz7ehsnaNgPjnyn5qwvw0G9VA8ShXL//fczZcoU489+fn4sWrQo3310Oh0///xzsc9tquMIIUqfpmmEXL7NvN9P0PWDHfT+cCcf/XmGU9fvYGmho3MDD+Y90pT9M7rz9fh2DG/rKwG9EGYi13ohRKWhaXn31INKwQc4ug5Sk0uvXYUkPfWVRP/+/UlISMh1Dti9e/fSoUMHgoODadWqVaGOe+DAARwcHEzVTABmzZrFzz//TEhISLb1YWFhuLq6mvRceUlISKBatWrodDquXr2KnZ1dqZxXiIokLV3jwMWb/HE0nE3HwgmLTjS+ZmNpQZcGHvRq4k23AC9c7KzM2FIhKga51hfMihUrmDJlCrdv3y7R8wghyoHoy5BwCyyswDMg5+t17gdHb4gNhzObIaBfqTexICSoryTGjRvHI488wqVLl/D19c322rJly2jRokWhL/IAHh4epmriPXl7e5faudatW0eTJk3QNI0ff/yR4cOHl9q576ZpGmlpaVhayn9XUXYkpaYRnZBCTEIK0Vkf8SlEJ6Ry9XY8205GEBmbeVfbwVrPAwFe9Grszf3+HjjYyO+0EKYk13ohhCiksIzUe8+GYJlLhqCFHpoOgr2fwOE1ZTaol/R7U9A0SI4zz0PTCtTEfv364enpyYoVK7Ktj4+PZ+3atYwbN46oqCiGDRtGjRo1sLe3p2nTpnz77bf5HvfulLwzZ87QuXNnbG1tadSoEVu2bMmxz6uvvkqDBg2wt7enTp06zJw5k5SUFEDdPZ89ezaHDh1Cp9Oh0+mMbb47Je/IkSM88MAD2NnZ4ebmxlNPPUVsbKzx9TFjxjBw4EA++OADfHx8cHNz49lnnzWeKz9Lly5lxIgRjBgxgqVLl+Z4/dixY/Tt2xdnZ2ecnJzo1KkT586dM76+bNkyGjdujI2NDT4+Pjz33HMAXLx4EZ1Ol61n4vbt2+h0Onbs2AHAjh070Ol0bNq0iaCgIGxsbNi5cyfnzp1jwIABeHl54ejoSOvWrXP0xiQlJfHKK69Qs2ZNbGxsqF+/PkuXLkXTNOrVq8cHH3yQbfujR49iYWGRre1CGFy9ncBnf51j/Ff/8thne+ix8C/avr2VhjN/x/+1P2jz1p90X/A3jy7Zy9gV//LC2kPMWn+chVtP892/V4iMTcbFzopBgTVYOjqI4JkP8vGwlvRt5iMBvSh/5Fpv/LmiXOvzEhoayoABA3B0dMTZ2ZnBgwdz/fp14+uHDh2ia9euODk54ezsTGBgIP/++y8Aly5don///ri6uuLg4EDjxo3ZuHFjkdsihChh+aXeGzQfpp5Pb4L4myXfpiKQb1WmkBIPb1czz7n/dw2s750SZ2lpyahRo1ixYgWvv/46uowpGb7//nuSk5MZPnw48fHxBAYG8uqrr+Ls7MyGDRsYOXIkderUoW3btvc8R3p6Oo888gju7u7s27ePmJiYbGPyDJycnFixYgXVqlXjyJEjPPnkkzg5OfHKK68wZMgQjh49yh9//GEMWF1cXHIcIz4+nl69etGuXTsOHDhAREQE48eP57nnnsv2ZWb79u34+Piwfft2zp49y5AhQ2jRogVPPvlknu/j3Llz7N27lx9//BFN05gyZQrnz5+nTp06AFy9epXOnTtz//33s23bNpydndm9ezepqakALFmyhKlTp/LOO+/Qu3dvoqOj2b179z0/v7u98sorfPDBB9SpU4cqVapw5coV+vTpw9y5c7G1teWrr76if//+nDp1ilq1agEwatQo9u7dy0cffUTz5s25cOECkZGR6HQ6xo4dy/Lly3nppZeM51i2bBmdOnWibt26hW6fqJhuxSWz8WgYvxy8xv6L+V+4dDpwsrHExd4KF7vsD1d7azrUdadtnapY6eX+sagA5FoPVJxrfV40TWPgwIE4ODjw119/kZqaysSJExkyZIjx5vvw4cNp2bIlS5YsQa/XExISgpWVGkL07LPPkpyczN9//42DgwPHjx/H0dGx0O0QQpQSY1DfIu9tvJuAVxO4fhSO/QStx5VK0wpDgvpKZOzYsbz//vvs2LGDrl27Aiqoe+SRR3B1dcXV1TVbwDdp0iT++OMPvv/++wJd6Ldu3cqJEye4ePEiNWrUAODtt9+md+/e2bZ77bXXjMt+fn68+OKLrF27lldeeQU7OzscHR2xtLTMNwXv66+/JiEhgZUrVxrH+X3yySf079+fd999Fy8vLwBcXV355JNP0Ov1NGzYkL59+/Lnn3/me6FftmwZvXv3No7p69WrF8uWLWPu3LkAfPrpp7i4uLBmzRrjRbxBgwbG/efOncuLL77I5MmTjetat259z8/vbnPmzOHBBx80/uzm5kbz5pl3EefOnctPP/3Er7/+ynPPPcfp06f57rvv2LJlC927dwcw3ogAeOKJJ3j99dfZv38/bdq0ISUlhdWrV/P+++8Xum2iYklITmPLiev8GnKVv07fICVN9QrqdNC2dlV6NPLGy9k2R+DuZGuJhUXZnbNViMpIrvUFu9bn9/4OHz7MhQsXqFmzJgCrVq2icePGHDhwgNatWxMaGsrLL79Mw4YNAahfv75x/9DQUB599FGaNm0KZL8OCyHKIENQf3fl+7s1HwqbX4PDayWor7Cs7NVddHOdu4AaNmxIhw4dWLZsGV27duXcuXPs3LmTzZs3A5CWlsY777zD2rVruXr1KklJSSQlJRW4OM6JEyeoVauW8SIP0L59+xzb/fDDDyxatIizZ88SGxtLamoqzs7OBX4fhnM1b948W9s6duxIeno6p06dMl7oGzdujF6vN27j4+PDkSNH8jxuWloaX331FR9++KFx3YgRI3jhhReYPXu28Y58p06djAF9VhEREVy7do1u3boV6v3kJigo+7QZcXFxzJ49m99++41r166RmppKQkICoaGhAISEhKDX6+nSpUuux/Px8aFv374sW7aMNm3a8Ntvv5GYmMhjjz1W7LaK8ic1LZ1dZyP5JeQam46FE5+cZnytkY8zA1tWo1+zalSrIkUihQDkWp+hIlzr73XOmjVrGgN6gEaNGlGlShVOnDhB69atmTp1KuPHj2fVqlV0796dxx57zJjx9vzzz/PMM8+wefNmunfvzqOPPkqzZvcIFoQQ5nHnuiqAh071xuen6WOw5XW4/A9EnQO3spXlKjmRpqDTqbQ4czx0heslGzduHOvWrSMmJobly5fj6+trDEDnz5/PwoULeeWVV9i2bRshISH07NmT5OSCTd+g5TLmT3dX+/bt28fQoUPp3bs3v/32GwcPHmTGjBkFPkfWc9197NzOeXfgrdPpSE9Pz/O4mzZt4urVqwwZMgRLS0ssLS0ZOnQoV65cMX4hyq8S/r2q5FtYWBjbb5DXuL+7v2C9/PLLrFu3jrfeeoudO3cSEhJC06ZNjZ9dQSr0jx8/njVr1pCQkMDy5csZMmQI9vYF/7IoyjdN0wi+dIs3fjlK27f/ZMzyA/x08CrxyWnUrGrHc13rseWFzmyc3ImnOteVgF6IrORaD1SMa31Rzpl1/axZs4y1dbZt20ajRo346aefAHWdPX/+PCNHjuTIkSMEBQXx8ccfF6ktQogSZpif3r3BvYc4OXmrSvgAh78r0WYVhQT1lczgwYPR6/V88803fPXVVzzxxBPGi9TOnTsZMGAAI0aMoHnz5tSpU4czZ84U+NiNGjUiNDSUa9cyezL27t2bbZvdu3fj6+vLjBkzCAoKon79+ly6dCnbNtbW1qSlpZGfRo0aERISQlxcXLZjW1hYZEuFL6ylS5cydOhQQkJCsj2GDx9uLJjXrFkzdu7cmWsw7uTkhJ+fH3/++WeuxzdUEA4LCzOuu3s6n7zs3LmTMWPG8PDDD9O0aVO8vb25ePGi8fWmTZuSnp7OX3/9lecx+vTpg4ODA0uWLOH3339n7NixBTq3KJ+SUtMIvnSLL/4+zzOrg2n79p88umQPX+29RFRcMm4O1oxu78u6Zzrw98tdeamnP/W9nMzdbCFEMcm1vugM7+/y5cvGdcePHyc6OpqAgMzprho0aMALL7zA5s2beeSRR1i+fLnxtZo1azJhwgR+/PFHXnzxRb744osSaasQopjCQtSzTwGzaQwF8w6vKXAB09Ii6feVjKOjI0OGDOF///sf0dHRjBkzxvhavXr1WLduHXv27MHV1ZUFCxYQHh6e7SKWn+7du+Pv78+oUaOYP38+MTExzJgxI9s29erVIzQ0lDVr1tC6dWs2bNhgvLtt4Ofnx4ULFwgJCaFGjRo4OTlhY5N9ionhw4fzxhtvMHr0aGbNmsWNGzeYNGkSI0eONKbjFdaNGzdYv349v/76K02aZE/BGT16NH379uXGjRs899xzfPzxxwwdOpTp06fj4uLCvn37aNOmDf7+/syaNYsJEybg6elJ7969uXPnDrt372bSpEnY2dnRrl073nnnHfz8/IiMjMw27jA/9erV48cff6R///7odDpmzpyZrSfCz8+P0aNHM3bsWGOhvEuXLhEREcHgwYMB0Ov1jBkzhunTp1OvXr1cUyZF+RURk8h/obcIvqQeR6/GkJyWvbfK3lpPz8beDGhRjY713KWInRAVkFzr7y0tLS3HTXVra2u6d+9Os2bNGD58OIsWLTIWyuvSpQtBQUEkJCTw8ssvM2jQIGrXrs2VK1c4cOAAjz76KABTpkyhd+/eNGjQgFu3brFt27YCf7ZCiFJmmM4uv8r3WTXsC1YOcOuiSsOv1a7EmlZY8m2uEho3bhy3bt2ie/fuxqrpADNnzqRVq1b07NmT+++/H29vbwYOHFjg41pYWPDTTz+RlJREmzZtGD9+PG+99Va2bQYMGMALL7zAc889R4sWLdizZw8zZ87Mts2jjz5Kr1696Nq1Kx4eHrlOtWNvb8+mTZu4efMmrVu3ZtCgQXTr1o1PPvmkcB9GFoZCPLmNhzdMXbNq1Src3NzYtm0bsbGxdOnShcDAQL744gtj+t/o0aNZtGgRixcvpnHjxvTr1y9bL8iyZctISUkhKCiIyZMnGwvw3cvChQtxdXWlQ4cO9O/fn549e+aYb3jJkiUMGjSIiRMn0rBhQ5588slsPRyg/v2Tk5Oll76cS01L5+jVaFbuvcjkNQe5791ttHn7Tyas/o8vdl7gv9DbJKel4+ZgTfcAL17t1ZDvnm7PfzMfZOGQFtzv7ykBvRAVmFzr8xcbG0vLli2zPfr06WOcUs/V1ZXOnTvTvXt36tSpw9q1awF1czwqKopRo0bRoEEDBg8eTO/evZk9ezagbhY8++yzBAQE0KtXL/z9/Vm8eHGx2yuEKAEFmc4uK2sHaDRALR9aUzJtKiKdltvgqEouJiYGFxcXoqOjcxR1SUxM5MKFC9SuXRtbW1sztVCIotu9ezf3338/V65cybenQ37Xy6YLkXGs2nuJH4IvE5OYmu01nQ78vZwI9HWlVS1XAn1d8XWzz3NMqihf8rs2iaLJ6zOVv3+iNMjvmRBmlHAL3vVTy69eArsqBdvv/A5YOQBsXeDF02Bl2v+7Rb3WS/q9EJVEUlISly9fZubMmQwePLjYqYui9KSla2w/GcHKfZf4+/QN43onW0ta1nIlMCOAb17TBSfbnLMyCCGEEEKILMIzZsio4lvwgB7ArxM4V4eYq3BmU2bPvZlJUC9EJfHtt98ybtw4WrRowapVq8zdHFEAt+KSWfvvZVbvu8SVWwmA6o3v6u/JyPa+dK7vgV7miRdCCCGEKJzCpt4bWOjV9Ha7F8GhtRLUCyFK15gxY7IVSxJl15Er0Xy19yLrD10jKVUVunOxs2JI65qMaOtLLTeZhlAIIYQQosiKGtQDNB+qgvozmyAuChzcTNq0opCgXgghyoCk1DQ2Hgnjqz2XCLl827i+kY8zYzr40b95Neys9eZroBBCCCFERVHYyvdZeQao/cIOwbEfoc2Tpm1bEUhQX0RSX1BUdPI7XrI0TeNGbBInw+6w93wU3x24TFRcMgBWeh19mvowqr0vrWq5SqE7IcxE/g6KkiS/X0KYSXIcRJ5Wy0UJ6gGaDVVB/aFvJagvjwzTlsXHx2NnZ2fm1ghRcuLj44HM33lRdIkpaZyNiOVEWAwnw+9wMjyGk2F3jEG8gbezLcPb1mJom1p4ONnkcTQhyqfFixfz/vvvExYWRuPGjVm0aBGdOnXKddsdO3bQtWvXHOtPnDhBw4YNAVixYgVPPPFEjm0SEhKKXUlcrvWiNMh1VggzCT8KaODkA46eRTtG00Gw+TW4GgyRZ8C9vkmbWFgS1BeSXq+nSpUqREREAGoOVelFExWJpmnEx8cTERFBlSpV0Osl5bugUtLSuR6TyMkwFbifCL/DybAYLkTGkZ5Lh4yFDvzcHQjwdqZfMx+6N/KSueNFhbR27VqmTJnC4sWL6dixI//3f/9H7969OX78eLY51O926tSpbFP6eHh4ZHvd2dmZU6dOZVtniqnB5FovSpJcZ4UwM8N4eu9mRT+GoyfU6wZnNsPhtfDAa6ZpWxFJUF8E3t7eAMaLvRAVUZUqVYy/65VRREwix8NiiElMJSYhhTuJqcQkpuSznEpCSlqex3O1tyLAxxl/bycCvJ1p6ONEfU8nGScvKoUFCxYwbtw4xo8fD8CiRYvYtGkTS5YsYd68eXnu5+npSZUqVfJ8XafTldjfKbnWi5JW2a+zQphNeDGK5GXVbIgK6g+thfv/Bxbm65iRoL4IdDodPj4+eHp6kpKSYu7mCGFyVlZWlbbnID1d46u9F3n3j5MkpqQXen8rvY66Ho4E+DjT0NuJhj7OBHg74eFkIz19olJKTk4mODiYadOmZVvfo0cP9uzZk+++LVu2JDExkUaNGvHaa6/lSMmPjY3F19eXtLQ0WrRowZtvvknLli3zPF5SUhJJSUnGn2NiYvLcVq71oiRV5uusEGZXnMr3WTXsCzbOEB0KoXvBr2Px21ZEEtQXg16vlz/IQlQgl2/G8/IPh9h3/iYAddwd8HS2wdnWCmc7K5xsLY3LzraWONla4WyXsS5j2cnWSuaOFyKLyMhI0tLS8PLyyrbey8uL8PDwXPfx8fHh888/JzAwkKSkJFatWkW3bt3YsWMHnTt3BqBhw4asWLGCpk2bEhMTw4cffkjHjh05dOgQ9evnPrZx3rx5zJ49u1Dtl2u9EELk4c51sHEEawdzt6TgUpMg4oRa9ilG+j2AlR00eggOrlYF8ySoF0II89E0je/+vcybv50gNikVOys9/+sbwIi2taR3XQgTufv/kqZpef7/8vf3x9/f3/hz+/btuXz5Mh988IExqG/Xrh3t2rUzbtOxY0datWrFxx9/zEcffZTrcadPn87UqVONP8fExFCzZs0ivychhKi0bl2ET9pAzTYwej2Ul+9LEScgPRXsXMHFBH//mw9TQf3xX6DP+yrQNwMJ6oUQldr1mESmrTvM9lM3AGjt58oHjzXH160c3XUWogxzd3dHr9fn6JWPiIjI0Xufn3bt2rF69eo8X7ewsKB169acOXMmz21sbGywsZGZJYQQotgu74e0JLi4E679B9UDzd2igsmaem+KGxG1OqibA/E34foxqBFU/GMWgZRZFkJUSpqm8euha/RY+DfbT93A2tKCGX0CWPNUewnohTAha2trAgMD2bJlS7b1W7ZsoUOHDgU+zsGDB/Hx8cnzdU3TCAkJyXcbIYQQJhKZ5Qbqv8vM147CMkXl+6wsLGDYt/DyGbMF9CA99UKISuhmXDIzfz7KhiNhADSt7sL8wc1p4OVk5pYJUTFNnTqVkSNHEhQURPv27fn8888JDQ1lwoQJgEqLv3r1KitXrgRUdXw/Pz8aN25McnIyq1evZt26daxbt854zNmzZ9OuXTvq169PTEwMH330ESEhIXz66admeY9CCFGpRGUJ6o+sgx5zVUp7WRd+WD0Xt0heVt5NTXesIpKgXghRqWw9fp1pPx4hMjYJSwsdzz1Qj2e71pP54YUoQUOGDCEqKoo5c+YQFhZGkyZN2LhxI76+vgCEhYURGhpq3D45OZmXXnqJq1evYmdnR+PGjdmwYQN9+vQxbnP79m2eeuopwsPDcXFxoWXLlvz999+0adOm1N+fEEJUOlFn1bOFJaQmqGnd2k0wb5vuJS0Vwo+qZZ8WZm2Kqek0TdPM3YiyJiYmBhcXF6Kjo3F2djZ3c4QQJhCTmMKc9cf5IfgKAPU9HVkwuAVNa7iYuWVCFIxcm0xPPlMhhCiC9HSYVx1S4qHtM/DPEnD3h2f/KdsF8yJOwOJ2YO0I0y6bdV75vBT1ulT23okQQpjY7rOR9Fr4Nz8EX0Gng6c712H9pPskoBdCCCGEKKw7YSqgt7CELq+AlQNEnoJLe8zdsvyFZaTeezctkwF9cUj6vRCiwrp8M553/jjJhsNq7Lyvmz3zH2tOkF9VM7dMCCGEEKKcMoynd/UD+6rQdBD895UqmGfGudrvKWvl+wpGgnohRIUTm5TKkh1n+WLnBZJT09HpYGQ7X17t1RAHG/mzJ4QQQghRZIbK92711HPrcSqoP/4LxL4Djh7ma1t+JKgXQoiyLy1dY13wFd7ffIobd5IAaF/HjZn9GtGomoyXFUIIIYQotqhz6tkQ1Ps0V/PUXw2GkNVw3wvma1te0tMzK9+bajq7MkSCeiFEhbD3XBRv/nac42ExAPi52fO/PgE82MgLXVku2iKEEEIIUZ4Y0u/d62euCxqrgvp/l0OHyWVvzPrti5AUA3ob8PA3d2tMzuyf9uLFi6lduza2trYEBgayc+fOfLf/9NNPCQgIwM7ODn9/f+OctgZffPEFnTp1wtXVFVdXV7p3787+/ftL8i0IIczoUlQcT6/6l2Ff7ON4WAxOtpa81jeAzS90oUdjbwnohRAlLj45ldPX73AyPMbcTRFCiJJnmM7O0FMP0PgRsHGB25fg/DbztCs/htR7r8agtzJvW0qAWYP6tWvXMmXKFGbMmMHBgwfp1KkTvXv3zjZXbVZLlixh+vTpzJo1i2PHjjF79myeffZZ1q9fb9xmx44dDBs2jO3bt7N3715q1apFjx49uHr1amm9LSFEKYhJTOHtjSd4cMHfbDp2HYuMcfM7Xrqf8Z3qYG1p9nuWQohK4u/TkfRY+DfT1h0xd1OEEKJkpSbB7YxYzS1LT721PbQYppb/XV767boX43j6ipd6D2ZOv1+wYAHjxo1j/PjxACxatIhNmzaxZMkS5s2bl2P7VatW8fTTTzNkyBAA6tSpw759+3j33Xfp378/AF9//XW2fb744gt++OEH/vzzT0aNGlXC70gIUdJS09JZc+AyC7ecJiouGYBO9d15rW8j/L2dzNw6IURl5OZoDcDNjL9JQghRYd08D1o6WDuBo2f21wKfgH8+g1O/Q/RVcKlunjbmxjCdXQUskgdmDOqTk5MJDg5m2rRp2db36NGDPXtyn+MwKSkJW1vbbOvs7OzYv38/KSkpWFnlTKWIj48nJSWFqlXznsIqKSmJpKQk488xMZI+J0RZE3EnkU3HrrN67yVOXb8DQB0PB2b2bcT9/h6SZi+EMJuqDhLUCyEqCUPqvXs9uPu7l2dD8O0Il3bDwVVw/7Sc+5uDplXoyvdgxqA+MjKStLQ0vLy8sq338vIiPDw813169uzJl19+ycCBA2nVqhXBwcEsW7aMlJQUIiMj8fHxybHPtGnTqF69Ot27d8+zLfPmzWP27NnFe0NCCJMLj07kj6NhbDwazoGLN9E0td7FzooXutdneDtfrPSSZi+EMC+3jKA+NimVpNQ0bCz1Zm6REEKUEON0dvVzfz1orArqg7+CTi+BvgzUZY+5BvGRoNODZ2Nzt6ZEmP1Tvrt3TdO0PHvcZs6cSXh4OO3atUPTNLy8vBgzZgzvvfceen3OC+h7773Ht99+y44dO3L08Gc1ffp0pk6davw5JiaGmjVrFvEdCSGK4+rtBH4/EsbvR8MJvnQr22stalahdxNvhrSuSRV7azO1UAghsnO2tUJvoSMtXeNmXDI+LnbmbpIQQpSMu6ezu1tAf7B3hzvX4PQfENCv9NqWF8NUdh4NwSrvmLA8M1tQ7+7ujl6vz9ErHxERkaP33sDOzo5ly5bxf//3f1y/fh0fHx8+//xznJyccHd3z7btBx98wNtvv83WrVtp1iz/ggg2NjbY2NgU7w0JIYosNCqejUdVIH/o8u1srwX5utK7qQ+9mnhTvYp8URZClD0WFjpc7a2JjE0iKlaCeiFEBWaczi6PoN7SBlqOgN2L4N9lZSOor+Cp92DGoN7a2prAwEC2bNnCww8/bFy/ZcsWBgwYkO++VlZW1KhRA4A1a9bQr18/LLLMhfj+++8zd+5cNm3aRFBQUMm8ASFEkaWkpXMy7A5/n7nBxiNhHLuWWcdCp4M2flXp09SHno298XapmHdUhRAVi5uDCuplXL0QokK7V/o9QOAYFdSf+xNuXoCqtUujZXmr4JXvwczp91OnTmXkyJEEBQXRvn17Pv/8c0JDQ5kwYQKg0uKvXr1qnIv+9OnT7N+/n7Zt23Lr1i0WLFjA0aNH+eqrr4zHfO+995g5cybffPMNfn5+xkwAR0dHHB0dS/9NCiG4GZfMwdBbBF+6xX+htzh0OZqElDTj6xY6aF/Xjd5NfOjR2AtPJwnkhRDlixTLE0JUePE3IeGmWnarm/d2VWtD3W4qqA9eAQ+auXZZBa98D2YO6ocMGUJUVBRz5swhLCyMJk2asHHjRnx9fQEICwvLNmd9Wloa8+fP59SpU1hZWdG1a1f27NmDn5+fcZvFixeTnJzMoEGDsp3rjTfeYNasWaXxtoSo1NLTNc5ExBoD+P8u3eJ8ZFyO7ZxtLQn0daVnY28ebOSFm6MMgRFClF9VM6a1i5KgXghRURkq3ztXB2uH/LcNGquC+oOroev/VFq+OcRFQswVtezd1DxtKAVmL5Q3ceJEJk6cmOtrK1asyPZzQEAABw8ezPd4Fy9eNFHLhBAFFXL5NjtORRB86RYhl29zJzE1xzZ1PRwI9HUl0NeVVrVcqevhiIWFTEMnhKgY3Iw99Un32FIIIcopY+p9Pr30Bg16gZMP3AmDE+uh6aB771MSDKn3VeuCjZN52lAKzB7UCyHKJ03T2Hs+ik+2nWXPuahsr9lZ6WlRs4oxiG9Zq4pUqxdCVGiSfi+EqPAMPfX5jac30FtCq9Hw1zvw73LzBfXhFT/1HiSoF0IUkqZp/H0mko//PMO/GVPOWVro6NnYm7Z1qtKqlisNvZ2wlPnjhRCViKGnPipWgnohRAVlrHxfgKAeoNUo+Ps9uLQLIk6CZ8OSa1teKkHle5CgXghRQJqmsfVEBJ9sO8OhK9EAWFtaMCSoJhPuryvTzQkhKrWqDmq8qPTUCyEqrHvNUX83l+rQoDec2gDBy6H3uyXXtrxIUC+EEKrw3e9Hw/l42xlOht8BwNbKguFtfXmqcx28nKVSvRBCSPq9EKJCS08rfFAP0HqsCupDvoVub4C1fcm0LzeJMXDzvFqWoF4IURmlpqWz/vA1Pt1+jrMRsQA4WOsZ1cGPcffVxl2q1QshhJGbVL8XQlRk0ZchLQn01lClVsH3q/MAVPGF25fg2I/QckTJtfFu4UfUs0tNsK9aeuc1AwnqhRDZJKem89PBKyzecY5LUfGAmn7uiY61eaKjnxS8E0KIXBh66qMTUkhJS8dK6ooIISoSQ5G8qnXAQl/w/SwsIOgJ2DoL/l1WukF9JUm9BwnqhRBZbD1+nVnrj3HlVgKgvqSOu682I9v74mxrZebWCSFE2eVqb41OB5oGt+KT8XSSoUlCiAok0lD5vhCp9wYtRsC2t+BqMFwLgWotTNmyvBmCeu9mpXM+M5KgXghBREwis9cfZ8ORMADcHW14unMdhrerhb21/JkQQoh70VvoqGJnxa34FG7FpUhQL4SoWKKKEdQ7ekCjh+DoOtVb/9BHpm1bXirJdHYAkhsmRCWWnq7x7f5Qui34iw1HwtBb6Hi6Sx12vtKVJzvXkYBeCCEKwZCCHxWXZOaWCCGEiRV2Oru7BY1Vz0d+gMRo07QpP8nxcOOkWq4EQb18YxeikjobEcv/fjrC/gs3AWha3YV5jzSlSXUXM7dMCCHKJzcHG87diJMK+EKIiqc46fcAvh3BvQFEnobD30GbJ03XttxEHActHRw8wMm7ZM9VBkhPvRCVTHJqOh/9eYY+H+5k/4Wb2Fnpea1vAD9N7CABvRBCFINMayeEqJCS4yHmilp2K2JPvU6X2Vv/7zI1RV5JOrtVPfs0V+eu4CSoF6ISCb50k74f7WTBltMkp6XTpYEHm1/ozPhOdbCUSs1CCFEsVQ3T2sVKUC+EqEBuZsxPb+cKDm5FP07zoWBlr3rRN7yoKouWhGM/w4531HLDviVzjjJG0u+FqARiElN474+TrN4XCoC7ozWv929M/2Y+6CrB3UshhCgNbtJTL4SoiIpTJC8rO1cY8Cn8MBaCl4OtM3Sfbdqe9PM74McnAU1lBgQ+Ybpjl2ES1AtRwf1xNJw3fj3K9RhVuGlwUA3+1ydA5psXQggTk/R7IUSFZBxPX8TU+6yaPAJJd2D987D7Q7B1gU4vFv+4ANcOwprhkJYMjQZAnw8qReo9SFAvRIUSm5RKeHQC124nEhadwJ8nIth8/DoAfm72vP1IUzrUdTdzK4UQomKS6vdCiArJWPm+mD31BoGjISkGNr8Gf84BG+fiF86LPAurB0FyLNTuDI98ARZ607S3HJCgXohyIiE5jbDoBMKiE7l2Wz2rRwJhtxO5Fp3AncTUHPtZZkxTN+mB+thaVZ4/bkIIUdrcHGwA6akXQlQwpkq/z6rDJEiMgb/fg40vqcC++ZCiHSsmDFY9DPGR4NMChn4Dljama2s5IEG9EGWcpmnMXn+cFXsuFmh7J1tLqrnY4VPFlhqudgxv60uAj3PJNlIIIYSk3wshKh5NM236fVZd/6fmrN//f/DzM2DjWPjCdgm3YPUjEB0KVevC8B/Axsm07SwHJKgXooz7Yud5Y0Bvb63Hx8WWalXs8HGxxccl47mKHdUynh1t5L+1EEKYg1tG9ftb8Smkp2tYWFSOsZxCiAosLhKSogEdVK1t2mPrdNDrHTXG/tA38P0YGP491Lm/YPsnx8M3Q1U1fUdvGPkTOHqYto3lhHz7F6IM++v0Dd75/SQAs/o3YnQHP6lWL4QQZZRrRgHStHSN6IQUXB2kIKkQopwzjKevUhOs7Ex/fAsLeOhjSL4DJ9bDt4/DqF+gZuv890tLUTcBLu9TxfZG/giuvqZvXzkhE1MLUUZdjIxj0jf/ka7BkKCaEtALIUQZZ21pgZOt6i+JkhR8IURFEJkR1Js69T4rvSU8uhTqdIWUOPj6UQg/mvf26enw6yQ4swksbeHx78Crccm1rxyQoF6IMig2KZUnV/5LTGIqrWpVYc7AxhLQCyFEOSBz1QshKpSSKJKXG0sbGPo11GyrxtmvehiizuW+7dbX4dC3oNPDY19BrXYl27ZyQIJ6IcqY9HSNF9aGcCYiFi9nGz4bEYiNpVStF0KI8iCzWJ5MayeEqAAMQb17CfbUG1g7qF5376YQFwErB0D0lezb7P4Q9nyslgd8Cv69Sr5d5YAE9UKUMYv+PMOW49extrTg/0YG4elsa+4mCSGEKKCqGdPaSfq9EKJCMPbU1y2d89lVgRE/qcyA6MuwciDE3lCvHVwNW15Xyz3mQothpdOmckCCeiHKkD+OhvHRn2rs0tsPN6VFzSrmbZAQQohCqepgBcDNWAnqhRDlXFoq3LyglktyTP3dHD1UsTyXmqpQ3+qH4dAa+PV59XrHyWqee2EkQb0QZcTJ8BimfncIgCc6+jEosIaZWySEEKKwpKdeCFFh3L4E6SlgaQfO1Uv33C41VGDv4AnhR+Cnp0FLgxYjoPvs0m1LOSBBvRBlwO34ZJ5aGUx8chod6roxo0+AuZskhBAmtXjxYmrXro2trS2BgYHs3Lkzz2137NiBTqfL8Th58mS27datW0ejRo2wsbGhUaNG/PTTTyX9Nu5JCuUJISqMrKn3FmYIG93qqrnnbV3Uz/59oP+Han57kY0E9UKYWWpaOs99c5DQm/HUrGrHp4+3wlIv/zWFEBXH2rVrmTJlCjNmzODgwYN06tSJ3r17Exoamu9+p06dIiwszPioXz8z/XPv3r0MGTKEkSNHcujQIUaOHMngwYP5559/Svrt5KuqBPVCiIrCOJ1dCVe+z493Exi3FfougEHL1PR3IgeJHIQws3m/n2TX2UjsrPR8PjII14wvhEIIUVEsWLCAcePGMX78eAICAli0aBE1a9ZkyZIl+e7n6emJt7e38aHXZ84EsmjRIh588EGmT59Ow4YNmT59Ot26dWPRokUl/G7yV9VR/Q2X9HshRLkXlRHUl0bl+/x4NIDW48DKzrztKMMkqBfCjNYFX2HpLlWAZMHg5gT4OJu5RUIIYVrJyckEBwfTo0ePbOt79OjBnj178t23ZcuW+Pj40K1bN7Zv357ttb179+Y4Zs+ePfM9ZlJSEjExMdkepuYmU9oJISoKwzzx5uypFwUiQb0QZnLo8m2m/3QEgEkP1KN3Ux8zt0gIIUwvMjKStLQ0vLy8sq338vIiPDw81318fHz4/PPPWbduHT/++CP+/v5069aNv//+27hNeHh4oY4JMG/ePFxcXIyPmjVrFuOd5S5r+r2maSY/vhBClBpj+r2Ze+rFPcmgBCHMIOJOIk+vCiY5NZ3uAZ680L2BuZskhBAlSndXYSNN03KsM/D398ff39/4c/v27bl8+TIffPABnTt3LtIxAaZPn87UqVONP8fExJg8sHfLqH6fkqZxJykVZ1srkx5fCCFKRdIdiM24SVpac9SLIpOeeiFKWVJqGs+s/o/wmETqeTqycEgLLCykiqcQomJyd3dHr9fn6EGPiIjI0dOen3bt2nHmzBnjz97e3oU+po2NDc7OztkepmZnrcfOSo39l7nqhRDllqHyvYMH2FUxa1PEvUlQL0QJS0/XuHo7gZ1nbvDVnos8tTKY4Eu3cLK15PORgThJL44QogKztrYmMDCQLVu2ZFu/ZcsWOnToUODjHDx4EB+fzGFK7du3z3HMzZs3F+qYJcWQgi/F8oQQ5VakYTo7Sb0vDyT9XggTiUtK5UJkHOduxHLuRhznb8Ry/kYcFyLjSEhJy7atTgcfD2tJHQ9HM7VWCCFKz9SpUxk5ciRBQUG0b9+ezz//nNDQUCZMmACotPirV6+ycuVKQFW29/Pzo3HjxiQnJ7N69WrWrVvHunXrjMecPHkynTt35t1332XAgAH88ssvbN26lV27dpnlPWbl5mjN1dsJMq2dEKL8yjpHvSjzJKgXoohuxSXz2d/nOHo1mnMRcYTHJOa5raWFDl83e+p4OFLXw5EHGnrSpnbVUmytEEKYz5AhQ4iKimLOnDmEhYXRpEkTNm7ciK+vLwBhYWHZ5qxPTk7mpZde4urVq9jZ2dG4cWM2bNhAnz59jNt06NCBNWvW8NprrzFz5kzq1q3L2rVradu2bam/v7tVlQr4QojyrqxMZycKRKdJadYcYmJicHFxITo6ukTG24ny74+j4bz28xEi7xovWdXBmroeDtRxd6Sup3qu4+FAzar2WOlltIsQoujk2mR6JfWZTv0uhB//u8orvfyZeL9MBSWEKIf+rzOEHYKh30DDvuZuTaVR1OuS9NQLUQi34pJ549dj/HroGgD1PB15slNt6nk6UdfDgSr21mZuoRBCCHMzzlUvhfKEEOWRpmWZo1566ssDCeqFKKCsvfMWOni6S10md6uPbUaVYyGEEAKgasa0djfjJagXQpRDd8IgORZ0enD1M3drRAFIUC/EPdzM6J1fn9E7X9/TkQ8ea07zmlXM2zAhhBBlkrGnXgrlCSHKI0ORPFdfsJQs1PJAgnoh8vHH0TBe+/mosXd+Qpe6PC+980IIIfJRVYJ6IUR5FplRJE9S78sNCeqFyMXdvfMNvBx5f5D0zgshhLi3qo4Z89TLmHohRHlkGE8vle/LDQnqhbhL1t55vYWOCV3q8Hy3+thYSu+8EEKIe5P0eyFEuWaYzk7mqC83JKgXIsPNuGRe/+Uovx0OA1Tv/AePNadZjSrmbZgQQohyxZB+n5CSRkJyGnbWclNYCFGOSPp9uSNBvRDA/gs3eWZ1MFFx0jsvhBCieBxtLLHWW5Cclk5UXBI1rO3N3SQhhCiY1GS4fUktu9Uzb1tEgUlQLyq9o1ejGbviALFJqfh7OfH+Y82kd14IIUSR6XQ6qjpYEx6TyM24ZGq4SlAvhCgnbl0ALR2sHcHJ29ytEQUkQb2o1M7fiGX0sv3EJqXSrk5VVjzRRirbCyGEKDZDUB8l4+qFEOWJYTo7t3qg05m3LaLALMzdACHM5drtBEYu3U9UXDJNqjvzxaggCeiFEEKYhFtGBfybUgFfCFGeGMfTS+p9eSJBvaiUbsYlM3LpP1y9nUAddwdWPNEGJ1srczdLCCFEBSFz1QshyiVD5XuZzq5ckaBeVDqxSamMWb6fczfi8HGxZdX4trg72pi7WUIIISoQQ1Av6fdCiHLFMEe99NSXKxLUi0olMSWNp1b+y+Er0bjaW7FqXBuqV7Ezd7OEEEJUMJlz1SeZuSVCCFEIkn5fLklQLyqN1LR0Jq85yJ5zUThY6/lqbBvqeTqZu1lCCCEqoKoOKgNM0u+FEOVGwi2Ij1TLEtSXKxLUi0pB0zRm/HSUTceuY6234ItRQTJtnRBCiBIj6fdCiHLHkHrv5AM2juZtiygUCepFpfDO7ydZ++9lLHTw8eMt6VDP3dxNEkIIUYEZq99LUC+EKC8k9b7ckqBeVHhLdpzj//4+D8A7jzajZ2NvM7dICCFERWesfi9T2gkhygvDHPVS+b7cMXtQv3jxYmrXro2trS2BgYHs3Lkz3+0//fRTAgICsLOzw9/fn5UrV+bYZt26dTRq1AgbGxsaNWrETz/9VFLNF2Xct/tDefePkwDM6BPA4KCaZm6REEKIysBQKO9OUipJqWlmbo0QIlfxN+H8X6BpJX+uYz/DjVMlf57iiJKe+vLKrEH92rVrmTJlCjNmzODgwYN06tSJ3r17Exoamuv2S5YsYfr06cyaNYtjx44xe/Zsnn32WdavX2/cZu/evQwZMoSRI0dy6NAhRo4cyeDBg/nnn39K622JMmLjkTBm/HQEgGfur8uTneuYuUVCCCEqC2dbK/QWOgBuxaWYuTVCiFytfx5WPgTn/izZ84T+A9+PhtWPQlpqyZ6rOCIzeurdpKe+vDFrUL9gwQLGjRvH+PHjCQgIYNGiRdSsWZMlS5bkuv2qVat4+umnGTJkCHXq1GHo0KGMGzeOd99917jNokWLePDBB5k+fToNGzZk+vTpdOvWjUWLFpXSuxJlwc4zN5i85iDpGgxrU4tXevqbu0lCCCEqEQsLHa72VgBEybR2QpRN4UfV88XdJXuey/vUc/RlOLu1ZM9VVOnpcNMwR31d87ZFFJrZgvrk5GSCg4Pp0aNHtvU9evRgz549ue6TlJSEra1ttnV2dnbs37+flBR1F3zv3r05jtmzZ888j2k4bkxMTLaHKL+CL93i6VXBpKRp9G3qw9yBTdDpdOZulhBCiErGOK5eiuUJUfakp0P0FbUcFlKy57p2MHM5eEXJnquoYq5AaiJYWEEVX3O3RhSS2YL6yMhI0tLS8PLyyrbey8uL8PDwXPfp2bMnX375JcHBwWiaxr///suyZctISUkhMlLNqRgeHl6oYwLMmzcPFxcX46NmTRl3XV6tPRDKsC/2EZ+cRqf67iwY0tyY/iiEEEKUJgnqhSjDYsMhPWNozLWDJTuu/lpI5vKZTRB9teTOVVSGInlV64De0rxtEYVm9kJ5d/egapqWZ6/qzJkz6d27N+3atcPKyooBAwYwZswYAPR6fZGOCTB9+nSio6ONj8uXLxfx3QhzSUhO4+XvD/HquiMkp6bzQENPPhsRiI2l/t47CyGEECXAzcEGgCipgC9E2XM7y/f9hFtwO/eaXsWWcAtuXVDL3k1BS4eDq0vmXMVhHE8vRfLKI7MF9e7u7uj1+hw96BERETl62g3s7OxYtmwZ8fHxXLx4kdDQUPz8/HBycsLdXc077u3tXahjAtjY2ODs7JztIcqPC5FxPLx4N98HX8FCBy/39OfLUUE42MhdRiGEEOYjPfVClGHRd3XilVQKftgh9VzFFzpMVsv/rYT0MjYrhqHyvbsE9eWR2YJ6a2trAgMD2bJlS7b1W7ZsoUOHDvnua2VlRY0aNdDr9axZs4Z+/fphYaHeSvv27XMcc/Pmzfc8piif/jgaxkMf7+Jk+B3cHa1ZPb4tz3ath4Wk3AshhDAzQ1AfJUG9EGXP7UvZf8467t2UDKn31VpCQH+wc1Xj18tawbwo6akvz8zalTl16lRGjhxJUFAQ7du35/PPPyc0NJQJEyYAKi3+6tWrxrnoT58+zf79+2nbti23bt1iwYIFHD16lK+++sp4zMmTJ9O5c2feffddBgwYwC+//MLWrVvZtWuXWd6jKBkpaem898dJvtip0pla+7nyyeOt8HK2vceeQgghROlwczT01Ev1eyHKHEP6vaO3Gl+fddy7KRkyAKq1ACtbaP447PtUFcxr0LNkzlkUMp1duWbWoH7IkCFERUUxZ84cwsLCaNKkCRs3bsTXV1VcDAsLyzZnfVpaGvPnz+fUqVNYWVnRtWtX9uzZg5+fn3GbDh06sGbNGl577TVmzpxJ3bp1Wbt2LW3bti3ttydKyPWYRJ775j8OXLwFwJOdavNKr4ZY6c1eIkIIIYQwkvR7Icowwxj6gP5w4IvMYnmmnjHJkAHg00I9B45WQf3pPyDmGjhXM+35iiIlIXM4grsE9eWR2QcdT5w4kYkTJ+b62ooVK7L9HBAQwMGD906NGTRoEIMGDTJF80QZs+dcJM9/e5DI2GScbCx5/7Fm9GriY+5mCSGEEDlI+r0QZZghiG3QE/77ChJvq5R8Vz/TnSPhFty6qJartVDPHv7g2xEu7VYF87q8YrrzFdXN84AGti5g72bu1ogikK5NUS6kp2t8uv0sI778h8jYZBp6O/HrpPskoBdCCFFmGarfS0+9EGWMpmWm37vVBc9GatnU4+oNRfJc/dRYeoPAMeq5rBTMi8wokudW3/SZCqJUSFAvyrzo+BSeXPkv7286RboGgwJr8NPEjtR2dzB304QQQog8GXrqb8enkJqWbubWCCGM4iIhNQHQgXMNVcQOTD+u3nCTwHB8g4CHwLaKyhY4t8205yyKC3+rZ0m9L7ckqBdl2pEr0fT9eCd/nozA2tKCdx9tygePNcfOWuafF0IIUba52lsZl28npJixJUKIbAzj6Z18wNI6MzXe1D31hpsEhvH0Bla20OJxtRy8wrTnLKywQxC8XC03G2Letogik6BelElxSam8vfEEAxfv5sqtBGpVtefHZzowpHUtczdNCCGEKBBLvQVVMgJ7ScEXogyJzgjqq9RUz4agOyxEpeabStbK93drNVo9n/odYsJMd87CSE+H36aClg6NH4G6Xc3TDlFsEtSLMkXTNH4/Eka3+X/x+d/nSUvX6NPUm/WT7qNJdRdzN08IIYQoFGOxvFgJ6oUoMwzj6atkdBZ5NgK9NSRGw60LpjlH/M3MInk+zXO+7tkQarUHLU0VzDOH/76Cq/+CtRP0fNs8bRAmIUG9KDMuRsYxZvkBnvn6P8JjEqlV1Z7lY1qzeHggLnZW9z6AEEIIUca4ybR2QpQ9hvR7l4yeektr8Gqslk01rt5YJK929iJ5WZmzYF5cJGydpZYfmAHOUny6PJOgXphdYkoai7aepseiv/nr9A2s9RY8360+m1/oTNeGnuZunhBCCFFkmXPVJ5m5JUIIo+i7euohS7E8E42rNxbJa5H3No0GZBTMC4Vz201z3oLa8oaaxs+7KbR+snTPLUzO7PPUi8ptx6kI3vj1GJei4gHoVN+dOQOaSGV7IYQQFULVjGntZK56IcqQ23eNqYfs4+pNwTievmXe21jZQfNh8M8SVayufnfTnPteLu2FkIyU/74LQS8hYXkn/4LCLK7dTuDN347z+9FwALycbXi9X2P6NPVGJ/NjCiGEqCAk/V6IMibrHPVVfDPXG3vqD6ltivt9NK/K93cLHK2C+lO/w51wcPIu3nnvJS0FNkxVy61GQ83WJXs+USokqBelKiUtneW7L7Bo6xnik9PQW+gY08GPKd3r42Qr4+aFEEJULMZCeRLUC1E2JNyC5Dtq2aVG5nrPANDbQFI03DwPbnWLfo74m3D7klrOrUheVp4BULMdXN6nCuZ1fqno5y2Ifz6DiONg7wbdZ5XsuUSpkTH1otQcuHiTfh/t4u2NJ4lPTiPQ15X1z93HzH6NJKAXQghRIbk5ZvTUS/V7IcoGw3h6Bw+V/m6gtwLvJmq5uCn4hv2r1gG7Kvfe3lgw7ys1zVxJib4C2+ep5QfngH3VkjuXKFUS1ItSsfX4dQb/315OXb+Dq70V7z3ajO+fbk+jas7mbpoQQghRYqpK+r0QZYtxPH2tnK8ZUuWLWyyvoKn3Bo0Hgq2Latv5EiyY98d0SIlTmQHNHy+584hSJ0G9KHFXbyfw4veH0DTo28yHbS/ez+DWNbGwkLHzopBSk+H0Jog8q8a7CSFEGSfp90KUMYbx9C41c75mqFRf3GntjJXv8ymSl5WVHTQbqpaDlxfv3Hk5swVO/Ao6PfSdDxYSBlYk8q8pSlRKWjqTvvmP6IQUmtdwYeHgFrhmfMERotB2LYRvBsMngbCoKfzyLBz5AWJvmLtlQoh7WLx4MbVr18bW1pbAwEB27txZoP12796NpaUlLVq0yLZ+xYoV6HS6HI/ExMQSaH3RuWVUv78Vn0x6utyMFMLs8uupNwThYYeKlwZvrHzfouD7GFLwDQXzTCklATZmjNVv90zmMANRYUhQL0rUB5tP8V/obZxsLfnk8VZYW8qvnCgiTYPDazN+0KkxcQdXw7px8EE9WNIRNs2AM1shOc6sTRVCZLd27VqmTJnCjBkzOHjwIJ06daJ3796Ehobmu190dDSjRo2iW7duub7u7OxMWFhYtoetrW1JvIUic3VQNWPS0jViElPM3BohRK5z1Bt4NMwolhcDty4U7fjxNzNvHNyrSF5WXo2gZltIT4WQr4t27rzsWgi3LoJTNbh/mmmPLcoEibBEidl+MoL/++s8AO892oyaVe3N3CJRrkUch5vn1MX2pdMwYh10mATeTdXr14/C3k/g60fhHV9Y3hf+eh+u/AtpqeZte3mmaZAcb+5WiHJuwYIFjBs3jvHjxxMQEMCiRYuoWbMmS5YsyXe/p59+mscff5z27dvn+rpOp8Pb2zvbo6yxsdTjZKMmG5IUfCHKgPx66vVWmd8rijqu3rBf1bpqnHxhGHrrg01YMC/yrArqAXrNAxsn0xxXlCkS1IsSERadwNTvQgAY1d6X3k19zNsgUf4d/1U91+sGjp5Qrzv0mAsTdsFLZ+HRpdBypBojl54Cl3bB9rnwZTd4rw7883/mbX95lBgDqx6Gd30h/Ki5WyPKqeTkZIKDg+nRo0e29T169GDPnj157rd8+XLOnTvHG2+8kec2sbGx+Pr6UqNGDfr168fBg/l/CU9KSiImJibbozRUdZRieUKUGYagPrcx9ZBlXH0Rg/qipN4bNBoINi5qOrwLO4p2/qw0DTa+CGnJ6ntTowHFP6YokySoFyaXmpbO5G9DuBWfQuNqzvyvT4C5myQqghMZQX3AQzlfc/SApoNgwCcw5QhM+g/6LlDb2lZRc87+9W7JThNT0cRFwlf9VRXetGQ11EGIIoiMjCQtLQ0vL69s6728vAgPz33c6JkzZ5g2bRpff/01lpaWuW7TsGFDVqxYwa+//sq3336Lra0tHTt25MyZM3m2Zd68ebi4uBgfNWvm8aXexIzF8mRaOyHMKzEGEm+r5Sp5BfUZ4+qLWiyvsJXvs7K2h+ZD1HLwiqKdP6tjP8H5HSrLsfd7oJMi1RWVBPXC5BZtPcP+izdxtLHk08dbYWulN3eTRHkXeUal31tYgn+v/LfV6cCtLrQeB0NWwUtnwMoB4qMg4ljptLe8u30ZlvVUvQ36jMKWx3+RmyKiWHR3fZnUNC3HOoC0tDQef/xxZs+eTYMGDfI8Xrt27RgxYgTNmzenU6dOfPfddzRo0ICPP/44z32mT59OdHS08XH58uWiv6FCcJNp7YQoGwzj6e1c805DNwTjRS2WZwjqC1r5/m6GFPyTGyA2omjHAHUD44/parnTVPXdSFRYEtQLk9p55gaf7jgLwNuPNMXP3cHMLRIVwvFf1HOd+9WFuDAsrcG3g1o+/5dJm1UhRZyEpT0g6qxKTXxyO1g7wZ1rcPVfc7dOlEPu7u7o9focvfIRERE5eu8B7ty5w7///stzzz2HpaUllpaWzJkzh0OHDmFpacm2bdtyPY+FhQWtW7fOt6fexsYGZ2fnbI/SkDlXfVKpnE8IkYf8prMz8GgIlraQfEfV8imM+JsQbSiS16xobfRqDDVaF79g3o55EBsOVetAxylFP44oFySoFyYTEZPIC2tD0DQY1qYWDzWvZu4mVW6X98PXg+Gv9yCqkBelsia/1PuCqNNFPV+QoD5fV4JheS8VwLv7w9hNatobQ3aE4eaKEIVgbW1NYGAgW7ZsybZ+y5YtdOjQIcf2zs7OHDlyhJCQEONjwoQJ+Pv7ExISQtu2bXM9j6ZphISE4ONT9mq4VM2Y1k4K5QlhZvkVyTPQW2YplhdSuOMXp0heVsaCeSuKli0Qdhj++Uwt9/kArMrWrCDC9CSoFyaRlq4xeU0IkbHJNPR24o3+jczdpMrt8n5V4OzMJtj+FnzcCj6/H/Z8AjHXzN26wrl5QaXA6SygYd+iHaN2RlB/aQ+kyZRSuTq3XY2hT7gF1QNh7B/gUl291migej7+iyq6I0QhTZ06lS+//JJly5Zx4sQJXnjhBUJDQ5kwYQKg0uJHjRoFqB73Jk2aZHt4enpia2tLkyZNcHBQGWCzZ89m06ZNnD9/npCQEMaNG2e8AVDWSPq9EGVEdAGCesgyrr6QxfIM2xc19d6g8SOqYN6ti4XvkEhPhw0vgpYOjR9WBYZFhZd79RkhCunjbWfYez4Ke2s9nw6XcfRmdTUYVj8KybFqvlNrB5V2fu2gemx+DfzugyaPqiqo9lXN3eL8nVivnn07goN70Y7h1QTsqkLCTfX51GpnuvZVBMd+hnXj1awBdbrCkNVg45j5er1uYO2oxiJe/Q9qBJqtqaJ8GjJkCFFRUcyZM4ewsDCaNGnCxo0b8fX1BSAsLOyec9bf7fbt2zz11FOEh4fj4uJCy5Yt+fvvv2nTpk1JvIViqSpBvRBlQ0F66iHLuPqQwh2/OJXvs7K2h2aD4cAXsPtDSLoDqUmQmqgeackZy0lZHhnrY6/Dlf3qut3z7eK1Q5QbEtSLYttzLpIP/1RjGN96uAl1PRzvsYcoMWGHVA99UgzU6gAjflBBfewNOP4zHPkBLu+DizvVY+NLULcbNH0M/HtnD+TKCkPqfXGmYbGwgNqdVE/zhb/LVlCfHKeGR3g1Ue0sbf8uh99eADTVI//I52Bpk30bKzto0BOOroPjP5XvoD49HfZ/DlcOqPl6HT3N3aJKY+LEiUycODHX11asWJHvvrNmzWLWrFnZ1i1cuJCFCxeaqHUlyzClnVS/F8LMCjKmHjKDckOxvIJen4tT+f5ugaNVUH9+u3oUVtf/gbMMha0sJKgXxRIZm8TkNWoc/WOBNXi4ZQ1zN6nyun4MVg6ExGio0QaGf6cCelBTvrV5Uj1uh8LRH1WAf/2IStE/swks7VRg33QQ1O8Beiuzvh0Aoq+q4AsdBPQv3rFqd1FB/fm/oMsrJmlekSTGqOERl3bBxd1w7T9VDMe/DwxaXnrj3jQNdi2AP+eonwOfgL7zwSKPLJtGAzKC+l/gwTfL57Q4sTfg5wlwdqv6OSUBhn5dPt+LKFeq2ktPvRBlgqH6/b166t391fei5FhVONYj75k4jOKiMo/v07x47QQ1rr/jZNUZYWmrbrjrbdSzpa0qBGxpm/s6R09o9HDx2yDKDQnqRZGlp2u8sDaEG3eSqO/pyOwBjc3dpMor4iR89ZBKL6/WSvXQ5zVVS5VacN8U9bhxSgX3R3+Am+fh2I/q0eRRGLSsNN9B7gyp9zXbgpN38Y5V5371fGU/JMer1LbSkHAbQvfCxV1wabe666/lUvTm1Eb4ZjAM/abkMybS02HLTNj7ifq500vwwGv5B7f1HgQre3VT6NpBqN6qZNtoauf/gh+fUpWALW3VjZRTG9Qcvk0eKbnzJt3J+/+iqDSypt/nNZWfEKKEJcdD3A21nNcc9QaGYnlX9quU+oIE9WEZ4+nd6oGtiWbWeHCOaY4jKjwplCeKbMlf59h5JhJbKws+Hd4Ke+sSuEf055tqDLgU58pb5FlY+RDER4J3Mxj5Y8Errnr4wwMzYNJ/auqy9s8BOtUjG3m2RJtdIKZIvTeoWgeca6jxZqF7i3+8vMTfVDcjfp8Gn90H7/rBt0NVAH3toAroq/hCi+EwYDFMPgyjf1Nj3y78BasGqmJ1JSUtFX55NjOg7/k2dJt5795qa3uVwQHlqwp+WipsewtWDlABvUdD9bve6UX1+saXVe9KSYi/CYs7wNbZqh2i0nLLSL9PTksnNkl+F4Qwi+gr6tnGGWyr3Hv7whbLM1WRPCGKQIJ6UST7L9xk/uZTAMwZ0IQGXiXQExV9FXZ+AHs+hpMbTH/8iuDmeVWxPPY6eDaGUb8Ufh53UAFd9VbQ8y01dhrgXzP31MdGqGr1UPzUe1DvsaSnttv+NrxXG9aOgH+WQPgRQFNT27QaBQ9/Di8cgymHYeBiaDkcXH3VeP9Rv6p/uysHYEU/9f5NLSUBvhsJh74BnR4Gfgbtny34/oabKyVRBT8lQd0I+es9uHPdNMeMvqr+f/z9HqBBy5EqoPdqpLITPALUzbBN001zvqzS01VmQHSo+rxS4k1/DlFu2FtbYmulvnJJCr4QZmIokudSs2DDrgzj6gs6rZ0px9MLUUgS1ItCuxmXzPPfHiRdg4dbVuexwBIaRx92KHP5zzmQnlYy5ymvbl1SKfd3rqnex1G/mKaSfevx6jlktUpVM5cT6wFNDSe4V5pcQdXurJ4v/G2a42WVkgh7F6tl9wYQNBYeXQovnoLn/4OHPobmQ8Alj/8vNQJhzEZw9ILrR2F578yCPqYQcVIFuKc2qvTzoV9Di2GFO0b9HmqM4a0LEH7YdG0DdRPpnyVqCsaFjeHHp1Wl/aI69Tt81hFC94C1k/q3GPBJ5rALS2sY8KmaKvHwWji92TTvw2DXfDi7RX3Wg1eaLhVTlFtuMle9EOZlnM6ugN8pDD3uYYcK9h3U8L21uJXvhSgCCepFoc3dcJzwmETqeDgwd2CTkhsbmDWojzwFh9aUzHnKo+grKkCLvqzGbo36VRXDM4W63VR6eGK0SsM3F2Pq/UOmO6ZhvvprIaZPcT+3DZLvgFM1mPgP9Fuoig4WphaAVyN44ndwqaUK8yzrVfxhEMnxKv37s44qC8DGGUb8qIoiFpaNI9TvrpZNmYKflgJ7P1XLVXzV1HqH18AXXeHLB1Xdh7SUgh0rNQn+mK6GPCTcUj0mT/+l/i3uViMQ2mVUY/9tiipiaAoX/lZZGwB9PgDvJqY5rijXjOPqpQK+EOZR0OnsDNwbqFoyKXHqmpyfuMiMInk6NRRSiFImQb0olCNXovnxv6sALBjcAgebEqy1aAjq3TOKk+yYp3pDK7uYMBXQ374ErrVh9Hpw8jLd8S0soPU4tXzgC/PUM4i/CRd2quUAEwb1zj4Zv0+aKlxnSsd/Vs+NBhRvajq3ujD2D3CrDzFXYHkvCD9atGOd+gMWt1VV7tNToUFvmLAL/DoWvX2NBqrnYz+b7nfj6DqIuaqyFJ7dD09ug2ZDwMJKFSlaNw4WNYW/3lcV7PMSdQ6W9oB9GRkT7Z6FcVvUZ5qXrjPA1U+df+sbxX8vMWHww1hVO6HFCGg1svjHFBWCzFUvhJkVdDo7Awt9ZoB+r3H1htR7UxbJE6IQJKgXBaZpGnM3HKeDxVF2ubxOi/QTJXtCQ3pv7/dU72f0ZfOP8za32AhVFO/meXWnefT6kpmDtMUINUVK2KHipUAX1amNoKWBV9P8A7KiMPTWnzfhuPrUJJXuDdB4YPGP51Jd9dh7N1WVelf0gcsHCr5/9BVYMxy+HaJ6JpxrqKr6j69RY/iLo0FP9btx85yaRrG4NA12f6iW205QU/pVD4RHMuoP3D8dHDzhThhsnwsLG8FPz+Qc43jkB/i/LqpKsZ0rDFsLvd5Wafb5sbZXQyNA/X0x3EwqirRUdQMi7oaqcdHn/aIfS1Q4bhlBvaTfC2Emhe2ph4KPqzdUvpfUe2EmEtSLAtt8/DohF8J5z+pzaiSdLdkAO/aG6jlDBzWC4P5X1fqdH6gpoiqjuEg1hj7ytArSRq833Vjzuzm4ZU7zdeDLkjlHfgyp3aZMvTcoiWJ557ZBUoy6+VSjjWmO6eihquLXbKuGQqwccO8bEWkpsPsj+KQNnPwNLCyhw/Pw7D/QsK9p2mXjBPUfVMuG7ITiOLsVIo6r6v9BY7O/5uQF909Twf0jX6j6CmnJqtDf513U8ISj6+CX51QwnXwHanWACbvBv1fB21C7MwSOUcvrny96LYltb6ppC62d1Dj60po2UZQLhp76W/ES1AthFsY56gvx3amgFfANQb9UvhdmIkG9KJDk1HTmbTzBE/o/qKGLVCuvlWAPbnhG6r1bPRVEtBihluOjMsfeVibxN2HlQLhxApx8YPSvKmW4JBkK5h1dp85fWhKj4dx2tWyKqezu5ncfoFM3R2KumeaYx35Wz40eKl7q/d3sqsDIn6BOVzWm7+vHMjMC7hb6j+qp3jJTbVurPTy9E3q8afp57w3/LqZIwTf00geOUe83N5bW0GwwPLUdxm2FJoPUDYvQvSrV/eAqQAedX1E3u1yqF74dD85RN2Vunocdbxd+/1N/wO5FannAx+Ber/DHEBVa1Yxp7aJkTL0QpS81SWV8gardUlCGSvbhh/MvlieV74WZSVAvCmT1vkvciQrjOassxbGizpbcfNqG8fQ+zdWz3hIeeE0t7/lY9VpXFqlJqujX9SMqDXn0etOnpOemeqAaS5aWBCFfl/z5DE5vUoXS3P3Bw9/0x7dzzfy9Kk6qtUFqkhouAJnjzU3J2gEeXwsN+6l/izXD4fD3ma/H31Q91ct6QMQxsKsKD32iKul7NTJ9ewAa9AK9NUSdgRsni36cK8FwcacK0Ns9U7B9araGQUthylEVxNu7q2B81C/wwAz1t6IobF1UcUNQNw6vBhd831sX4aen1HLbCdD44aK1QVRobsYx9UlmbokQlZBhjnpLO7B3K/h+7vXBykFNSxp5OvdtYm+oGjjowEeK5AnzkKBe3NPt+GQ+/PMMUyzX4UiCCogMdznvlY5UVMagPssfx4AB6g5ocizsnF8y5y2Lfn8VLv+jgo7Rv6oLTGnQ6TJ76w8sVfNul4aSTL03MGUK/rntGan3PipVviRY2sBjX0GzoarWwI9Pqn+Tg6vh48CMnmrUPOzP/auKs5kyY+Buts5qlgTIzFIoij0ZvfRNH8t7qr+8OPuoIP6lMzDlSOa/aXH491Jt0dLhl0mQWoAe1dQk+H6MyjCpHgQPvln8dogKqWrGlHZSKE8IMzCm3tcq2Bz1Bhb6zO+ieY2rD8tY715fZZcKYQYS1It7+njbWTwTL/C45Ta1oufbapw7lFwRtbCMInmGHlVQQUr3jOrUB77MLHhiLslx8N8qNf93SQleAcHLAR08ugw8A0ruXLlpOghsXNS85Oe3lfz5kmLVGGsomdR7g6zF8oqbPm4YVx5g4tT7u+ktYeCSjBstGmyYCr88Cwk3wbMRjN2k5mF3KEQPRHEY/n2KOrVd1Dk4sV4td5hU9HZYWBS9dz43vd5RvTgRx9SsAfey6X/q5qadKzy24t6F+USlVVUK5QlhPsYieUWoRWRIqTcE73eT1HtRBkhQL/J1ITKOlXsv8j/Lr9GTrlKA/e5TqdlQMkF9wm0VRELOuT7rdAW/TqpY1o53TX/ugkhNhv1fwIct4NfnYOmDJfM5XN4PG15Sy91mZs4PXpqsHaDF42r5wNKSP9/ZLZCaqKbq8yrBub1rtVfp4zFX1BjqokpNgpMZqfemqHp/LxYWat7z+6aqn63s1Vjwp/+GWu1K/vxZ+fdWU87dOAE3ThV+/72fqh7x+j3Aq7Hp21dUDu5qxg2Avz+A68fz3vbID5mFJB/5ouQKV4oKwU2mtBPCfG5n6akvrHsVyzME+1L5XpiRBPUiX+/8foJ22iG66g+pca8PzlEvVGulnkuiWF74EfVcpRbYV83+mk4H3Wep5UPflGwv+d3S09VY5k9bw8aXIC5CBYZJMbD6EdNM72UQEwZrR6qx5QEPZQZx5mCYs/70HyWfHZE19b4w6XGFZW2fWaX+/I6iH+f8DkiKBkdvqFlKQbVOpzJWxv8Jzx+EjpNBb1U6587KrgrU7aqWC9tbH3sjs05Dx8kmbZZJNHkU/Puo/3+/Ppd7caQbp+HX59VypxczZwQQIg+GQnnxyWkkpuRTcEuIiuRaCGx8RWVnmZPh+0tB56jPyhCshx9RU5fezRDsS+V7YUYS1Is8/XM+ii3HwphhmfHlu/WTmQXafJqBTq8qiZqqgrjB3UXy7lYjSGUMaOlqCqmSpmlwejP8X2f4cbwqiuXgqXpMXzylshYSbqnq9JFni3++1CT4bhTEhoNHgEq5LskA917c66t0dS1dDQcoKSkJ6nMGVT+hpBnH1f9d9GOUVNX7gqgRBE7epXvOuxkKAxZ2XP3+z1VGRvVA8O1o6lYVn04HfeeDjbMqmLdvSfbXk+PU/9GUOJU5dP//zNNOUa442VhipVd/yyUFX1R4KYmwdRZ88QDs/z/z10KKLkZPvVs9Ne1qbsXyYiMyp2C+O7tUiFIkQb3IVXq6xtwNJ3hM/xcNLS6DbRXo8krmBtYOahwvFK5KdEGEZ4yn984jqAd4YCboLNRc3Ff+Ne35s7q8H1b0hW8eU9XnbZzVuSeHQJsnVSbBiHXg1VT13K98CG5dKt45f38FruxXhfGGfm366ciKwlAw77+V6qZDSTi3TQVJzjWgequSOUdWtTur5wt/F60IYGoynNqglkui6n154N9bZfBEHIPIMwXbJylWBfWgeunNecMqP87VoMdctbxtbmYvk6bBb1PVsANHL3h0qWnH9IsKS6fTGcfV35Rp7URFFvoPfHYf7FqoirtCyRVWLijjmPoiBPUW+syA/e5x9Ybx9O4Nysb3NVFpSVAvcvVzyFXOXw3nZcvv1Iour+ZMha+ekWZk6vHk9+qpB/BsCM0zxnpvnVX8Ymd3izgB3z6uxstf2g16G1XMa/Ih6PySuqlhYOeq5hJ3b6Du1q58qOjZC/8uz+gNzyiMVxpT1xWEfx9V3T3uRmZxM1M7/qt6LunUe4PqgerOe8JNuH608Puf36Eqnjt6lf549rLCvirUuV8tFzQF/+BqSLwNVeuojJuyrNUodfMnNQHWT1Z/Z/77Cg6vUTcVBy0DJy9zt1KUI4YK+FEyrZ2oiJLj1Iw9y3qqKU8dvVTWE6jpT5PjzdOutNTM72VFSb+HvMfVy3h6UUZIUC9ySEhO4/1Np5hguR53XbT68m3oqc3KWCzPhD31yXGZqU35BfUA909TY9ov7oTz201z/tuh8NMzsLi96oXVWahpwp7/T/Xa3X1jw8DRQ82T7eqn0vNXDlDjhgsj9B/Y+LJaNldhvLzoLSHwCbVsKAxmSqnJcOp3tRxQglPZZaW3At8OarkoU9tlq3qvN1mzyh1jFfyf771tWgrs/UQtd5hU9j83nQ76f6TmNb64E/6YrsaGgsrY8bvPvO0T5Y4UyxMV1vkd6rvTP58BGrQYDs/+A0Hj1JBFLb1oN9BNIeaqyhjQW6sbDUVhCNrvntZOKt+LMkKCepHDlzvPQ/RVnrLMqOr94Jzcp2kyBPXXQkw3h/n1Y+oPv6P3vXvAqtTMvNmwdXbx2hB/U31h/zhQFeBDg4D+MHGfmiasIHNoO1eDUb+q9PHI07DqYXXcgogJg+/KSGG8vLQapVKtQ/eatiggqKDaWHCuhOZ6z03Wqe0KIzVZDf2A0ql6X5b591X1NcKP3LsQ0rGf1bhGe3doPqxUmldsVWurm2wA/yyBtCRo0As6TjFrs0T5VFWCelHRJEbDr5NUZ8btS6onfMQ6GLhYZTLqdHkHxKXFMJ7epUbR698Ygva7i+VJkTxRRkhQL7KJuJPIkr/O8bLVWmxIVkWs8kqR9QhQPVhJ0XDTRFVNjan3BSw20ulFlUIdFgInijBfdlqKKoL1UQvYt1hNlefXCcZvgyGrwcO/cMdz9VU99g6eagz+14MgMSb/fYyF8a6XjcJ4eXH2gYZ91bKpp7czpG4H9CvdgnOGYnmX9qhAvaAu/KW+yDh4qunxKjMHt8z6BPml4Gsa7P5QLbedAFZ2Jd82U2k7AWq0VssutdT/0dIujCgqBJmrXlQop36HT9uqejugCipP3Av17so0vNc87yWtONPZGRiK5aUmQGTGNK6xEXDnGqpIXtNiN1OI4pBvJSKbBZtPUy/lNI/od6kVPebmHWDqLTNT5E2Vgl+Q8fRZObirNF6AP99UQXpBndkCSzrAH9NUgObVRN1dHr0eagQWrt1ZuddTgb1dVfW5fDMk/3FkZbEwXl4MmRGH1977ZkVBpaXCyYyCc6WVem/g2Rjs3VSBvsJMz5it6n0ZTyEvDcYU/HyC+vPb1Y0uK/vMaRLLCwu9Gj8fNBaGf5/3MBwh7sFNCuWJiiAuCtaNh2+HqlmQqtaFMRuh7wdg45Rze3P31BdnOjsDC4vM76aG3nkpkifKEAnqhdGJsBjW/hvKDKuMKeyaDb13FXLD66YqllfYoB6g/bMqMLt5LnPu6/zcOA2rB6le9MjTat9+C+Hpv9XdZVP0kns1UsXzbFwgdA+sHZ571fiyWhgvL36d1MUrOVYF9qZwaZcqVmfvVvrTm1lYqPcEBU/BT0vJTL2vrFXv7xbQX9WfCAtRNSVyY+ilbzW6fAbFVWqpvxOeDc3dElGOGeaql556US5pGhxdB5+2gSPfq7/7HZ6HZ3aDXz7Xb0NP/Y2Tavra0hZtqHzvW7zjGIvlhWQ8S+q9KDskqBcAaJrGWxtO0EN3gLYWJ1VavWEcaX5MWSwvNUlVnYfCBfU2TtA5o8DcjnfzvmDE31RVWZe0h7NbwMIK2j8Hk/5TPXCm7nGt1gJG/ABWDmq6tu/HZM8kKMuF8fKi02X21h9YappZBwxV7xv2Nc/UYMb56gsY1J//S1Vvd/DMLLRX2Tm4ZxaNy623/lqIKqKk00P7iaXZMiHKlMxCeVL9XpRD29+CH8ZCfKSa1nj8Vujx5r2HUzlXAwcPVawu3AzF8ozT2RWjpx4yb04YgnmpfC/KEAnqBQA7Tt3gn7Ph/M/qW7Wiw3MFKw5n6KkPP1y4Mcm5iTihCsXZVil8ilTQWLXPnWuw/4vsr6WlqnUft1JVWdNToUFvVZW151tgV6V47c5PzTbw+BqwtIVTG+HHpyA9rXwUxstL86EqhfrGCTUWvTjS0zJ7vQMGFL9tRWEolnd5v5p94V6O/6SeA/pL6n1WhqyF3IL6PR+p5yaPFm9MoxDlnGFKOymUJ8qdpDuw91O13OkleOqvzI6de9HpzDuu3jCmvjjp95DZI3/9qPpuKZXvRRkiQb0gNS2dtzaeYJR+M76662q6j4JWdnatraqbpiVDRDEromdNvS9sCrylDdw/XS3vnA8Jt9XyuW3w2X2w8SVIuKUK0Y38SQXapZXqXruzKrpnYQXHflRVYr8bWfYL4+XF1gWaDVbLxZ3e7vI/6nOwcckstlbaqtZRF/r0FFXZPz9pKZnj/yt71fu7GVLwrwZn9oqASsc/lnEjpOPzZmmaEGWFFMoT5daxnyElXhWMe+C13GdFyo+5xtWnp0P0FbVc3JvKVeuAtROkJqrsvjvX1HVPiuSJMkCCesG3By4TGRHGZKuML94PvFbwgh86HVQzjKsvZgp++GH1XJjU+6yaDwWPhio1evNr8M1QNa3cjRPqxkOfD2DCLqj7QPHaWRT1H1SFtnR6Ne7/yoHyURgvL0EZhc5O/Ap3rhf9OMbU+z6F/4JgKjpdwae2u/CXujnk4FH64//LOkfPzM/E8O8KqmdHS4e63eSLj6j0DOn3dxJTSU410VSwQpQGQ82iFsOL1hFhrp762HB1016nByef4h3LwiLz5kTwCvUsRfJEGSFBfSUXk5jCwi2nmWz5I87EqQrwLYYX7iDGYnkHi9eYohTJy8pCDw9k1AE4uApO/67mVW/7jBo33+ZJ84zZNmj0EDz8GaCj3BTGy4tPMzWffHpq5lQ2hZWerm4KQOlXvb+bcVz93/lvZ6h6L6n3uTNWwf9ZPcdFwX+r1HLHyWZpkhBliYudFXoLFRDdipfeelFORJ1TmWw6C2g+rGjHMATDESdKt1iesfJ9ddN8BzR8Rz21UT1LkTxRRkhQX8l9uu0sLvGXGGm5Va3oMbfwwYopiuWlpWYWTynO2KSGfcE3o2BXvQfhmb3Q+52yU2272WBVWGbc5vJRGC8/hoJ5wcvVv19hXfsPYq6qeV/NkT2RlaECftghVVAxN1L1/t4C+gM6lYkSfQUOfKHm9PVpbr7hFUKUIRYWOlztrQCIkmntRHlh6KWv2w2ci9jb7Vwd7N1VsbzrxRyuWRjG8fQmqudiCOLTM773yHh6UUZIUF+JhVy+zZe7LjDd8hssSYP6PaFu18IfyJB+f+OkKqRSFFFn1Jd/a0c1ZqmodDoY/h0896+qPO/RoOjHKik1glQBvfKu0QA1DV3MVTizqeD7pafBlX9h5wL1c4OeYGVbMm0sKGcfcPcHNLi4K/dtLvytUu/t3SX1Pi9O3lCrvVo+vBb2f66WO04uX3UjhChBVY0V8CWoF+VAehqEZBRRblnITM6sdLos4+qLmdlZGLcvqWdTFWm9u2deKt+LMsLsQf3ixYupXbs2tra2BAYGsnPnzny3//rrr2nevDn29vb4+PjwxBNPEBUVlW2bRYsW4e/vj52dHTVr1uSFF14gMTGxJN9GuZOYksbU70JozTF66IPVWKMebxbtYE5e4FwD0DJT6AvLsJ93UzVmqTisHcC9fvGOIe7N0gZajlTL+RXM0zSIPKtmIFgzHN6tDV92g1OGgnMPl3xbC+JeU9sZUsoD+pt3GEdZZ0jB3/EOxEepeYHNNbOBEGVQZrE8mdZOlAPntquCcHau4N+neMcyx7j66Iye+uJOZ2fgWhtsnNWyFMkTZYhZg/q1a9cyZcoUZsyYwcGDB+nUqRO9e/cmNDQ01+137drFqFGjGDduHMeOHeP777/nwIEDjB8/3rjN119/zbRp03jjjTc4ceIES5cuZe3atUyfPr203la58On6XQy79X+ssH5PrQh6Ajz8i37A6sUslhdWzCJ5wjyCngB0apaBqHOZ62Mj4PD38POzsLAJfBKoZiA4+RskRasigQH94aFPwL+v2ZqfTX7F8tJS4ERG6r1Uvc9fo4z6CGkZvZAdJslNECGycJNp7UR5ErJaPTd9TN3MLw5jT30RO4CKwpB+b6qeeguLzO+q7v6qI0mIMsCs37QWLFjAuHHjjEH5okWL2LRpE0uWLGHevHk5tt+3bx9+fn48/7yaFql27do8/fTTvPfee8Zt9u7dS8eOHXn88ccB8PPzY9iwYezfv78U3lE5EH2VsI3v8OzJb7G1TFHraraFrjOKd9zqgaroWZGD+mIWyRPm4eoH9Xuo9Ps/Z6up4c7vUHO4ZqW3Vr9nde6HOl3Vhb2sFZrzu0/ddY86AzHXwLla5msXd0LCTTXcwFCzQeTOuZr6t778D9hVLXzhTSEqOEm/F+VG/M3MaVxN8bfc0FN/4wSkJJbO0DtjoTwT9dSD+s57cWdmTSkhygCz9dQnJycTHBxMjx49sq3v0aMHe/bsyXWfDh06cOXKFTZu3IimaVy/fp0ffviBvn0ze/ruu+8+goODjUH8+fPn2bhxY7Zt7paUlERMTEy2R4Vz+zL8NhXtoxb4nFqJrS6FS/ZNYMQ6GLup+IXkilMBPz09czo772bFa4cofYaCecd/gb2fZAb03k1VL+2IH+HVSzDmN+j8EtQILHsBPYBdlcwvHHdXwc9a9V56ne+t9ZPqucsrYG1v3rYIUcbIXPWi3Di6TmVdeTUxTaeLSw11czw9tXSK5Wma6dPvQdWJ6TgZ7p9mumMKUUxm+3YaGRlJWloaXl5e2dZ7eXkRHh6e6z4dOnTg66+/ZsiQISQmJpKamspDDz3Exx9/bNxm6NCh3Lhxg/vuuw9N00hNTeWZZ55h2rS8/+PNmzeP2bNnm+aNlTW3LqqCZCHfQHoKOuCf9IZ8azeMt55/FmytTHMenxaADqJDIfYGOHoUoo0XICkG9DbFGwIgzKNeN1VkMfKUqiJft6tKZXdwN3fLCq92Z1WV//xf0HyoWpeWAifWq2Wpel8wzR5TszvYuZq7JUKUOcaeeql+L8q6gxmp9y1HmKbYqU6nvi+e+xPCDqqb/CUp7gakJgK6jNpPJmJfFR6cY7rjCWEChe6p9/PzY86cOXmOey8s3V1/JDRNy7HO4Pjx4zz//PO8/vrrBAcH88cff3DhwgUmTJhg3GbHjh289dZbLF68mP/++48ff/yR3377jTffzLsI3PTp04mOjjY+Ll++bJL3ZlZR59R45o9awX9fQXoKUZ7tGJI0k6EprzN82CgcTBXQA9g6g3tGpflr/xVuX0PqvVdj0JuwTaJ0WOjVjAOTD8GAT6DJo+UzoIfsxfI0TS1nTb03TH0n7k0CeiFyJen3oly4fkwVtLOwgqaDTXdc47j6ENMdMy+G8fROPmBpXfLnE8KMCt1T/+KLL7JixQrmzJlD165dGTduHA8//DA2NoUrnuHu7o5er8/RKx8REZGj995g3rx5dOzYkZdffhmAZs2a4eDgQKdOnZg7dy4+Pj7MnDmTkSNHGsfpN23alLi4OJ566ilmzJiBRS6V1W1sbArd/jIr8gz8/QEc+Q60dLWubjei20yh5/dJRGrJPN2lDq39SmDe9uqBqrf2arCapqygwqVInigjarZT4/9jrqobY+71MlPvG/aT1HshRLG5SfV7UR4czJib3r8XOLiZ7rilWQHf1NPZCVGGFbqnftKkSQQHBxMcHEyjRo14/vnn+f/27js+qir94/hnJpWE9EAKJQSUGkAIAgliQWkqAq4rNlAXVFZUiutvZUFFVkVdCy4IdtFdBETFsqIYbHSU3nsJhISQQAoJ6ff3x81MCAlIQpLJJN/36zWvmdy5c+e5lyEnz5xznhMWFsYjjzzChg0X30Pr7u5OdHQ0cXFxpbbHxcURGxtb7muys7PLJOUuLubcXKO4V+18+xiGYd+nzvr2cZh5JWyZbyb0l/eHUT9i3PM5f//Nm5TTebQJ8WFC32pau72yFfBVJE9qC3cvs8gbwMFfoLDArNgPqnovIlUisKF66qWWK8gz/5YEuOKeqj22rac+ubhYXnWqjvn0IrVUpQvlde7cmTfeeIOEhASeeeYZ3nvvPa688ko6d+7MBx98cFEJ9IQJE3jvvff44IMP2LlzJ+PHjyc+Pt4+nH7ixImMGDHCvv+gQYP44osvmD17NgcOHGDlypU89thjdO/enfDwcPs+s2fPZv78+Rw8eJC4uDieeuopbrnlFvsXAHXS6eTitcINc4mwB38xh0Q37caXmxL4fnsSrlYLr97eGQ/XaroO9qR+Q8nQ5T9inLW2fZiK5EktYFva7uAyc+h9dqpZxb3F1Y6NS0TqBNvw+7Qz+RQW1fHOBnFOe5eYbV/DELjshqo9tl8zs00tKoDkai6WZ6t8r556qQcqPZY0Pz+fRYsW8eGHHxIXF0fPnj0ZOXIkx44dY9KkSSxdupRPPvnkgscYNmwYqampTJ06lcTERKKioli8eDEREREAJCYmlpq7f99995GZmcnMmTN5/PHH8ff3p0+fPrz00kv2fSZPnozFYmHy5MkkJCTQqFEjBg0axPPPP1/ZU3UOqfvMe//mcGfJdT+WdoanvzJ/aY674XKimvhVXwwhUebQ5TMnzQJ9gZF//JqMBLPhsLhA4w7VF5vIxWp5Dfz8HBxcDp7F/1/aaei9iFSNAC8zqTcMSMvOI6hhHZn+J3WHbeh9p2FV3/ZZLGZv/f6fzHn11bksnG1OfVUuZydSS1X4f+qGDRv48MMPmTdvHi4uLgwfPpzXX3+dtm3b2vfp168fV199cb1aDz/8MA8//HC5z82ZM6fMtkcffZRHH330vMdzdXXlmWee4Zlnnrmo968zUveb94Gt7JsMw+Dvn28hM6eAK5r5M/qaVud5cRVx9TAT+2MbzNvFJPWJxfPpG7ermfVKRf5IeBdwb2h+ObW5ePihqt6LyIXs/wnm3g4Wa3GVcEvJY4u1+GfAYsUNCxs8Cyg0wO9ND4jsBbd9COXU/BGpcZnHYe8P5uMuVTz03ibsCvP/THXPq1dPvdQjFW5BrrzySvbu3cvs2bM5evQor7zySqmEHqB9+/bccccdVRakXARbT33QZfZN/11zmOV7U/B0s/Lq7Z1xdamBPxhs37gmXGR9Bc2nl9rGxQ0iepmPC/PMKu6RGnovcqlmzZpFZGQknp6eREdHs3z58ot63cqVK3F1deWKK64o89znn39O+/bt8fDwoH379ixatKiKo75IRUVQlA+FueYSWgVnID8L8k6bS7bmpkNOOpw5BWdOEkgGjSwZuJ45ATu+hBO7HBO3yLm2LACjEJp0q75lhmuiAn6pNeqV1EvdV+Ge+gMHDtiHx5+Pt7c3H374YaWDkko4WdxTH2T2xh9MyeL5xTsBeHJAW1o1algzcTSJht/fvfhiebakPlTz6aUWaXmNOacQiqvea6lFkUuxYMECxo0bx6xZs+jVqxdvv/02AwcOZMeOHTRvfv4/uNPT0xkxYgTXX389x48fL/Xc6tWrGTZsGP/85z8ZOnQoixYt4vbbb2fFihX06NGjuk+ptBZXwfjtZiJhFAHF97b6MrbHxc+NX7CRncfS+ST8UwJTN0D8aghpX7Mxi5zLMGBT8dD76uqlh5IK+Mk7oSDXHOlZ1c6cMr9UA/CrwjXqRWqpCnfdJicns3bt2jLb165dy7p166okKKmE1APmfWArCgqLePzTTeTkFxHbKogRMS1qLg5bsbzEzWbl8D+innqpjWzF8kBV70WqwGuvvcbIkSMZNWoU7dq1Y/r06TRr1ozZs2df8HUPPfQQd911FzExMWWemz59On379mXixIm0bduWiRMncv311zN9+vRqOosLcPM0Ewf/ZhAQAQEtILCl+UV7UCsIvhwatYbGbaFxO7L8WrPLaM4R/+7m6+NX13zMIudK2GCOGnFtAFG3Vt/7+Dc3R8EV5cPxaiqWZxt6790Y3BpUz3uI1CIVTurHjBnDkSNHymxPSEhgzJgxVRKUVFBREZwsTuqDWvH2sgNsiE/Dx8OVf/25M1arpeZiCboc3H0gP/uPhxOePgGZxwALhEbVSHgiF6Vxe2h1vTkM/+wEX0QqLC8vj/Xr19OvX79S2/v168eqVavO+7oPP/yQ/fv3n7dGzurVq8scs3///hc8Zm5uLhkZGaVujhBUvKzd/gYdzQ3xaxwSh0gpm/5r3rcbVFIotjpYLNW/Xr2Ws5N6psJJ/Y4dO+jatWuZ7V26dGHHjh1VEpRUUGaiOX/P4sKOM/5MX7oHgGdu6UAT/xr+dtJqhSZdzMd/NAQ/qbiXPugy8PCp3rhEKsJqheFfwP2LNfRe5BKlpKRQWFhISEhIqe0hISEkJSWV+5q9e/fy5JNPMnfuXFxdy58pmJSUVKFjAkybNg0/Pz/7rVkzx/zBb1vWbqe1tbn6S/qRkkrdIo6Qfwa2fm4+7nJ39b9fdc+rV5E8qWcqnNR7eHiUmdcG5vJz52t4pZoVz6cvCmjBhM+2k19o0Ld9CH/q2sQx8YQXf+lz7A+K5WnovYhIvWGxlB41ZhhGmW0AhYWF3HXXXTz77LO0bt26So5pM3HiRNLT0+238kYe1oRAb3MOcWKOK4QV15RRb7040s7/mQUd/ZpDixooDlvdPfVazk7qmQon9bb5a+np6fZtaWlp/OMf/6Bv375VGpxcpOLK9weLQtiVlEmQtzvTbu14wT9sqpW9Av4f9NTbk3oVyRMRqauCg4NxcXEp04OenJxcpqcdIDMzk3Xr1vHII4/g6uqKq6srU6dOZfPmzbi6uvLTTz8BEBoaetHHtPHw8MDX17fUzRGCinvqT2blQfNYc2P8+acNiFQ729D7K+6smeUVbT31x3eYxfKqmnrqpZ6p8P/aV199lSNHjhAREcF1113HddddR2RkJElJSbz66qvVEaP8keI16pelmn+cPD+0I8ENq6GS6MWyFcs7vsMcznU+6qkXEanz3N3diY6OJi4urtT2uLg4YmNjy+zv6+vL1q1b2bRpk/02evRo2rRpw6ZNm+yV7WNiYsoc84cffij3mLVNYKmkvqe5UT314ihpR+DAr+bjK+6qmff0jwBPf7NYXnI1TN9NV1Iv9UuFx8s3adKELVu2MHfuXDZv3kyDBg24//77ufPOO3Fz09xThyguknegKJTWIQ0ZEBXq2Hh8m0DDEDh9HBK3QPNylhY6kwanDpmPtZydiEidNmHCBIYPH063bt2IiYnhnXfeIT4+ntGjRwPmsPiEhAQ+/vhjrFYrUVGli6c2btwYT0/PUtvHjh3L1VdfzUsvvcTgwYP56quvWLp0KStWrKjRc6sMW1KfmpUHzYsr+yfvgOyT4BXowMikXto8DzCgRW9z5YaaYLGYvfUHfjHn1Yd3qdrjq6de6plKTYL39vbmwQcfrOpYpLKKe+oPGaFcfXkjBweD+Yu6STTsXmwOwS8vqU/aat77N9cfMCIiddywYcNITU1l6tSpJCYmEhUVxeLFi4mIiADMujzx8fEVOmZsbCzz589n8uTJPPXUU7Rq1YoFCxbU/Br1lWCrfn8qKw/DOxhL0GXmVLojv0GbAQ6OTuqVoqKaWZu+PGFXmEl9Vc+rz8mAnOJpwppTL/VEpSvb7dixg/j4ePLy8kptv+WWWy45KKmAokKMUwexAAeNMEZeHuzoiEzhXc2k/nzF8mxD79VLLyJSLzz88MM8/PDD5T43Z86cC752ypQpTJkypcz22267jdtuu60KoqtZtp76giKDjDMF+DWPMZP6+FVK6qVmxa8yR066+0C7Gv4bvroq4NuWs2sQAB4Nq/bYIrVUhZP6AwcOMHToULZu3YrFYsEwDKCkAm1hYWHVRigXln4ES2EeuYYrKdZG9IgMcnREJtu8+vMVy7PPp7+iRsIREZGKO3LkCBaLhaZNmwLw22+/8cknn9C+fXuN2LsEHq4uNPRw5XRuAalZuWZSv/E/dWNe/d44KMyHtjc6OhK5GBuLe+mjhoK7V82+t+1vwOQdUJAHru5Vc1wNvZd6qMKF8saOHUtkZCTHjx/Hy8uL7du3s2zZMrp168Yvv/xSDSHKBRUPvY83QujaIogG7i4ODqiYbW7UyQPmHMFzqUieiEitd9ddd/Hzzz8D5rrwffv25bfffuMf//gHU6dOdXB0zq1UsbyI4nn1CRsuXGC2tsvJgPl3wYJ74PQJR0cjfyQ3E3Z8aT6+ooaH3oM5f9/THwrzqrZYnpazk3qowkn96tWrmTp1Ko0aNcJqtWK1WrnqqquYNm0ajz32WHXEKBdSXCTvkBFK79own97GKxACW5qPj20s/VxeFqTsMR8rqRcRqbW2bdtG9+7dAfj000+Jiopi1apVfPLJJ384ZF4urFSxvIBIs8BsUb6Z2DurpC1mgmYUlnx5L7XX9kWQnw1Bl0Oz7jX//hZLyd+BVTmvPu2wee8fUXXHFKnlKpzUFxYW0rChOT8lODiYY8eOARAREcHu3burNjr5Q4UpxWvUG6H0ri3z6W3s69Wf8wfK8e2AAQ1Dwef86wmLiIhj5efn4+FhLpG6dOlSe92ctm3bkpiY6MjQnF6pteotlpIq+M68Xv3Zc6OruviZVD3b0Psr7jI/g45QHfPqbXPq/dVTL/VHhZP6qKgotmzZAkCPHj14+eWXWblyJVOnTqVly5ZVHqBcWGaC+UXKCbcmtA/zdXA05wgvnld/brE8+9B7FckTEanNOnTowFtvvcXy5cuJi4tjwACziNuxY8cICqolNVycVKnh93BWUu/E8+rP7p1P2uK4OOSPpeyDI2vAYoXOdzouDtu8+irtqdeceql/KpzUT548maKiIgCee+45Dh8+TO/evVm8eDH//ve/qzxAuTAj1eyp923aDqvVQd+yno+tp/7oOiguqAiU/OLW0HsRkVrtpZde4u233+baa6/lzjvvpHNn8/f2119/bR+WL5UTWLysXerp4qTeNq/+yG9Q5KRFh89OzDT8vnazLWPX6nrwDXNcHLae+uPbzWJ5VUFz6qUeqnD1+/79+9sft2zZkh07dnDy5EkCAgLsFfClhhTm45uTAECL1h0dHEw5wjqBxQWykiEjAfzM6skqkici4hyuvfZaUlJSyMjIICAgwL79wQcfxMurhitl1zElw+9zzQ0hUeayYrkZZoLjbKPZcjMhZW/Jz6cOmWuFe/o5LCQ5jzNpZ61Nf7dDQyEgEjz8IDcdTuy89L8N87IgO8V8rJ56qUcq1FNfUFCAq6sr27ZtK7U9MDBQCb0DZCbux4UizhjudOvY3tHhlOXWAEKK47LNqy/IheSd5mMl9SIitdqZM2fIzc21J/SHDx9m+vTp7N69m8aNGzs4OucW6G3WKki1Db+3upQUK4tf7aCoLkHSNsAAnzDwK06mkrY6NCQph2HAV2Pg9HEz6W3j4KUHLZaSL7CqYl59+lHz3sMXGvhf+vFEnESFknpXV1ciIiK0Fn0tsXvHJgASXcII8/d2bDDnYy+WV7xeffJOKCowlzDRsCgRkVpt8ODBfPzxxwCkpaXRo0cPXn31VYYMGcLs2bMdHJ1zCzp3Tj2cNa/eCZN6+9S6K0qSNA3Br31Wz4Rd/wMXd/jzR+Dq4eiISobgV8W8ett8ev2NKfVMpebUT5w4kZMny1l7XGpU4qHtAOT4Rjo4kgs4t1je2UPvNbpDRKRW27BhA7179wbgs88+IyQkhMOHD/Pxxx+rjs4lKlMoD0rm1R9eXboWjTOwte/hV5y1TJmK5dUqh1dD3DPm4wHToElXx8ZjYyuWVxU99SqSJ/VUhefU//vf/2bfvn2Eh4cTERGBt3fpHuING5x4fVUnYhgGecfNuWveYW0cHM0F2HvqN0JRkebTi4g4kezsbHx8fAD44YcfuPXWW7FarfTs2ZPDhw87ODrndvY69YZhmNMYm0SD1Q1OJ5lz0gNr8Zf257IlZGGdgeIv7dVTX3ucToaF94FRCB3/DN1GOjqiEuFdzPvj26EwH1zcKn8sLWcn9VSFk/ohQ4ZUQxhSUYdTs2mUdxRcILRlB0eHc36N2oKbF+RlQupeJfUiIk7ksssu48svv2To0KEsWbKE8ePHA5CcnIyvby1bRtXJBBVXv88rKCI1K4/ghh5mLZrwLnD0N3MIvrMk9XlZkGIusWvvdQVzW142uDtxUUXDgP+NNwsBDn0bXCr8p7PjFRXC5yPNL4uC28DN02vXaMmASHMOfG6GOU3zUopEqqde6qkK/2Z65plnqiMOqaDle09wrSUJAI/Glzs4mgtwcTUT+PjV5jI9x80pA0rqRURqv6effpq77rqL8ePH06dPH2JizOHhP/zwA126dHFwdM7Ny92VtqE+7ErK5Oddyfy5W3HPYvOeJUn9FXc5NsiLdXw7GEXQMMRcHs0wwLsRZJ2A5B3QtJujI6y8o7/D+g/Nx816QI8HHRtPZfz8AhxcBm7eMOw/4NHQ0RGVZrWafxceWm52/lxSUq/l7KR+qvCceqkdVu85RrileMmOwFaODeaP2Ibgb1kABWfAvWHtj1lERLjtttuIj49n3bp1LFmyxL79+uuv5/XXX3dgZHXDgKhQAJZsTyrZGBFr3h92omJ5pYbeY/YCh9aRYnnr55Q8/vl5yHaymlJ7lsDyV8zHt/wbGtXSKZv2OgybLu046qmXeqrCSb3VasXFxeW8N6l++YVFHD2wExeLQaGbNzSs5csK2QqxHFpu3od2NL+VFRGRWi80NJQuXbpw7NgxEhISAOjevTtt27Z1cGTOz5bUL9ubwuncAnNjsx7mfepeyEpxUGQVdHblextbkpbkxMXyzqTBti/Mx96NISfN7PV2Fmnx8EXxyIIrH4COtzk2nguxzau/lGJ5BbnmFANQUi/1ToUzq0WLFvHFF1/YbwsWLODJJ58kLCyMd955pzpilHNsPpJG43zzDytr8GW1a15UecLPqa6qofciIk6hqKiIqVOn4ufnR0REBM2bN8ff359//vOfFBUVOTo8p9cmxIcWQV7kFRTxy+5kc6NXIDRqZz52lqXtzq58b1MXlrXbutAcYdioHfzpPXPbuvfh+A7HxnUxCnLh03vNLyLCu0L/5x0d0YXZvhA6vg0KCyp3DNsa9W5e4BVUJWGJOIsKz6kfPHhwmW233XYbHTp0YMGCBYwcWYuqadZRy/emEGlJBMDiDMPYA1pAg0A4UzxkTUm9iIhTmDRpEu+//z4vvvgivXr1wjAMVq5cyZQpU8jJyeH552t5olDLWSwW+keF8vavB/h+WxI3dwo3n2jeE07shPg10G6QY4P8I/lnzOJmULp9tz0+vuPSK5o7gmHA+o/Mx9H3QctrzH+Lnd/A90/CiK9qd6fKkknmcsKe/nB7LVmP/kICW4K7j1lY+cQuCI2q+DHOXqO+Nv/biFSDKhsD3aNHD5YuXVpVh5MLWL73BJHFRfIIcoKk3mIpvRZq6CUUQBERkRrz0Ucf8d577/HXv/6VTp060blzZx5++GHeffdd5syZ4+jw6oQBHcwh+D/vSiYnv9DcaJ9Xv8pBUVXA8e3mMmleweDbpGS7fwuzonlhLpzY7bDwKu3YBji+FVw9odPt5ra+/wQXDzj4K+xe7Nj4LmTrZ/D7u+bjW991jqHotmJ5UPl59fb59CqSJ/VPlST1Z86cYcaMGTRt2rQqDicXkH4mn81H02lhS+qdoaceSorluXjU3iItIiJSysmTJ8udO9+2bVtOnnSygmG1VOem/oT6epKVV8iq/cVz6Jv3NO8TN5vLxdVmtgQs/IrSvaNWa8mX+M44r95WIK/9YHNKBJhLDMaMMR8vmWQOca9tTuyGrx8zH/f+G7Tu59h4KsI2faOy8+rta9Q7wZcYIlWswkl9QEAAgYGB9ltAQAA+Pj588MEH/Otf/6qOGOUsq/enUlhkcJnrcXODM/TUA7Tobd436+58Q/BEROqpzp07M3PmzDLbZ86cSadOGnVVFaxWC/07hADw/bazinz5NjV7wI/+7sDoLsK5le/P5qzz6nMzYevn5uPo+0o/13sCNAyFUwdhzewaD+2Cck/DguGQnwWRV8N1/3B0RBVjm1df6Z56LWcn9VeF59S//vrrWM76JtZqtdKoUSN69OhBQEBAlQYnZS3fewJPcmlspJobgi5zbEAXK7I33POFeulFRJzIyy+/zE033cTSpUuJiYnBYrGwatUqjhw5wuLFtXj4sZPpHxXKR6sPE7fjOAWFRbi6WM3e+m2fmfPqW17r6BDPr7zK9zb24dRO1lO/9TMzMQ5uDc1jSj/n4QM3TIEvR8Oyf0HnO8EnxCFhlmIY8M1YSNkNPmHwpw/A6mSrUtl66pOKi+W5VDBN0XJ2Uo9VOKm/7777qiEMuVgr9qXQwlLcS+/pXzIkzBlcdr2jIxARkQq45ppr2LNnD2+++Sa7du3CMAxuvfVWHnzwQaZMmULv3r0dHWKd0L1FIAFebpzKzue3QyeJbRUMETFmUl+b59UX5JYUyTu78r3N2cPvi4qcZzlb29D7rveWX3Ct0zBzznrCevhxKgx5s0bDK9e6983Pi8UFbvsQGjZydEQVF9iqpFheym4I6XDxrzUMSDtsPlZSL/VQhX+7fvjhhyxcuLDM9oULF/LRRx9VSVBSvsOpWRxOzaaV1YmK5ImIiFMLDw/n+eef5/PPP+eLL77gueee49SpU2rzq5Cri5W+7c3e3iW2IfjNi4vlHV1nVo+vjY5vh6ICaBBQ/pDn4NZmobm80+ZwdWdwbJM5+sDF3eyFL4/VCgNeNB9v+i8kbKia9zYMSN5lTlc4sQdOHYbTyZCTAQV55vPlSVgP3080H/d91vxCyBlZrSVTNioyr/7wanjvesgwl3smoEVVRyZS61W4p/7FF1/krbfeKrO9cePGPPjgg9x7771VEpiUtXyvWUAnNiAdTuM8RfJERETkggZEhfLpuqMs2X6cZwZ1wNqorTkiLyfN7Om2FZytTc4eel9ej7aLq9nbmrDeTFSdoTNiQ/GXVe0GgfcF1jpv1t3ssd+ywFzi7i9LLm0ZtfwzsGg07Pjy/PtYrOaXJLabW/F9xjEozIO2N0PMI5WPoTYIuwIOrzQ/W13uvvC+qfth6TPmMoMAbt5w3URo2Li6oxSpdSrcU3/48GEiIyPLbI+IiCA+Pr5KgpLyrShO6q/wts2nd4LGUURERP5QbKtgGnq4kpSRw+ajaWavpa0Kfvwah8Z2XrYCeOUNvbcJdaJieXlZsKV4NOq5BfLKc8MUcPOCI2th2+eVf9/TyTDnZjOht7qahfg8/c2E/WxGEeRnw5mTkHkMTh6A5B3mFz8BkTD4Tedfn/1iKuBnn4TvnoQ3u5sJvcVq/ns9thFiH62BIEVqnwr31Ddu3JgtW7bQokWLUts3b95MUNAFvtGUS1JQWMTK4qVuIrANv3eSInkiIiJyQZ5uLlzXtjHfbD7G99uT6NI8wEzq93xvzqu3LaVWm1yo8r2N7TlnWNZu2xfmfO7AliWr9lyIbzhcNQF+fg7inoY2A8Hdu2LvmbwT5t4O6fFmIn/HXGhxVcnzhmHWLig4Y97nnyn5OT8HCnLMXvom0dDAv2LvXRvZCi4mbS1bLK8gF357xyxQmJNubrusL/SdCiHtazxUkdqkwkn9HXfcwWOPPYaPjw9XX301AL/++itjx47ljjvuqPIAxbQlIZ3MnAL8GrjhnVVcCCSwpWODEhGROunWW2+94PNpaWk1E0g9M6BDKN9sPsaSbUk8OaAtFtu8+vg1ZnJXm3phC/LMXmIov/K9zdnL2tW2czjXHxXIK0/sI7DhYzMpX/lGxZaR2/cjLLwPcjPMv+nuWgjB53TYWCzmMHs3z3IPUecEXQbuDc06DCl7zGTdMGD7Ilg6paQYXkgU9PsntOrj0HBFaosKJ/XPPfcchw8f5vrrr8fV1Xx5UVERI0aM4IUXXqjyAMW0fI/ZS399pCeWA062Rr2IiDgVPz+/P3x+xIgRNRRN/XFtm0a4u1o5lJrN7uOZtA2/Alw8IDsFUvdB8OWODrHEiZ1mD7Gn34ULkzXuYFZkz0415377NamxECskaRskrDOHv19x18W/zq2BmVwuvNdM6rsMB/+LWCd93Qfw7d/AKDSLIt4x17lWNKouVqs5ZSN+lTmvPjcTfpgER383n28YCtc/ZRYxdLYl+0SqUYWTend3dxYsWMBzzz3Hpk2baNCgAR07diQiIqI64pNiy/eeAKBvaDYcALyCzYZURESkin344YeODqFe8vZw5erLg1m6M5nvtyXR9obW0LSbWTgsfnXtSurPHnp/oV5tN09o1BaSt5u99bU1qbcVyGt7U8ULrbUfDBFXweEV5jD8P1/g/09RobnP6pnmz53ugFv+Da4elYu7Lgq/wkzq456BrGRzm5s39Bprjoyo6BQHkXqg0guGXn755fz5z3/m5ptvVkJfzTJz8tl4JA2AK31PmRvVSy8iIlLn9O8QCsCS7cWj8mzF8g6vdlBE52ErfHehofc2tX1efV62WcUeLq5A3rksFhgwDbDA9i/MGgjlvk8WLBhektBfNxmGvqWE/ly2z1RWslkEr+sIeGwDXPt3JfQi51HhpP62227jxRdfLLP9X//6F3/+85+rJCgpbfX+VAqLDCKDvQnOPWpuVJE8ERGROueGdiG4WC3sTMzgcGpWyXr18bUtqd9k3l+o8r2NfV59LU3qd3xlFl7zj4DIayt3jLBOEF28rPN3fzd75M+WkQgfDoTd35pTKv70PlzzRO2uMeAol90AwW3g8v4wegXcMgN8Qh0dlUitVuGk/tdff+Wmm24qs33AgAEsW7asSoKS0mzr0191WTCc3G9uVJE8ERGROifA252eLc251Uu2J0GzKwELnDoImUmODc6mMN+cgw4X11Nf25e1sxfIG2HO6a6sPk+Bh585ImHT3JLtSVvhvevN8/cKgnu/gY63XVLIdZp3EDzyG9z9KYR0cHQ0Ik6hwr+5Tp8+jbu7e5ntbm5uZGRkVElQUtqKfWZS3/vyYLNQDmj4vYiISB01oHgI/vfbksz6OaFR5hO1pbf+xG4ozAUPX3N99D8S2tG8zzgKWanVG1tFJe+CI2vMYn5d7rm0Y3kHm0PEAX6cavb+71kCHwyAjAQIbg2jfoTmPS49bhGRs1Q4qY+KimLBggVlts+fP5/27bVGZFU7cjKbgylZuFgt9GwVBKm2nnol9SIiInVRv+KkfkN8GsczcqB5jPlEbZlXbxt6H9b54nq2PX1LRhgm1bLeeluBvDYDq2aI95UPmFMks07Af2+DeXeYy7NFXgMj4yDwIr4EERGpoApXv3/qqaf405/+xP79++nTx1wb8scff+STTz7hs88+q/IA6ztbL32XZv74GqfhzEnzCQ2/FxERqZNCfD3p2tyfDfFp/LA9ieHNY+C3d2pPT/3Zle8vVlhnOHnAnFdfW9YWz8+BzfPMx5UpkFceV3foPw0++TMc/c3c1mU43Pw6uLhVzXuIiJyjwj31t9xyC19++SX79u3j4Ycf5vHHHychIYGffvqJFi1aVEOI9ZttKbvelzeC1APmRp8w8GjowKhERESkOg2IKh6Cvz2ppKf++DbIqQVTHStS+d6mNs6r3/kNnDkFfs2q9ouG1v2gw1CzcvsNz5qF3pTQi0g1qlQ1kJtuuomVK1eSlZXFvn37uPXWWxk3bhzR0dFVHV+9VlhksHKfOffsqsvPLpKnofciIiJ1mW1puzUHTnLKJQgCWoBRVNL76yiFBWbhN7i4yvc2tXFZO1uBvC7DwepStcf+0wfwfwfhqnGqcC8i1a7SJT5/+ukn7rnnHsLDw5k5cyY33ngj69atq8rY6r2tCemkn8nHx9OVzk39ziqSp6H3IiIidVlEkDftwnwpLDJYuvN47ZlXn7IHCs6Ae8OKdTLYkvrUfZCbeelxFBVB/Fpz7ffKSNkHh1eYvemXWiCvPFYrNPCv+uOKiJSjQkn90aNHee6552jZsiV33nknAQEB5Ofn8/nnn/Pcc8/RpUuX6oqzXlq+xxx6H9sqCFcXq4rkiYiI1CO2KvhLzh6CH7/GgRFRMnw+tFPFln/zDgafcPOxbTm8S7HiVfigH7xxBax5y5wfXxEb5pj3l/cDvyaXHo+IiANd9G/jG2+8kfbt27Njxw5mzJjBsWPHmDFjRnXGVu/Z1qfvfXkjc4Nt+L2WsxMREanzbPPql+1NISvsSnNjwjooyHVcULbK9xUZem9TVUPwC3Jh7dvm46xk+P7vMKMrrPsQCvMv7vWbPjEfV1WBPBERB7ropP6HH35g1KhRPPvss9x00024uFTx3CMp5XRuARviTwFw9eWNwDBKCuUFXebAyERERKQmtA5pSGSwN3kFRfxywh+8gqAgx7HF5uxF8ipQ+d4mrIqK5W3/0lwyzifcrCrv28RcB/5/42BmN9g0D4oKz//6Xd9CdqpZePiyvpcWi4hILXDRSf3y5cvJzMykW7du9OjRg5kzZ3LixInqjK1eW7M/lYIig+aBXjQP8jIbn9x0wAIBWuNURESkrrNYLPaCed/vOHte/SrHBFRUaC5JBxWrfG9j+yIg8RJ76n97x7y/8i/Q7S/w6AYY8BJ4N4ZTh+DL0TCrJ2z7wpx7f66zC+S5VHh1ZxGRWueik/qYmBjeffddEhMTeeihh5g/fz5NmjShqKiIuLg4MjOroOiJ2NnWp+99ebC5wTaf3q8puHk6KCoREZHKmTVrFpGRkXh6ehIdHc3y5cvPu++KFSvo1asXQUFBNGjQgLZt2/L666+X2mfOnDlYLJYyt5ycCs6truX6dwgB4Kedx8lv2sPc6Kh59an7ID8L3Lwg+PKKv962rN2JnZWfQpCw3pyC4OIOXe8zt7l5Qs/RMHaTuYRcgwCzoN9n98PbV8Pu78wRjwAnD8DBXwELdB1euRhERGqZCle/9/Ly4i9/+QsrVqxg69atPP7447z44os0btyYW265pcIBVKSRB5g7dy6dO3fGy8uLsLAw7r//flJTU0vtk5aWxpgxYwgLC8PT05N27dqxePHiCsfmSMvs69PbkvriyveBqnwvIiLOZcGCBYwbN45JkyaxceNGevfuzcCBA4mPjy93f29vbx555BGWLVvGzp07mTx5MpMnT+add94ptZ+vry+JiYmlbp6edeuL785N/Qn19SQrr5BNlrbmxvjV5fdAVzd7kbyOlVsCzq8pNAiEogJI3lG5GH57z7zvMBQaNir9nLu3uYTc2C1w7UTw8IXjW2HeHfDe9bD/J9jwsbnvZdeDf/PKxSAiUstUekk7gDZt2vDyyy9z9OhR5s2bV+HXV7SRX7FiBSNGjGDkyJFs376dhQsX8vvvvzNq1Cj7Pnl5efTt25dDhw7x2WefsXv3bt59912aNHGeyqYJaWc4cCILqwViWhUn9SqSJyIiTuq1115j5MiRjBo1inbt2jF9+nSaNWvG7Nmzy92/S5cu3HnnnXTo0IEWLVpwzz330L9//zJf/FssFkJDQ0vd6hqr1WLvrf/8WJDZS56TBseroIJ8RR3bZN5XZug9mOu1X8q8+qwU2Pa5+bj7g+ffz9MXrn0Sxm6Gq8ab1yxhPfxnKKx8w9yn670Vf38RkVrqkpJ6GxcXF4YMGcLXX39doddVtJFfs2YNLVq04LHHHiMyMpKrrrqKhx56iHXr1tn3+eCDDzh58iRffvklvXr1IiIigquuuorOnStR0MVBtiWkA9A+3Be/Bm7mRtvwexXJExERJ5KXl8f69evp169fqe39+vVj1aqLmxu+ceNGVq1axTXXXFNq++nTp4mIiKBp06bcfPPNbNy48YLHyc3NJSMjo9TNGfQvroK/ZGcqRS16mxv/N67mq+DbKt9XpkiezaXMq9/wMRTmQngXaBL9x/t7BcINU8zkvufD4OIBRpE5977NwIq/v4hILVUlSX1lVKaRj42N5ejRoyxevBjDMDh+/DifffYZN910k32fr7/+mpiYGMaMGUNISAhRUVG88MILFBaevwpqbWvkT2XlAdDY56whhCe1Rr2IiDiflJQUCgsLCQkJKbU9JCSEpKSkC762adOmeHh40K1bN8aMGVNqZF7btm2ZM2cOX3/9NfPmzcPT05NevXqxd+/e8x5v2rRp+Pn52W/NmjW7tJOrId1bBBLg5cap7Hw2dpgInv5mz/OSSTUXRFFRSSJemeXsbGzz6iu6rF1hAaz7wHzc/UGz1/9iNWwMA6bBYxuhz2S4Yy64uFXs/UVEajGHJfWVaeRjY2OZO3cuw4YNw93dndDQUPz9/ZkxY4Z9nwMHDvDZZ59RWFjI4sWLmTx5Mq+++irPP//8eWOpbY38qWxzjdUAL3dzQ6nl7JTUi4iI87Gck4QZhlFm27mWL1/OunXreOutt5g+fXqpqX49e/bknnvuoXPnzvTu3ZtPP/2U1q1bl/qb4FwTJ04kPT3dfjty5MilnVQNcXWx0re9+ffS14fd4NZ3zSd+fxe2fFozQZw8AHmZ4OoJwW0qfxz7WvXbLrzs3Ln2fAfpR8xl/TrcWrn39msCVz8BzbpX7vUiIrWUw5J6m4o08jt27OCxxx7j6aefZv369Xz//fccPHiQ0aNH2/cpKiqicePGvPPOO0RHR3PHHXcwadKk8w7ph9rXyJ/KNnvqA7yKv0XOTDKrzVqs4B/hwMhEREQqJjg4GBcXlzJf2CcnJ5f5Yv9ckZGRdOzYkQceeIDx48czZcqU8+5rtVq58sorL9hT7+Hhga+vb6mbsxhgG4K//ThFl/WFq//PfOKbsXC8kkXnKsI29D4k6tKWgQtsBe4NoeAMpJz/36oM2zJ2Xe/VKkAiIudwWFJfmUZ+2rRp9OrViyeeeIJOnTrRv39/Zs2axQcffEBiYiIAYWFhtG7dGheXkqqs7dq1Iykpiby8vHKPW9saedvw+wDv4p5629B7/+bg6u6gqERERCrO3d2d6Oho4uLiSm2Pi4sjNjb2oo9jGAa5ueefQ24YBps2bSIsLKzSsdZmsa2CaejhSlJGDpuPppmF4FpeB/nZsOAeyKnmqYO2pP5Sht4DWK3mFwNw8cXyknfBwWVm50a3v1za+4uI1EEOS+or08hnZ2djtZYO2Za8G8Xrj/bq1Yt9+/ZRdNZSL3v27CEsLAx3d+dIiG3D7/29VCRPRESc34QJE3jvvff44IMP2LlzJ+PHjyc+Pt4+0m7ixImMGDHCvv+bb77JN998w969e9m7dy8ffvghr7zyCvfcc499n2effZYlS5Zw4MABNm3axMiRI9m0aVOp0Xt1iaebC9e1bQzA99uTzCXl/vQ++DY1v/z/6uGStdirw6VWvj+bfQj+Rc6r/714ukGbG8HfOeogiIjUJIcOv69oIz9o0CC++OILZs+ezYEDB1i5ciWPPfYY3bt3Jzw8HIC//vWvpKamMnbsWPbs2cO3337LCy+8wJgxYxxyjpWRVjz8PtDrnJ56FckTEREnNGzYMKZPn87UqVO54oorWLZsGYsXLyYiwpxSlpiYWGo526KiIiZOnMgVV1xBt27dmDFjBi+++CJTp06175OWlsaDDz5Iu3bt6NevHwkJCSxbtozu3evufOkBHYqH4G9LMjszvIPg9o/A6gY7v4HVM6vnjQ2jpEjepVS+t6nIsnY56bCpuJbChZaxExGpxy5hUtSlGzZsGKmpqUydOpXExESioqIu2Mjfd999ZGZmMnPmTB5//HH8/f3p06cPL730kn2fZs2a8cMPPzB+/Hg6depEkyZNGDt2LH//+99r/Pwqyzan3t+W1KdqjXoREXFuDz/8MA8//HC5z82ZM6fUz48++iiPPvroBY/3+uuv8/rrr1dVeE7h2jaNcHe1cig1m+3HMohq4gdNu5mV3Rf/DeKegfCu0KJX1b7xqYOQm24uCde43aUf7+xl7QzjwpXsN8836woFt4HIqy/9vUVE6iCHJvVQsUYeLq6hj4mJYc2aNVURnkPYq997nzP8Xj31IiIi9Za3hyt924fw7ZZEXli8k7mjepjFha8cBUd+g62fwmf3w0PLwCe06t7YNvQ+pEPVLAXXqC24uJtfFJw6BIGR5e9XVFRSIK/7AxVbxk5EpB5xePV7Ka2oyLAPvw/wcjcbtFMHzSeDWjowMhEREXG0Jwe0xcPVyqr9qXy9+Zi50WKBQdOhcXs4fRwW3g+F+VX3prYieVUx9B7MLwYatzcfX2he/YGfIXUfuPtA5zuq5r1FROogJfW1TGZOAUXFdW78vdwgIwEKcsz5cn7NHRuciIiIOFSzQC8euc4snPvctzvJyClO3t294fb/mAlw/Cr48dmqe1Pb3PdLrXx/Nvu8+gsk9b8VF8jrcjd4+FTde4uI1DFK6msZ23x6b3cXPFxdSorkBbS4tHVhRUREpE548JqWRAZ7cyIzl9fj9pQ8EXwZDJllPl41A3Z8felvZhhVW/neJvQPiuWdOgR7vjcfXzmq6t5XRKQOUlJfy5xUkTwRERG5AA9XF6YO7gDAR6sOsf1YesmT7W+B2OLaQ18+DCn7Lu3N0uIhJ80cMVgVRfJsbF8QnG/4/e/vAwa06gPBl1fd+4qI1EFK6msZ+3x6W5G8kwfMexXJExERkWK9L2/ETZ3CKDLgqS+3UVR01hr110+BiF6QlwmfDoe8rMq/kW0+fUh7cPW4lJBLC+kAFqtZAyAzqfRzedmw4WPzsZaxExH5Q0rqa5lTWcWV7+099cXfsKtInoiIiJzlqZva4+3uwob4NBauP1LyhIsr3PYBNAyB5B3wv/HmMPrKqI6h9wDuXhDc2nx87rz6bZ+bowP8m8Pl/ar2fUVE6iAl9bXMqbMr38NZw+8vc1BEIiIiUhuF+nkyvq+ZGL/43S5OZeWVPOkTCrd9CBYX2LIA1r1fuTexzXmvqsr3ZytvXr1hwG9vm4+vHAVWl6p/XxGROkZJfS1TktS7QWGBWSgGNPxeREREyrg3tgVtQnw4lZ3Py0t2lX6yRS/oW1wF/7snYdMnFVvqzjBKht9XZeV7G9sXBUlnJfVH1kLSVnD1hC7Dq/49RUTqICX1tcypbLOx9fdyh/QjUJRvNmy+TRwcmYiIiNQ2bi5WnhsaBcD834+wIf5U6R1iHoF2t5h/T3z5V/h3F1g9C3JP//HB049CdipYXaFxh6oPvrxl7X57x7zveBt4BVb9e4qI1EFK6muZtLN76u3L2UWCVf9UIiIiUtaVLQK5LbopRnHRvMKzi+ZZLHDru9DnKfBubHYYLJkIr3eAH/8Jp5PPf2DbsPhG7cDNs+oDtw2/TzsMZ06ZBfN2fGVuU4E8EZGLpkyxlrEXyvN213J2IiIiclGeHNgWX09Xth/L4L9rDpd+0s0Trv4bjNsKg94wp/TlpMHyV+D1KPhmXMnfHGezD72vhvn0AA38wT/CfJy0FdbPgaICaNazeubwi4jUUUrqa5lShfKU1IuIiMhFCG7owf8NaAvAK0t2k5yZU3YnN0+Ivg8e+R1u/w806QaFubD+Q5gRDQuGw9H1JftXV+X7s9mG4B9dB+s+MB93f6D63k9EpA5SUl/LlErqbcPvVSRPRERE/sCd3ZvTqakfmbkFvPDtzvPvaHWB9rfAqKVw/3fQegBgwM6v4b0+8OFNsOeHsyrfX1F9Qdt65Fe/aa5Z3zDErAEgIiIXTUl9dTOM8oe0lburcVahPDf11IuIiMhFc7FaeG5IFBYLfLnpGKv3p174BRYLRMTCXQvg4TVwxd1gdYPDK+CTP0NWsrkkXmhU9QUdWpzUZ6eY99H3g6t79b2fiEgdpKS+um2aC292h6XPQv6ZC+56Jr+QvIIiAAI9LZAWbz6hnnoRERG5CJ2a+nNPD3Oe+lNfbbP/XfGHGreDIbNg7GaIfRTcfcztYZ3BrUE1RUvpufNWV3N6gIiIVIiS+uoWv8Ys+rLiNZgdCweXnXdXWy+9u4sVr+yjYBSCmzf4hNZUtCIiIuLk/tavDUHe7uxLPs0HKw9W7MV+TaDfczB+Gwx926ycX518Qswh92AOu/cNq973ExGpg5TUV7fBM2HYXPAJg5MH4KNB8OUYyD5ZZtdTWeZ8en8vNyy2ofeBLc3hcSIiIiIXwc/LjX/c2A6AN5buJSHtwiMFy9XAHzrfAcGXVW1w5Wl3C7h5Qa+x1f9eIiJ1kJL6mtDuZhizFq4cBVhg03/NIflbPzPn3Bcrt0ie5tOLiIhIBd3atQndWwRyJr+Qf36zw9HhXNiN/4L/OwDhVzg6EhERp6SkvqZ4+sFNr8JflkCjtpB1Aj4fCXP/bJ87bxt+H+CtInkiIiJSeRaLhX8OicLFauH77Un8vDvZ0SGdn8VSvfP2RUTqOCX1Na15D3hoOVw3CVzcYV8cvNkDVr9JepY5PE7L2YmIiMilahPqw196tQDgma+2k5Nf6NiARESkWiipdwRXd7jm/2D0SmgeC/nZsOQf9F11N+0th/D3cofUA+a+6qkXERGRShp7Q2tCfT2JP5nNrF8uboldERFxLkrqHalRa7jvWxj0Bnj4EXp6J1+7T2boiVmQfsTcRz31IiIiUkkNPVx5elB7AN76ZT/7kk87OCIREalqSuodzWo112R95Dc2+lyLq6WI7omfAAZ4+IF3sKMjFBERESc2MCqUPm0bk1dYxKRFWzHOKtIrIiLOT0l9beETyusBkxiZ9zjZnsXr0jduq+XsRERE5JJYLBaevaUDDdxcWHvwJJ+tP+rokEREpAopqa9FTmXl8WNRNL/duBgGvAg3vebokERERKQOaBboxbgbLgfghcU7OZmV5+CIRESkqiipr0Vs69T7+AVCz79CaJSDIxIREZG64i9XRdI21IdT2fk8/+1OR4cjIiJVREl9LZJmW6fey83BkYiIiEhd4+Zi5YVbO2KxwOcbjrJqf4qjQxIRkSqgpL6WyCso4nRuAQCB3u4OjkZERETqoq7NA7inRwQAkxdtI7dAa9eLiDg7JfW1RFrx0HurBXw91VMvIiIi1eOJAW1o5OPBgZQsZmvtehERp6ekvpY4VTz03q+BG1arKt6LiIhI9fD1dOOZ4rXrZ/28n/0ntHa9iIgzU1JfS9iK5AV4aei9iIiIVK+bOoZxbZtGWrteRKQOUFJfS9iG3wdoPr2IiIhUM4vFwj8HR+HpZmXNgZN8viHB0SGJiEglKamvJU6p8r2IiIjUIHPt+tYAPP/tDq1dLyLipJTU1xK2htRfw+9FRESkhow8a+36aYu1dr2IiDNSUl9L2Iffq6deREREaoibi5Xnh3YEYOH6o6zen+rgiEREpKKU1NcStuH36qkXERGRmhQdEcDdPZoDMOnLrVq7XkTEySipryVsPfWBKpQnIiIiNez/BrQluKEHB05k8dYvBxwdjoiIVICS+lrCNqdew+9FRESkpvk1KFm7/s2f93FAa9eLiDgNJfW1RJqG34uIiIgD3dwpjKtbm2vXT/5ym9auFxFxEkrqa4lT9kJ5SupFRESk5lksFp4bHIWHq5VV+1NZtFFr14uIOAMl9bVAYZFB+pnideq9NfxeRETqnlmzZhEZGYmnpyfR0dEsX778vPuuWLGCXr16ERQURIMGDWjbti2vv/56mf0+//xz2rdvj4eHB+3bt2fRokXVeQr1QvMgL8becDkAz327k1Nau15EpNZTUl8LZJzJp6h4hJt/A/XUi4hI3bJgwQLGjRvHpEmT2LhxI71792bgwIHEx8eXu7+3tzePPPIIy5YtY+fOnUyePJnJkyfzzjvv2PdZvXo1w4YNY/jw4WzevJnhw4dz++23s3bt2po6rTrrgd4taRPiw8msPCZ9uZWCwiJHhyQiIhdgMTRhqoyMjAz8/PxIT0/H19e32t/vwInT9Hn1Vxp6uLLt2f7V/n4iIuJ8arptqko9evSga9euzJ49276tXbt2DBkyhGnTpl3UMW699Va8vb35z3/+A8CwYcPIyMjgu+++s+8zYMAAAgICmDdv3kUd05mvaXVbf/gkt7+9hsIigxs7hjJ9WBfcXdUXJCJSnSrbLum3cy1Qska9ht6LiEjdkpeXx/r16+nXr1+p7f369WPVqlUXdYyNGzeyatUqrrnmGvu21atXlzlm//79L3jM3NxcMjIySt2kfNERgbx5V1fcXaws3prEg/9ZR06+1q8XEamNlNTXAlqjXkRE6qqUlBQKCwsJCQkptT0kJISkpKQLvrZp06Z4eHjQrVs3xowZw6hRo+zPJSUlVfiY06ZNw8/Pz35r1qxZJc6o/hgQFcp793bD083KL7tPcO8Hv3E6t8DRYYmIyDmU1NcCtjXqtZydiIjUVRaLpdTPhmGU2Xau5cuXs27dOt566y2mT59eZlh9RY85ceJE0tPT7bcjR45U8Czqn6tbN+I/I3vg4+HK2oMnufu9tfbOCBERqR2U1NcCtjXqAzT8XkRE6pjg4GBcXFzK9KAnJyeX6Wk/V2RkJB07duSBBx5g/PjxTJkyxf5caGhohY/p4eGBr69vqZv8sStbBPLJAz0J8HJj85E07nhnDScycx0dloiIFFNSXwtojXoREamr3N3diY6OJi4urtT2uLg4YmNjL/o4hmGQm1uSSMbExJQ55g8//FChY8rF69jUjwUPxdDIx4NdSZnc/vZqEtLOODosEREBXB0dgJQUylNSLyIiddGECRMYPnw43bp1IyYmhnfeeYf4+HhGjx4NmMPiExIS+PjjjwF48803ad68OW3btgXMdetfeeUVHn30Ufsxx44dy9VXX81LL73E4MGD+eqrr1i6dCkrVqyo+ROsJ1qH+LDwoRjufm8tB1OyuP2t1cwd1YMWwd6ODk1EpF5TUl8L2OamBXhr+L2IiNQ9w4YNIzU1lalTp5KYmEhUVBSLFy8mIiICgMTExFJr1hcVFTFx4kQOHjyIq6srrVq14sUXX+Shhx6y7xMbG8v8+fOZPHkyTz31FK1atWLBggX06NGjxs+vPmkR7M3C0THc895aDqRk8ee3V/PfkT1oE+rj6NBEROotrVNfjppet3bY26tZe/Ak/76zC7d0Dq/29xMREeejNdWrnq5p5Z3IzGX4+2vZlZSJv5cbH/+lO52a+js6LBERp6Z16p2YCuWJiIiIM2nk48H8B3vSuZk/adn53PXuWn47eNLRYYmI1EtK6msBFcoTERERZ+Pv5c7cUT3o2TKQ07kFjPhgLcv2nHB0WCIi9Y6SegczDKOkp95bSb2IiIg4j4Yersy5vzvXtmlETn4Roz5ax/fbkv74hSIiUmUcntTPmjWLyMhIPD09iY6OZvny5Rfcf+7cuXTu3BkvLy/CwsK4//77SU1NLXff+fPnY7FYGDJkSDVEXjWy8grJKywCNPxeREREnI+nmwvvDO/GjR1DySss4q9z1/Pmz/tQ2SYRkZrh0KR+wYIFjBs3jkmTJrFx40Z69+7NwIEDS1XAPduKFSsYMWIEI0eOZPv27SxcuJDff/+dUaNGldn38OHD/O1vf6N3797VfRqX5FSWOfTe3dVKAzcXB0cjIiIiUnHurlb+fUcX7urRHMOAfy3ZzcNzN3A6t8DRoYmI1HkOTepfe+01Ro4cyahRo2jXrh3Tp0+nWbNmzJ49u9z916xZQ4sWLXjssceIjIzkqquu4qGHHmLdunWl9issLOTuu+/m2WefpWXLljVxKpV2dpE8i8Xi4GhEREREKsfVxcoLQzvywtCOuLlY+G5bEkPfXMnBlCxHhyYiUqc5LKnPy8tj/fr19OvXr9T2fv36sWrVqnJfExsby9GjR1m8eDGGYXD8+HE+++wzbrrpplL7TZ06lUaNGjFy5MiLiiU3N5eMjIxSt5qiInkiIiJSl9zVoznzH4yhsY8He5NPc8vMFfy067ijwxIRqbMcltSnpKRQWFhISEhIqe0hISEkJZVfYCU2Npa5c+cybNgw3N3dCQ0Nxd/fnxkzZtj3WblyJe+//z7vvvvuRccybdo0/Pz87LdmzZpV7qQqQUm9iIiI1DXREQH879Gr6BYRQGZOASM/WscbS/dSVKR59iIiVc3hhfLOHXJuGMZ5h6Hv2LGDxx57jKeffpr169fz/fffc/DgQUaPHg1AZmYm99xzD++++y7BwcEXHcPEiRNJT0+3344cOVL5E6og25z6AG8VyRMREZG6o7GvJ5880JPhPSMwDHh96R4e+u96MnPyHR2aiEid4uqoNw4ODsbFxaVMr3xycnKZ3nubadOm0atXL5544gkAOnXqhLe3N7179+a5557j+PHjHDp0iEGDBtlfU1RkVpZ3dXVl9+7dtGrVqsxxPTw88PDwqKpTq5BTxXPq/dVTLyIiInWMu6uVfw6JomNTPyZ/uY24HccZ/OZK3hnejcsaN3R0eCIidYLDeurd3d2Jjo4mLi6u1Pa4uDhiY2PLfU12djZWa+mQXVzMivGGYdC2bVu2bt3Kpk2b7LdbbrmF6667jk2bNtXosPqLlVY8/D5QSb2IiIjUUbd3a8bCh2II8/PkwIkshry5kiXbtZ69iEhVcFhPPcCECRMYPnw43bp1IyYmhnfeeYf4+Hj7cPqJEyeSkJDAxx9/DMCgQYN44IEHmD17Nv379ycxMZFx48bRvXt3wsPDAYiKiir1Hv7+/uVury1Keuo1/F5ERETqrs7N/Pnm0asYM3cDaw+e5KH/rOexPpcx7obWWK1aAUhEpLIcmtQPGzaM1NRUpk6dSmJiIlFRUSxevJiIiAgAEhMTS61Zf99995GZmcnMmTN5/PHH8ff3p0+fPrz00kuOOoVLpkJ5IiIiUl8EN/Tgv6N68MLinXy48hD//mkfWxPSmX5HF/waqINDRKQyLIZhqAzpOTIyMvDz8yM9PR1fX99qfa+bZyxnW0IGH9zXjT5ty68lICIiUpNtU32ha+pYizYe5cnPt5JbUESLIC9m3xNNuzD9O4hI/VXZdsnh1e/ru1NZKpQnIiIi9c/QLk35/K+xNPFvwKHUbIa8uZJP19XcCkQiInWFknoHU6E8ERERqa+imvjxv0ev4to2jcgtKOL/PtvCEws3cyav0NGhiYg4DSX1DpRbUEhWcaOlOfUiIiJSHwV4u/PBvVfyt36tsVpg4fqjDJ21kgMnTjs6NBERp6Ck3oHSiivfWy3g4+nQmoUiIiIiDmO1Wnikz+X8d1QPght6sCspk1tmruTbLYmODk1EpNZTUu9Atsr3/l7uWspFRERE6r3YVsEsfuwqukcGcjq3gDGfbGDK19vJKyhydGgiIrWWknoHshXJC9Aa9SIiIiIANPb15JNRPRh9TSsA5qw6xJ/fXs3RU9kOjkxEpHZSUu9AWqNeREREpCxXFytPDmzL+/d2w6+BG5uPpHHzjBX8vCvZ0aGJiNQ6Suod6Ozh9yIiIiJS2vXtQvjfo1fRqakfadn53D/nd17+fhcFhRqOLyJio6TegWyF8jT8XkRERKR8zQK9WDg6hhExEQDM+mU/97y/luTMHAdHJiJSOyipd6BTWcVr1Hurp15ERETkfDxcXZg6OIoZd3bB292FNQdOcuMbK/j90ElHhyYi4nBK6h3opIbfi4iIiFy0QZ3D+frRq2gT4kPK6VzufnctX25McHRYIiIOpaTegTT8XkRERKRiWjVqyKIxsQzoEEpeYRHjFmzi9bg9GIbh6NBERBxCSb0DqVCeiIiISMV5ubsy6+6uPHRNSwDe+HEvY+dvIie/0MGRiYjUPCX1DmTrqdecehEREZGKsVotTBzYjhdv7Yir1cLXm49xz3trST2d6+jQRERqlJJ6BypZp17D70VEREQq447uzfnoL93x8XRl3eFTDJ21in3Jpx0dlohIjVFS7yCFRQbpZ8yeeg2/FxEREam8XpcFs+jhWJoHehF/Mpuhs1aycl+Ko8MSEakRSuodJP1MPrZ6Lv7qqRcRERG5JJc19mHRw7FERwSQmVPAvR/8xvzf4h0dlohItVNS7yC2ofc+Hq64ueifQURERORSBTX0YO6oHtzSOZyCIoMnv9jKtO92UlSkyvgiUncpm3SQNNt8ehXJExEREakynm4uvHHHFYy9/nIA3v71AA/P3cCZPFXGF5G6SUm9g5zM0hr1IiIiItXBYrEwvm9rpg+7AncXK99vT2LYO6tJzshxdGgiIlVOSb2DaI16ERERkeo1pEsT/juqBwFebmw5ms6QN1ey/vApR4clIlKllNQ7SJqWsxMRERGpdt0jA1n0cC9aBntzLD2HP81exZ9mr+KbzcfILyxydHgiIpdMSb2DnMouHn6vOfUiIiIi1apFsDeLHu7FrV2b4OZiYf3hUzw6byNXvfQTM3/aS+rpXEeHKCJSaUrqHeRUlq2nXkm9iIiISHXz83LjtduvYOXf+zD2+ssJbujB8YxcXvlhDzEv/sTfFm5mW0K6o8MUEakwV0cHUF+d0vB7ERERkRrX2NeT8X1b8/B1rVi8NZE5Kw+x+Wg6n60/ymfrj9ItIoD7erWgf4dQLTssIk5BSb2D2Ibfq1CeiIiISM3zcHVhaJemDO3SlI3xp5iz6hDfbklk3eFTrDt8ilBfT4bHRHDHlc0Iaujh6HBFRM5LSb2D2ArlBWpOvYiIiIhDdWkeQJfmAfzjxnbMXRvPJ2sPk5SRw7+W7OaNH/cyqFM4d/VoTtfm/lgsFkeHKyJSipJ6B7GtU++v4fciIiIitUKIrycT+rZmzHWt+HZLInNWHWLL0XQ+33CUzzccpXVIQ+7s3pyhXZpotKWI1BqaKOQAhmGctaSdGgQREan7Zs2aRWRkJJ6enkRHR7N8+fLz7vvFF1/Qt29fGjVqhK+vLzExMSxZsqTUPnPmzMFisZS55eTkVPepSD3g4erCrV2b8tWYXnzxcCy3RTfF083KnuOnefabHXR/4UfGL9jEbwdPYhiGo8MVkXpOSb0DnM4toKDIbACU1IuISF23YMECxo0bx6RJk9i4cSO9e/dm4MCBxMfHl7v/smXL6Nu3L4sXL2b9+vVcd911DBo0iI0bN5baz9fXl8TExFI3T0/PmjglqScsFgtdmwfwyp87s/YfNzB1cAfahvqQV1DEoo0J3P72am547VfeW36Ak8UrG4mI1DSLoa8Xy8jIyMDPz4/09HR8fX2r/PhHTmbT++Wf8XSzsuufA6v8+CIiUvdUd9tUnXr06EHXrl2ZPXu2fVu7du0YMmQI06ZNu6hjdOjQgWHDhvH0008DZk/9uHHjSEtLq3RcznxNxXEMw2Dz0XTmrY3n683HOJNfCIC7i5X+UaHc2b0ZMS2DNPdeRCqssu2Seuod4JSG3ouISD2Rl5fH+vXr6devX6nt/fr1Y9WqVRd1jKKiIjIzMwkMDCy1/fTp00RERNC0aVNuvvnmMj3558rNzSUjI6PUTaSiLBYLVzTz56XbOvHbpOt5fmgUHcJ9ySss4pvNx7jr3bX0efVX3l12gNyCQkeHKyL1gJJ6B7ANz1KBFRERqetSUlIoLCwkJCSk1PaQkBCSkpIu6hivvvoqWVlZ3H777fZtbdu2Zc6cOXz99dfMmzcPT09PevXqxd69e897nGnTpuHn52e/NWvWrHInJVLMx9ONu3tE8O1jvfnmkau4s3tzvN1dOJiSxfOLd3Lzv1ew+Uiao8MUkTpOSb0DpBWvUR+gyvciIlJPnDsU2TCMixqePG/ePKZMmcKCBQto3LixfXvPnj2555576Ny5M7179+bTTz+ldevWzJgx47zHmjhxIunp6fbbkSNHKn9CIufo2NSPabd25LdJN/DC0I4EN3Rnb/Jpbp29in8t2aVeexGpNkrqHUDD70VEpL4IDg7GxcWlTK98cnJymd77cy1YsICRI0fy6aefcsMNN1xwX6vVypVXXnnBnnoPDw98fX1L3USqmreHK3f1aM4P469hUOdwCosM3vx5P7fMWMnWo+mODk9E6iAl9Q5wytZT762eehERqdvc3d2Jjo4mLi6u1Pa4uDhiY2PP+7p58+Zx33338cknn3DTTTf94fsYhsGmTZsICwu75JhFqkKgtzsz7uzCW/d0Jcjbnd3HMxkyayWv/rCbvIIiR4cnInWIknoHOJWlnnoREak/JkyYwHvvvccHH3zAzp07GT9+PPHx8YwePRowh8WPGDHCvv+8efMYMWIEr776Kj179iQpKYmkpCTS00t6OZ999lmWLFnCgQMH2LRpEyNHjmTTpk32Y4rUFgOiwvhh/NXc1CmMwiKDGT/t45aZK9iWoF57EakaSuodwDb8XoXyRESkPhg2bBjTp09n6tSpXHHFFSxbtozFixcTEREBQGJiYqk1699++20KCgoYM2YMYWFh9tvYsWPt+6SlpfHggw/Srl07+vXrR0JCAsuWLaN79+41fn4ifySooQdv3tWVWXd3JdDbnV1JmQx5cyWvxe1Rr72IXDKtU1+O6l639p731rJiXwqv3d6ZW7s2rfLji4hI3aM11auerqk4QsrpXJ7+ahuLt5p1JtqF+fLqnzvTPlyfQZH6TuvUOxF7oTxv9dSLiIiI1CfBDT2YdXc0M+/qQoCXGzsTM7hl5gqmL91DfqF67UWk4pTUO4Dm1IuIiIjUbzd3CueH8dcwoEMoBUUG05fuZcibK1m47ggJaWccHZ6IOBFXRwdQH53SOvUiIiIi9V4jHw9m39OVb7Yk8vRX29h+LIMnPtsCQESQF7GtgohpFUxMyyAa+Xg4OFoRqa2U1NewnPxCzuQXAiqUJyIiIlLfWSwWbukcTs+WgXy86jAr96ew5Wg6h1OzOZyazbzfjgDQOqQhsa2CiWkVRM/IIPzUOSQixZTU17C04l56F6sFX09dfhERERGBxj6e/K1/G/5GGzJz8vn90ElW7Utl1f5UdiRmsOf4afYcP82cVYewWCAq3K+4Jz+Ini2D8HRzcfQpiIiDKKusYSft8+ndsFgsDo5GRERERGobH083+rQNoU/bEMD8+3HtATPBX7k/hQMnstiakM7WhHTeXnaAcD9P/j6wLbd0DtfflyL1kJL6GpamNepFREREpAICvd0Z2DGMgR3DAEhKz2H1gRRW7Uvllz0nOJaew9j5m5iz6hBP39yeLs0DHByxiNQkJfU1TEXyRERERORShPp5MrRLU4Z2aUpOfiHvLT/ArF/2szE+jaGzVjHkinD+b0Bbwv0bODpUEakBWtKuhp1ST72IiIiIVBFPNxce6XM5P//tWm6LbgrAl5uO0efVX3g9bg/ZeQUOjlBEqpuS+hpmG34fqKReRERERKpIiK8nr/y5M988chVXtgggJ7+IN37cS59XfmXRxqMUFRmODlFEqomS+hp2Msscfu/vreH3IiIiIlK1Ojb149OHYph1d1eaBjQgKSOH8Qs2M3T2KtYfPuXo8ESkGiipr2G2nvoA9dSLiIiISDWwWCzc2DGMpROu4f8GtMHb3YXNR9L40+xVPDZvIwlpZxwdoohUISX1NexUdsmSdiIiIiIi1cXTzYWHr72Mn5+4lmHdmmGxwNebj9HnlV94Zclu0s/kOzpEEakCSuprWEn1e/XUi4iIiEj1a+zjyUu3deKbR66ie2QguQVFzPx5H71f+ok3f95HVq6K6Yk4MyX1NczeU++tpF5EREREak5UEz8WPNiTt+6J5vLGDcnIKeBfS3bT++WfeXfZAXLyCx0doohUgpL6GnYqS8PvRURERMQxLBYLA6JC+X7c1bxxxxW0CPLiZFYezy/eydUv/8zHqw+RW6DkXsSZODypnzVrFpGRkXh6ehIdHc3y5csvuP/cuXPp3LkzXl5ehIWFcf/995Oammp//t1336V3794EBAQQEBDADTfcwG+//Vbdp3FRCgqLyMgxhzdpnXoRERERcRQXq4XBVzRh6YRrePm2TjTxb0ByZi5Pf7WdPq/8yvzf4skvLHJ0mCJyERya1C9YsIBx48YxadIkNm7cSO/evRk4cCDx8fHl7r9ixQpGjBjByJEj2b59OwsXLuT3339n1KhR9n1++eUX7rzzTn7++WdWr15N8+bN6devHwkJCTV1Wud1djES/wbqqRcRERERx3J1sXJ7t2b8/Ldr+eeQKEJ8PUhIO8OTX2zlhtfMNe4Ltca9SK1mMQzDYf9Le/ToQdeuXZk9e7Z9W7t27RgyZAjTpk0rs/8rr7zC7Nmz2b9/v33bjBkzePnllzly5Ei571FYWEhAQAAzZ85kxIgR5e6Tm5tLbm6u/eeMjAyaNWtGeno6vr6+lT29MvYlZ3LDa8vw9XRly5T+VXZcERGp+zIyMvDz86vytqk+0zUVKSsnv5C5a+OZ/cs+Uk6b00Yva9yQ8Te0ZmBUKFarxcERitRdlW2XXKsxpgvKy8tj/fr1PPnkk6W29+vXj1WrVpX7mtjYWCZNmsTixYsZOHAgycnJfPbZZ9x0003nfZ/s7Gzy8/MJDAw87z7Tpk3j2WefrdyJVIC98r2K5ImIiIhILeTp5sLIqyK548pmfLT6EG//eoB9yacZ88kGIoO9aR7oRYCXG/5e7gR4uePv5Ya/l5v9se2+oYcrFou+ABCpCQ5L6lNSUigsLCQkJKTU9pCQEJKSksp9TWxsLHPnzmXYsGHk5ORQUFDALbfcwowZM877Pk8++SRNmjThhhtuOO8+EydOZMKECfafbT31Vc1WJE/z6UVERESkNvP2cOXhay/jnp4RfLDiIO8vP8jBlCwOpmRd1OtdrRb8vdwI8vag9+XB3Nq1Ke3DNSJGpDo4LKm3OfcbPMMwzvut3o4dO3jsscd4+umn6d+/P4mJiTzxxBOMHj2a999/v8z+L7/8MvPmzeOXX37B09PzvDF4eHjg4eFxaSdyEdKKe+oDVfleRERERJyAr6cb425ozf2xkfx+6CQns/NIy84jLTufU9n5Zz0uuc8tKKKgyCDldB4pp/PYfTyT91YcpG2oD0O7NGHwFU0I9Tv/3+YiUjEOS+qDg4NxcXEp0yufnJxcpvfeZtq0afTq1YsnnngCgE6dOuHt7U3v3r157rnnCAsLs+/7yiuv8MILL7B06VI6depUfSdSASdta9Srp15EREREnIiflxs3tC//b/Rz5eQXcio7j1NZ+RxOzeLrzcf4cWcyu5IymfbdLl78fhe9WgUztEsTBkSF4u3h8H5GEafmsP9B7u7uREdHExcXx9ChQ+3b4+LiGDx4cLmvyc7OxtW1dMguLi6A2cNv869//YvnnnuOJUuW0K1bt2qIvnJOZWv4vYiIiIjUbZ5uLoT5NSDMrwHtw30Z2DGM9Ox8vt2ayKKNR/n90ClW7Ethxb4UJn+5jf4dQhjatSm9WgXh6uLwFbdFnI5DvxabMGECw4cPp1u3bsTExPDOO+8QHx/P6NGjAXOue0JCAh9//DEAgwYN4oEHHmD27Nn24ffjxo2je/fuhIeHA+aQ+6eeeopPPvmEFi1a2EcCNGzYkIYNGzrmRIulZRUXytPwexERERGpR/y83LirR3Pu6tGc+NRsvtyUwBcbjnIoNZsvNx3jy03HaOTjweDO4Qzt2oT2Yb4qtCdykRya1A8bNozU1FSmTp1KYmIiUVFRLF68mIiICAASExNLrVl/3333kZmZycyZM3n88cfx9/enT58+vPTSS/Z9Zs2aRV5eHrfddlup93rmmWeYMmVKjZzX+dh76lX9XkRERETqqeZBXjx2/eU82ucyNh5JY9GGBL7ZcowTmbm8t+Ig7604SMtG3vTvEEq/9iF0buqvpfRELsCh69TXVtW1bu3tb63mt0MnefOurtzUKeyPXyAiIlJMa6pXPV1Tkdojr6CIX3Yns2hjAj/uTCavsMj+XIivB33bh9C/Qyg9WwbhpiH6Ukc53Tr19VFJoTwNvxcRERERsXF3tdKvQyj9OoSSkZPPz7uS+WHHcX7ZlczxjFz+uyae/66Jx8fTlevbNqZfh1Cuad1IRfZEUFJfo9JUKE9ERERE5IJ8Pd0YfIW59F1OfiGr96eyZHsScTuOk5qVZ5+D7+5qpfdlwfTvEMr17RoT1LD6l6gWqY2U1NcQwzDs69QHeKunXkRERETkj3i6uXBd28Zc17Yxzw812BB/ih+2J7Fk+3HiT2bz465kftyVjNUC3VoEMqBDKAOiQgn3b+Do0EVqjJL6GpKZW0BBkVm+QOvUi4iIiIhUjIvVwpUtArmyRSD/uLEdu49nsmTbcX7YkcT2Yxn8dvAkvx08ydT/7aBzUz8GRIUxICqUyGBvR4cuUq2U1NeQU1nm0PsGbi54urk4OBoREREREedlsVhoG+pL21Bfxt5wOUdOZrNkexJLtiex7vApNh9NZ/PRdF76fhdtQ33o3yGUgR1DaRPio6XypM5RUl9DTmVrjXoRERERkerQLNCLUb1bMqp3S5Izcvhhx3GWbE9i1f5UdiVlsispkzd+3EuLIC/6R4UyMCqMzk39lOBLnaCkvoacUpE8EREREZFq19jXk3t6RnBPzwjSsvNYujOZ77clsmxvCodSs3n71wO8/esBwvw8zR78qFC6tQjExaoEX5yTkvoaYqt8H+itpF5EREREpCb4e7lzW3RTbotuyuncAn7elcz325P4eVcyiek5zFl1iDmrDhHc0IMBUSHcGBVG98hAXF2sjg5d5KIpqa8hJ7PM4ff+Gn4vIiIiIlLjGnq4MqhzOIM6h5OTX8jyvSl8ty2RuB3HSTmdy3/XxPPfNfEEervTr30IAzuGEdsqCDcl+FLLKamvIbaeelW+FxERERFxLE83F/q2D6Fv+xDyCopYtT+F77Ym8cOOJE5m5TH/9yPM//0Ivp6u9G0fyo0dQ7nq8mA8XCtX8LqwyNDwfqk2SupryCl7Uq+eehERERGR2sLd1cq1bRpzbZvGPF8YxdqDJ1m8NZEl280e/M83HOXzDUdp6OHK9e0a07d9CB6uLmTm5JNxJp/MnAIycwvMn3MKyMwpKN5e/FxOAWfyC+nc1I9xN7Tm2jaNVKBPqpSS+hpir36vOfUiIiIiIrWSq4uVXpcF0+uyYKYOjmLdoZN8ty2J77clkZSRw1ebjvHVpmOVOvbmo+ncP+d3ujb35/F+bYhtFaTkXqqEkvoaouH3IiIiIiLOw8VqoUfLIHq0DOLpm9uz8Uga329LZNX+VNxcrPh4uuLr6YaPp2vxza3Uve9Z9xYL/GfNYT5adYgN8Wnc/d5aekQG8ni/NnSPDHT0qYqTU1JfQ1QoT0RERETEOVmtFqIjAoiOCKj0Mf5xYztGXRXJrF/288naeNYePMntb6+m9+XBTOjbmi7NK39sqd9UyrGGqKdeRETqs1mzZhEZGYmnpyfR0dEsX778vPt+8cUX9O3bl0aNGuHr60tMTAxLliwps9/nn39O+/bt8fDwoH379ixatKg6T0FE5JI19vVkyi0d+OWJa7mze3NcrRaW701h6KxVjJzzO9sS0h0dojghJfU15JSSehERqacWLFjAuHHjmDRpEhs3bqR3794MHDiQ+Pj4cvdftmwZffv2ZfHixaxfv57rrruOQYMGsXHjRvs+q1evZtiwYQwfPpzNmzczfPhwbr/9dtauXVtTpyUiUmnh/g2YdmtHfnr8Wm6LborVAj/uSubmGSv463/Xs+d4pqNDFCdiMQzDcHQQtU1GRgZ+fn6kp6fj6+t7ycc7k1dIu6e/B2DrlH74eGoIvoiIVExVt001qUePHnTt2pXZs2fbt7Vr144hQ4Ywbdq0izpGhw4dGDZsGE8//TQAw4YNIyMjg++++86+z4ABAwgICGDevHkXdUxnvqYiUrfsP3GaN5bu5ZstxzAMsFhgUKdw7uvVghZB3gR4uamoXj1Q2XZJc+prgK2X3tVqoaGHLrmIiNQfeXl5rF+/nieffLLU9n79+rFq1aqLOkZRURGZmZkEBpYUk1q9ejXjx48vtV///v2ZPn36eY+Tm5tLbm6u/eeMjIyLen8RkerWqlFD/n1nF8ZcdxnTl+7hu21JfL35GF9vNivte7pZCfdrQLh/A8L8PAn3b0C4v2fxz+ZjL3flGfWV/uVrgC2p9/dy1zdsIiJSr6SkpFBYWEhISEip7SEhISQlJV3UMV599VWysrK4/fbb7duSkpIqfMxp06bx7LPPViB6EZGa1SbUh9n3RLMtIZ2ZP+1j3eFTpJzOJSe/iAMpWRxIyTrvawO83Ajza0BEkBexrYK4tk1jmgV61WD04ihK6mtAmm2NelW+FxGReurcL7UNw7ioL7rnzZvHlClT+Oqrr2jcuPElHXPixIlMmDDB/nNGRgbNmjW7mPBFRGpUVBM/3hoeDUBuQSFJ6TkcS8vhWNoZEtPPkJCWQ2L6GY6lneFYWg6ncws4lZ3Pqex8diRm8N22JGA7LYO9ubp1I65p04iekUE0cHdx7IlJtVBSXwPsRfK8VSRPRETql+DgYFxcXMr0oCcnJ5fpaT/XggULGDlyJAsXLuSGG24o9VxoaGiFj+nh4YGHh0cFz0BExLE8XF2ICPImIsj7vPtk5OSbCX9aDjsSM/h1zwnWHz5l792fs+oQHq5WerQM4prWjbimdSNaNfLWKOI6Qkl9DTiVZat8r556ERGpX9zd3YmOjiYuLo6hQ4fat8fFxTF48ODzvm7evHn85S9/Yd68edx0001lno+JiSEuLq7UvPoffviB2NjYqj0BEREn4Ovphm+oG21DfbmubWPGXHcZGTn5rNqXyq97kvl19wmOpeewbM8Jlu05wT+BJv4NuKaNmeD3uizYXvvLMAyKDCgyDPNWZD4uNAyMsx8bEOjtjotVXww4mpL6GnDKPvxePfUiIlL/TJgwgeHDh9OtWzdiYmJ45513iI+PZ/To0YA5LD4hIYGPP/4YMBP6ESNG8MYbb9CzZ097j3yDBg3w8/MDYOzYsVx99dW89NJLDB48mK+++oqlS5eyYsUKx5ykiEgt4+vpxoCoUAZEhWIYBvuST/PrnhP8uucEaw+cJCHtDJ+sjeeTtfFYLGC1WCgqTtYvVrifJ3f3jGDYlc0IbqiRUI6ipL4GnF0oT0REpL4ZNmwYqampTJ06lcTERKKioli8eDEREREAJCYmllqz/u2336agoIAxY8YwZswY+/Z7772XOXPmABAbG8v8+fOZPHkyTz31FK1atWLBggX06NGjRs9NRMQZWCwWLg/x4fIQH0b1bkl2XgFrDqTy624zyT+Umk1hJVY6P5aew7+W7OaNpXu5qVMYw2Mi6NLMX8P6a5jWqS9HVa9bO37BJhZtTOAfN7blwatbVUGEIiJS32hN9aqnayoiYko5nUthkWHvsXexWLBaLFis2B9breZz5g1yC4r435ZE/rP6EJuPptuP1bGJH8NjIrilcziebirMVxFap74WO5mlnnoREREREamdKjN03tPNhduim3JbdFM2H0nj49WH+WbLMbYmpPN/n23hhcU7GdatGff0jNDSetXM6ugA6oM0W/V7JfUiIiIiIlLHdG7mz6u3d2bNxOv5+4C2NPFvQFp2Pm8vO8DV//qZv8z5nZ93J1NUpEHi1UE99TXglNapFxERERGROi7Q252/XtuKB69uyc+7kvlo9SGW703hp13J/LQrmRZBXgzp0oSocD/ahvnQxL+B5t9XASX1NUCF8kREREREpL5wsVq4oX0IN7QP4cCJ0/x3TTwL1x/hUGo205fute/n4+FK2zAf2ob62u/bhPrYl9eTi6OrVc3yC4vIzCkAzG+uRERERERE6ouWjRry9KD2/K1/a77edIy1B0+yMzGD/SdOk5lbwO+HTvH7oVOlXtMssAFtQ31pF+pD2zBf2ob6EBHkjYtVvfrlUVJfzdKKh95bLODXQMPvRURERESk/vFyd+WO7s25o3tzAPIKijiQcppdiZnsTMpgV2Imu5IyOJ6Ry5GTZzhy8gxxO47bX+/hauXykIa0CfGlTWhD2oT60ibEhxBfj3o/hF9JfTWzFcnz9XTTN0siIiIiIiKAu6vVHHYf6ssQmti3n8rKY1eSmeDbEv3dxzPJyS9iW0IG2xIySh3Hr4EbbUJ8aBNacmsd4lOvOlSV1FczFckTERERERG5OAHe7sS0CiKmVZB9W2GRwZGT2exKymR3UiZ7jpvJ/sGULNLP5PPboZP8duhkqeOE+XnSIdyXqCZ+dGrqR1QTPxr7eNb06dQIJfXVzFYkL0Dz6UVERERERCrMxWqhRbA3LYK9GRAVat+ek1/I/hOn2Z2Uye7jZsK/OymTxPQc+23pzmT7/iG+HnRsYib4HYtvjX2dP9FXUl/NTmVpjXoREREREZGq5unmQodwPzqE+5Xann4mn12JGWw7lsG2hHS2JqSz/8RpjmfkcjwjuVSi39indKLfLNALvwZu+DVww9PN6hTz9ZXUVzPb8Ht/Db8XERERERGpdn4N3OjRMogeLUuG8GflFrAjMYOtR9NLJfrJmbn8uCuZH3cllzmOu6vVnuD7NXDDv/jet4Eb/l5nbfdyo2fLILzcHZNeK6mvZrZCeeqpFxERERERcQxvD1eubBHIlS0C7duy8wrYYe/Nz2D7sXSSM3NJP5NPYZFBXkERJzJzOZGZ+4fHX/H365TU11Vhfp5ERwTQspG3o0MRERERERGRYl7urnRrEUi3sxJ9AMMwOJ1bQPqZ/JJbdsnjtLO2Z5zJJy07H38HduIqqa9m9/WK5L5ekY4OQ0RERERERC6CxWLBx9MNH083mgY4Opo/ZnV0ACIiIiIiIiJSOUrqRURERERERJyUknoRERERERERJ6WkXkRERERERMRJKakXERERERERcVJK6kVERERERESclJJ6ERERERERESelpF5ERERERETESSmpFxEREREREXFSSupFREREREREnJSSehEREREREREnpaReRERERERExEkpqRcRERERERFxUkrqRURERERERJyUknoRERERERERJ+XwpH7WrFlERkbi6elJdHQ0y5cvv+D+c+fOpXPnznh5eREWFsb9999PampqqX0+//xz2rdvj4eHB+3bt2fRokXVeQoiIiIiIiIiDuHQpH7BggWMGzeOSZMmsXHjRnr37s3AgQOJj48vd/8VK1YwYsQIRo4cyfbt21m4cCG///47o0aNsu+zevVqhg0bxvDhw9m8eTPDhw/n9ttvZ+3atTV1WiIiIiIiIiI1wmIYhuGoN+/Rowddu3Zl9uzZ9m3t2rVjyJAhTJs2rcz+r7zyCrNnz2b//v32bTNmzODll1/myJEjAAwbNoyMjAy+++47+z4DBgwgICCAefPmXVRcGRkZ+Pn5kZ6ejq+vb2VPT0REpMqobap6uqYiIlKbVLZdcq3GmC4oLy+P9evX8+STT5ba3q9fP1atWlXua2JjY5k0aRKLFy9m4MCBJCcn89lnn3HTTTfZ91m9ejXjx48v9br+/fszffr088aSm5tLbm6u/ef09HTAvKgiIiK1ga1NcuB38XWO7VqqvRcRkdqgsm29w5L6lJQUCgsLCQkJKbU9JCSEpKSkcl8TGxvL3LlzGTZsGDk5ORQUFHDLLbcwY8YM+z5JSUkVOibAtGnTePbZZ8tsb9asWUVOSUREpNplZmbi5+fn6DDqhMzMTEDtvYiI1C4VbesdltTbWCyWUj8bhlFmm82OHTt47LHHePrpp+nfvz+JiYk88cQTjB49mvfff79SxwSYOHEiEyZMsP9cVFTEyZMnCQoKuuDrLkZGRgbNmjXjyJEj9X5on66FSdfBpOtQQtfCpOtgOt91MAyDzMxMwsPDHRhd3RIeHs6RI0fw8fFRe19FdB1Mug4ldC1Mug4mXQdTVbf1Dkvqg4ODcXFxKdODnpycXKan3WbatGn06tWLJ554AoBOnTrh7e1N7969ee655wgLCyM0NLRCxwTw8PDAw8Oj1DZ/f/9KnNX5+fr61usP7tl0LUy6DiZdhxK6FiZdB1N510E99FXLarXStGnTKj2mPr8mXQeTrkMJXQuTroNJ18FUVW29w6rfu7u7Ex0dTVxcXKntcXFxxMbGlvua7OxsrNbSIbu4uAAl8w5iYmLKHPOHH3447zFFREREREREnJVDh99PmDCB4cOH061bN2JiYnjnnXeIj49n9OjRgDksPiEhgY8//hiAQYMG8cADDzB79mz78Ptx48bRvXt3+xCFsWPHcvXVV/PSSy8xePBgvvrqK5YuXcqKFSscdp4iIiIiIiIi1cGhSf2wYcNITU1l6tSpJCYmEhUVxeLFi4mIiAAgMTGx1Jr19913H5mZmcycOZPHH38cf39/+vTpw0svvWTfJzY2lvnz5zN58mSeeuopWrVqxYIFC+jRo0eNnx+YQ/ufeeaZMsP76yNdC5Oug0nXoYSuhUnXwaTr4Jz072bSdTDpOpTQtTDpOph0HUxVfR0cuk69iIiIiIiIiFSew+bUi4iIiIiIiMilUVIvIiIiIiIi4qSU1IuIiIiIiIg4KSX1IiIiIiIiIk5KSX01mzVrFpGRkXh6ehIdHc3y5csdHVKNmjJlChaLpdQtNDTU0WHViGXLljFo0CDCw8OxWCx8+eWXpZ43DIMpU6YQHh5OgwYNuPbaa9m+fbtjgq1Gf3Qd7rvvvjKfkZ49ezom2Go0bdo0rrzySnx8fGjcuDFDhgxh9+7dpfapD5+Ji7kO9eEzMXv2bDp16oSvry++vr7ExMTw3Xff2Z+vD5+FuqS+t/VQf9t7tfUmtfUmtfUmtfUlaqq9V1JfjRYsWMC4ceOYNGkSGzdupHfv3gwcOLDUMn31QYcOHUhMTLTftm7d6uiQakRWVhadO3dm5syZ5T7/8ssv89prrzFz5kx+//13QkND6du3L5mZmTUcafX6o+sAMGDAgFKfkcWLF9dghDXj119/ZcyYMaxZs4a4uDgKCgro168fWVlZ9n3qw2fiYq4D1P3PRNOmTXnxxRdZt24d69ato0+fPgwePNjekNeHz0Jdoba+RH1s79XWm9TWm9TWm9TWl6ix9t6QatO9e3dj9OjRpba1bdvWePLJJx0UUc175plnjM6dOzs6DIcDjEWLFtl/LioqMkJDQ40XX3zRvi0nJ8fw8/Mz3nrrLQdEWDPOvQ6GYRj33nuvMXjwYIfE40jJyckGYPz666+GYdTfz8S518Ew6u9nIiAgwHjvvffq7WfBWamtN6m9V1tvo7a+hNp6k9r60qqjvVdPfTXJy8tj/fr19OvXr9T2fv36sWrVKgdF5Rh79+4lPDycyMhI7rjjDg4cOODokBzu4MGDJCUllfp8eHh4cM0119S7zwfAL7/8QuPGjWndujUPPPAAycnJjg6p2qWnpwMQGBgI1N/PxLnXwaY+fSYKCwuZP38+WVlZxMTE1NvPgjNSW1+a2vvS9H+5tPr0e91Gbb1Jbb2pOtt7JfXVJCUlhcLCQkJCQkptDwkJISkpyUFR1bwePXrw8ccfs2TJEt59912SkpKIjY0lNTXV0aE5lO0zUN8/HwADBw5k7ty5/PTTT7z66qv8/vvv9OnTh9zcXEeHVm0Mw2DChAlcddVVREVFAfXzM1HedYD685nYunUrDRs2xMPDg9GjR7No0SLat29fLz8LzkptfQm192Xp/3KJ+vJ7/Wxq6031va2HmmnvXassWimXxWIp9bNhGGW21WUDBw60P+7YsSMxMTG0atWKjz76iAkTJjgwstqhvn8+AIYNG2Z/HBUVRbdu3YiIiODbb7/l1ltvdWBk1eeRRx5hy5YtrFixosxz9ekzcb7rUF8+E23atGHTpk2kpaXx+eefc++99/Lrr7/an69PnwVnp38rtfcXos9H/fm9fja19ab63tZDzbT36qmvJsHBwbi4uJT5liU5ObnMtzH1ibe3Nx07dmTv3r2ODsWhbBWB9fkoKywsjIiIiDr7GXn00Uf5+uuv+fnnn2natKl9e337TJzvOpSnrn4m3N3dueyyy+jWrRvTpk2jc+fOvPHGG/Xus+DM1Nafn9r7+vd7vSLq6u91G7X1JrX1pppo75XUVxN3d3eio6OJi4srtT0uLo7Y2FgHReV4ubm57Ny5k7CwMEeH4lCRkZGEhoaW+nzk5eXx66+/1uvPB0BqaipHjhypc58RwzB45JFH+OKLL/jpp5+IjIws9Xx9+Uz80XUoT139TJzLMAxyc3PrzWehLlBbf35q7+vP7/XKqKu/19XWm9TWX1i1tPeXVrtPLmT+/PmGm5ub8f777xs7duwwxo0bZ3h7exuHDh1ydGg15vHHHzd++eUX48CBA8aaNWuMm2++2fDx8akX1yAzM9PYuHGjsXHjRgMwXnvtNWPjxo3G4cOHDcMwjBdffNHw8/MzvvjiC2Pr1q3GnXfeaYSFhRkZGRkOjrxqXeg6ZGZmGo8//rixatUq4+DBg8bPP/9sxMTEGE2aNKlz1+Gvf/2r4efnZ/zyyy9GYmKi/ZadnW3fpz58Jv7oOtSXz8TEiRONZcuWGQcPHjS2bNli/OMf/zCsVqvxww8/GIZRPz4LdYXaelN9be/V1pvU1pvU1pvU1peoqfZeSX01e/PNN42IiAjD3d3d6Nq1a6mlHOqDYcOGGWFhYYabm5sRHh5u3Hrrrcb27dsdHVaN+Pnnnw2gzO3ee+81DMNc1uSZZ54xQkNDDQ8PD+Pqq682tm7d6tigq8GFrkN2drbRr18/o1GjRoabm5vRvHlz49577zXi4+MdHXaVK+8aAMaHH35o36c+fCb+6DrUl8/EX/7yF3vb0KhRI+P666+3N/CGUT8+C3VJfW/rDaP+tvdq601q601q601q60vUVHtvMQzDqFjfvoiIiIiIiIjUBppTLyIiIiIiIuKklNSLiIiIiIiIOCkl9SIiIiIiIiJOSkm9iIiIiIiIiJNSUi8iIiIiIiLipJTUi4iIiIiIiDgpJfUiIiIiIiIiTkpJvYiIiIiIiIiTUlIvIrWSxWLhyy+/dHQYIiIiUk3U1otUDSX1IlLGfffdh8ViKXMbMGCAo0MTERGRKqC2XqTucHV0ACJSOw0YMIAPP/yw1DYPDw8HRSMiIiJVTW29SN2gnnoRKZeHhwehoaGlbgEBAYA5XG727NkMHDiQBg0aEBkZycKFC0u9fuvWrfTp04cGDRoQFBTEgw8+yOnTp0vt88EHH9ChQwc8PDwICwvjkUceKfV8SkoKQ4cOxcvLi8svv5yvv/66ek9aRESkHlFbL1I3KKkXkUp56qmn+NOf/sTmzZu55557uPPOO9m5cycA2dnZDBgwgICAAH7//XcWLlzI0qVLSzXks2fPZsyYMTz44INs3bqVr7/+mssuu6zUezz77LPcfvvtbNmyhRtvvJG7776bkydP1uh5ioiI1Fdq60WchCEico57773XcHFxMby9vUvdpk6dahiGYQDG6NGjS72mR48exl//+lfDMAzjnXfeMQICAozTp0/bn//2228Nq9VqJCUlGYZhGOHh4cakSZPOGwNgTJ482f7z6dOnDYvFYnz33XdVdp4iIiL1ldp6kbpDc+pFpFzXXXcds2fPLrUtMDDQ/jgmJqbUczExMWzatAmAnTt30rlzZ7y9ve3P9+rVi6KiInbv3o3FYuHYsWNcf/31F4yhU6dO9sfe3t74+PiQnJxc2VMSERGRs6itF6kblNSLSLm8vb3LDJH7aK7BUgAAAd9JREFUIxaLBQDDMOyPy9unQYMGF3U8Nze3Mq8tKiqqUEwiIiJSPrX1InWD5tSLSKWsWbOmzM9t27YFoH379mzatImsrCz78ytXrsRqtdK6dWt8fHxo0aIFP/74Y43GLCIiIhdPbb2Ic1BPvYiUKzc3l6SkpFLbXF1dCQ4OBmDhwoV069aNq666irlz5/Lbb7/x/vvvA3D33XfzzDPPcO+99zJlyhROnDjBo48+yvDhwwkJCQFgypQpjB49msaNGzNw4EAyMzNZuXIljz76aM2eqIiISD2ltl6kblBSLyLl+v777wkLCyu1rU2bNuzatQswq9XOnz+fhx9+mNDQUObOnUv79u0B8PLyYsmSJYwdO5Yrr7wSLy8v/vSnP/Haa6/Zj3XvvfeSk5PD66+/zt/+9jeCg4O57bbbau4ERURE6jm19SJ1g8UwDMPRQYiIc7FYLCxatIghQ4Y4OhQRERGpBmrrRZyH5tSLiIiIiIiIOCkl9SIiIiIiIiJOSsPvRURERERERJyUeupFREREREREnJSSehEREREREREnpaReRERERERExEkpqRcRERERERFxUkrqRURERERERJyUknoRERERERERJ6WkXkRERERERMRJKakXERERERERcVL/D4gudIGPmQDKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FMM.evaluate(model, X_test, y_test, history)\n",
    "FMM.plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend shows that the training loss is increasing over time, while the validation loss is decreasing. This suggests that the model is overfitting the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune, train\n",
    "\n",
    "# ! pip install -U \"ray[data,train,tune,serve]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 22:01:10,732\tINFO worker.py:1715 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0b32b967324195a177da4403568f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.11.5</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.9.2</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8266\" target=\"_blank\">http://127.0.0.1:8266</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8266', python_version='3.11.5', ray_version='2.9.2', ray_commit='fce7a361807580953364e2da964f9498f3123bf9', protocol_version=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train the model\n",
    "def train_model(config):\n",
    "    from fashionmnist_model import FMM\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = FMM.load_data()\n",
    "    X_train, X_test = FMM.reshape_data(X_train, X_test)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        # rho=config[\"rho\"],\n",
    "        # epsilon=config[\"epsilon\"],\n",
    "        # weight_decay=config[\"weight_decay\"],\n",
    "    )\n",
    "\n",
    "    model = FMM.create_model_v1()\n",
    "    history = FMM.compile_and_train(\n",
    "        model, X_train, y_train, optimizer\n",
    "    )\n",
    "    \n",
    "    loss, accuracy, _, _ = FMM.evaluate(model, X_test, y_test, history)\n",
    "\n",
    "    train.report({\"accuracy\": accuracy, \"loss\": loss, **config})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"learning_rate\": tune.grid_search([0.001, 0.0005, 0.0001]),\n",
    "    # \"rho\": tune.grid_search([0.9, 0.95, 0.99]),\n",
    "    # \"epsilon\": tune.grid_search([1e-8, 1e-7, 1e-6]),\n",
    "    # \"weight_decay\": tune.grid_search([1e-6, 1e-5, 1e-4]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 22:01:17,243\tINFO tune.py:583 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:01:19,679 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7851278336; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-02-22 22:07:32</td></tr>\n",
       "<tr><td>Running for: </td><td>00:06:05.71        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.4/8.0 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  learning_rate</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_d00f2_00000</td><td>TERMINATED</td><td>127.0.0.1:78153</td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         345.078</td><td style=\"text-align: right;\">    0.8871</td><td style=\"text-align: right;\">0.624277</td><td style=\"text-align: right;\">         0.001 </td></tr>\n",
       "<tr><td>train_model_d00f2_00001</td><td>TERMINATED</td><td>127.0.0.1:78156</td><td style=\"text-align: right;\">         0.0005</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         348.741</td><td style=\"text-align: right;\">    0.8872</td><td style=\"text-align: right;\">0.487521</td><td style=\"text-align: right;\">         0.0005</td></tr>\n",
       "<tr><td>train_model_d00f2_00002</td><td>TERMINATED</td><td>127.0.0.1:78157</td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         346.111</td><td style=\"text-align: right;\">    0.8805</td><td style=\"text-align: right;\">0.339811</td><td style=\"text-align: right;\">         0.0001</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:01:29,685 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7850934272; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:01:39,780 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7850528768; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:01:49,874 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7849869312; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:01:59,963 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7848939520; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m 2024-02-22 22:02:03.533800: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 1/30\n",
      "  9/750 [..............................] - ETA: 4s - loss: 1.6304 - accuracy: 0.4514   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=78157)\u001b[0m WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/750 [..............................] - ETA: 19s - loss: 1.5408 - accuracy: 0.4744\n",
      " 12/750 [..............................] - ETA: 24s - loss: 1.5392 - accuracy: 0.4714\n",
      " 19/750 [..............................] - ETA: 19s - loss: 1.3512 - accuracy: 0.5288\n",
      " 30/750 [>.............................] - ETA: 15s - loss: 1.1775 - accuracy: 0.5896\n",
      " 43/750 [>.............................] - ETA: 12s - loss: 1.0756 - accuracy: 0.6232\n",
      " 52/750 [=>............................] - ETA: 11s - loss: 1.0159 - accuracy: 0.6454\n",
      " 53/750 [=>............................] - ETA: 12s - loss: 1.0085 - accuracy: 0.6474\n",
      " 69/750 [=>............................] - ETA: 10s - loss: 0.9476 - accuracy: 0.6655\n",
      " 77/750 [==>...........................] - ETA: 9s - loss: 0.9162 - accuracy: 0.6761 \n",
      " 88/750 [==>...........................] - ETA: 9s - loss: 0.8880 - accuracy: 0.6848 \n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 1/30\n",
      " 97/750 [==>...........................] - ETA: 9s - loss: 0.8676 - accuracy: 0.6914\n",
      "108/750 [===>..........................] - ETA: 9s - loss: 0.8469 - accuracy: 0.6997\n",
      "122/750 [===>..........................] - ETA: 8s - loss: 0.8222 - accuracy: 0.7052\n",
      "130/750 [====>.........................] - ETA: 8s - loss: 0.8017 - accuracy: 0.7126\n",
      "134/750 [====>.........................] - ETA: 8s - loss: 0.7985 - accuracy: 0.7142\n",
      "141/750 [====>.........................] - ETA: 8s - loss: 0.7903 - accuracy: 0.7170\n",
      "146/750 [====>.........................] - ETA: 8s - loss: 0.7823 - accuracy: 0.7208\n",
      "148/750 [====>.........................] - ETA: 8s - loss: 0.7792 - accuracy: 0.7223\n",
      "153/750 [=====>........................] - ETA: 8s - loss: 0.7713 - accuracy: 0.7253\n",
      "165/750 [=====>........................] - ETA: 8s - loss: 0.7567 - accuracy: 0.7307\n",
      "175/750 [======>.......................] - ETA: 7s - loss: 0.7465 - accuracy: 0.7343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:02:09,973 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6771683328; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m 2024-02-22 22:02:07.575025: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/750 [======>.......................] - ETA: 8s - loss: 0.7429 - accuracy: 0.7359\n",
      "184/750 [======>.......................] - ETA: 8s - loss: 0.7379 - accuracy: 0.7378\n",
      "186/750 [======>.......................] - ETA: 8s - loss: 0.7371 - accuracy: 0.7373\n",
      "188/750 [======>.......................] - ETA: 8s - loss: 0.7360 - accuracy: 0.7379\n",
      "194/750 [======>.......................] - ETA: 8s - loss: 0.7315 - accuracy: 0.7403\n",
      "207/750 [=======>......................] - ETA: 7s - loss: 0.7178 - accuracy: 0.7453\n",
      "216/750 [=======>......................] - ETA: 7s - loss: 0.7106 - accuracy: 0.7480\n",
      "230/750 [========>.....................] - ETA: 7s - loss: 0.7029 - accuracy: 0.7503\n",
      "240/750 [========>.....................] - ETA: 7s - loss: 0.7002 - accuracy: 0.7510\n",
      "246/750 [========>.....................] - ETA: 7s - loss: 0.6944 - accuracy: 0.7530\n",
      "259/750 [=========>....................] - ETA: 6s - loss: 0.6879 - accuracy: 0.7551\n",
      "271/750 [=========>....................] - ETA: 6s - loss: 0.6797 - accuracy: 0.7578\n",
      "282/750 [==========>...................] - ETA: 6s - loss: 0.6719 - accuracy: 0.7605\n",
      "292/750 [==========>...................] - ETA: 6s - loss: 0.6666 - accuracy: 0.7621\n",
      "296/750 [==========>...................] - ETA: 6s - loss: 0.6631 - accuracy: 0.7633\n",
      "303/750 [===========>..................] - ETA: 6s - loss: 0.6580 - accuracy: 0.7654\n",
      "313/750 [===========>..................] - ETA: 5s - loss: 0.6507 - accuracy: 0.7679\n",
      "315/750 [===========>..................] - ETA: 5s - loss: 0.6494 - accuracy: 0.7683\n",
      "325/750 [============>.................] - ETA: 5s - loss: 0.6429 - accuracy: 0.7703\n",
      "332/750 [============>.................] - ETA: 5s - loss: 0.6384 - accuracy: 0.7716\n",
      "345/750 [============>.................] - ETA: 5s - loss: 0.6323 - accuracy: 0.7736\n",
      "353/750 [=============>................] - ETA: 5s - loss: 0.6282 - accuracy: 0.7752\n",
      "358/750 [=============>................] - ETA: 5s - loss: 0.6262 - accuracy: 0.7760\n",
      "363/750 [=============>................] - ETA: 5s - loss: 0.6238 - accuracy: 0.7766\n",
      "366/750 [=============>................] - ETA: 5s - loss: 0.6227 - accuracy: 0.7770\n",
      "376/750 [==============>...............] - ETA: 5s - loss: 0.6182 - accuracy: 0.7781\n",
      "382/750 [==============>...............] - ETA: 5s - loss: 0.6160 - accuracy: 0.7788\n",
      "393/750 [==============>...............] - ETA: 5s - loss: 0.6123 - accuracy: 0.7801\n",
      "401/750 [===============>..............] - ETA: 4s - loss: 0.6100 - accuracy: 0.7811\n",
      "410/750 [===============>..............] - ETA: 4s - loss: 0.6079 - accuracy: 0.7818\n",
      "  1/750 [..............................] - ETA: 1:11:42 - loss: 2.2308 - accuracy: 0.1719\n",
      "413/750 [===============>..............] - ETA: 4s - loss: 0.6068 - accuracy: 0.7820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=78156)\u001b[0m WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/750 [================>.............] - ETA: 4s - loss: 0.6021 - accuracy: 0.7837\n",
      "  8/750 [..............................] - ETA: 11s - loss: 2.1475 - accuracy: 0.2227  \n",
      "428/750 [================>.............] - ETA: 4s - loss: 0.6017 - accuracy: 0.7838\n",
      "  9/750 [..............................] - ETA: 23s - loss: 2.1292 - accuracy: 0.2448\n",
      "436/750 [================>.............] - ETA: 4s - loss: 0.5990 - accuracy: 0.7845\n",
      " 21/750 [..............................] - ETA: 12s - loss: 1.9544 - accuracy: 0.3549\n",
      "448/750 [================>.............] - ETA: 4s - loss: 0.5946 - accuracy: 0.7863\n",
      " 32/750 [>.............................] - ETA: 10s - loss: 1.8365 - accuracy: 0.4307\n",
      "454/750 [=================>............] - ETA: 4s - loss: 0.5933 - accuracy: 0.7867\n",
      " 40/750 [>.............................] - ETA: 10s - loss: 1.7712 - accuracy: 0.4633\n",
      "464/750 [=================>............] - ETA: 3s - loss: 0.5908 - accuracy: 0.7873\n",
      " 51/750 [=>............................] - ETA: 9s - loss: 1.6900 - accuracy: 0.4933 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=78156)\u001b[0m WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474/750 [=================>............] - ETA: 3s - loss: 0.5890 - accuracy: 0.7878\n",
      " 57/750 [=>............................] - ETA: 9s - loss: 1.6478 - accuracy: 0.5055\n",
      "478/750 [==================>...........] - ETA: 3s - loss: 0.5889 - accuracy: 0.7878\n",
      " 64/750 [=>............................] - ETA: 10s - loss: 1.6067 - accuracy: 0.5183\n",
      "486/750 [==================>...........] - ETA: 3s - loss: 0.5883 - accuracy: 0.7882\n",
      " 66/750 [=>............................] - ETA: 10s - loss: 1.5950 - accuracy: 0.5208\n",
      "494/750 [==================>...........] - ETA: 3s - loss: 0.5855 - accuracy: 0.7893\n",
      " 78/750 [==>...........................] - ETA: 9s - loss: 1.5239 - accuracy: 0.5441 \n",
      "500/750 [===================>..........] - ETA: 3s - loss: 0.5843 - accuracy: 0.7898\n",
      " 83/750 [==>...........................] - ETA: 9s - loss: 1.4983 - accuracy: 0.5503\n",
      "504/750 [===================>..........] - ETA: 3s - loss: 0.5834 - accuracy: 0.7903\n",
      " 87/750 [==>...........................] - ETA: 10s - loss: 1.4802 - accuracy: 0.5551\n",
      "506/750 [===================>..........] - ETA: 3s - loss: 0.5828 - accuracy: 0.7905\n",
      "517/750 [===================>..........] - ETA: 3s - loss: 0.5789 - accuracy: 0.7918\n",
      " 92/750 [==>...........................] - ETA: 10s - loss: 1.4586 - accuracy: 0.5615\n",
      "519/750 [===================>..........] - ETA: 3s - loss: 0.5780 - accuracy: 0.7921\n",
      "100/750 [===>..........................] - ETA: 10s - loss: 1.4206 - accuracy: 0.5695\n",
      "523/750 [===================>..........] - ETA: 3s - loss: 0.5774 - accuracy: 0.7922\n",
      "104/750 [===>..........................] - ETA: 10s - loss: 1.4027 - accuracy: 0.5735\n",
      "528/750 [====================>.........] - ETA: 3s - loss: 0.5755 - accuracy: 0.7930\n",
      "114/750 [===>..........................] - ETA: 10s - loss: 1.3646 - accuracy: 0.5842\n",
      "542/750 [====================>.........] - ETA: 2s - loss: 0.5726 - accuracy: 0.7942\n",
      "119/750 [===>..........................] - ETA: 10s - loss: 1.3467 - accuracy: 0.5892\n",
      "550/750 [=====================>........] - ETA: 2s - loss: 0.5701 - accuracy: 0.7954\n",
      "129/750 [====>.........................] - ETA: 10s - loss: 1.3119 - accuracy: 0.5998\n",
      "553/750 [=====================>........] - ETA: 2s - loss: 0.5692 - accuracy: 0.7956\n",
      "137/750 [====>.........................] - ETA: 9s - loss: 1.2864 - accuracy: 0.6066 \n",
      "562/750 [=====================>........] - ETA: 2s - loss: 0.5673 - accuracy: 0.7966\n",
      "145/750 [====>.........................] - ETA: 9s - loss: 1.2638 - accuracy: 0.6128\n",
      "571/750 [=====================>........] - ETA: 2s - loss: 0.5652 - accuracy: 0.7971\n",
      "153/750 [=====>........................] - ETA: 9s - loss: 1.2430 - accuracy: 0.6165\n",
      "579/750 [======================>.......] - ETA: 2s - loss: 0.5632 - accuracy: 0.7978\n",
      "159/750 [=====>........................] - ETA: 9s - loss: 1.2268 - accuracy: 0.6213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=78156)\u001b[0m 2024-02-22 22:02:15.876994: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/750 [======================>.......] - ETA: 2s - loss: 0.5625 - accuracy: 0.7981\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 1/30\n",
      "171/750 [=====>........................] - ETA: 8s - loss: 1.1991 - accuracy: 0.6290\n",
      "595/750 [======================>.......] - ETA: 2s - loss: 0.5603 - accuracy: 0.7989\n",
      "184/750 [======>.......................] - ETA: 8s - loss: 1.1679 - accuracy: 0.6372\n",
      "602/750 [=======================>......] - ETA: 2s - loss: 0.5583 - accuracy: 0.7995\n",
      "607/750 [=======================>......] - ETA: 2s - loss: 0.5577 - accuracy: 0.7997\n",
      "191/750 [======>.......................] - ETA: 8s - loss: 1.1525 - accuracy: 0.6416\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.5565 - accuracy: 0.8000\n",
      "196/750 [======>.......................] - ETA: 8s - loss: 1.1425 - accuracy: 0.6443\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.5541 - accuracy: 0.8007\n",
      "204/750 [=======>......................] - ETA: 8s - loss: 1.1266 - accuracy: 0.6492\n",
      "635/750 [========================>.....] - ETA: 1s - loss: 0.5516 - accuracy: 0.8017\n",
      "214/750 [=======>......................] - ETA: 7s - loss: 1.1107 - accuracy: 0.6535\n",
      "649/750 [========================>.....] - ETA: 1s - loss: 0.5488 - accuracy: 0.8027\n",
      "225/750 [========>.....................] - ETA: 7s - loss: 1.0941 - accuracy: 0.6584\n",
      "655/750 [=========================>....] - ETA: 1s - loss: 0.5484 - accuracy: 0.8029\n",
      "231/750 [========>.....................] - ETA: 7s - loss: 1.0852 - accuracy: 0.6610\n",
      "237/750 [========>.....................] - ETA: 7s - loss: 1.0752 - accuracy: 0.6642\n",
      "662/750 [=========================>....] - ETA: 1s - loss: 0.5475 - accuracy: 0.8032\n",
      "238/750 [========>.....................] - ETA: 7s - loss: 1.0735 - accuracy: 0.6647\n",
      "670/750 [=========================>....] - ETA: 1s - loss: 0.5467 - accuracy: 0.8036\n",
      "247/750 [========>.....................] - ETA: 7s - loss: 1.0613 - accuracy: 0.6687\n",
      "681/750 [==========================>...] - ETA: 0s - loss: 0.5442 - accuracy: 0.8045\n",
      "256/750 [=========>....................] - ETA: 7s - loss: 1.0524 - accuracy: 0.6712\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.5432 - accuracy: 0.8049\n",
      "265/750 [=========>....................] - ETA: 7s - loss: 1.0397 - accuracy: 0.6747\n",
      "691/750 [==========================>...] - ETA: 0s - loss: 0.5429 - accuracy: 0.8051\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.5421 - accuracy: 0.8053\n",
      "275/750 [==========>...................] - ETA: 7s - loss: 1.0261 - accuracy: 0.6791\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.5406 - accuracy: 0.8059\n",
      "288/750 [==========>...................] - ETA: 6s - loss: 1.0106 - accuracy: 0.6828\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.5403 - accuracy: 0.8060\n",
      "298/750 [==========>...................] - ETA: 6s - loss: 1.0008 - accuracy: 0.6848\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.5395 - accuracy: 0.8061\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.5387 - accuracy: 0.8064\n",
      "304/750 [===========>..................] - ETA: 6s - loss: 0.9929 - accuracy: 0.6877\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.5367 - accuracy: 0.8071\n",
      "318/750 [===========>..................] - ETA: 6s - loss: 0.9778 - accuracy: 0.6921\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.5354 - accuracy: 0.8074\n",
      "329/750 [============>.................] - ETA: 6s - loss: 0.9673 - accuracy: 0.6947\n",
      "333/750 [============>.................] - ETA: 6s - loss: 0.9633 - accuracy: 0.6957\n",
      "341/750 [============>.................] - ETA: 5s - loss: 0.9563 - accuracy: 0.6977\n",
      "356/750 [=============>................] - ETA: 5s - loss: 0.9435 - accuracy: 0.7016\n",
      "361/750 [=============>................] - ETA: 5s - loss: 0.9394 - accuracy: 0.7029\n",
      "367/750 [=============>................] - ETA: 5s - loss: 0.9344 - accuracy: 0.7044\n",
      "371/750 [=============>................] - ETA: 5s - loss: 0.9310 - accuracy: 0.7055\n",
      "377/750 [==============>...............] - ETA: 5s - loss: 0.9266 - accuracy: 0.7067\n",
      "384/750 [==============>...............] - ETA: 5s - loss: 0.9216 - accuracy: 0.7082\n",
      "399/750 [==============>...............] - ETA: 4s - loss: 0.9104 - accuracy: 0.7117\n",
      "408/750 [===============>..............] - ETA: 4s - loss: 0.9025 - accuracy: 0.7139\n",
      "419/750 [===============>..............] - ETA: 4s - loss: 0.8930 - accuracy: 0.7174\n",
      "432/750 [================>.............] - ETA: 4s - loss: 0.8840 - accuracy: 0.7203\n",
      "448/750 [================>.............] - ETA: 4s - loss: 0.8745 - accuracy: 0.7226\n",
      "450/750 [=================>............] - ETA: 4s - loss: 0.8729 - accuracy: 0.7232\n",
      "462/750 [=================>............] - ETA: 3s - loss: 0.8653 - accuracy: 0.7250\n",
      "472/750 [=================>............] - ETA: 3s - loss: 0.8602 - accuracy: 0.7267\n",
      "485/750 [==================>...........] - ETA: 3s - loss: 0.8523 - accuracy: 0.7293\n",
      "493/750 [==================>...........] - ETA: 3s - loss: 0.8471 - accuracy: 0.7313\n",
      "497/750 [==================>...........] - ETA: 3s - loss: 0.8447 - accuracy: 0.7320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:02:19,984 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6771224576; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499/750 [==================>...........] - ETA: 3s - loss: 0.8437 - accuracy: 0.7322\n",
      "512/750 [===================>..........] - ETA: 3s - loss: 0.8370 - accuracy: 0.7341\n",
      "518/750 [===================>..........] - ETA: 3s - loss: 0.8334 - accuracy: 0.7352\n",
      "521/750 [===================>..........] - ETA: 3s - loss: 0.8314 - accuracy: 0.7357\n",
      "535/750 [====================>.........] - ETA: 2s - loss: 0.8242 - accuracy: 0.7379\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.8205 - accuracy: 0.7389\n",
      "547/750 [====================>.........] - ETA: 2s - loss: 0.8183 - accuracy: 0.7395\n",
      "551/750 [=====================>........] - ETA: 2s - loss: 0.8166 - accuracy: 0.7399\n",
      "560/750 [=====================>........] - ETA: 2s - loss: 0.8118 - accuracy: 0.7415\n",
      "571/750 [=====================>........] - ETA: 2s - loss: 0.8084 - accuracy: 0.7424\n",
      "  1/750 [..............................] - ETA: 1:04:45 - loss: 2.3501 - accuracy: 0.1250\n",
      "581/750 [======================>.......] - ETA: 2s - loss: 0.8041 - accuracy: 0.7438\n",
      " 16/750 [..............................] - ETA: 8s - loss: 1.4809 - accuracy: 0.5371   \n",
      "583/750 [======================>.......] - ETA: 2s - loss: 0.8032 - accuracy: 0.7439\n",
      " 17/750 [..............................] - ETA: 13s - loss: 1.4526 - accuracy: 0.5469\n",
      "586/750 [======================>.......] - ETA: 2s - loss: 0.8022 - accuracy: 0.7442\n",
      " 25/750 [>.............................] - ETA: 12s - loss: 1.3150 - accuracy: 0.5781\n",
      "596/750 [======================>.......] - ETA: 2s - loss: 0.7979 - accuracy: 0.7455\n",
      " 37/750 [>.............................] - ETA: 10s - loss: 1.1824 - accuracy: 0.6128\n",
      "606/750 [=======================>......] - ETA: 1s - loss: 0.7942 - accuracy: 0.7467\n",
      "750/750 [==============================] - 18s 19ms/step - loss: 0.5348 - accuracy: 0.8078 - val_loss: 0.4059 - val_accuracy: 0.8547\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 2/30\n",
      " 43/750 [>.............................] - ETA: 9s - loss: 1.1472 - accuracy: 0.6210 \n",
      "613/750 [=======================>......] - ETA: 1s - loss: 0.7917 - accuracy: 0.7473\n",
      " 52/750 [=>............................] - ETA: 9s - loss: 1.0884 - accuracy: 0.6343 \n",
      "623/750 [=======================>......] - ETA: 1s - loss: 0.7876 - accuracy: 0.7486\n",
      "  8/750 [..............................] - ETA: 20s - loss: 0.3959 - accuracy: 0.8555\n",
      " 64/750 [=>............................] - ETA: 9s - loss: 1.0275 - accuracy: 0.6553\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.7839 - accuracy: 0.7493\n",
      " 12/750 [..............................] - ETA: 18s - loss: 0.3824 - accuracy: 0.8659\n",
      " 21/750 [..............................] - ETA: 14s - loss: 0.3891 - accuracy: 0.8586\n",
      " 74/750 [=>............................] - ETA: 9s - loss: 0.9832 - accuracy: 0.6706 \n",
      "640/750 [========================>.....] - ETA: 1s - loss: 0.7831 - accuracy: 0.7496\n",
      " 80/750 [==>...........................] - ETA: 9s - loss: 0.9584 - accuracy: 0.6793\n",
      "648/750 [========================>.....] - ETA: 1s - loss: 0.7809 - accuracy: 0.7503\n",
      " 88/750 [==>...........................] - ETA: 9s - loss: 0.9358 - accuracy: 0.6873\n",
      "657/750 [=========================>....] - ETA: 1s - loss: 0.7771 - accuracy: 0.7516\n",
      "101/750 [===>..........................] - ETA: 8s - loss: 0.9098 - accuracy: 0.6955\n",
      "668/750 [=========================>....] - ETA: 1s - loss: 0.7745 - accuracy: 0.7523\n",
      " 55/750 [=>............................] - ETA: 10s - loss: 0.3869 - accuracy: 0.8574\n",
      "107/750 [===>..........................] - ETA: 8s - loss: 0.8931 - accuracy: 0.7002\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.7723 - accuracy: 0.7529\n",
      " 60/750 [=>............................] - ETA: 11s - loss: 0.3855 - accuracy: 0.8568\n",
      "109/750 [===>..........................] - ETA: 9s - loss: 0.8874 - accuracy: 0.7017\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.7712 - accuracy: 0.7533\n",
      "111/750 [===>..........................] - ETA: 9s - loss: 0.8819 - accuracy: 0.7034\n",
      " 69/750 [=>............................] - ETA: 10s - loss: 0.3895 - accuracy: 0.8580\n",
      "121/750 [===>..........................] - ETA: 9s - loss: 0.8641 - accuracy: 0.7095\n",
      "688/750 [==========================>...] - ETA: 0s - loss: 0.7692 - accuracy: 0.7539\n",
      " 81/750 [==>...........................] - ETA: 9s - loss: 0.3925 - accuracy: 0.8561 \n",
      "135/750 [====>.........................] - ETA: 8s - loss: 0.8395 - accuracy: 0.7153\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.7647 - accuracy: 0.7550\n",
      "145/750 [====>.........................] - ETA: 8s - loss: 0.8270 - accuracy: 0.7182\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.7611 - accuracy: 0.7561\n",
      "154/750 [=====>........................] - ETA: 7s - loss: 0.8148 - accuracy: 0.7226\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.7582 - accuracy: 0.7571\n",
      "157/750 [=====>........................] - ETA: 8s - loss: 0.8123 - accuracy: 0.7230\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.7552 - accuracy: 0.7579\n",
      "163/750 [=====>........................] - ETA: 7s - loss: 0.8009 - accuracy: 0.7275\n",
      "168/750 [=====>........................] - ETA: 7s - loss: 0.7931 - accuracy: 0.7301\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.7514 - accuracy: 0.7591\n",
      "128/750 [====>.........................] - ETA: 8s - loss: 0.3918 - accuracy: 0.8558\n",
      "179/750 [======>.......................] - ETA: 7s - loss: 0.7795 - accuracy: 0.7346\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.7501 - accuracy: 0.7596\n",
      "134/750 [====>.........................] - ETA: 8s - loss: 0.3913 - accuracy: 0.8563\n",
      "140/750 [====>.........................] - ETA: 8s - loss: 0.3897 - accuracy: 0.8570\n",
      "190/750 [======>.......................] - ETA: 7s - loss: 0.7678 - accuracy: 0.7387\n",
      "146/750 [====>.........................] - ETA: 7s - loss: 0.3923 - accuracy: 0.8561\n",
      "195/750 [======>.......................] - ETA: 7s - loss: 0.7635 - accuracy: 0.7405\n",
      "155/750 [=====>........................] - ETA: 8s - loss: 0.3923 - accuracy: 0.8559\n",
      "205/750 [=======>......................] - ETA: 7s - loss: 0.7543 - accuracy: 0.7434\n",
      "167/750 [=====>........................] - ETA: 7s - loss: 0.3940 - accuracy: 0.8565\n",
      "215/750 [=======>......................] - ETA: 7s - loss: 0.7466 - accuracy: 0.7446\n",
      "178/750 [======>.......................] - ETA: 7s - loss: 0.3968 - accuracy: 0.8559\n",
      "223/750 [=======>......................] - ETA: 7s - loss: 0.7384 - accuracy: 0.7474\n",
      "226/750 [========>.....................] - ETA: 7s - loss: 0.7366 - accuracy: 0.7479\n",
      "238/750 [========>.....................] - ETA: 6s - loss: 0.7251 - accuracy: 0.7518\n",
      "244/750 [========>.....................] - ETA: 6s - loss: 0.7205 - accuracy: 0.7535\n",
      "249/750 [========>.....................] - ETA: 6s - loss: 0.7182 - accuracy: 0.7537\n",
      "210/750 [=======>......................] - ETA: 7s - loss: 0.3965 - accuracy: 0.8544\n",
      "257/750 [=========>....................] - ETA: 6s - loss: 0.7135 - accuracy: 0.7543\n",
      "265/750 [=========>....................] - ETA: 6s - loss: 0.7070 - accuracy: 0.7567\n",
      "276/750 [==========>...................] - ETA: 6s - loss: 0.6993 - accuracy: 0.7590\n",
      "285/750 [==========>...................] - ETA: 6s - loss: 0.6925 - accuracy: 0.7613\n",
      "293/750 [==========>...................] - ETA: 6s - loss: 0.6891 - accuracy: 0.7626\n",
      "302/750 [===========>..................] - ETA: 6s - loss: 0.6838 - accuracy: 0.7642\n",
      "264/750 [=========>....................] - ETA: 6s - loss: 0.3960 - accuracy: 0.8539\n",
      "308/750 [===========>..................] - ETA: 5s - loss: 0.6814 - accuracy: 0.7655\n",
      "318/750 [===========>..................] - ETA: 5s - loss: 0.6778 - accuracy: 0.7672\n",
      "328/750 [============>.................] - ETA: 5s - loss: 0.6727 - accuracy: 0.7689\n",
      "341/750 [============>.................] - ETA: 5s - loss: 0.6665 - accuracy: 0.7708\n",
      "353/750 [=============>................] - ETA: 5s - loss: 0.6617 - accuracy: 0.7724\n",
      "357/750 [=============>................] - ETA: 5s - loss: 0.6589 - accuracy: 0.7733\n",
      "371/750 [=============>................] - ETA: 4s - loss: 0.6526 - accuracy: 0.7748\n",
      "383/750 [==============>...............] - ETA: 4s - loss: 0.6477 - accuracy: 0.7766\n",
      "393/750 [==============>...............] - ETA: 4s - loss: 0.6427 - accuracy: 0.7780\n",
      "349/750 [============>.................] - ETA: 5s - loss: 0.3954 - accuracy: 0.8558\n",
      "  1/750 [..............................] - ETA: 8s - loss: 0.2984 - accuracy: 0.9219\n",
      "403/750 [===============>..............] - ETA: 4s - loss: 0.6396 - accuracy: 0.7795\n",
      "409/750 [===============>..............] - ETA: 4s - loss: 0.6372 - accuracy: 0.7803\n",
      "  4/750 [..............................] - ETA: 15s - loss: 0.3840 - accuracy: 0.8555\n",
      "423/750 [===============>..............] - ETA: 4s - loss: 0.6312 - accuracy: 0.7821\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 0.3946 - accuracy: 0.8564\n",
      "428/750 [================>.............] - ETA: 4s - loss: 0.6283 - accuracy: 0.7831\n",
      " 45/750 [>.............................] - ETA: 11s - loss: 0.3779 - accuracy: 0.8611\n",
      "437/750 [================>.............] - ETA: 4s - loss: 0.6256 - accuracy: 0.7840\n",
      "394/750 [==============>...............] - ETA: 4s - loss: 0.3949 - accuracy: 0.8564\n",
      " 34/750 [>.............................] - ETA: 13s - loss: 0.3806 - accuracy: 0.8585\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "449/750 [================>.............] - ETA: 3s - loss: 0.6216 - accuracy: 0.7847\n",
      "396/750 [==============>...............] - ETA: 4s - loss: 0.3952 - accuracy: 0.8562\n",
      "402/750 [===============>..............] - ETA: 4s - loss: 0.3946 - accuracy: 0.8564\n",
      "458/750 [=================>............] - ETA: 3s - loss: 0.6191 - accuracy: 0.7854\n",
      "407/750 [===============>..............] - ETA: 4s - loss: 0.3936 - accuracy: 0.8568\n",
      "411/750 [===============>..............] - ETA: 4s - loss: 0.3943 - accuracy: 0.8566\n",
      "466/750 [=================>............] - ETA: 3s - loss: 0.6179 - accuracy: 0.7856\n",
      "478/750 [==================>...........] - ETA: 3s - loss: 0.6143 - accuracy: 0.7868\n",
      " 97/750 [==>...........................] - ETA: 9s - loss: 0.3943 - accuracy: 0.8562\n",
      "485/750 [==================>...........] - ETA: 3s - loss: 0.6117 - accuracy: 0.7877\n",
      " 94/750 [==>...........................] - ETA: 9s - loss: 0.3890 - accuracy: 0.8582\n",
      "500/750 [===================>..........] - ETA: 3s - loss: 0.6079 - accuracy: 0.7887\n",
      "450/750 [=================>............] - ETA: 3s - loss: 0.3922 - accuracy: 0.8572\n",
      "504/750 [===================>..........] - ETA: 3s - loss: 0.6074 - accuracy: 0.7890\n",
      "456/750 [=================>............] - ETA: 3s - loss: 0.3918 - accuracy: 0.8573\n",
      "109/750 [===>..........................] - ETA: 8s - loss: 0.3891 - accuracy: 0.8578\n",
      "514/750 [===================>..........] - ETA: 2s - loss: 0.6040 - accuracy: 0.7903\n",
      "750/750 [==============================] - 20s 19ms/step - loss: 0.7492 - accuracy: 0.7599 - val_loss: 0.5413 - val_accuracy: 0.8141\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 2/30\n",
      "  1/750 [..............................] - ETA: 8s - loss: 0.6683 - accuracy: 0.7969\n",
      "118/750 [===>..........................] - ETA: 8s - loss: 0.3923 - accuracy: 0.8563\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "522/750 [===================>..........] - ETA: 2s - loss: 0.6017 - accuracy: 0.7909\n",
      " 11/750 [..............................] - ETA: 7s - loss: 0.5365 - accuracy: 0.8139\n",
      "534/750 [====================>.........] - ETA: 2s - loss: 0.5987 - accuracy: 0.7918\n",
      " 17/750 [..............................] - ETA: 11s - loss: 0.5255 - accuracy: 0.8153\n",
      "547/750 [====================>.........] - ETA: 2s - loss: 0.5960 - accuracy: 0.7925\n",
      " 23/750 [..............................] - ETA: 11s - loss: 0.5183 - accuracy: 0.8166\n",
      "492/750 [==================>...........] - ETA: 3s - loss: 0.3926 - accuracy: 0.8575\n",
      "498/750 [==================>...........] - ETA: 3s - loss: 0.3918 - accuracy: 0.8575\n",
      "554/750 [=====================>........] - ETA: 2s - loss: 0.5943 - accuracy: 0.7930\n",
      " 29/750 [>.............................] - ETA: 12s - loss: 0.5252 - accuracy: 0.8120\n",
      "556/750 [=====================>........] - ETA: 2s - loss: 0.5933 - accuracy: 0.7933\n",
      " 41/750 [>.............................] - ETA: 10s - loss: 0.5183 - accuracy: 0.8209\n",
      "560/750 [=====================>........] - ETA: 2s - loss: 0.5925 - accuracy: 0.7937\n",
      "561/750 [=====================>........] - ETA: 2s - loss: 0.5924 - accuracy: 0.7938\n",
      "566/750 [=====================>........] - ETA: 2s - loss: 0.5914 - accuracy: 0.7941\n",
      "528/750 [====================>.........] - ETA: 2s - loss: 0.3906 - accuracy: 0.8577\n",
      "574/750 [=====================>........] - ETA: 2s - loss: 0.5894 - accuracy: 0.7948\n",
      " 49/750 [>.............................] - ETA: 12s - loss: 0.5162 - accuracy: 0.8243\n",
      "534/750 [====================>.........] - ETA: 2s - loss: 0.3898 - accuracy: 0.8579\n",
      "194/750 [======>.......................] - ETA: 7s - loss: 0.3967 - accuracy: 0.8547\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "582/750 [======================>.......] - ETA: 2s - loss: 0.5887 - accuracy: 0.7950\n",
      " 58/750 [=>............................] - ETA: 11s - loss: 0.5239 - accuracy: 0.8214\n",
      "539/750 [====================>.........] - ETA: 2s - loss: 0.3903 - accuracy: 0.8578\n",
      "546/750 [====================>.........] - ETA: 2s - loss: 0.3901 - accuracy: 0.8577\n",
      "589/750 [======================>.......] - ETA: 2s - loss: 0.5869 - accuracy: 0.7957\n",
      " 66/750 [=>............................] - ETA: 11s - loss: 0.5245 - accuracy: 0.8194\n",
      "187/750 [======>.......................] - ETA: 7s - loss: 0.3951 - accuracy: 0.8558\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.5849 - accuracy: 0.7965\n",
      " 74/750 [=>............................] - ETA: 11s - loss: 0.5248 - accuracy: 0.8180\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.5845 - accuracy: 0.7964\n",
      " 82/750 [==>...........................] - ETA: 10s - loss: 0.5137 - accuracy: 0.8230\n",
      "218/750 [=======>......................] - ETA: 7s - loss: 0.3961 - accuracy: 0.8548\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.5805 - accuracy: 0.7975\n",
      " 90/750 [==>...........................] - ETA: 10s - loss: 0.5139 - accuracy: 0.8248\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.5784 - accuracy: 0.7982\n",
      "103/750 [===>..........................] - ETA: 9s - loss: 0.5092 - accuracy: 0.8263 \n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.5758 - accuracy: 0.7988\n",
      "112/750 [===>..........................] - ETA: 9s - loss: 0.5106 - accuracy: 0.8255\n",
      "249/750 [========>.....................] - ETA: 6s - loss: 0.3969 - accuracy: 0.8540\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "649/750 [========================>.....] - ETA: 1s - loss: 0.5747 - accuracy: 0.7992\n",
      "127/750 [====>.........................] - ETA: 8s - loss: 0.5129 - accuracy: 0.8263\n",
      "607/750 [=======================>......] - ETA: 1s - loss: 0.3866 - accuracy: 0.8587\n",
      "659/750 [=========================>....] - ETA: 1s - loss: 0.5722 - accuracy: 0.7999\n",
      "137/750 [====>.........................] - ETA: 8s - loss: 0.5127 - accuracy: 0.8270\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.3851 - accuracy: 0.8592\n",
      "662/750 [=========================>....] - ETA: 1s - loss: 0.5720 - accuracy: 0.7999\n",
      "142/750 [====>.........................] - ETA: 8s - loss: 0.5120 - accuracy: 0.8278\n",
      "663/750 [=========================>....] - ETA: 1s - loss: 0.5716 - accuracy: 0.8001\n",
      "273/750 [=========>....................] - ETA: 6s - loss: 0.3946 - accuracy: 0.8547\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "676/750 [==========================>...] - ETA: 0s - loss: 0.5699 - accuracy: 0.8007\n",
      "153/750 [=====>........................] - ETA: 8s - loss: 0.5070 - accuracy: 0.8297\n",
      "681/750 [==========================>...] - ETA: 0s - loss: 0.5688 - accuracy: 0.8010\n",
      "161/750 [=====>........................] - ETA: 8s - loss: 0.5081 - accuracy: 0.8285\n",
      "651/750 [=========================>....] - ETA: 1s - loss: 0.3841 - accuracy: 0.8596\n",
      "684/750 [==========================>...] - ETA: 0s - loss: 0.5683 - accuracy: 0.8012\n",
      "170/750 [=====>........................] - ETA: 8s - loss: 0.5075 - accuracy: 0.8275\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 0.5672 - accuracy: 0.8016\n",
      "295/750 [==========>...................] - ETA: 5s - loss: 0.3949 - accuracy: 0.8557\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.5646 - accuracy: 0.8023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:02:29,985 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6856208384; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/750 [===========================>..] - ETA: 0s - loss: 0.5638 - accuracy: 0.8026\n",
      "188/750 [======>.......................] - ETA: 7s - loss: 0.5122 - accuracy: 0.8261\n",
      "305/750 [===========>..................] - ETA: 5s - loss: 0.3944 - accuracy: 0.8562\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.5611 - accuracy: 0.8035\n",
      "314/750 [===========>..................] - ETA: 5s - loss: 0.3941 - accuracy: 0.8562\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.5594 - accuracy: 0.8043\n",
      "322/750 [===========>..................] - ETA: 5s - loss: 0.3929 - accuracy: 0.8567\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.5578 - accuracy: 0.8049\n",
      "214/750 [=======>......................] - ETA: 7s - loss: 0.5115 - accuracy: 0.8272\n",
      "344/750 [============>.................] - ETA: 5s - loss: 0.3961 - accuracy: 0.8557\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "367/750 [=============>................] - ETA: 4s - loss: 0.3944 - accuracy: 0.8564\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "389/750 [==============>...............] - ETA: 4s - loss: 0.3943 - accuracy: 0.8566\n",
      "267/750 [=========>....................] - ETA: 6s - loss: 0.5050 - accuracy: 0.8299\n",
      "423/750 [===============>..............] - ETA: 4s - loss: 0.3925 - accuracy: 0.8571\n",
      "281/750 [==========>...................] - ETA: 6s - loss: 0.5045 - accuracy: 0.8299\n",
      "298/750 [==========>...................] - ETA: 6s - loss: 0.5018 - accuracy: 0.8309\n",
      "307/750 [===========>..................] - ETA: 5s - loss: 0.5003 - accuracy: 0.8317\n",
      "318/750 [===========>..................] - ETA: 5s - loss: 0.4986 - accuracy: 0.8320\n",
      "438/750 [================>.............] - ETA: 4s - loss: 0.3924 - accuracy: 0.8571\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "324/750 [===========>..................] - ETA: 5s - loss: 0.4988 - accuracy: 0.8316\n",
      " 43/750 [>.............................] - ETA: 12s - loss: 0.5139 - accuracy: 0.8241\n",
      "467/750 [=================>............] - ETA: 3s - loss: 0.3919 - accuracy: 0.8578\n",
      "478/750 [==================>...........] - ETA: 3s - loss: 0.3914 - accuracy: 0.8578\n",
      "484/750 [==================>...........] - ETA: 3s - loss: 0.3923 - accuracy: 0.8574\n",
      "381/750 [==============>...............] - ETA: 4s - loss: 0.4928 - accuracy: 0.8349\n",
      "391/750 [==============>...............] - ETA: 4s - loss: 0.4928 - accuracy: 0.8353\n",
      "523/750 [===================>..........] - ETA: 2s - loss: 0.3908 - accuracy: 0.8578\n",
      "402/750 [===============>..............] - ETA: 4s - loss: 0.4927 - accuracy: 0.8351\n",
      "514/750 [===================>..........] - ETA: 3s - loss: 0.3905 - accuracy: 0.8580\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "416/750 [===============>..............] - ETA: 4s - loss: 0.4908 - accuracy: 0.8356\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.3813 - accuracy: 0.8606 - val_loss: 0.3924 - val_accuracy: 0.8583\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 3/30\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.5038 - accuracy: 0.8125\n",
      "429/750 [================>.............] - ETA: 3s - loss: 0.4916 - accuracy: 0.8353\n",
      "  4/750 [..............................] - ETA: 18s - loss: 0.3449 - accuracy: 0.8672\n",
      "435/750 [================>.............] - ETA: 3s - loss: 0.4907 - accuracy: 0.8353\n",
      " 13/750 [..............................] - ETA: 16s - loss: 0.3237 - accuracy: 0.8714\n",
      " 27/750 [>.............................] - ETA: 10s - loss: 0.3576 - accuracy: 0.8640\n",
      "570/750 [=====================>........] - ETA: 2s - loss: 0.3883 - accuracy: 0.8584\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "450/750 [=================>............] - ETA: 3s - loss: 0.4881 - accuracy: 0.8364\n",
      " 34/750 [>.............................] - ETA: 10s - loss: 0.3704 - accuracy: 0.8640\n",
      "460/750 [=================>............] - ETA: 3s - loss: 0.4877 - accuracy: 0.8365\n",
      " 44/750 [>.............................] - ETA: 10s - loss: 0.3596 - accuracy: 0.8658\n",
      "471/750 [=================>............] - ETA: 3s - loss: 0.4876 - accuracy: 0.8366\n",
      " 56/750 [=>............................] - ETA: 9s - loss: 0.3598 - accuracy: 0.8655\n",
      "481/750 [==================>...........] - ETA: 3s - loss: 0.4865 - accuracy: 0.8369\n",
      " 63/750 [=>............................] - ETA: 8s - loss: 0.3586 - accuracy: 0.8648\n",
      "197/750 [======>.......................] - ETA: 7s - loss: 0.5147 - accuracy: 0.8261\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "491/750 [==================>...........] - ETA: 3s - loss: 0.4859 - accuracy: 0.8371\n",
      " 74/750 [=>............................] - ETA: 8s - loss: 0.3549 - accuracy: 0.8672\n",
      "593/750 [======================>.......] - ETA: 2s - loss: 0.3874 - accuracy: 0.8585\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "503/750 [===================>..........] - ETA: 3s - loss: 0.4856 - accuracy: 0.8374\n",
      " 86/750 [==>...........................] - ETA: 8s - loss: 0.3571 - accuracy: 0.8672\n",
      " 97/750 [==>...........................] - ETA: 7s - loss: 0.3559 - accuracy: 0.8681\n",
      "624/750 [=======================>......] - ETA: 1s - loss: 0.3856 - accuracy: 0.8592\n",
      "522/750 [===================>..........] - ETA: 2s - loss: 0.4851 - accuracy: 0.8373\n",
      "532/750 [====================>.........] - ETA: 2s - loss: 0.4846 - accuracy: 0.8373\n",
      "221/750 [=======>......................] - ETA: 7s - loss: 0.5112 - accuracy: 0.8275\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "540/750 [====================>.........] - ETA: 2s - loss: 0.4846 - accuracy: 0.8372\n",
      "550/750 [=====================>........] - ETA: 2s - loss: 0.4838 - accuracy: 0.8374\n",
      "635/750 [========================>.....] - ETA: 1s - loss: 0.3843 - accuracy: 0.8597\n",
      "118/750 [===>..........................] - ETA: 7s - loss: 0.3483 - accuracy: 0.8709\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  9/750 [..............................] - ETA: 4s - loss: 0.4412 - accuracy: 0.8368\n",
      "244/750 [========>.....................] - ETA: 7s - loss: 0.5067 - accuracy: 0.8293\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "130/750 [====>.........................] - ETA: 7s - loss: 0.3507 - accuracy: 0.8698\n",
      " 19/750 [..............................] - ETA: 6s - loss: 0.4293 - accuracy: 0.8405\n",
      "567/750 [=====================>........] - ETA: 2s - loss: 0.4834 - accuracy: 0.8376\n",
      "572/750 [=====================>........] - ETA: 2s - loss: 0.4831 - accuracy: 0.8376\n",
      "150/750 [=====>........................] - ETA: 7s - loss: 0.3488 - accuracy: 0.8699\n",
      "668/750 [=========================>....] - ETA: 1s - loss: 0.3839 - accuracy: 0.8599\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "143/750 [====>.........................] - ETA: 7s - loss: 0.3502 - accuracy: 0.8702\n",
      " 26/750 [>.............................] - ETA: 8s - loss: 0.4267 - accuracy: 0.8407\n",
      "134/750 [====>.........................] - ETA: 7s - loss: 0.3498 - accuracy: 0.8702\n",
      " 35/750 [>.............................] - ETA: 8s - loss: 0.4101 - accuracy: 0.8500\n",
      "264/750 [=========>....................] - ETA: 6s - loss: 0.5051 - accuracy: 0.8303\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "677/750 [==========================>...] - ETA: 0s - loss: 0.3840 - accuracy: 0.8598\n",
      " 41/750 [>.............................] - ETA: 8s - loss: 0.4037 - accuracy: 0.8502\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.4823 - accuracy: 0.8380\n",
      " 44/750 [>.............................] - ETA: 8s - loss: 0.4021 - accuracy: 0.8509\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 0.3841 - accuracy: 0.8597\n",
      "168/750 [=====>........................] - ETA: 7s - loss: 0.3460 - accuracy: 0.8714\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 48/750 [>.............................] - ETA: 9s - loss: 0.4031 - accuracy: 0.8519\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 0.4821 - accuracy: 0.8378\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.3841 - accuracy: 0.8599\n",
      "609/750 [=======================>......] - ETA: 1s - loss: 0.4819 - accuracy: 0.8378\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.3838 - accuracy: 0.8598\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.4821 - accuracy: 0.8378\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.3824 - accuracy: 0.8603\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "184/750 [======>.......................] - ETA: 6s - loss: 0.3499 - accuracy: 0.8692\n",
      " 77/750 [==>...........................] - ETA: 8s - loss: 0.4021 - accuracy: 0.8549\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.4819 - accuracy: 0.8378\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8604\n",
      " 80/750 [==>...........................] - ETA: 8s - loss: 0.4025 - accuracy: 0.8547\n",
      "635/750 [========================>.....] - ETA: 1s - loss: 0.4817 - accuracy: 0.8377\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8606\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "645/750 [========================>.....] - ETA: 1s - loss: 0.4812 - accuracy: 0.8375\n",
      "218/750 [=======>......................] - ETA: 6s - loss: 0.3509 - accuracy: 0.8688\n",
      "345/750 [============>.................] - ETA: 5s - loss: 0.4962 - accuracy: 0.8332\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "250/750 [=========>....................] - ETA: 6s - loss: 0.3509 - accuracy: 0.8698\n",
      "136/750 [====>.........................] - ETA: 7s - loss: 0.4101 - accuracy: 0.8505\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.4807 - accuracy: 0.8372\n",
      "368/750 [=============>................] - ETA: 4s - loss: 0.4950 - accuracy: 0.8337\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "139/750 [====>.........................] - ETA: 7s - loss: 0.4093 - accuracy: 0.8508\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.4800 - accuracy: 0.8372\n",
      "144/750 [====>.........................] - ETA: 7s - loss: 0.4072 - accuracy: 0.8511\n",
      "281/750 [==========>...................] - ETA: 5s - loss: 0.3512 - accuracy: 0.8699\n",
      "152/750 [=====>........................] - ETA: 7s - loss: 0.4078 - accuracy: 0.8512\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.4796 - accuracy: 0.8374\n",
      "293/750 [==========>...................] - ETA: 5s - loss: 0.3488 - accuracy: 0.8709\n",
      "301/750 [===========>..................] - ETA: 5s - loss: 0.3480 - accuracy: 0.8712\n",
      "167/750 [=====>........................] - ETA: 7s - loss: 0.4097 - accuracy: 0.8510\n",
      "179/750 [======>.......................] - ETA: 7s - loss: 0.4112 - accuracy: 0.8505\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.4783 - accuracy: 0.8376\n",
      "188/750 [======>.......................] - ETA: 6s - loss: 0.4094 - accuracy: 0.8504\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.4783 - accuracy: 0.8375\n",
      "327/750 [============>.................] - ETA: 5s - loss: 0.3458 - accuracy: 0.8722\n",
      "312/750 [===========>..................] - ETA: 5s - loss: 0.3482 - accuracy: 0.8710\n",
      "442/750 [================>.............] - ETA: 3s - loss: 0.4891 - accuracy: 0.8360\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.4771 - accuracy: 0.8377\n",
      "210/750 [=======>......................] - ETA: 6s - loss: 0.4069 - accuracy: 0.8516\n",
      "315/750 [===========>..................] - ETA: 5s - loss: 0.3476 - accuracy: 0.8714\n",
      "215/750 [=======>......................] - ETA: 6s - loss: 0.4062 - accuracy: 0.8520\n",
      "228/750 [========>.....................] - ETA: 6s - loss: 0.4061 - accuracy: 0.8520\n",
      "235/750 [========>.....................] - ETA: 6s - loss: 0.4069 - accuracy: 0.8519\n",
      "409/750 [===============>..............] - ETA: 3s - loss: 0.3449 - accuracy: 0.8718\n",
      "394/750 [==============>...............] - ETA: 4s - loss: 0.3447 - accuracy: 0.8721\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "275/750 [==========>...................] - ETA: 5s - loss: 0.4061 - accuracy: 0.8529\n",
      "404/750 [===============>..............] - ETA: 4s - loss: 0.3440 - accuracy: 0.8722\n",
      "516/750 [===================>..........] - ETA: 2s - loss: 0.4851 - accuracy: 0.8374\n",
      "418/750 [===============>..............] - ETA: 3s - loss: 0.3429 - accuracy: 0.8724\n",
      "294/750 [==========>...................] - ETA: 5s - loss: 0.4058 - accuracy: 0.8526\n",
      "441/750 [================>.............] - ETA: 3s - loss: 0.3436 - accuracy: 0.8717\n",
      "750/750 [==============================] - 18s 18ms/step - loss: 0.5577 - accuracy: 0.8049 - val_loss: 0.4216 - val_accuracy: 0.8512\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 2/30\n",
      "428/750 [================>.............] - ETA: 3s - loss: 0.3439 - accuracy: 0.8720\n",
      "448/750 [================>.............] - ETA: 3s - loss: 0.3432 - accuracy: 0.8718\n",
      "312/750 [===========>..................] - ETA: 5s - loss: 0.4050 - accuracy: 0.8529\n",
      "327/750 [============>.................] - ETA: 5s - loss: 0.4055 - accuracy: 0.8530\n",
      "562/750 [=====================>........] - ETA: 2s - loss: 0.4836 - accuracy: 0.8374\n",
      "472/750 [=================>............] - ETA: 3s - loss: 0.3443 - accuracy: 0.8711\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "351/750 [=============>................] - ETA: 4s - loss: 0.4079 - accuracy: 0.8523\n",
      "493/750 [==================>...........] - ETA: 2s - loss: 0.3433 - accuracy: 0.8714\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "514/750 [===================>..........] - ETA: 2s - loss: 0.3434 - accuracy: 0.8714\n",
      " 56/750 [=>............................] - ETA: 8s - loss: 0.4152 - accuracy: 0.8477\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "195/750 [======>.......................] - ETA: 6s - loss: 0.4111 - accuracy: 0.8500\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "380/750 [==============>...............] - ETA: 4s - loss: 0.4051 - accuracy: 0.8533\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.4772 - accuracy: 0.8376 - val_loss: 0.4469 - val_accuracy: 0.8474\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 3/30\n",
      "527/750 [====================>.........] - ETA: 2s - loss: 0.3436 - accuracy: 0.8716\n",
      " 62/750 [=>............................] - ETA: 9s - loss: 0.4082 - accuracy: 0.8518\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.4821 - accuracy: 0.8379\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "503/750 [===================>..........] - ETA: 2s - loss: 0.3433 - accuracy: 0.8715\n",
      "533/750 [====================>.........] - ETA: 2s - loss: 0.3435 - accuracy: 0.8715\n",
      " 90/750 [==>...........................] - ETA: 8s - loss: 0.4062 - accuracy: 0.8547\n",
      "401/750 [===============>..............] - ETA: 4s - loss: 0.4046 - accuracy: 0.8533\n",
      " 18/750 [..............................] - ETA: 10s - loss: 0.4645 - accuracy: 0.8385\n",
      "411/750 [===============>..............] - ETA: 3s - loss: 0.4044 - accuracy: 0.8535\n",
      " 31/750 [>.............................] - ETA: 8s - loss: 0.4515 - accuracy: 0.8458\n",
      "540/750 [====================>.........] - ETA: 2s - loss: 0.3431 - accuracy: 0.8716\n",
      "417/750 [===============>..............] - ETA: 3s - loss: 0.4044 - accuracy: 0.8535\n",
      "560/750 [=====================>........] - ETA: 2s - loss: 0.3439 - accuracy: 0.8717\n",
      "206/750 [=======>......................] - ETA: 6s - loss: 0.4097 - accuracy: 0.8505\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "426/750 [================>.............] - ETA: 3s - loss: 0.4052 - accuracy: 0.8530\n",
      "570/750 [=====================>........] - ETA: 2s - loss: 0.3439 - accuracy: 0.8720\n",
      "550/750 [=====================>........] - ETA: 2s - loss: 0.3435 - accuracy: 0.8716\n",
      " 58/750 [=>............................] - ETA: 8s - loss: 0.4521 - accuracy: 0.8475\n",
      "123/750 [===>..........................] - ETA: 7s - loss: 0.4140 - accuracy: 0.8493\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  7/750 [..............................] - ETA: 7s - loss: 0.4546 - accuracy: 0.8482\n",
      "243/750 [========>.....................] - ETA: 6s - loss: 0.3522 - accuracy: 0.8689\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 15/750 [..............................] - ETA: 9s - loss: 0.4669 - accuracy: 0.8406\n",
      "672/750 [=========================>....] - ETA: 0s - loss: 0.4804 - accuracy: 0.8374\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 47/750 [>.............................] - ETA: 8s - loss: 0.4493 - accuracy: 0.8491\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 94/750 [==>...........................] - ETA: 7s - loss: 0.4388 - accuracy: 0.8507\n",
      "268/750 [=========>....................] - ETA: 5s - loss: 0.4058 - accuracy: 0.8530\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "101/750 [===>..........................] - ETA: 7s - loss: 0.4357 - accuracy: 0.8512\n",
      "161/750 [=====>........................] - ETA: 7s - loss: 0.4109 - accuracy: 0.8503\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.3426 - accuracy: 0.8726\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "488/750 [==================>...........] - ETA: 2s - loss: 0.4031 - accuracy: 0.8538\n",
      "114/750 [===>..........................] - ETA: 7s - loss: 0.4359 - accuracy: 0.8496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:02:40,073 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6857154560; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/750 [===================>..........] - ETA: 2s - loss: 0.4021 - accuracy: 0.8541\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.4794 - accuracy: 0.8372\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 79/750 [==>...........................] - ETA: 7s - loss: 0.4476 - accuracy: 0.8481\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.3419 - accuracy: 0.8730\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "667/750 [=========================>....] - ETA: 0s - loss: 0.3430 - accuracy: 0.8727\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.4776 - accuracy: 0.8376\n",
      "156/750 [=====>........................] - ETA: 6s - loss: 0.4427 - accuracy: 0.8480\n",
      "672/750 [=========================>....] - ETA: 0s - loss: 0.3437 - accuracy: 0.8725\n",
      "547/750 [====================>.........] - ETA: 2s - loss: 0.4016 - accuracy: 0.8544\n",
      "171/750 [=====>........................] - ETA: 6s - loss: 0.4442 - accuracy: 0.8479\n",
      "336/750 [============>.................] - ETA: 4s - loss: 0.4063 - accuracy: 0.8528\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "554/750 [=====================>........] - ETA: 2s - loss: 0.4013 - accuracy: 0.8547\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.3428 - accuracy: 0.8728\n",
      "250/750 [=========>....................] - ETA: 5s - loss: 0.4062 - accuracy: 0.8525\n",
      "145/750 [====>.........................] - ETA: 7s - loss: 0.4400 - accuracy: 0.8486\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "690/750 [==========================>...] - ETA: 0s - loss: 0.3426 - accuracy: 0.8729\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "578/750 [======================>.......] - ETA: 1s - loss: 0.4001 - accuracy: 0.8553\n",
      "201/750 [=======>......................] - ETA: 6s - loss: 0.4409 - accuracy: 0.8493\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.3431 - accuracy: 0.8727\n",
      "372/750 [=============>................] - ETA: 4s - loss: 0.4062 - accuracy: 0.8529\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "289/750 [==========>...................] - ETA: 5s - loss: 0.4062 - accuracy: 0.8526\n",
      "163/750 [=====>........................] - ETA: 6s - loss: 0.4442 - accuracy: 0.8471\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.3432 - accuracy: 0.8729\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.8730\n",
      "300/750 [===========>..................] - ETA: 5s - loss: 0.4063 - accuracy: 0.8524\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.3429 - accuracy: 0.8727\n",
      "283/750 [==========>...................] - ETA: 5s - loss: 0.4328 - accuracy: 0.8516\n",
      "294/750 [==========>...................] - ETA: 4s - loss: 0.4320 - accuracy: 0.8518\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.3967 - accuracy: 0.8564\n",
      "305/750 [===========>..................] - ETA: 4s - loss: 0.4326 - accuracy: 0.8513\n",
      "682/750 [==========================>...] - ETA: 0s - loss: 0.3971 - accuracy: 0.8564\n",
      "312/750 [===========>..................] - ETA: 4s - loss: 0.4328 - accuracy: 0.8517\n",
      "246/750 [========>.....................] - ETA: 5s - loss: 0.4341 - accuracy: 0.8512\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "327/750 [============>.................] - ETA: 4s - loss: 0.4298 - accuracy: 0.8529\n",
      "332/750 [============>.................] - ETA: 4s - loss: 0.4304 - accuracy: 0.8525\n",
      "389/750 [==============>...............] - ETA: 4s - loss: 0.4027 - accuracy: 0.8539\n",
      "370/750 [=============>................] - ETA: 4s - loss: 0.4302 - accuracy: 0.8524\n",
      "297/750 [==========>...................] - ETA: 4s - loss: 0.4310 - accuracy: 0.8519\n",
      "391/750 [==============>...............] - ETA: 3s - loss: 0.4290 - accuracy: 0.8531\n",
      "448/750 [================>.............] - ETA: 3s - loss: 0.4034 - accuracy: 0.8540\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "319/750 [===========>..................] - ETA: 4s - loss: 0.4323 - accuracy: 0.8516\n",
      "  1/750 [..............................] - ETA: 6s - loss: 0.2450 - accuracy: 0.9062\n",
      " 14/750 [..............................] - ETA: 5s - loss: 0.2864 - accuracy: 0.8962\n",
      " 26/750 [>.............................] - ETA: 6s - loss: 0.3027 - accuracy: 0.8882\n",
      "473/750 [=================>............] - ETA: 3s - loss: 0.4029 - accuracy: 0.8543\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "353/750 [=============>................] - ETA: 4s - loss: 0.4285 - accuracy: 0.8532\n",
      " 50/750 [=>............................] - ETA: 6s - loss: 0.3068 - accuracy: 0.8869\n",
      "495/750 [==================>...........] - ETA: 2s - loss: 0.4023 - accuracy: 0.8539\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "516/750 [===================>..........] - ETA: 2s - loss: 0.4010 - accuracy: 0.8545\n",
      " 68/750 [=>............................] - ETA: 8s - loss: 0.4440 - accuracy: 0.8504\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "191/750 [======>.......................] - ETA: 6s - loss: 0.4422 - accuracy: 0.8490\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 0.4289 - accuracy: 0.8530\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.3430 - accuracy: 0.8730 - val_loss: 0.3788 - val_accuracy: 0.8661\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 4/30\n",
      "525/750 [====================>.........] - ETA: 2s - loss: 0.3997 - accuracy: 0.8548\n",
      "598/750 [======================>.......] - ETA: 1s - loss: 0.3985 - accuracy: 0.8558\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "475/750 [==================>...........] - ETA: 3s - loss: 0.4299 - accuracy: 0.8519\n",
      "538/750 [====================>.........] - ETA: 2s - loss: 0.4004 - accuracy: 0.8548\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "405/750 [===============>..............] - ETA: 3s - loss: 0.4299 - accuracy: 0.8527\n",
      " 21/750 [..............................] - ETA: 5s - loss: 0.2991 - accuracy: 0.8929\n",
      "414/750 [===============>..............] - ETA: 3s - loss: 0.4303 - accuracy: 0.8525\n",
      "511/750 [===================>..........] - ETA: 2s - loss: 0.4298 - accuracy: 0.8519\n",
      "514/750 [===================>..........] - ETA: 2s - loss: 0.4296 - accuracy: 0.8520\n",
      "568/750 [=====================>........] - ETA: 2s - loss: 0.4006 - accuracy: 0.8549\n",
      "221/750 [=======>......................] - ETA: 6s - loss: 0.4365 - accuracy: 0.8507\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "428/750 [================>.............] - ETA: 3s - loss: 0.4311 - accuracy: 0.8523\n",
      "518/750 [===================>..........] - ETA: 2s - loss: 0.4289 - accuracy: 0.8521\n",
      " 69/750 [=>............................] - ETA: 6s - loss: 0.3155 - accuracy: 0.8838\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "120/750 [===>..........................] - ETA: 6s - loss: 0.3147 - accuracy: 0.8867\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "526/750 [====================>.........] - ETA: 2s - loss: 0.4289 - accuracy: 0.8522\n",
      "242/750 [========>.....................] - ETA: 5s - loss: 0.4340 - accuracy: 0.8512\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.3943 - accuracy: 0.8572 - val_loss: 0.4390 - val_accuracy: 0.8474\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 3/30\n",
      " 14/750 [..............................] - ETA: 3s - loss: 0.3264 - accuracy: 0.8705\n",
      "133/750 [====>.........................] - ETA: 6s - loss: 0.3151 - accuracy: 0.8873\n",
      "668/750 [=========================>....] - ETA: 0s - loss: 0.3971 - accuracy: 0.8562\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "555/750 [=====================>........] - ETA: 2s - loss: 0.4312 - accuracy: 0.8514\n",
      "152/750 [=====>........................] - ETA: 6s - loss: 0.3144 - accuracy: 0.8859\n",
      " 37/750 [>.............................] - ETA: 6s - loss: 0.3126 - accuracy: 0.8839\n",
      " 92/750 [==>...........................] - ETA: 6s - loss: 0.3194 - accuracy: 0.8823\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 34/750 [>.............................] - ETA: 6s - loss: 0.3721 - accuracy: 0.8598\n",
      "563/750 [=====================>........] - ETA: 2s - loss: 0.4308 - accuracy: 0.8516\n",
      "269/750 [=========>....................] - ETA: 5s - loss: 0.4332 - accuracy: 0.8506\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "102/750 [===>..........................] - ETA: 6s - loss: 0.3209 - accuracy: 0.8834\n",
      " 47/750 [>.............................] - ETA: 6s - loss: 0.3758 - accuracy: 0.8617\n",
      "571/750 [=====================>........] - ETA: 1s - loss: 0.4305 - accuracy: 0.8517\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.3984 - accuracy: 0.8559\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "575/750 [======================>.......] - ETA: 1s - loss: 0.4310 - accuracy: 0.8516\n",
      "177/750 [======>.......................] - ETA: 6s - loss: 0.3184 - accuracy: 0.8852\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.4301 - accuracy: 0.8519\n",
      "501/750 [===================>..........] - ETA: 2s - loss: 0.4295 - accuracy: 0.8523\n",
      " 75/750 [==>...........................] - ETA: 6s - loss: 0.3671 - accuracy: 0.8667\n",
      "596/750 [======================>.......] - ETA: 1s - loss: 0.4299 - accuracy: 0.8519\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.4300 - accuracy: 0.8520\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.3951 - accuracy: 0.8569\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 77/750 [==>...........................] - ETA: 7s - loss: 0.3630 - accuracy: 0.8683\n",
      "608/750 [=======================>......] - ETA: 1s - loss: 0.4304 - accuracy: 0.8519\n",
      " 80/750 [==>...........................] - ETA: 7s - loss: 0.3614 - accuracy: 0.8684\n",
      "642/750 [========================>.....] - ETA: 1s - loss: 0.3984 - accuracy: 0.8558\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 90/750 [==>...........................] - ETA: 7s - loss: 0.3578 - accuracy: 0.8694\n",
      "612/750 [=======================>......] - ETA: 1s - loss: 0.4300 - accuracy: 0.8521\n",
      "674/750 [=========================>....] - ETA: 0s - loss: 0.3969 - accuracy: 0.8562\n",
      "168/750 [=====>........................] - ETA: 6s - loss: 0.3190 - accuracy: 0.8853\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 94/750 [==>...........................] - ETA: 7s - loss: 0.3584 - accuracy: 0.8700\n",
      "631/750 [========================>.....] - ETA: 1s - loss: 0.4296 - accuracy: 0.8525\n",
      "101/750 [===>..........................] - ETA: 7s - loss: 0.3568 - accuracy: 0.8705\n",
      "229/750 [========>.....................] - ETA: 5s - loss: 0.3206 - accuracy: 0.8847\n",
      "535/750 [====================>.........] - ETA: 2s - loss: 0.4300 - accuracy: 0.8518\n",
      "343/750 [============>.................] - ETA: 4s - loss: 0.4297 - accuracy: 0.8530\n",
      "128/750 [====>.........................] - ETA: 6s - loss: 0.3622 - accuracy: 0.8693\n",
      "654/750 [=========================>....] - ETA: 1s - loss: 0.4289 - accuracy: 0.8529\n",
      "243/750 [========>.....................] - ETA: 5s - loss: 0.3203 - accuracy: 0.8845\n",
      "657/750 [=========================>....] - ETA: 1s - loss: 0.4289 - accuracy: 0.8529\n",
      "146/750 [====>.........................] - ETA: 6s - loss: 0.3142 - accuracy: 0.8868\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.3956 - accuracy: 0.8568\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.3959 - accuracy: 0.8566\n",
      "366/750 [=============>................] - ETA: 4s - loss: 0.4303 - accuracy: 0.8523\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.4289 - accuracy: 0.8528\n",
      "277/750 [==========>...................] - ETA: 5s - loss: 0.3199 - accuracy: 0.8847\n",
      "688/750 [==========================>...] - ETA: 0s - loss: 0.4288 - accuracy: 0.8527\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.3944 - accuracy: 0.8571\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.4285 - accuracy: 0.8527\n",
      "293/750 [==========>...................] - ETA: 5s - loss: 0.3211 - accuracy: 0.8847\n",
      "181/750 [======>.......................] - ETA: 6s - loss: 0.3576 - accuracy: 0.8697\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.4286 - accuracy: 0.8526\n",
      "186/750 [======>.......................] - ETA: 6s - loss: 0.3568 - accuracy: 0.8701\n",
      "305/750 [===========>..................] - ETA: 4s - loss: 0.3203 - accuracy: 0.8848\n",
      "316/750 [===========>..................] - ETA: 4s - loss: 0.3207 - accuracy: 0.8847\n",
      "200/750 [=======>......................] - ETA: 6s - loss: 0.3547 - accuracy: 0.8703\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.4279 - accuracy: 0.8527\n",
      "287/750 [==========>...................] - ETA: 5s - loss: 0.3193 - accuracy: 0.8849\n",
      "216/750 [=======>......................] - ETA: 5s - loss: 0.3565 - accuracy: 0.8693\n",
      "339/750 [============>.................] - ETA: 4s - loss: 0.3199 - accuracy: 0.8853\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.4271 - accuracy: 0.8530\n",
      "349/750 [============>.................] - ETA: 4s - loss: 0.3204 - accuracy: 0.8849\n",
      "361/750 [=============>................] - ETA: 4s - loss: 0.3207 - accuracy: 0.8847\n",
      "253/750 [=========>....................] - ETA: 5s - loss: 0.3572 - accuracy: 0.8686\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 0.3211 - accuracy: 0.8847\n",
      "233/750 [========>.....................] - ETA: 5s - loss: 0.3223 - accuracy: 0.8843\n",
      "327/750 [============>.................] - ETA: 4s - loss: 0.3196 - accuracy: 0.8849\n",
      "271/750 [=========>....................] - ETA: 5s - loss: 0.3554 - accuracy: 0.8695\n",
      "401/750 [===============>..............] - ETA: 3s - loss: 0.3217 - accuracy: 0.8845\n",
      "290/750 [==========>...................] - ETA: 4s - loss: 0.3531 - accuracy: 0.8706\n",
      "414/750 [===============>..............] - ETA: 3s - loss: 0.3231 - accuracy: 0.8836\n",
      "427/750 [================>.............] - ETA: 3s - loss: 0.3233 - accuracy: 0.8833\n",
      "318/750 [===========>..................] - ETA: 4s - loss: 0.3562 - accuracy: 0.8695\n",
      "323/750 [===========>..................] - ETA: 4s - loss: 0.3556 - accuracy: 0.8699\n",
      "443/750 [================>.............] - ETA: 3s - loss: 0.3230 - accuracy: 0.8835\n",
      "448/750 [================>.............] - ETA: 3s - loss: 0.3231 - accuracy: 0.8834\n",
      "399/750 [==============>...............] - ETA: 3s - loss: 0.3210 - accuracy: 0.8847\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "437/750 [================>.............] - ETA: 3s - loss: 0.3232 - accuracy: 0.8833\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "330/750 [============>.................] - ETA: 4s - loss: 0.3549 - accuracy: 0.8699\n",
      "354/750 [=============>................] - ETA: 4s - loss: 0.3543 - accuracy: 0.8701\n",
      " 25/750 [>.............................] - ETA: 4s - loss: 0.3541 - accuracy: 0.8650\n",
      "467/750 [=================>............] - ETA: 3s - loss: 0.3227 - accuracy: 0.8830\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "500/750 [===================>..........] - ETA: 2s - loss: 0.3217 - accuracy: 0.8830\n",
      "488/750 [==================>...........] - ETA: 2s - loss: 0.3217 - accuracy: 0.8832\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  5/750 [..............................] - ETA: 22s - loss: 0.3938 - accuracy: 0.8719\n",
      "196/750 [======>.......................] - ETA: 6s - loss: 0.3554 - accuracy: 0.8702\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 11/750 [..............................] - ETA: 12s - loss: 0.3871 - accuracy: 0.8707\n",
      "534/750 [====================>.........] - ETA: 2s - loss: 0.3220 - accuracy: 0.8831\n",
      "476/750 [==================>...........] - ETA: 2s - loss: 0.3227 - accuracy: 0.8827\n",
      " 23/750 [..............................] - ETA: 9s - loss: 0.3677 - accuracy: 0.8750 \n",
      "540/750 [====================>.........] - ETA: 2s - loss: 0.3216 - accuracy: 0.8834\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "523/750 [===================>..........] - ETA: 2s - loss: 0.3225 - accuracy: 0.8827\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "451/750 [=================>............] - ETA: 3s - loss: 0.3559 - accuracy: 0.8704\n",
      " 58/750 [=>............................] - ETA: 8s - loss: 0.4106 - accuracy: 0.8621\n",
      "577/750 [======================>.......] - ETA: 1s - loss: 0.3201 - accuracy: 0.8842\n",
      "213/750 [=======>......................] - ETA: 5s - loss: 0.3564 - accuracy: 0.8691\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 67/750 [=>............................] - ETA: 7s - loss: 0.4040 - accuracy: 0.8640\n",
      " 59/750 [=>............................] - ETA: 7s - loss: 0.3752 - accuracy: 0.8628\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "112/750 [===>..........................] - ETA: 7s - loss: 0.3594 - accuracy: 0.8686\n",
      " 68/750 [=>............................] - ETA: 8s - loss: 0.4058 - accuracy: 0.8626\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.3191 - accuracy: 0.8845\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.4270 - accuracy: 0.8530 - val_loss: 0.4198 - val_accuracy: 0.8534\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 4/30\n",
      "131/750 [====>.........................] - ETA: 6s - loss: 0.3629 - accuracy: 0.8683\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.3192 - accuracy: 0.8846\n",
      "668/750 [=========================>....] - ETA: 0s - loss: 0.4291 - accuracy: 0.8528\n",
      " 96/750 [==>...........................] - ETA: 7s - loss: 0.4052 - accuracy: 0.8628\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 45/750 [>.............................] - ETA: 9s - loss: 0.4142 - accuracy: 0.8604\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "563/750 [=====================>........] - ETA: 2s - loss: 0.3202 - accuracy: 0.8840\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "106/750 [===>..........................] - ETA: 7s - loss: 0.4050 - accuracy: 0.8620\n",
      "267/750 [=========>....................] - ETA: 5s - loss: 0.3557 - accuracy: 0.8693\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "516/750 [===================>..........] - ETA: 2s - loss: 0.3536 - accuracy: 0.8709\n",
      "632/750 [========================>.....] - ETA: 1s - loss: 0.3175 - accuracy: 0.8851\n",
      "615/750 [=======================>......] - ETA: 1s - loss: 0.3189 - accuracy: 0.8846\n",
      "583/750 [======================>.......] - ETA: 1s - loss: 0.3193 - accuracy: 0.8845\n",
      "527/750 [====================>.........] - ETA: 2s - loss: 0.3537 - accuracy: 0.8708\n",
      "124/750 [===>..........................] - ETA: 7s - loss: 0.4039 - accuracy: 0.8624\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.3176 - accuracy: 0.8852\n",
      "131/750 [====>.........................] - ETA: 6s - loss: 0.4028 - accuracy: 0.8632\n",
      "645/750 [========================>.....] - ETA: 1s - loss: 0.3168 - accuracy: 0.8855\n",
      "655/750 [=========================>....] - ETA: 1s - loss: 0.3172 - accuracy: 0.8852\n",
      "550/750 [=====================>........] - ETA: 2s - loss: 0.3517 - accuracy: 0.8717\n",
      "137/750 [====>.........................] - ETA: 7s - loss: 0.4015 - accuracy: 0.8629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:02:50,163 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6856994816; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662/750 [=========================>....] - ETA: 0s - loss: 0.3182 - accuracy: 0.8849\n",
      "155/750 [=====>........................] - ETA: 6s - loss: 0.4067 - accuracy: 0.8597\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.3188 - accuracy: 0.8844\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.4285 - accuracy: 0.8525\n",
      "637/750 [========================>.....] - ETA: 1s - loss: 0.4293 - accuracy: 0.8527\n",
      "181/750 [======>.......................] - ETA: 6s - loss: 0.4036 - accuracy: 0.8608\n",
      "165/750 [=====>........................] - ETA: 6s - loss: 0.4052 - accuracy: 0.8598\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.3183 - accuracy: 0.8849\n",
      "112/750 [===>..........................] - ETA: 7s - loss: 0.4070 - accuracy: 0.8622\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.3187 - accuracy: 0.8843\n",
      "231/750 [========>.....................] - ETA: 5s - loss: 0.3573 - accuracy: 0.8686\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.3519 - accuracy: 0.8713\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.3186 - accuracy: 0.8843\n",
      "607/750 [=======================>......] - ETA: 1s - loss: 0.3515 - accuracy: 0.8712\n",
      "204/750 [=======>......................] - ETA: 6s - loss: 0.4066 - accuracy: 0.8603\n",
      "242/750 [========>.....................] - ETA: 5s - loss: 0.3564 - accuracy: 0.8691\n",
      "619/750 [=======================>......] - ETA: 1s - loss: 0.3510 - accuracy: 0.8714\n",
      "144/750 [====>.........................] - ETA: 6s - loss: 0.3624 - accuracy: 0.8684\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.3506 - accuracy: 0.8715\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.3189 - accuracy: 0.8844\n",
      "635/750 [========================>.....] - ETA: 1s - loss: 0.3504 - accuracy: 0.8716\n",
      "225/750 [========>.....................] - ETA: 6s - loss: 0.4070 - accuracy: 0.8598\n",
      "280/750 [==========>...................] - ETA: 4s - loss: 0.3549 - accuracy: 0.8697\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.3194 - accuracy: 0.8844\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "642/750 [========================>.....] - ETA: 1s - loss: 0.3502 - accuracy: 0.8715\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.3187 - accuracy: 0.8842\n",
      "233/750 [========>.....................] - ETA: 6s - loss: 0.4081 - accuracy: 0.8592\n",
      "651/750 [=========================>....] - ETA: 1s - loss: 0.3504 - accuracy: 0.8713\n",
      "193/750 [======>.......................] - ETA: 6s - loss: 0.4062 - accuracy: 0.8603\n",
      "248/750 [========>.....................] - ETA: 5s - loss: 0.4086 - accuracy: 0.8591\n",
      "301/750 [===========>..................] - ETA: 4s - loss: 0.3540 - accuracy: 0.8705\n",
      "681/750 [==========================>...] - ETA: 0s - loss: 0.3506 - accuracy: 0.8711\n",
      "314/750 [===========>..................] - ETA: 4s - loss: 0.3560 - accuracy: 0.8696\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.3193 - accuracy: 0.8843\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.3509 - accuracy: 0.8709\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.3504 - accuracy: 0.8712\n",
      "341/750 [============>.................] - ETA: 4s - loss: 0.3548 - accuracy: 0.8700\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.3199 - accuracy: 0.8842\n",
      "304/750 [===========>..................] - ETA: 5s - loss: 0.4100 - accuracy: 0.8585\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.3502 - accuracy: 0.8710\n",
      "320/750 [===========>..................] - ETA: 4s - loss: 0.4084 - accuracy: 0.8585\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.3498 - accuracy: 0.8711\n",
      "362/750 [=============>................] - ETA: 4s - loss: 0.3554 - accuracy: 0.8695\n",
      "377/750 [==============>...............] - ETA: 3s - loss: 0.3560 - accuracy: 0.8694\n",
      "338/750 [============>.................] - ETA: 4s - loss: 0.4099 - accuracy: 0.8573\n",
      "368/750 [=============>................] - ETA: 4s - loss: 0.4085 - accuracy: 0.8579\n",
      "292/750 [==========>...................] - ETA: 5s - loss: 0.4106 - accuracy: 0.8576\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "421/750 [===============>..............] - ETA: 3s - loss: 0.3553 - accuracy: 0.8703\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3192 - accuracy: 0.8845 - val_loss: 0.3417 - val_accuracy: 0.8799\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 5/30\n",
      " 10/750 [..............................] - ETA: 4s - loss: 0.3054 - accuracy: 0.8844\n",
      " 18/750 [..............................] - ETA: 4s - loss: 0.2955 - accuracy: 0.8932\n",
      "395/750 [==============>...............] - ETA: 3s - loss: 0.4091 - accuracy: 0.8578\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "440/750 [================>.............] - ETA: 3s - loss: 0.3549 - accuracy: 0.8707\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "343/750 [============>.................] - ETA: 4s - loss: 0.4090 - accuracy: 0.8577\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 24/750 [..............................] - ETA: 7s - loss: 0.2816 - accuracy: 0.8958\n",
      "426/750 [================>.............] - ETA: 3s - loss: 0.4062 - accuracy: 0.8594\n",
      "352/750 [=============>................] - ETA: 4s - loss: 0.4090 - accuracy: 0.8576\n",
      "471/750 [=================>............] - ETA: 2s - loss: 0.3560 - accuracy: 0.8703\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 79/750 [==>...........................] - ETA: 5s - loss: 0.2976 - accuracy: 0.8896\n",
      "496/750 [==================>...........] - ETA: 2s - loss: 0.3540 - accuracy: 0.8708\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "475/750 [==================>...........] - ETA: 3s - loss: 0.4037 - accuracy: 0.8603\n",
      " 93/750 [==>...........................] - ETA: 6s - loss: 0.2967 - accuracy: 0.8906\n",
      "190/750 [======>.......................] - ETA: 6s - loss: 0.4045 - accuracy: 0.8606\n",
      "542/750 [====================>.........] - ETA: 2s - loss: 0.3522 - accuracy: 0.8713\n",
      "546/750 [====================>.........] - ETA: 2s - loss: 0.3212 - accuracy: 0.8837\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.4584 - accuracy: 0.8594\n",
      "131/750 [====>.........................] - ETA: 6s - loss: 0.2960 - accuracy: 0.8917\n",
      "514/750 [===================>..........] - ETA: 2s - loss: 0.4017 - accuracy: 0.8608\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "576/750 [======================>.......] - ETA: 1s - loss: 0.3521 - accuracy: 0.8711\n",
      "221/750 [=======>......................] - ETA: 6s - loss: 0.4065 - accuracy: 0.8599\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 16/750 [..............................] - ETA: 9s - loss: 0.3488 - accuracy: 0.8682 \n",
      "530/750 [====================>.........] - ETA: 2s - loss: 0.4007 - accuracy: 0.8614\n",
      "533/750 [====================>.........] - ETA: 2s - loss: 0.4006 - accuracy: 0.8615\n",
      "147/750 [====>.........................] - ETA: 6s - loss: 0.2960 - accuracy: 0.8912\n",
      " 63/750 [=>............................] - ETA: 6s - loss: 0.2955 - accuracy: 0.8911\n",
      " 29/750 [>.............................] - ETA: 8s - loss: 0.3531 - accuracy: 0.8675\n",
      "537/750 [====================>.........] - ETA: 2s - loss: 0.4003 - accuracy: 0.8616\n",
      "594/750 [======================>.......] - ETA: 1s - loss: 0.3522 - accuracy: 0.8712\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "547/750 [====================>.........] - ETA: 2s - loss: 0.3993 - accuracy: 0.8622\n",
      " 54/750 [=>............................] - ETA: 7s - loss: 0.3444 - accuracy: 0.8724\n",
      "173/750 [=====>........................] - ETA: 6s - loss: 0.2973 - accuracy: 0.8898\n",
      " 88/750 [==>...........................] - ETA: 6s - loss: 0.2969 - accuracy: 0.8908\n",
      " 40/750 [>.............................] - ETA: 8s - loss: 0.3462 - accuracy: 0.8691\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "559/750 [=====================>........] - ETA: 2s - loss: 0.4000 - accuracy: 0.8616\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "102/750 [===>..........................] - ETA: 6s - loss: 0.2967 - accuracy: 0.8917\n",
      " 63/750 [=>............................] - ETA: 7s - loss: 0.3415 - accuracy: 0.8757\n",
      "181/750 [======>.......................] - ETA: 6s - loss: 0.2951 - accuracy: 0.8905\n",
      "271/750 [=========>....................] - ETA: 5s - loss: 0.4085 - accuracy: 0.8587\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 71/750 [=>............................] - ETA: 7s - loss: 0.3334 - accuracy: 0.8772\n",
      "577/750 [======================>.......] - ETA: 1s - loss: 0.4002 - accuracy: 0.8616\n",
      "192/750 [======>.......................] - ETA: 6s - loss: 0.2963 - accuracy: 0.8905\n",
      "528/750 [====================>.........] - ETA: 2s - loss: 0.4008 - accuracy: 0.8613\n",
      "123/750 [===>..........................] - ETA: 6s - loss: 0.2997 - accuracy: 0.8901\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "136/750 [====>.........................] - ETA: 6s - loss: 0.2961 - accuracy: 0.8910\n",
      "196/750 [======>.......................] - ETA: 6s - loss: 0.2972 - accuracy: 0.8909\n",
      " 91/750 [==>...........................] - ETA: 7s - loss: 0.3243 - accuracy: 0.8832\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 0.3988 - accuracy: 0.8623\n",
      "212/750 [=======>......................] - ETA: 5s - loss: 0.2960 - accuracy: 0.8908\n",
      "666/750 [=========================>....] - ETA: 0s - loss: 0.3510 - accuracy: 0.8710\n",
      "103/750 [===>..........................] - ETA: 7s - loss: 0.3244 - accuracy: 0.8827\n",
      "218/750 [=======>......................] - ETA: 5s - loss: 0.2954 - accuracy: 0.8907\n",
      "675/750 [==========================>...] - ETA: 0s - loss: 0.3507 - accuracy: 0.8710\n",
      "168/750 [=====>........................] - ETA: 6s - loss: 0.2987 - accuracy: 0.8898\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "125/750 [====>.........................] - ETA: 7s - loss: 0.3260 - accuracy: 0.8823\n",
      "151/750 [=====>........................] - ETA: 6s - loss: 0.3270 - accuracy: 0.8820\n",
      "620/750 [=======================>......] - ETA: 1s - loss: 0.3994 - accuracy: 0.8623\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "663/750 [=========================>....] - ETA: 0s - loss: 0.3994 - accuracy: 0.8622\n",
      "274/750 [=========>....................] - ETA: 5s - loss: 0.3015 - accuracy: 0.8887\n",
      "674/750 [=========================>....] - ETA: 0s - loss: 0.3993 - accuracy: 0.8620\n",
      "644/750 [========================>.....] - ETA: 1s - loss: 0.3995 - accuracy: 0.8619\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "229/750 [========>.....................] - ETA: 5s - loss: 0.2938 - accuracy: 0.8914\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.3983 - accuracy: 0.8624\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.3491 - accuracy: 0.8715\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "247/750 [========>.....................] - ETA: 5s - loss: 0.2971 - accuracy: 0.8902\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.3987 - accuracy: 0.8622\n",
      "318/750 [===========>..................] - ETA: 4s - loss: 0.3024 - accuracy: 0.8887\n",
      "657/750 [=========================>....] - ETA: 1s - loss: 0.3992 - accuracy: 0.8623\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.3984 - accuracy: 0.8622\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.3980 - accuracy: 0.8625\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.3983 - accuracy: 0.8625\n",
      "681/750 [==========================>...] - ETA: 0s - loss: 0.3990 - accuracy: 0.8622\n",
      "355/750 [=============>................] - ETA: 4s - loss: 0.3012 - accuracy: 0.8889\n",
      "300/750 [===========>..................] - ETA: 5s - loss: 0.3020 - accuracy: 0.8886\n",
      "375/750 [==============>...............] - ETA: 4s - loss: 0.3016 - accuracy: 0.8889\n",
      "323/750 [===========>..................] - ETA: 4s - loss: 0.3034 - accuracy: 0.8881\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "254/750 [=========>....................] - ETA: 5s - loss: 0.3225 - accuracy: 0.8830\n",
      "381/750 [==============>...............] - ETA: 4s - loss: 0.3027 - accuracy: 0.8885\n",
      "340/750 [============>.................] - ETA: 4s - loss: 0.3025 - accuracy: 0.8886\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "277/750 [==========>...................] - ETA: 5s - loss: 0.3236 - accuracy: 0.8826\n",
      "403/750 [===============>..............] - ETA: 3s - loss: 0.3026 - accuracy: 0.8886\n",
      "421/750 [===============>..............] - ETA: 3s - loss: 0.3037 - accuracy: 0.8884\n",
      "364/750 [=============>................] - ETA: 4s - loss: 0.3028 - accuracy: 0.8885\n",
      "298/750 [==========>...................] - ETA: 5s - loss: 0.3271 - accuracy: 0.8817\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "414/750 [===============>..............] - ETA: 3s - loss: 0.3034 - accuracy: 0.8883\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "437/750 [================>.............] - ETA: 3s - loss: 0.3031 - accuracy: 0.8887\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3487 - accuracy: 0.8716 - val_loss: 0.3430 - val_accuracy: 0.8774\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 4/30\n",
      "340/750 [============>.................] - ETA: 4s - loss: 0.3251 - accuracy: 0.8818\n",
      "  5/750 [..............................] - ETA: 16s - loss: 0.3606 - accuracy: 0.8594\n",
      "394/750 [==============>...............] - ETA: 4s - loss: 0.3020 - accuracy: 0.8889\n",
      "447/750 [================>.............] - ETA: 3s - loss: 0.3032 - accuracy: 0.8890\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "345/750 [============>.................] - ETA: 4s - loss: 0.3246 - accuracy: 0.8820\n",
      "367/750 [=============>................] - ETA: 4s - loss: 0.3249 - accuracy: 0.8818\n",
      "501/750 [===================>..........] - ETA: 2s - loss: 0.3021 - accuracy: 0.8891\n",
      "469/750 [=================>............] - ETA: 3s - loss: 0.3024 - accuracy: 0.8890\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "386/750 [==============>...............] - ETA: 4s - loss: 0.3235 - accuracy: 0.8824\n",
      "399/750 [==============>...............] - ETA: 3s - loss: 0.3246 - accuracy: 0.8820\n",
      "525/750 [====================>.........] - ETA: 2s - loss: 0.3022 - accuracy: 0.8890\n",
      "491/750 [==================>...........] - ETA: 2s - loss: 0.3022 - accuracy: 0.8891\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "482/750 [==================>...........] - ETA: 2s - loss: 0.3023 - accuracy: 0.8891\n",
      " 82/750 [==>...........................] - ETA: 7s - loss: 0.3241 - accuracy: 0.8826\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.3982 - accuracy: 0.8626 - val_loss: 0.4159 - val_accuracy: 0.8566\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 5/30\n",
      "  8/750 [..............................] - ETA: 7s - loss: 0.3770 - accuracy: 0.8730\n",
      " 24/750 [..............................] - ETA: 7s - loss: 0.4204 - accuracy: 0.8581\n",
      "551/750 [=====================>........] - ETA: 2s - loss: 0.3019 - accuracy: 0.8887\n",
      "556/750 [=====================>........] - ETA: 2s - loss: 0.3016 - accuracy: 0.8889\n",
      "  1/750 [..............................] - ETA: 6s - loss: 0.6947 - accuracy: 0.8281\n",
      " 30/750 [>.............................] - ETA: 7s - loss: 0.4058 - accuracy: 0.8672\n",
      "142/750 [====>.........................] - ETA: 6s - loss: 0.3245 - accuracy: 0.8833\n",
      "515/750 [===================>..........] - ETA: 2s - loss: 0.3023 - accuracy: 0.8890\n",
      "457/750 [=================>............] - ETA: 3s - loss: 0.3243 - accuracy: 0.8816\n",
      "220/750 [=======>......................] - ETA: 6s - loss: 0.3227 - accuracy: 0.8827\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "546/750 [====================>.........] - ETA: 2s - loss: 0.3019 - accuracy: 0.8887\n",
      "583/750 [======================>.......] - ETA: 1s - loss: 0.3003 - accuracy: 0.8893\n",
      "595/750 [======================>.......] - ETA: 1s - loss: 0.3005 - accuracy: 0.8892\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "544/750 [====================>.........] - ETA: 2s - loss: 0.3021 - accuracy: 0.8887\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 81/750 [==>...........................] - ETA: 7s - loss: 0.4017 - accuracy: 0.8607\n",
      "611/750 [=======================>......] - ETA: 1s - loss: 0.3012 - accuracy: 0.8892\n",
      " 47/750 [>.............................] - ETA: 8s - loss: 0.4093 - accuracy: 0.8600\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "569/750 [=====================>........] - ETA: 2s - loss: 0.3009 - accuracy: 0.8890\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 68/750 [=>............................] - ETA: 7s - loss: 0.3988 - accuracy: 0.8619\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "506/750 [===================>..........] - ETA: 2s - loss: 0.3248 - accuracy: 0.8811\n",
      "624/750 [=======================>......] - ETA: 1s - loss: 0.3017 - accuracy: 0.8889\n",
      "199/750 [======>.......................] - ETA: 6s - loss: 0.3271 - accuracy: 0.8811\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "265/750 [=========>....................] - ETA: 5s - loss: 0.3211 - accuracy: 0.8837\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "578/750 [======================>.......] - ETA: 1s - loss: 0.2998 - accuracy: 0.8893\n",
      "517/750 [===================>..........] - ETA: 2s - loss: 0.3250 - accuracy: 0.8811\n",
      "120/750 [===>..........................] - ETA: 7s - loss: 0.3265 - accuracy: 0.8819\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "178/750 [======>.......................] - ETA: 6s - loss: 0.3281 - accuracy: 0.8806\n",
      "109/750 [===>..........................] - ETA: 7s - loss: 0.3890 - accuracy: 0.8674\n",
      " 94/750 [==>...........................] - ETA: 7s - loss: 0.3972 - accuracy: 0.8644\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.3014 - accuracy: 0.8890\n",
      "527/750 [====================>.........] - ETA: 2s - loss: 0.3257 - accuracy: 0.8806\n",
      "112/750 [===>..........................] - ETA: 7s - loss: 0.3885 - accuracy: 0.8676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:03:00,258 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7116152832; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/750 [=======>......................] - ETA: 6s - loss: 0.3248 - accuracy: 0.8827\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "132/750 [====>.........................] - ETA: 7s - loss: 0.3872 - accuracy: 0.8642\n",
      "142/750 [====>.........................] - ETA: 7s - loss: 0.3912 - accuracy: 0.8628\n",
      "675/750 [==========================>...] - ETA: 0s - loss: 0.3018 - accuracy: 0.8892\n",
      "171/750 [=====>........................] - ETA: 6s - loss: 0.3273 - accuracy: 0.8821\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "146/750 [====>.........................] - ETA: 7s - loss: 0.3913 - accuracy: 0.8632\n",
      "685/750 [==========================>...] - ETA: 0s - loss: 0.3018 - accuracy: 0.8891\n",
      "692/750 [==========================>...] - ETA: 0s - loss: 0.3020 - accuracy: 0.8888\n",
      "581/750 [======================>.......] - ETA: 1s - loss: 0.3240 - accuracy: 0.8811\n",
      "621/750 [=======================>......] - ETA: 1s - loss: 0.3013 - accuracy: 0.8890\n",
      "672/750 [=========================>....] - ETA: 0s - loss: 0.3022 - accuracy: 0.8891\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 0.3238 - accuracy: 0.8808\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.3015 - accuracy: 0.8891\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.3238 - accuracy: 0.8807\n",
      "245/750 [========>.....................] - ETA: 5s - loss: 0.3212 - accuracy: 0.8837\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.3032 - accuracy: 0.8881\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.3023 - accuracy: 0.8884\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "240/750 [========>.....................] - ETA: 6s - loss: 0.3203 - accuracy: 0.8839\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "632/750 [========================>.....] - ETA: 1s - loss: 0.3238 - accuracy: 0.8809\n",
      "322/750 [===========>..................] - ETA: 4s - loss: 0.3242 - accuracy: 0.8828\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.3020 - accuracy: 0.8885\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.3241 - accuracy: 0.8808\n",
      "225/750 [========>.....................] - ETA: 6s - loss: 0.3786 - accuracy: 0.8667\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.3020 - accuracy: 0.8885\n",
      "677/750 [==========================>...] - ETA: 0s - loss: 0.3240 - accuracy: 0.8808\n",
      "353/750 [=============>................] - ETA: 4s - loss: 0.3239 - accuracy: 0.8822\n",
      "269/750 [=========>....................] - ETA: 5s - loss: 0.3823 - accuracy: 0.8661\n",
      "377/750 [==============>...............] - ETA: 4s - loss: 0.3240 - accuracy: 0.8820\n",
      "311/750 [===========>..................] - ETA: 5s - loss: 0.3260 - accuracy: 0.8822\n",
      "278/750 [==========>...................] - ETA: 5s - loss: 0.3826 - accuracy: 0.8659\n",
      "303/750 [===========>..................] - ETA: 5s - loss: 0.3842 - accuracy: 0.8645\n",
      "319/750 [===========>..................] - ETA: 4s - loss: 0.3851 - accuracy: 0.8637\n",
      "289/750 [==========>...................] - ETA: 5s - loss: 0.3830 - accuracy: 0.8652\n",
      "334/750 [============>.................] - ETA: 4s - loss: 0.3834 - accuracy: 0.8644\n",
      "420/750 [===============>..............] - ETA: 3s - loss: 0.3247 - accuracy: 0.8815\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "350/750 [=============>................] - ETA: 4s - loss: 0.3834 - accuracy: 0.8646\n",
      "447/750 [================>.............] - ETA: 3s - loss: 0.3259 - accuracy: 0.8812\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  5/750 [..............................] - ETA: 10s - loss: 0.3410 - accuracy: 0.8875\n",
      "438/750 [================>.............] - ETA: 3s - loss: 0.3266 - accuracy: 0.8807\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 0.3815 - accuracy: 0.8648\n",
      " 19/750 [..............................] - ETA: 6s - loss: 0.2859 - accuracy: 0.8956\n",
      " 27/750 [>.............................] - ETA: 7s - loss: 0.2958 - accuracy: 0.8906\n",
      "400/750 [===============>..............] - ETA: 3s - loss: 0.3818 - accuracy: 0.8646\n",
      "363/750 [=============>................] - ETA: 4s - loss: 0.3818 - accuracy: 0.8649\n",
      "474/750 [=================>............] - ETA: 3s - loss: 0.3247 - accuracy: 0.8813\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "387/750 [==============>...............] - ETA: 4s - loss: 0.3821 - accuracy: 0.8643\n",
      "427/750 [================>.............] - ETA: 3s - loss: 0.3815 - accuracy: 0.8648\n",
      "440/750 [================>.............] - ETA: 3s - loss: 0.3810 - accuracy: 0.8651\n",
      " 78/750 [==>...........................] - ETA: 7s - loss: 0.2879 - accuracy: 0.8976\n",
      "525/750 [====================>.........] - ETA: 2s - loss: 0.3257 - accuracy: 0.8807\n",
      "497/750 [==================>...........] - ETA: 2s - loss: 0.3238 - accuracy: 0.8815\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 86/750 [==>...........................] - ETA: 7s - loss: 0.2872 - accuracy: 0.8981\n",
      " 84/750 [==>...........................] - ETA: 7s - loss: 0.3963 - accuracy: 0.8625\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3033 - accuracy: 0.8881 - val_loss: 0.3637 - val_accuracy: 0.8699\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 6/30\n",
      " 97/750 [==>...........................] - ETA: 7s - loss: 0.2840 - accuracy: 0.8984\n",
      "566/750 [=====================>........] - ETA: 2s - loss: 0.3243 - accuracy: 0.8811\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3243 - accuracy: 0.8807 - val_loss: 0.3613 - val_accuracy: 0.8651\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 5/30\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.2666 - accuracy: 0.8906\n",
      "125/750 [====>.........................] - ETA: 6s - loss: 0.2839 - accuracy: 0.8981\n",
      "450/750 [=================>............] - ETA: 3s - loss: 0.3808 - accuracy: 0.8650\n",
      "  7/750 [..............................] - ETA: 18s - loss: 0.2708 - accuracy: 0.8996\n",
      "221/750 [=======>......................] - ETA: 6s - loss: 0.3798 - accuracy: 0.8660\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 21/750 [..............................] - ETA: 9s - loss: 0.2866 - accuracy: 0.8943 \n",
      "500/750 [===================>..........] - ETA: 2s - loss: 0.3795 - accuracy: 0.8654\n",
      "585/750 [======================>.......] - ETA: 1s - loss: 0.3240 - accuracy: 0.8811\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.3235 - accuracy: 0.8815\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "162/750 [=====>........................] - ETA: 6s - loss: 0.2857 - accuracy: 0.8978\n",
      "620/750 [=======================>......] - ETA: 1s - loss: 0.3238 - accuracy: 0.8808\n",
      " 51/750 [=>............................] - ETA: 7s - loss: 0.2992 - accuracy: 0.8934\n",
      "523/750 [===================>..........] - ETA: 2s - loss: 0.3783 - accuracy: 0.8663\n",
      " 45/750 [>.............................] - ETA: 7s - loss: 0.3023 - accuracy: 0.8917\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "563/750 [=====================>........] - ETA: 2s - loss: 0.3246 - accuracy: 0.8809\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 72/750 [=>............................] - ETA: 6s - loss: 0.2847 - accuracy: 0.8987\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "519/750 [===================>..........] - ETA: 2s - loss: 0.3783 - accuracy: 0.8662\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "531/750 [====================>.........] - ETA: 2s - loss: 0.3778 - accuracy: 0.8663\n",
      " 59/750 [=>............................] - ETA: 9s - loss: 0.3047 - accuracy: 0.8906\n",
      "175/750 [======>.......................] - ETA: 6s - loss: 0.2864 - accuracy: 0.8968\n",
      "197/750 [======>.......................] - ETA: 6s - loss: 0.3834 - accuracy: 0.8655\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "262/750 [=========>....................] - ETA: 5s - loss: 0.3820 - accuracy: 0.8664\n",
      "115/750 [===>..........................] - ETA: 7s - loss: 0.2767 - accuracy: 0.9004\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "535/750 [====================>.........] - ETA: 2s - loss: 0.3780 - accuracy: 0.8663\n",
      " 76/750 [==>...........................] - ETA: 8s - loss: 0.3010 - accuracy: 0.8904\n",
      "104/750 [===>..........................] - ETA: 7s - loss: 0.2804 - accuracy: 0.8992\n",
      "550/750 [=====================>........] - ETA: 2s - loss: 0.3792 - accuracy: 0.8659\n",
      "202/750 [=======>......................] - ETA: 6s - loss: 0.2871 - accuracy: 0.8957\n",
      "214/750 [=======>......................] - ETA: 6s - loss: 0.3807 - accuracy: 0.8659\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "573/750 [=====================>........] - ETA: 2s - loss: 0.3791 - accuracy: 0.8662\n",
      "103/750 [===>..........................] - ETA: 8s - loss: 0.3034 - accuracy: 0.8893\n",
      "583/750 [======================>.......] - ETA: 1s - loss: 0.3800 - accuracy: 0.8660\n",
      "146/750 [====>.........................] - ETA: 6s - loss: 0.2863 - accuracy: 0.8967\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "171/750 [=====>........................] - ETA: 6s - loss: 0.2848 - accuracy: 0.8977\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "594/750 [======================>.......] - ETA: 1s - loss: 0.3800 - accuracy: 0.8660\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.3233 - accuracy: 0.8811\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.3793 - accuracy: 0.8662\n",
      "255/750 [=========>....................] - ETA: 5s - loss: 0.2878 - accuracy: 0.8944\n",
      "616/750 [=======================>......] - ETA: 1s - loss: 0.3792 - accuracy: 0.8665\n",
      "262/750 [=========>....................] - ETA: 5s - loss: 0.2872 - accuracy: 0.8943\n",
      "277/750 [==========>...................] - ETA: 5s - loss: 0.2876 - accuracy: 0.8943\n",
      "656/750 [=========================>....] - ETA: 1s - loss: 0.3238 - accuracy: 0.8810\n",
      "283/750 [==========>...................] - ETA: 5s - loss: 0.2870 - accuracy: 0.8948\n",
      "645/750 [========================>.....] - ETA: 1s - loss: 0.3241 - accuracy: 0.8809\n",
      "611/750 [=======================>......] - ETA: 1s - loss: 0.3796 - accuracy: 0.8664\n",
      "653/750 [=========================>....] - ETA: 1s - loss: 0.3783 - accuracy: 0.8671\n",
      "296/750 [==========>...................] - ETA: 5s - loss: 0.2874 - accuracy: 0.8943\n",
      "176/750 [======>.......................] - ETA: 6s - loss: 0.3001 - accuracy: 0.8897\n",
      "659/750 [=========================>....] - ETA: 1s - loss: 0.3779 - accuracy: 0.8673\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.3243 - accuracy: 0.8807\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.3241 - accuracy: 0.8808\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "237/750 [========>.....................] - ETA: 6s - loss: 0.2865 - accuracy: 0.8949\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.3789 - accuracy: 0.8666\n",
      "670/750 [=========================>....] - ETA: 0s - loss: 0.3780 - accuracy: 0.8672\n",
      "315/750 [===========>..................] - ETA: 4s - loss: 0.2867 - accuracy: 0.8952\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.3243 - accuracy: 0.8806\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "329/750 [============>.................] - ETA: 4s - loss: 0.2871 - accuracy: 0.8953\n",
      "633/750 [========================>.....] - ETA: 1s - loss: 0.3788 - accuracy: 0.8667\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.3788 - accuracy: 0.8672\n",
      "345/750 [============>.................] - ETA: 4s - loss: 0.2866 - accuracy: 0.8951\n",
      "225/750 [========>.....................] - ETA: 6s - loss: 0.2967 - accuracy: 0.8903\n",
      "353/750 [=============>................] - ETA: 4s - loss: 0.2874 - accuracy: 0.8948\n",
      "234/750 [========>.....................] - ETA: 6s - loss: 0.2959 - accuracy: 0.8902\n",
      "366/750 [=============>................] - ETA: 4s - loss: 0.2869 - accuracy: 0.8949\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8670\n",
      "385/750 [==============>...............] - ETA: 4s - loss: 0.2866 - accuracy: 0.8950\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8668\n",
      "397/750 [==============>...............] - ETA: 3s - loss: 0.2874 - accuracy: 0.8947\n",
      "308/750 [===========>..................] - ETA: 4s - loss: 0.2872 - accuracy: 0.8947\n",
      "338/750 [============>.................] - ETA: 4s - loss: 0.2870 - accuracy: 0.8952\n",
      "420/750 [===============>..............] - ETA: 3s - loss: 0.2877 - accuracy: 0.8945\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "312/750 [===========>..................] - ETA: 4s - loss: 0.2995 - accuracy: 0.8893\n",
      "444/750 [================>.............] - ETA: 3s - loss: 0.3812 - accuracy: 0.8651\n",
      "320/750 [===========>..................] - ETA: 4s - loss: 0.2992 - accuracy: 0.8890\n",
      "454/750 [=================>............] - ETA: 3s - loss: 0.2878 - accuracy: 0.8948\n",
      "335/750 [============>.................] - ETA: 4s - loss: 0.2976 - accuracy: 0.8895\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 0.2872 - accuracy: 0.8946\n",
      "347/750 [============>.................] - ETA: 4s - loss: 0.2981 - accuracy: 0.8892\n",
      "483/750 [==================>...........] - ETA: 2s - loss: 0.2894 - accuracy: 0.8946\n",
      "489/750 [==================>...........] - ETA: 2s - loss: 0.2910 - accuracy: 0.8944\n",
      "495/750 [==================>...........] - ETA: 2s - loss: 0.2910 - accuracy: 0.8944\n",
      "381/750 [==============>...............] - ETA: 4s - loss: 0.3008 - accuracy: 0.8887\n",
      "470/750 [=================>............] - ETA: 3s - loss: 0.2889 - accuracy: 0.8947\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "401/750 [===============>..............] - ETA: 3s - loss: 0.2999 - accuracy: 0.8889\n",
      "446/750 [================>.............] - ETA: 3s - loss: 0.2879 - accuracy: 0.8946\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 94/750 [==>...........................] - ETA: 8s - loss: 0.2997 - accuracy: 0.8921\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "479/750 [==================>...........] - ETA: 2s - loss: 0.2890 - accuracy: 0.8948\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "428/750 [================>.............] - ETA: 3s - loss: 0.3020 - accuracy: 0.8883\n",
      "580/750 [======================>.......] - ETA: 1s - loss: 0.2885 - accuracy: 0.8948\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3790 - accuracy: 0.8669 - val_loss: 0.3816 - val_accuracy: 0.8658\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 6/30\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.4863 - accuracy: 0.8438\n",
      "126/750 [====>.........................] - ETA: 7s - loss: 0.3054 - accuracy: 0.8885\n",
      " 21/750 [..............................] - ETA: 8s - loss: 0.3342 - accuracy: 0.8869\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "477/750 [==================>...........] - ETA: 2s - loss: 0.3016 - accuracy: 0.8886\n",
      " 45/750 [>.............................] - ETA: 6s - loss: 0.3272 - accuracy: 0.8861\n",
      "607/750 [=======================>......] - ETA: 1s - loss: 0.2889 - accuracy: 0.8943\n",
      "221/750 [=======>......................] - ETA: 6s - loss: 0.2975 - accuracy: 0.8901\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "621/750 [=======================>......] - ETA: 1s - loss: 0.2893 - accuracy: 0.8945\n",
      "505/750 [===================>..........] - ETA: 2s - loss: 0.3018 - accuracy: 0.8887\n",
      "633/750 [========================>.....] - ETA: 1s - loss: 0.2894 - accuracy: 0.8944\n",
      "545/750 [====================>.........] - ETA: 2s - loss: 0.2888 - accuracy: 0.8951\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "635/750 [========================>.....] - ETA: 1s - loss: 0.2898 - accuracy: 0.8942\n",
      "510/750 [===================>..........] - ETA: 2s - loss: 0.2890 - accuracy: 0.8953\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 83/750 [==>...........................] - ETA: 7s - loss: 0.3456 - accuracy: 0.8805\n",
      "649/750 [========================>.....] - ETA: 1s - loss: 0.2900 - accuracy: 0.8942\n",
      " 35/750 [>.............................] - ETA: 7s - loss: 0.3339 - accuracy: 0.8848\n",
      "568/750 [=====================>........] - ETA: 1s - loss: 0.2895 - accuracy: 0.8946\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 69/750 [=>............................] - ETA: 6s - loss: 0.3398 - accuracy: 0.8820\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "524/750 [===================>..........] - ETA: 2s - loss: 0.3018 - accuracy: 0.8886\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "194/750 [======>.......................] - ETA: 6s - loss: 0.2989 - accuracy: 0.8905\n",
      "187/750 [======>.......................] - ETA: 6s - loss: 0.3013 - accuracy: 0.8895\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "525/750 [====================>.........] - ETA: 2s - loss: 0.3017 - accuracy: 0.8886\n",
      "111/750 [===>..........................] - ETA: 8s - loss: 0.3036 - accuracy: 0.8899\n",
      " 77/750 [==>...........................] - ETA: 7s - loss: 0.3429 - accuracy: 0.8811\n",
      "106/750 [===>..........................] - ETA: 7s - loss: 0.3554 - accuracy: 0.8753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:03:10,350 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7115857920; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/750 [=======>......................] - ETA: 6s - loss: 0.2990 - accuracy: 0.8905\n",
      "219/750 [=======>......................] - ETA: 6s - loss: 0.2880 - accuracy: 0.8948\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "544/750 [====================>.........] - ETA: 2s - loss: 0.3018 - accuracy: 0.8888\n",
      "111/750 [===>..........................] - ETA: 8s - loss: 0.3585 - accuracy: 0.8735\n",
      "675/750 [==========================>...] - ETA: 0s - loss: 0.2894 - accuracy: 0.8944\n",
      "556/750 [=====================>........] - ETA: 2s - loss: 0.3027 - accuracy: 0.8888\n",
      "117/750 [===>..........................] - ETA: 7s - loss: 0.3602 - accuracy: 0.8729\n",
      "121/750 [===>..........................] - ETA: 7s - loss: 0.3587 - accuracy: 0.8738\n",
      "679/750 [==========================>...] - ETA: 0s - loss: 0.2895 - accuracy: 0.8943\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.2898 - accuracy: 0.8942\n",
      "594/750 [======================>.......] - ETA: 1s - loss: 0.2891 - accuracy: 0.8942\n",
      "148/750 [====>.........................] - ETA: 7s - loss: 0.3050 - accuracy: 0.8881\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 0.2898 - accuracy: 0.8941\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.2900 - accuracy: 0.8942\n",
      "165/750 [=====>........................] - ETA: 7s - loss: 0.3016 - accuracy: 0.8888\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "690/750 [==========================>...] - ETA: 0s - loss: 0.3782 - accuracy: 0.8672\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "581/750 [======================>.......] - ETA: 1s - loss: 0.3014 - accuracy: 0.8890\n",
      "151/750 [=====>........................] - ETA: 7s - loss: 0.3562 - accuracy: 0.8750\n",
      "251/750 [=========>....................] - ETA: 5s - loss: 0.2946 - accuracy: 0.8907\n",
      "600/750 [=======================>......] - ETA: 1s - loss: 0.2887 - accuracy: 0.8943\n",
      "595/750 [======================>.......] - ETA: 1s - loss: 0.3020 - accuracy: 0.8888\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2899 - accuracy: 0.8943\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.3030 - accuracy: 0.8887\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2902 - accuracy: 0.8944\n",
      "262/750 [=========>....................] - ETA: 5s - loss: 0.2993 - accuracy: 0.8897\n",
      "277/750 [==========>...................] - ETA: 5s - loss: 0.3005 - accuracy: 0.8893\n",
      "180/750 [======>.......................] - ETA: 6s - loss: 0.3586 - accuracy: 0.8747\n",
      "296/750 [==========>...................] - ETA: 5s - loss: 0.2997 - accuracy: 0.8898\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "201/750 [=======>......................] - ETA: 6s - loss: 0.3591 - accuracy: 0.8742\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2905 - accuracy: 0.8941\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "242/750 [========>.....................] - ETA: 6s - loss: 0.2959 - accuracy: 0.8906\n",
      "666/750 [=========================>....] - ETA: 0s - loss: 0.2898 - accuracy: 0.8943\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "655/750 [=========================>....] - ETA: 1s - loss: 0.3019 - accuracy: 0.8888\n",
      "660/750 [=========================>....] - ETA: 1s - loss: 0.3020 - accuracy: 0.8888\n",
      "319/750 [===========>..................] - ETA: 4s - loss: 0.2870 - accuracy: 0.8953\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2897 - accuracy: 0.8944\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "230/750 [========>.....................] - ETA: 6s - loss: 0.3617 - accuracy: 0.8735\n",
      "672/750 [=========================>....] - ETA: 0s - loss: 0.3015 - accuracy: 0.8890\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2902 - accuracy: 0.8941\n",
      "235/750 [========>.....................] - ETA: 6s - loss: 0.3611 - accuracy: 0.8735\n",
      "249/750 [========>.....................] - ETA: 6s - loss: 0.3599 - accuracy: 0.8736\n",
      "369/750 [=============>................] - ETA: 4s - loss: 0.2991 - accuracy: 0.8891\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "263/750 [=========>....................] - ETA: 5s - loss: 0.3623 - accuracy: 0.8727\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.3038 - accuracy: 0.8884\n",
      "276/750 [==========>...................] - ETA: 5s - loss: 0.3624 - accuracy: 0.8728\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.3040 - accuracy: 0.8883\n",
      "392/750 [==============>...............] - ETA: 3s - loss: 0.3006 - accuracy: 0.8886\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2901 - accuracy: 0.8943\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "290/750 [==========>...................] - ETA: 5s - loss: 0.3617 - accuracy: 0.8732\n",
      "303/750 [===========>..................] - ETA: 5s - loss: 0.3608 - accuracy: 0.8733\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.3036 - accuracy: 0.8883\n",
      "330/750 [============>.................] - ETA: 4s - loss: 0.3614 - accuracy: 0.8730\n",
      "411/750 [===============>..............] - ETA: 3s - loss: 0.3016 - accuracy: 0.8883\n",
      "317/750 [===========>..................] - ETA: 5s - loss: 0.3608 - accuracy: 0.8731\n",
      "354/750 [=============>................] - ETA: 4s - loss: 0.3616 - accuracy: 0.8725\n",
      "339/750 [============>.................] - ETA: 4s - loss: 0.3620 - accuracy: 0.8724\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2904 - accuracy: 0.8941 - val_loss: 0.3382 - val_accuracy: 0.8800\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 7/30\n",
      "  6/750 [..............................] - ETA: 7s - loss: 0.2469 - accuracy: 0.9089\n",
      "374/750 [=============>................] - ETA: 4s - loss: 0.3616 - accuracy: 0.8725\n",
      "384/750 [==============>...............] - ETA: 4s - loss: 0.3622 - accuracy: 0.8722\n",
      "391/750 [==============>...............] - ETA: 4s - loss: 0.3626 - accuracy: 0.8723\n",
      " 32/750 [>.............................] - ETA: 8s - loss: 0.2630 - accuracy: 0.8950\n",
      "399/750 [==============>...............] - ETA: 3s - loss: 0.3623 - accuracy: 0.8725\n",
      " 40/750 [>.............................] - ETA: 9s - loss: 0.2834 - accuracy: 0.8891\n",
      "408/750 [===============>..............] - ETA: 3s - loss: 0.3630 - accuracy: 0.8720\n",
      " 49/750 [>.............................] - ETA: 8s - loss: 0.2860 - accuracy: 0.8906\n",
      "467/750 [=================>............] - ETA: 3s - loss: 0.3009 - accuracy: 0.8889\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "417/750 [===============>..............] - ETA: 3s - loss: 0.3626 - accuracy: 0.8720\n",
      "449/750 [================>.............] - ETA: 3s - loss: 0.3023 - accuracy: 0.8883\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "423/750 [===============>..............] - ETA: 3s - loss: 0.3627 - accuracy: 0.8720\n",
      " 69/750 [=>............................] - ETA: 7s - loss: 0.2834 - accuracy: 0.8918\n",
      " 94/750 [==>...........................] - ETA: 7s - loss: 0.3465 - accuracy: 0.8788\n",
      "492/750 [==================>...........] - ETA: 2s - loss: 0.3006 - accuracy: 0.8890\n",
      " 75/750 [==>...........................] - ETA: 8s - loss: 0.2759 - accuracy: 0.8946\n",
      " 92/750 [==>...........................] - ETA: 7s - loss: 0.2735 - accuracy: 0.8947\n",
      " 97/750 [==>...........................] - ETA: 7s - loss: 0.2704 - accuracy: 0.8959\n",
      "575/750 [======================>.......] - ETA: 1s - loss: 0.3020 - accuracy: 0.8890\n",
      "466/750 [=================>............] - ETA: 3s - loss: 0.3625 - accuracy: 0.8721\n",
      " 23/750 [..............................] - ETA: 5s - loss: 0.2606 - accuracy: 0.8933\n",
      " 25/750 [>.............................] - ETA: 8s - loss: 0.2646 - accuracy: 0.8919\n",
      "485/750 [==================>...........] - ETA: 3s - loss: 0.3612 - accuracy: 0.8724\n",
      "127/750 [====>.........................] - ETA: 7s - loss: 0.2761 - accuracy: 0.8920\n",
      "621/750 [=======================>......] - ETA: 1s - loss: 0.3033 - accuracy: 0.8885\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "223/750 [=======>......................] - ETA: 6s - loss: 0.3607 - accuracy: 0.8737\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.4703 - accuracy: 0.8594\n",
      "496/750 [==================>...........] - ETA: 2s - loss: 0.3617 - accuracy: 0.8720\n",
      " 16/750 [..............................] - ETA: 7s - loss: 0.3105 - accuracy: 0.8916\n",
      "648/750 [========================>.....] - ETA: 1s - loss: 0.3024 - accuracy: 0.8887\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "542/750 [====================>.........] - ETA: 2s - loss: 0.3018 - accuracy: 0.8888\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 25/750 [>.............................] - ETA: 7s - loss: 0.2983 - accuracy: 0.8969\n",
      "628/750 [========================>.....] - ETA: 1s - loss: 0.3029 - accuracy: 0.8886\n",
      " 31/750 [>.............................] - ETA: 7s - loss: 0.3059 - accuracy: 0.8916\n",
      "526/750 [====================>.........] - ETA: 2s - loss: 0.3615 - accuracy: 0.8724\n",
      "164/750 [=====>........................] - ETA: 6s - loss: 0.2742 - accuracy: 0.8943\n",
      "566/750 [=====================>........] - ETA: 2s - loss: 0.3021 - accuracy: 0.8891\n",
      " 62/750 [=>............................] - ETA: 8s - loss: 0.2774 - accuracy: 0.8947\n",
      "515/750 [===================>..........] - ETA: 2s - loss: 0.3612 - accuracy: 0.8724\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "191/750 [======>.......................] - ETA: 6s - loss: 0.3585 - accuracy: 0.8748\n",
      " 43/750 [>.............................] - ETA: 8s - loss: 0.2998 - accuracy: 0.8881\n",
      "542/750 [====================>.........] - ETA: 2s - loss: 0.3610 - accuracy: 0.8725\n",
      "186/750 [======>.......................] - ETA: 6s - loss: 0.2745 - accuracy: 0.8948\n",
      "115/750 [===>..........................] - ETA: 7s - loss: 0.2775 - accuracy: 0.8924\n",
      " 62/750 [=>............................] - ETA: 8s - loss: 0.2956 - accuracy: 0.8931\n",
      "565/750 [=====================>........] - ETA: 2s - loss: 0.3623 - accuracy: 0.8722\n",
      "100/750 [===>..........................] - ETA: 8s - loss: 0.2741 - accuracy: 0.8947\n",
      " 66/750 [=>............................] - ETA: 9s - loss: 0.2946 - accuracy: 0.8942\n",
      "572/750 [=====================>........] - ETA: 2s - loss: 0.3620 - accuracy: 0.8722\n",
      "147/750 [====>.........................] - ETA: 7s - loss: 0.2754 - accuracy: 0.8929\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "583/750 [======================>.......] - ETA: 1s - loss: 0.3627 - accuracy: 0.8719\n",
      "173/750 [=====>........................] - ETA: 6s - loss: 0.2726 - accuracy: 0.8952\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.3029 - accuracy: 0.8887\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "587/750 [======================>.......] - ETA: 1s - loss: 0.3629 - accuracy: 0.8719\n",
      "104/750 [===>..........................] - ETA: 8s - loss: 0.3016 - accuracy: 0.8900\n",
      "593/750 [======================>.......] - ETA: 1s - loss: 0.3629 - accuracy: 0.8719\n",
      "109/750 [===>..........................] - ETA: 8s - loss: 0.3015 - accuracy: 0.8899\n",
      "244/750 [========>.....................] - ETA: 6s - loss: 0.2747 - accuracy: 0.8961\n",
      "113/750 [===>..........................] - ETA: 8s - loss: 0.3019 - accuracy: 0.8897\n",
      "248/750 [========>.....................] - ETA: 6s - loss: 0.2740 - accuracy: 0.8962\n",
      "193/750 [======>.......................] - ETA: 6s - loss: 0.2751 - accuracy: 0.8950\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "119/750 [===>..........................] - ETA: 9s - loss: 0.3031 - accuracy: 0.8881\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.3624 - accuracy: 0.8719\n",
      "254/750 [=========>....................] - ETA: 6s - loss: 0.2755 - accuracy: 0.8955\n",
      "285/750 [==========>...................] - ETA: 5s - loss: 0.3620 - accuracy: 0.8732\n",
      "124/750 [===>..........................] - ETA: 9s - loss: 0.3018 - accuracy: 0.8884\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.3626 - accuracy: 0.8718\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.3627 - accuracy: 0.8718\n",
      "634/750 [========================>.....] - ETA: 1s - loss: 0.3624 - accuracy: 0.8718\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.3035 - accuracy: 0.8884\n",
      "669/750 [=========================>....] - ETA: 0s - loss: 0.3019 - accuracy: 0.8889\n",
      "132/750 [====>.........................] - ETA: 9s - loss: 0.3027 - accuracy: 0.8878\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.3039 - accuracy: 0.8884\n",
      "651/750 [=========================>....] - ETA: 1s - loss: 0.3640 - accuracy: 0.8714\n",
      "282/750 [==========>...................] - ETA: 6s - loss: 0.2760 - accuracy: 0.8956\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.3637 - accuracy: 0.8716\n",
      "290/750 [==========>...................] - ETA: 6s - loss: 0.2774 - accuracy: 0.8954\n",
      "664/750 [=========================>....] - ETA: 1s - loss: 0.3649 - accuracy: 0.8712\n",
      "298/750 [==========>...................] - ETA: 6s - loss: 0.2777 - accuracy: 0.8959\n",
      "240/750 [========>.....................] - ETA: 6s - loss: 0.2747 - accuracy: 0.8956\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "368/750 [=============>................] - ETA: 4s - loss: 0.3611 - accuracy: 0.8725\n",
      "270/750 [=========>....................] - ETA: 6s - loss: 0.2756 - accuracy: 0.8956\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "675/750 [==========================>...] - ETA: 0s - loss: 0.3646 - accuracy: 0.8715\n",
      "302/750 [===========>..................] - ETA: 6s - loss: 0.2778 - accuracy: 0.8958\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.3646 - accuracy: 0.8715\n",
      "304/750 [===========>..................] - ETA: 6s - loss: 0.2784 - accuracy: 0.8958\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.3647 - accuracy: 0.8714\n",
      "314/750 [===========>..................] - ETA: 5s - loss: 0.2794 - accuracy: 0.8956\n",
      "320/750 [===========>..................] - ETA: 5s - loss: 0.2796 - accuracy: 0.8959\n",
      "276/750 [==========>...................] - ETA: 6s - loss: 0.2755 - accuracy: 0.8955\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.3637 - accuracy: 0.8719\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.3642 - accuracy: 0.8718\n",
      "335/750 [============>.................] - ETA: 5s - loss: 0.2805 - accuracy: 0.8953\n",
      "200/750 [=======>......................] - ETA: 8s - loss: 0.2945 - accuracy: 0.8920\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.3640 - accuracy: 0.8718\n",
      "340/750 [============>.................] - ETA: 5s - loss: 0.2803 - accuracy: 0.8956\n",
      "328/750 [============>.................] - ETA: 5s - loss: 0.2797 - accuracy: 0.8961\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.3637 - accuracy: 0.8719\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.3642 - accuracy: 0.8715\n",
      "343/750 [============>.................] - ETA: 5s - loss: 0.2813 - accuracy: 0.8955\n",
      "346/750 [============>.................] - ETA: 5s - loss: 0.2814 - accuracy: 0.8952\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.3639 - accuracy: 0.8716\n",
      "220/750 [=======>......................] - ETA: 8s - loss: 0.2944 - accuracy: 0.8930\n",
      "360/750 [=============>................] - ETA: 5s - loss: 0.2819 - accuracy: 0.8950\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.3633 - accuracy: 0.8719\n",
      "368/750 [=============>................] - ETA: 5s - loss: 0.2825 - accuracy: 0.8945\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.3036 - accuracy: 0.8883 - val_loss: 0.3286 - val_accuracy: 0.8832\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 6/30\n",
      "350/750 [=============>................] - ETA: 5s - loss: 0.2809 - accuracy: 0.8951\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.3631 - accuracy: 0.8719\n",
      "376/750 [==============>...............] - ETA: 5s - loss: 0.2818 - accuracy: 0.8949\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.3634 - accuracy: 0.8718\n",
      "390/750 [==============>...............] - ETA: 4s - loss: 0.2808 - accuracy: 0.8953\n",
      "393/750 [==============>...............] - ETA: 4s - loss: 0.2801 - accuracy: 0.8954\n",
      " 49/750 [>.............................] - ETA: 9s - loss: 0.2910 - accuracy: 0.8932\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "399/750 [==============>...............] - ETA: 4s - loss: 0.2796 - accuracy: 0.8956\n",
      "409/750 [===============>..............] - ETA: 4s - loss: 0.2793 - accuracy: 0.8956\n",
      "473/750 [=================>............] - ETA: 3s - loss: 0.3617 - accuracy: 0.8724\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "420/750 [===============>..............] - ETA: 4s - loss: 0.2784 - accuracy: 0.8962\n",
      "446/750 [================>.............] - ETA: 3s - loss: 0.3623 - accuracy: 0.8718\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "428/750 [================>.............] - ETA: 4s - loss: 0.2779 - accuracy: 0.8963\n",
      " 77/750 [==>...........................] - ETA: 8s - loss: 0.2994 - accuracy: 0.8912\n",
      " 94/750 [==>...........................] - ETA: 8s - loss: 0.2988 - accuracy: 0.8908\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "453/750 [=================>............] - ETA: 4s - loss: 0.2787 - accuracy: 0.8962\n",
      "459/750 [=================>............] - ETA: 4s - loss: 0.2778 - accuracy: 0.8968\n",
      "463/750 [=================>............] - ETA: 3s - loss: 0.2784 - accuracy: 0.8965\n",
      "621/750 [=======================>......] - ETA: 1s - loss: 0.3623 - accuracy: 0.8719\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "215/750 [=======>......................] - ETA: 8s - loss: 0.2936 - accuracy: 0.8930\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "482/750 [==================>...........] - ETA: 3s - loss: 0.2792 - accuracy: 0.8963\n",
      "491/750 [==================>...........] - ETA: 3s - loss: 0.2789 - accuracy: 0.8964\n",
      "645/750 [========================>.....] - ETA: 1s - loss: 0.3640 - accuracy: 0.8714\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.3614 - accuracy: 0.8724\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "497/750 [==================>...........] - ETA: 3s - loss: 0.2784 - accuracy: 0.8967\n",
      "174/750 [=====>........................] - ETA: 9s - loss: 0.2988 - accuracy: 0.8915\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "505/750 [===================>..........] - ETA: 3s - loss: 0.2786 - accuracy: 0.8967\n",
      "517/750 [===================>..........] - ETA: 3s - loss: 0.2785 - accuracy: 0.8967\n",
      "525/750 [====================>.........] - ETA: 3s - loss: 0.2788 - accuracy: 0.8969\n",
      "185/750 [======>.......................] - ETA: 8s - loss: 0.2992 - accuracy: 0.8905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:03:20,445 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7115304960; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 11s 15ms/step - loss: 0.3636 - accuracy: 0.8719 - val_loss: 0.3818 - val_accuracy: 0.8675\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 7/30\n",
      "  1/750 [..............................] - ETA: 6s - loss: 0.3955 - accuracy: 0.8594\n",
      "553/750 [=====================>........] - ETA: 2s - loss: 0.2803 - accuracy: 0.8968\n",
      "148/750 [====>.........................] - ETA: 9s - loss: 0.3002 - accuracy: 0.8901\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 12/750 [..............................] - ETA: 8s - loss: 0.3248 - accuracy: 0.8906\n",
      "563/750 [=====================>........] - ETA: 2s - loss: 0.2795 - accuracy: 0.8971\n",
      " 20/750 [..............................] - ETA: 9s - loss: 0.3506 - accuracy: 0.8820 \n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.2796 - accuracy: 0.8969\n",
      "164/750 [=====>........................] - ETA: 9s - loss: 0.3006 - accuracy: 0.8906\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "584/750 [======================>.......] - ETA: 2s - loss: 0.2800 - accuracy: 0.8970\n",
      "471/750 [=================>............] - ETA: 3s - loss: 0.2907 - accuracy: 0.8938\n",
      "591/750 [======================>.......] - ETA: 2s - loss: 0.2805 - accuracy: 0.8968\n",
      "597/750 [======================>.......] - ETA: 2s - loss: 0.2802 - accuracy: 0.8970\n",
      " 52/750 [=>............................] - ETA: 8s - loss: 0.3458 - accuracy: 0.8810\n",
      "235/750 [========>.....................] - ETA: 7s - loss: 0.2919 - accuracy: 0.8941\n",
      "489/750 [==================>...........] - ETA: 3s - loss: 0.2902 - accuracy: 0.8942\n",
      " 57/750 [=>............................] - ETA: 7s - loss: 0.3421 - accuracy: 0.8821\n",
      "196/750 [======>.......................] - ETA: 8s - loss: 0.2958 - accuracy: 0.8917\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 63/750 [=>............................] - ETA: 8s - loss: 0.3427 - accuracy: 0.8832\n",
      "497/750 [==================>...........] - ETA: 3s - loss: 0.2911 - accuracy: 0.8938\n",
      " 69/750 [=>............................] - ETA: 8s - loss: 0.3411 - accuracy: 0.8843\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.2796 - accuracy: 0.8969\n",
      "502/750 [===================>..........] - ETA: 3s - loss: 0.2923 - accuracy: 0.8935\n",
      " 75/750 [==>...........................] - ETA: 8s - loss: 0.3377 - accuracy: 0.8852\n",
      "634/750 [========================>.....] - ETA: 1s - loss: 0.2792 - accuracy: 0.8972\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.2796 - accuracy: 0.8974\n",
      "644/750 [========================>.....] - ETA: 1s - loss: 0.2792 - accuracy: 0.8974\n",
      "293/750 [==========>...................] - ETA: 6s - loss: 0.2898 - accuracy: 0.8945\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "528/750 [====================>.........] - ETA: 3s - loss: 0.2925 - accuracy: 0.8933\n",
      "107/750 [===>..........................] - ETA: 8s - loss: 0.3467 - accuracy: 0.8823\n",
      "667/750 [=========================>....] - ETA: 1s - loss: 0.2791 - accuracy: 0.8975\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "117/750 [===>..........................] - ETA: 8s - loss: 0.3456 - accuracy: 0.8837\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.2926 - accuracy: 0.8938\n",
      "242/750 [========>.....................] - ETA: 7s - loss: 0.2908 - accuracy: 0.8948\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "271/750 [=========>....................] - ETA: 7s - loss: 0.2889 - accuracy: 0.8948\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "129/750 [====>.........................] - ETA: 7s - loss: 0.3461 - accuracy: 0.8832\n",
      "682/750 [==========================>...] - ETA: 0s - loss: 0.2792 - accuracy: 0.8975\n",
      "312/750 [===========>..................] - ETA: 6s - loss: 0.2886 - accuracy: 0.8954\n",
      "134/750 [====>.........................] - ETA: 7s - loss: 0.3472 - accuracy: 0.8826\n",
      "137/750 [====>.........................] - ETA: 8s - loss: 0.3484 - accuracy: 0.8822\n",
      "691/750 [==========================>...] - ETA: 0s - loss: 0.2788 - accuracy: 0.8977\n",
      "316/750 [===========>..................] - ETA: 6s - loss: 0.2888 - accuracy: 0.8957\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.2786 - accuracy: 0.8978\n",
      "600/750 [=======================>......] - ETA: 2s - loss: 0.2914 - accuracy: 0.8939\n",
      "349/750 [============>.................] - ETA: 5s - loss: 0.2902 - accuracy: 0.8952\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2790 - accuracy: 0.8976\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 0.2915 - accuracy: 0.8939\n",
      "177/750 [======>.......................] - ETA: 7s - loss: 0.3459 - accuracy: 0.8818\n",
      "325/750 [============>.................] - ETA: 6s - loss: 0.2897 - accuracy: 0.8953\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2794 - accuracy: 0.8975\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "189/750 [======>.......................] - ETA: 7s - loss: 0.3441 - accuracy: 0.8829\n",
      "202/750 [=======>......................] - ETA: 6s - loss: 0.3435 - accuracy: 0.8830\n",
      "374/750 [=============>................] - ETA: 5s - loss: 0.2899 - accuracy: 0.8952\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2798 - accuracy: 0.8974\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "397/750 [==============>...............] - ETA: 4s - loss: 0.2899 - accuracy: 0.8947\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "378/750 [==============>...............] - ETA: 5s - loss: 0.2895 - accuracy: 0.8951\n",
      " 40/750 [>.............................] - ETA: 8s - loss: 0.3438 - accuracy: 0.8805\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "696/750 [==========================>...] - ETA: 0s - loss: 0.2895 - accuracy: 0.8944\n",
      "417/750 [===============>..............] - ETA: 4s - loss: 0.2899 - accuracy: 0.8946\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "469/750 [=================>............] - ETA: 3s - loss: 0.2788 - accuracy: 0.8964\n",
      "276/750 [==========>...................] - ETA: 5s - loss: 0.3500 - accuracy: 0.8791\n",
      "441/750 [================>.............] - ETA: 4s - loss: 0.2893 - accuracy: 0.8943\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "296/750 [==========>...................] - ETA: 5s - loss: 0.3478 - accuracy: 0.8801\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2890 - accuracy: 0.8944\n",
      " 99/750 [==>...........................] - ETA: 8s - loss: 0.3429 - accuracy: 0.8845\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2883 - accuracy: 0.8945\n",
      "332/750 [============>.................] - ETA: 4s - loss: 0.3496 - accuracy: 0.8782\n",
      "452/750 [=================>............] - ETA: 4s - loss: 0.2889 - accuracy: 0.8943\n",
      "456/750 [=================>............] - ETA: 4s - loss: 0.2892 - accuracy: 0.8942\n",
      "609/750 [=======================>......] - ETA: 1s - loss: 0.2912 - accuracy: 0.8941\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "222/750 [=======>......................] - ETA: 6s - loss: 0.3462 - accuracy: 0.8819\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  9/750 [..............................] - ETA: 5s - loss: 0.2630 - accuracy: 0.9045\n",
      "492/750 [==================>...........] - ETA: 3s - loss: 0.2910 - accuracy: 0.8939\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "379/750 [==============>...............] - ETA: 4s - loss: 0.3479 - accuracy: 0.8789\n",
      "539/750 [====================>.........] - ETA: 2s - loss: 0.2923 - accuracy: 0.8935\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 28/750 [>.............................] - ETA: 7s - loss: 0.2653 - accuracy: 0.9023 \n",
      " 31/750 [>.............................] - ETA: 8s - loss: 0.2584 - accuracy: 0.9057\n",
      " 32/750 [>.............................] - ETA: 9s - loss: 0.2559 - accuracy: 0.9058\n",
      "172/750 [=====>........................] - ETA: 7s - loss: 0.3453 - accuracy: 0.8824\n",
      "405/750 [===============>..............] - ETA: 4s - loss: 0.3488 - accuracy: 0.8782\n",
      "519/750 [===================>..........] - ETA: 3s - loss: 0.2931 - accuracy: 0.8932\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 48/750 [>.............................] - ETA: 8s - loss: 0.2721 - accuracy: 0.8991\n",
      " 49/750 [>.............................] - ETA: 9s - loss: 0.2707 - accuracy: 0.8989\n",
      "526/750 [====================>.........] - ETA: 3s - loss: 0.2925 - accuracy: 0.8933\n",
      " 67/750 [=>............................] - ETA: 8s - loss: 0.2660 - accuracy: 0.9009\n",
      "428/750 [================>.............] - ETA: 3s - loss: 0.3494 - accuracy: 0.8778\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.2802 - accuracy: 0.8972 - val_loss: 0.3808 - val_accuracy: 0.8664\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 8/30\n",
      "  1/750 [..............................] - ETA: 7s - loss: 0.3590 - accuracy: 0.8906\n",
      "434/750 [================>.............] - ETA: 3s - loss: 0.3499 - accuracy: 0.8776\n",
      "553/750 [=====================>........] - ETA: 2s - loss: 0.2924 - accuracy: 0.8939\n",
      "149/750 [====>.........................] - ETA: 7s - loss: 0.3464 - accuracy: 0.8829\n",
      " 15/750 [..............................] - ETA: 12s - loss: 0.2672 - accuracy: 0.9062\n",
      "571/750 [=====================>........] - ETA: 2s - loss: 0.2919 - accuracy: 0.8940\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "448/750 [================>.............] - ETA: 3s - loss: 0.3490 - accuracy: 0.8771\n",
      "165/750 [=====>........................] - ETA: 7s - loss: 0.3476 - accuracy: 0.8823\n",
      "454/750 [=================>............] - ETA: 3s - loss: 0.3492 - accuracy: 0.8772\n",
      "101/750 [===>..........................] - ETA: 8s - loss: 0.2729 - accuracy: 0.8963\n",
      "589/750 [======================>.......] - ETA: 2s - loss: 0.2917 - accuracy: 0.8939\n",
      "584/750 [======================>.......] - ETA: 2s - loss: 0.2918 - accuracy: 0.8937\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "464/750 [=================>............] - ETA: 3s - loss: 0.3510 - accuracy: 0.8764\n",
      "474/750 [=================>............] - ETA: 3s - loss: 0.3506 - accuracy: 0.8766\n",
      " 70/750 [=>............................] - ETA: 8s - loss: 0.2674 - accuracy: 0.9009\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2883 - accuracy: 0.8944 - val_loss: 0.3316 - val_accuracy: 0.8803\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 7/30\n",
      "  9/750 [..............................] - ETA: 5s - loss: 0.2638 - accuracy: 0.9132\n",
      " 13/750 [..............................] - ETA: 11s - loss: 0.2591 - accuracy: 0.9183\n",
      "503/750 [===================>..........] - ETA: 2s - loss: 0.3508 - accuracy: 0.8766\n",
      "153/750 [=====>........................] - ETA: 6s - loss: 0.2673 - accuracy: 0.8998\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.2907 - accuracy: 0.8942\n",
      " 89/750 [==>...........................] - ETA: 8s - loss: 0.2755 - accuracy: 0.8969\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 17/750 [..............................] - ETA: 12s - loss: 0.2540 - accuracy: 0.9154\n",
      "158/750 [=====>........................] - ETA: 7s - loss: 0.2661 - accuracy: 0.9005\n",
      "644/750 [========================>.....] - ETA: 1s - loss: 0.2905 - accuracy: 0.8940\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 26/750 [>.............................] - ETA: 11s - loss: 0.2566 - accuracy: 0.9117\n",
      "174/750 [=====>........................] - ETA: 6s - loss: 0.2638 - accuracy: 0.9016\n",
      " 34/750 [>.............................] - ETA: 10s - loss: 0.2623 - accuracy: 0.9108\n",
      " 39/750 [>.............................] - ETA: 11s - loss: 0.2634 - accuracy: 0.9103\n",
      "192/750 [======>.......................] - ETA: 6s - loss: 0.2631 - accuracy: 0.9014\n",
      "286/750 [==========>...................] - ETA: 5s - loss: 0.3485 - accuracy: 0.8795\n",
      "123/750 [===>..........................] - ETA: 7s - loss: 0.2703 - accuracy: 0.8982\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 50/750 [=>............................] - ETA: 10s - loss: 0.2682 - accuracy: 0.9041\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.3505 - accuracy: 0.8764\n",
      "669/750 [=========================>....] - ETA: 1s - loss: 0.2897 - accuracy: 0.8944\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 61/750 [=>............................] - ETA: 9s - loss: 0.2713 - accuracy: 0.9029\n",
      "551/750 [=====================>........] - ETA: 2s - loss: 0.3511 - accuracy: 0.8764\n",
      "206/750 [=======>......................] - ETA: 6s - loss: 0.2630 - accuracy: 0.9023\n",
      "246/750 [========>.....................] - ETA: 6s - loss: 0.3479 - accuracy: 0.8802\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "272/750 [=========>....................] - ETA: 5s - loss: 0.3498 - accuracy: 0.8793\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.2896 - accuracy: 0.8943\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "139/750 [====>.........................] - ETA: 7s - loss: 0.2674 - accuracy: 0.8995\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "317/750 [===========>..................] - ETA: 5s - loss: 0.3479 - accuracy: 0.8793\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "583/750 [======================>.......] - ETA: 1s - loss: 0.3511 - accuracy: 0.8763\n",
      "228/750 [========>.....................] - ETA: 6s - loss: 0.2622 - accuracy: 0.9019\n",
      "233/750 [========>.....................] - ETA: 6s - loss: 0.2643 - accuracy: 0.9016\n",
      "593/750 [======================>.......] - ETA: 1s - loss: 0.3509 - accuracy: 0.8765\n",
      "101/750 [===>..........................] - ETA: 9s - loss: 0.2684 - accuracy: 0.9045\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.3503 - accuracy: 0.8767\n",
      "344/750 [============>.................] - ETA: 4s - loss: 0.3482 - accuracy: 0.8785\n",
      "260/750 [=========>....................] - ETA: 5s - loss: 0.2661 - accuracy: 0.9014\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2889 - accuracy: 0.8946\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "202/750 [=======>......................] - ETA: 6s - loss: 0.2620 - accuracy: 0.9027\n",
      "126/750 [====>.........................] - ETA: 8s - loss: 0.2631 - accuracy: 0.9043\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.3505 - accuracy: 0.8764\n",
      "278/750 [==========>...................] - ETA: 5s - loss: 0.2657 - accuracy: 0.9014\n",
      "368/750 [=============>................] - ETA: 4s - loss: 0.3477 - accuracy: 0.8791\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2880 - accuracy: 0.8946\n",
      "139/750 [====>.........................] - ETA: 8s - loss: 0.2628 - accuracy: 0.9034\n",
      "288/750 [==========>...................] - ETA: 5s - loss: 0.2665 - accuracy: 0.9013\n",
      "300/750 [===========>..................] - ETA: 5s - loss: 0.2682 - accuracy: 0.9006\n",
      "396/750 [==============>...............] - ETA: 4s - loss: 0.3481 - accuracy: 0.8787\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "183/750 [======>.......................] - ETA: 7s - loss: 0.2660 - accuracy: 0.9022\n",
      " 45/750 [>.............................] - ETA: 8s - loss: 0.2717 - accuracy: 0.8993\n",
      "188/750 [======>.......................] - ETA: 7s - loss: 0.2666 - accuracy: 0.9015\n",
      "334/750 [============>.................] - ETA: 5s - loss: 0.2672 - accuracy: 0.9011\n",
      "197/750 [======>.......................] - ETA: 7s - loss: 0.2667 - accuracy: 0.9006\n",
      "349/750 [============>.................] - ETA: 4s - loss: 0.2676 - accuracy: 0.9013\n",
      "420/750 [===============>..............] - ETA: 3s - loss: 0.3491 - accuracy: 0.8780\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "445/750 [================>.............] - ETA: 3s - loss: 0.3493 - accuracy: 0.8772\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.3501 - accuracy: 0.8764\n",
      "386/750 [==============>...............] - ETA: 4s - loss: 0.2675 - accuracy: 0.9013\n",
      " 93/750 [==>...........................] - ETA: 8s - loss: 0.2697 - accuracy: 0.9051\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.3498 - accuracy: 0.8763\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "327/750 [============>.................] - ETA: 5s - loss: 0.2676 - accuracy: 0.9009\n",
      "254/750 [=========>....................] - ETA: 6s - loss: 0.2663 - accuracy: 0.9008\n",
      "280/750 [==========>...................] - ETA: 5s - loss: 0.2704 - accuracy: 0.8998\n",
      "621/750 [=======================>......] - ETA: 1s - loss: 0.3501 - accuracy: 0.8764\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "223/750 [=======>......................] - ETA: 6s - loss: 0.2672 - accuracy: 0.9008\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "435/750 [================>.............] - ETA: 3s - loss: 0.2672 - accuracy: 0.9015\n",
      "490/750 [==================>...........] - ETA: 3s - loss: 0.3506 - accuracy: 0.8768\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "292/750 [==========>...................] - ETA: 5s - loss: 0.2698 - accuracy: 0.8995\n",
      "446/750 [================>.............] - ETA: 3s - loss: 0.2669 - accuracy: 0.9020\n",
      "537/750 [====================>.........] - ETA: 2s - loss: 0.3501 - accuracy: 0.8765\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "307/750 [===========>..................] - ETA: 5s - loss: 0.2695 - accuracy: 0.8995\n",
      "326/750 [============>.................] - ETA: 5s - loss: 0.2695 - accuracy: 0.8998\n",
      "520/750 [===================>..........] - ETA: 2s - loss: 0.3503 - accuracy: 0.8766\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:03:30,545 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7115100160; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72/750 [=>............................] - ETA: 9s - loss: 0.2734 - accuracy: 0.9021\n",
      "353/750 [=============>................] - ETA: 4s - loss: 0.2707 - accuracy: 0.8992\n",
      "360/750 [=============>................] - ETA: 4s - loss: 0.2706 - accuracy: 0.8991\n",
      "428/750 [================>.............] - ETA: 3s - loss: 0.2675 - accuracy: 0.9017\n",
      "366/750 [=============>................] - ETA: 4s - loss: 0.2710 - accuracy: 0.8990\n",
      "370/750 [=============>................] - ETA: 4s - loss: 0.2708 - accuracy: 0.8990\n",
      "511/750 [===================>..........] - ETA: 2s - loss: 0.2689 - accuracy: 0.9018\n",
      "566/750 [=====================>........] - ETA: 2s - loss: 0.3504 - accuracy: 0.8765\n",
      "586/750 [======================>.......] - ETA: 1s - loss: 0.3510 - accuracy: 0.8764\n",
      "474/750 [=================>............] - ETA: 3s - loss: 0.2677 - accuracy: 0.9016\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 12s - loss: 0.2339 - accuracy: 0.9375\n",
      "553/750 [=====================>........] - ETA: 2s - loss: 0.2688 - accuracy: 0.9018\n",
      " 12/750 [..............................] - ETA: 8s - loss: 0.3470 - accuracy: 0.8685\n",
      "570/750 [=====================>........] - ETA: 2s - loss: 0.2680 - accuracy: 0.9022\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 0.3503 - accuracy: 0.8761 - val_loss: 0.3683 - val_accuracy: 0.8714\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 8/30\n",
      "427/750 [================>.............] - ETA: 3s - loss: 0.2748 - accuracy: 0.8980\n",
      " 24/750 [..............................] - ETA: 7s - loss: 0.3285 - accuracy: 0.8724 \n",
      " 36/750 [>.............................] - ETA: 7s - loss: 0.3189 - accuracy: 0.8772\n",
      "153/750 [=====>........................] - ETA: 7s - loss: 0.2613 - accuracy: 0.9038\n",
      " 98/750 [==>...........................] - ETA: 9s - loss: 0.2676 - accuracy: 0.9048\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "448/750 [================>.............] - ETA: 3s - loss: 0.2754 - accuracy: 0.8977\n",
      " 43/750 [>.............................] - ETA: 6s - loss: 0.3212 - accuracy: 0.8815\n",
      "171/750 [=====>........................] - ETA: 7s - loss: 0.2661 - accuracy: 0.9024\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.3504 - accuracy: 0.8764\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 51/750 [=>............................] - ETA: 8s - loss: 0.3289 - accuracy: 0.8790\n",
      "463/750 [=================>............] - ETA: 3s - loss: 0.2763 - accuracy: 0.8973\n",
      " 57/750 [=>............................] - ETA: 8s - loss: 0.3360 - accuracy: 0.8764\n",
      " 70/750 [=>............................] - ETA: 7s - loss: 0.3337 - accuracy: 0.8772\n",
      "121/750 [===>..........................] - ETA: 8s - loss: 0.2626 - accuracy: 0.9044\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 76/750 [==>...........................] - ETA: 8s - loss: 0.3285 - accuracy: 0.8777\n",
      "669/750 [=========================>....] - ETA: 0s - loss: 0.3507 - accuracy: 0.8761\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "242/750 [========>.....................] - ETA: 6s - loss: 0.2666 - accuracy: 0.9004\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "268/750 [=========>....................] - ETA: 5s - loss: 0.2678 - accuracy: 0.9009\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "505/750 [===================>..........] - ETA: 2s - loss: 0.2757 - accuracy: 0.8973\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.3510 - accuracy: 0.8759\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "318/750 [===========>..................] - ETA: 5s - loss: 0.2691 - accuracy: 0.9001\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "597/750 [======================>.......] - ETA: 1s - loss: 0.2686 - accuracy: 0.9020\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "653/750 [=========================>....] - ETA: 1s - loss: 0.2687 - accuracy: 0.9016\n",
      "247/750 [========>.....................] - ETA: 6s - loss: 0.2668 - accuracy: 0.9007\n",
      "129/750 [====>.........................] - ETA: 7s - loss: 0.3343 - accuracy: 0.8795\n",
      "102/750 [===>..........................] - ETA: 7s - loss: 0.3311 - accuracy: 0.8790\n",
      "541/750 [====================>.........] - ETA: 2s - loss: 0.2754 - accuracy: 0.8982\n",
      "562/750 [=====================>........] - ETA: 2s - loss: 0.2755 - accuracy: 0.8986\n",
      "151/750 [=====>........................] - ETA: 7s - loss: 0.3336 - accuracy: 0.8803\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2705 - accuracy: 0.9012\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "126/750 [====>.........................] - ETA: 7s - loss: 0.3355 - accuracy: 0.8795\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.2684 - accuracy: 0.9018\n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.2748 - accuracy: 0.8987\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2709 - accuracy: 0.9011\n",
      "288/750 [==========>...................] - ETA: 5s - loss: 0.2691 - accuracy: 0.8998\n",
      "371/750 [=============>................] - ETA: 4s - loss: 0.2676 - accuracy: 0.9012\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "137/750 [====>.........................] - ETA: 7s - loss: 0.3362 - accuracy: 0.8789\n",
      "183/750 [======>.......................] - ETA: 6s - loss: 0.3407 - accuracy: 0.8786\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2704 - accuracy: 0.9012\n",
      "305/750 [===========>..................] - ETA: 5s - loss: 0.2696 - accuracy: 0.8996\n",
      "395/750 [==============>...............] - ETA: 4s - loss: 0.2719 - accuracy: 0.8991\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 0.2753 - accuracy: 0.8986\n",
      "200/750 [=======>......................] - ETA: 6s - loss: 0.3417 - accuracy: 0.8788\n",
      "188/750 [======>.......................] - ETA: 6s - loss: 0.3411 - accuracy: 0.8787\n",
      "621/750 [=======================>......] - ETA: 1s - loss: 0.2758 - accuracy: 0.8985\n",
      "349/750 [============>.................] - ETA: 4s - loss: 0.2705 - accuracy: 0.8992\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "232/750 [========>.....................] - ETA: 6s - loss: 0.3432 - accuracy: 0.8776\n",
      "418/750 [===============>..............] - ETA: 3s - loss: 0.2737 - accuracy: 0.8987\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "282/750 [==========>...................] - ETA: 5s - loss: 0.3415 - accuracy: 0.8782\n",
      "294/750 [==========>...................] - ETA: 5s - loss: 0.3414 - accuracy: 0.8779\n",
      "382/750 [==============>...............] - ETA: 4s - loss: 0.2715 - accuracy: 0.8990\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 97/750 [==>...........................] - ETA: 8s - loss: 0.3315 - accuracy: 0.8782\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2707 - accuracy: 0.9010\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "615/750 [=======================>......] - ETA: 1s - loss: 0.2758 - accuracy: 0.8986\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "217/750 [=======>......................] - ETA: 6s - loss: 0.3413 - accuracy: 0.8784\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "439/750 [================>.............] - ETA: 3s - loss: 0.2748 - accuracy: 0.8979\n",
      "491/750 [==================>...........] - ETA: 3s - loss: 0.2759 - accuracy: 0.8970\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "536/750 [====================>.........] - ETA: 2s - loss: 0.2754 - accuracy: 0.8981\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.2707 - accuracy: 0.9010 - val_loss: 0.3360 - val_accuracy: 0.8867\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 9/30\n",
      "  6/750 [..............................] - ETA: 7s - loss: 0.2370 - accuracy: 0.9062\n",
      "379/750 [==============>...............] - ETA: 4s - loss: 0.3434 - accuracy: 0.8783\n",
      " 19/750 [..............................] - ETA: 6s - loss: 0.2347 - accuracy: 0.9071\n",
      "326/750 [============>.................] - ETA: 4s - loss: 0.3403 - accuracy: 0.8788\n",
      "521/750 [===================>..........] - ETA: 2s - loss: 0.2762 - accuracy: 0.8976\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "400/750 [===============>..............] - ETA: 3s - loss: 0.3437 - accuracy: 0.8782\n",
      "430/750 [================>.............] - ETA: 3s - loss: 0.3444 - accuracy: 0.8782\n",
      "442/750 [================>.............] - ETA: 3s - loss: 0.3433 - accuracy: 0.8785\n",
      "452/750 [=================>............] - ETA: 3s - loss: 0.3442 - accuracy: 0.8783\n",
      "473/750 [=================>............] - ETA: 3s - loss: 0.2763 - accuracy: 0.8971\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "475/750 [==================>...........] - ETA: 2s - loss: 0.3432 - accuracy: 0.8786\n",
      "567/750 [=====================>........] - ETA: 2s - loss: 0.2751 - accuracy: 0.8987\n",
      "492/750 [==================>...........] - ETA: 2s - loss: 0.3431 - accuracy: 0.8789\n",
      "131/750 [====>.........................] - ETA: 6s - loss: 0.2528 - accuracy: 0.9062\n",
      " 48/750 [>.............................] - ETA: 6s - loss: 0.2530 - accuracy: 0.9040\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "145/750 [====>.........................] - ETA: 6s - loss: 0.2532 - accuracy: 0.9055\n",
      " 87/750 [==>...........................] - ETA: 6s - loss: 0.2525 - accuracy: 0.9057\n",
      " 25/750 [>.............................] - ETA: 6s - loss: 0.2501 - accuracy: 0.9013\n",
      "  1/750 [..............................] - ETA: 7s - loss: 0.3024 - accuracy: 0.8906\n",
      "168/750 [=====>........................] - ETA: 7s - loss: 0.3381 - accuracy: 0.8792\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.2748 - accuracy: 0.8988\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "526/750 [====================>.........] - ETA: 2s - loss: 0.3423 - accuracy: 0.8794\n",
      " 68/750 [=>............................] - ETA: 7s - loss: 0.2490 - accuracy: 0.9042\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 26/750 [>.............................] - ETA: 8s - loss: 0.2438 - accuracy: 0.9123\n",
      " 30/750 [>.............................] - ETA: 8s - loss: 0.2490 - accuracy: 0.9099\n",
      "178/750 [======>.......................] - ETA: 5s - loss: 0.2517 - accuracy: 0.9067\n",
      "122/750 [===>..........................] - ETA: 6s - loss: 0.2500 - accuracy: 0.9061\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 80/750 [==>...........................] - ETA: 6s - loss: 0.2523 - accuracy: 0.9059\n",
      "553/750 [=====================>........] - ETA: 2s - loss: 0.3427 - accuracy: 0.8789\n",
      "189/750 [======>.......................] - ETA: 6s - loss: 0.2514 - accuracy: 0.9069\n",
      "671/750 [=========================>....] - ETA: 0s - loss: 0.2738 - accuracy: 0.8991\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 53/750 [=>............................] - ETA: 6s - loss: 0.2487 - accuracy: 0.9092\n",
      "564/750 [=====================>........] - ETA: 2s - loss: 0.3423 - accuracy: 0.8789\n",
      "246/750 [========>.....................] - ETA: 5s - loss: 0.3428 - accuracy: 0.8777\n",
      "274/750 [=========>....................] - ETA: 5s - loss: 0.3423 - accuracy: 0.8777\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "506/750 [===================>..........] - ETA: 2s - loss: 0.3421 - accuracy: 0.8791\n",
      "574/750 [=====================>........] - ETA: 1s - loss: 0.3423 - accuracy: 0.8788\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.2740 - accuracy: 0.8994\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "320/750 [===========>..................] - ETA: 4s - loss: 0.3417 - accuracy: 0.8784\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.2751 - accuracy: 0.8987\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "220/750 [=======>......................] - ETA: 5s - loss: 0.2515 - accuracy: 0.9069\n",
      "224/750 [=======>......................] - ETA: 5s - loss: 0.2509 - accuracy: 0.9072\n",
      "227/750 [========>.....................] - ETA: 5s - loss: 0.2505 - accuracy: 0.9074\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 0.3425 - accuracy: 0.8785\n",
      "233/750 [========>.....................] - ETA: 5s - loss: 0.2508 - accuracy: 0.9071\n",
      "239/750 [========>.....................] - ETA: 5s - loss: 0.2503 - accuracy: 0.9075\n",
      "149/750 [====>.........................] - ETA: 6s - loss: 0.2514 - accuracy: 0.9064\n",
      "100/750 [===>..........................] - ETA: 7s - loss: 0.2588 - accuracy: 0.9050\n",
      "252/750 [=========>....................] - ETA: 5s - loss: 0.2500 - accuracy: 0.9073\n",
      "264/750 [=========>....................] - ETA: 5s - loss: 0.2495 - accuracy: 0.9074\n",
      "271/750 [=========>....................] - ETA: 5s - loss: 0.2502 - accuracy: 0.9071\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2734 - accuracy: 0.8995\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "280/750 [==========>...................] - ETA: 4s - loss: 0.2509 - accuracy: 0.9065\n",
      "283/750 [==========>...................] - ETA: 5s - loss: 0.2504 - accuracy: 0.9067\n",
      "653/750 [=========================>....] - ETA: 1s - loss: 0.3414 - accuracy: 0.8786\n",
      "368/750 [=============>................] - ETA: 4s - loss: 0.3433 - accuracy: 0.8782\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "150/750 [=====>........................] - ETA: 6s - loss: 0.2617 - accuracy: 0.9045\n",
      "158/750 [=====>........................] - ETA: 6s - loss: 0.2620 - accuracy: 0.9047\n",
      "302/750 [===========>..................] - ETA: 4s - loss: 0.2512 - accuracy: 0.9065\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2729 - accuracy: 0.8998\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "389/750 [==============>...............] - ETA: 3s - loss: 0.3437 - accuracy: 0.8782\n",
      "205/750 [=======>......................] - ETA: 5s - loss: 0.2526 - accuracy: 0.9065\n",
      "161/750 [=====>........................] - ETA: 6s - loss: 0.2612 - accuracy: 0.9048\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.3394 - accuracy: 0.8793\n",
      "325/750 [============>.................] - ETA: 4s - loss: 0.2517 - accuracy: 0.9073\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.3393 - accuracy: 0.8794\n",
      "335/750 [============>.................] - ETA: 4s - loss: 0.2510 - accuracy: 0.9078\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.3390 - accuracy: 0.8795\n",
      "422/750 [===============>..............] - ETA: 3s - loss: 0.3438 - accuracy: 0.8787\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "205/750 [=======>......................] - ETA: 6s - loss: 0.2610 - accuracy: 0.9038\n",
      "354/750 [=============>................] - ETA: 4s - loss: 0.2513 - accuracy: 0.9078\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.3383 - accuracy: 0.8799\n",
      "294/750 [==========>...................] - ETA: 4s - loss: 0.2514 - accuracy: 0.9065\n",
      "238/750 [========>.....................] - ETA: 5s - loss: 0.2611 - accuracy: 0.9036\n",
      "385/750 [==============>...............] - ETA: 4s - loss: 0.2516 - accuracy: 0.9075\n",
      "375/750 [==============>...............] - ETA: 4s - loss: 0.2512 - accuracy: 0.9077\n",
      " 88/750 [==>...........................] - ETA: 7s - loss: 0.2564 - accuracy: 0.9052\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "248/750 [========>.....................] - ETA: 5s - loss: 0.2627 - accuracy: 0.9027\n",
      "398/750 [==============>...............] - ETA: 3s - loss: 0.2527 - accuracy: 0.9073\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.3377 - accuracy: 0.8802\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "275/750 [==========>...................] - ETA: 5s - loss: 0.2626 - accuracy: 0.9024\n",
      "428/750 [================>.............] - ETA: 3s - loss: 0.2544 - accuracy: 0.9064\n",
      "289/750 [==========>...................] - ETA: 5s - loss: 0.2649 - accuracy: 0.9016\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.3414 - accuracy: 0.8791\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "224/750 [=======>......................] - ETA: 6s - loss: 0.2625 - accuracy: 0.9033\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "487/750 [==================>...........] - ETA: 2s - loss: 0.3436 - accuracy: 0.8788\n",
      "546/750 [====================>.........] - ETA: 2s - loss: 0.3420 - accuracy: 0.8791\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "326/750 [============>.................] - ETA: 4s - loss: 0.2645 - accuracy: 0.9013\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.2729 - accuracy: 0.8997 - val_loss: 0.3468 - val_accuracy: 0.8758\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 8/30\n",
      "330/750 [============>.................] - ETA: 4s - loss: 0.2637 - accuracy: 0.9018\n",
      "488/750 [==================>...........] - ETA: 2s - loss: 0.2576 - accuracy: 0.9054\n",
      "515/750 [===================>..........] - ETA: 2s - loss: 0.3428 - accuracy: 0.8790\n",
      "347/750 [============>.................] - ETA: 4s - loss: 0.2620 - accuracy: 0.9021\n",
      "499/750 [==================>...........] - ETA: 2s - loss: 0.2577 - accuracy: 0.9053\n",
      "512/750 [===================>..........] - ETA: 2s - loss: 0.2573 - accuracy: 0.9056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:03:40,640 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7114559488; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523/750 [===================>..........] - ETA: 2s - loss: 0.2571 - accuracy: 0.9058\n",
      "444/750 [================>.............] - ETA: 3s - loss: 0.2548 - accuracy: 0.9066\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 0.2617 - accuracy: 0.9024\n",
      "403/750 [===============>..............] - ETA: 3s - loss: 0.2615 - accuracy: 0.9027\n",
      "462/750 [=================>............] - ETA: 3s - loss: 0.2564 - accuracy: 0.9057\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "477/750 [==================>...........] - ETA: 2s - loss: 0.2574 - accuracy: 0.9054\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3386 - accuracy: 0.8797 - val_loss: 0.3636 - val_accuracy: 0.8727\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 9/30\n",
      "  8/750 [..............................] - ETA: 5s - loss: 0.3483 - accuracy: 0.8691\n",
      "436/750 [================>.............] - ETA: 3s - loss: 0.2608 - accuracy: 0.9031\n",
      " 17/750 [..............................] - ETA: 7s - loss: 0.3437 - accuracy: 0.8741\n",
      "491/750 [==================>...........] - ETA: 2s - loss: 0.2573 - accuracy: 0.9055\n",
      "449/750 [================>.............] - ETA: 3s - loss: 0.2610 - accuracy: 0.9030\n",
      " 27/750 [>.............................] - ETA: 7s - loss: 0.3363 - accuracy: 0.8802\n",
      "139/750 [====>.........................] - ETA: 7s - loss: 0.2642 - accuracy: 0.9032\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 43/750 [>.............................] - ETA: 7s - loss: 0.2443 - accuracy: 0.9124\n",
      " 36/750 [>.............................] - ETA: 7s - loss: 0.3423 - accuracy: 0.8772\n",
      " 48/750 [>.............................] - ETA: 7s - loss: 0.3394 - accuracy: 0.8799\n",
      "171/750 [=====>........................] - ETA: 6s - loss: 0.2611 - accuracy: 0.9049\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "642/750 [========================>.....] - ETA: 1s - loss: 0.3418 - accuracy: 0.8787\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "474/750 [=================>............] - ETA: 3s - loss: 0.2601 - accuracy: 0.9034\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.2575 - accuracy: 0.9062\n",
      " 54/750 [=>............................] - ETA: 8s - loss: 0.3415 - accuracy: 0.8785\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "487/750 [==================>...........] - ETA: 2s - loss: 0.2602 - accuracy: 0.9036\n",
      "124/750 [===>..........................] - ETA: 7s - loss: 0.2608 - accuracy: 0.9045\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "564/750 [=====================>........] - ETA: 1s - loss: 0.2577 - accuracy: 0.9059\n",
      " 76/750 [==>...........................] - ETA: 8s - loss: 0.3396 - accuracy: 0.8760\n",
      "194/750 [======>.......................] - ETA: 6s - loss: 0.2617 - accuracy: 0.9044\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "674/750 [=========================>....] - ETA: 0s - loss: 0.3395 - accuracy: 0.8793\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "574/750 [=====================>........] - ETA: 1s - loss: 0.2571 - accuracy: 0.9060\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "103/750 [===>..........................] - ETA: 7s - loss: 0.3336 - accuracy: 0.8794\n",
      "260/750 [=========>....................] - ETA: 5s - loss: 0.2620 - accuracy: 0.9031\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "665/750 [=========================>....] - ETA: 0s - loss: 0.2594 - accuracy: 0.9052\n",
      "314/750 [===========>..................] - ETA: 4s - loss: 0.2634 - accuracy: 0.9020\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "598/750 [======================>.......] - ETA: 1s - loss: 0.2567 - accuracy: 0.9064\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "529/750 [====================>.........] - ETA: 2s - loss: 0.2589 - accuracy: 0.9044\n",
      "107/750 [===>..........................] - ETA: 7s - loss: 0.3373 - accuracy: 0.8789\n",
      "676/750 [==========================>...] - ETA: 0s - loss: 0.2598 - accuracy: 0.9052\n",
      "120/750 [===>..........................] - ETA: 7s - loss: 0.3353 - accuracy: 0.8799\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.2592 - accuracy: 0.9055\n",
      "229/750 [========>.....................] - ETA: 6s - loss: 0.2621 - accuracy: 0.9036\n",
      "545/750 [====================>.........] - ETA: 2s - loss: 0.2583 - accuracy: 0.9045\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2611 - accuracy: 0.9048\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "650/750 [=========================>....] - ETA: 1s - loss: 0.2581 - accuracy: 0.9056\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 0.2589 - accuracy: 0.9043\n",
      "366/750 [=============>................] - ETA: 4s - loss: 0.2621 - accuracy: 0.9021\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "151/750 [=====>........................] - ETA: 7s - loss: 0.3316 - accuracy: 0.8817\n",
      "168/750 [=====>........................] - ETA: 6s - loss: 0.3325 - accuracy: 0.8810\n",
      "301/750 [===========>..................] - ETA: 4s - loss: 0.2651 - accuracy: 0.9014\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2609 - accuracy: 0.9049\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "651/750 [=========================>....] - ETA: 1s - loss: 0.2601 - accuracy: 0.9039\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.2601 - accuracy: 0.9050\n",
      "228/750 [========>.....................] - ETA: 5s - loss: 0.3283 - accuracy: 0.8830\n",
      "341/750 [============>.................] - ETA: 4s - loss: 0.2632 - accuracy: 0.9019\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "236/750 [========>.....................] - ETA: 5s - loss: 0.3274 - accuracy: 0.8829\n",
      "414/750 [===============>..............] - ETA: 3s - loss: 0.2612 - accuracy: 0.9028\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "204/750 [=======>......................] - ETA: 6s - loss: 0.3296 - accuracy: 0.8825\n",
      "355/750 [=============>................] - ETA: 4s - loss: 0.2620 - accuracy: 0.9020\n",
      "245/750 [========>.....................] - ETA: 5s - loss: 0.3274 - accuracy: 0.8832\n",
      "391/750 [==============>...............] - ETA: 3s - loss: 0.2604 - accuracy: 0.9029\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2604 - accuracy: 0.9041\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "323/750 [===========>..................] - ETA: 4s - loss: 0.3263 - accuracy: 0.8837\n",
      "426/750 [================>.............] - ETA: 3s - loss: 0.2607 - accuracy: 0.9027\n",
      "295/750 [==========>...................] - ETA: 4s - loss: 0.3288 - accuracy: 0.8826\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.2602 - accuracy: 0.9037\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "215/750 [=======>......................] - ETA: 6s - loss: 0.3298 - accuracy: 0.8824\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.3060 - accuracy: 0.8906\n",
      "367/750 [=============>................] - ETA: 4s - loss: 0.3266 - accuracy: 0.8833\n",
      "  7/750 [..............................] - ETA: 6s - loss: 0.2926 - accuracy: 0.8839\n",
      " 10/750 [..............................] - ETA: 9s - loss: 0.2865 - accuracy: 0.8797\n",
      "540/750 [====================>.........] - ETA: 2s - loss: 0.2585 - accuracy: 0.9045\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "383/750 [==============>...............] - ETA: 3s - loss: 0.3246 - accuracy: 0.8837\n",
      "395/750 [==============>...............] - ETA: 3s - loss: 0.3252 - accuracy: 0.8831\n",
      "495/750 [==================>...........] - ETA: 2s - loss: 0.2599 - accuracy: 0.9037\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 45/750 [>.............................] - ETA: 8s - loss: 0.2724 - accuracy: 0.8972\n",
      "425/750 [================>.............] - ETA: 3s - loss: 0.3255 - accuracy: 0.8831\n",
      "521/750 [===================>..........] - ETA: 2s - loss: 0.2587 - accuracy: 0.9044\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "451/750 [=================>............] - ETA: 3s - loss: 0.3253 - accuracy: 0.8829\n",
      " 84/750 [==>...........................] - ETA: 7s - loss: 0.2691 - accuracy: 0.8986\n",
      " 91/750 [==>...........................] - ETA: 7s - loss: 0.2672 - accuracy: 0.8999\n",
      "102/750 [===>..........................] - ETA: 7s - loss: 0.2658 - accuracy: 0.9023\n",
      "474/750 [=================>............] - ETA: 2s - loss: 0.3252 - accuracy: 0.8831\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2609 - accuracy: 0.9049 - val_loss: 0.3606 - val_accuracy: 0.8839\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 10/30\n",
      "126/750 [====>.........................] - ETA: 6s - loss: 0.2589 - accuracy: 0.9031\n",
      "435/750 [================>.............] - ETA: 3s - loss: 0.3252 - accuracy: 0.8830\n",
      " 20/750 [..............................] - ETA: 9s - loss: 0.2856 - accuracy: 0.8852 \n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2612 - accuracy: 0.9039 - val_loss: 0.3343 - val_accuracy: 0.8854\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 9/30\n",
      " 11/750 [..............................] - ETA: 4s - loss: 0.2334 - accuracy: 0.9162\n",
      "502/750 [===================>..........] - ETA: 2s - loss: 0.3248 - accuracy: 0.8837\n",
      "150/750 [=====>........................] - ETA: 6s - loss: 0.2597 - accuracy: 0.9024\n",
      "137/750 [====>.........................] - ETA: 6s - loss: 0.2620 - accuracy: 0.9023\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 41/750 [>.............................] - ETA: 8s - loss: 0.2736 - accuracy: 0.8960\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "519/750 [===================>..........] - ETA: 2s - loss: 0.3253 - accuracy: 0.8836\n",
      "167/750 [=====>........................] - ETA: 6s - loss: 0.2601 - accuracy: 0.9035\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "640/750 [========================>.....] - ETA: 1s - loss: 0.2599 - accuracy: 0.9038\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 69/750 [=>............................] - ETA: 8s - loss: 0.2708 - accuracy: 0.8988\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 56/750 [=>............................] - ETA: 7s - loss: 0.2560 - accuracy: 0.9043\n",
      "552/750 [=====================>........] - ETA: 2s - loss: 0.3256 - accuracy: 0.8839\n",
      "187/750 [======>.......................] - ETA: 6s - loss: 0.2614 - accuracy: 0.9034\n",
      "479/750 [==================>...........] - ETA: 2s - loss: 0.3254 - accuracy: 0.8832\n",
      "114/750 [===>..........................] - ETA: 7s - loss: 0.2595 - accuracy: 0.9041\n",
      " 78/750 [==>...........................] - ETA: 6s - loss: 0.2496 - accuracy: 0.9067\n",
      "572/750 [=====================>........] - ETA: 1s - loss: 0.3260 - accuracy: 0.8839\n",
      "203/750 [=======>......................] - ETA: 6s - loss: 0.2587 - accuracy: 0.9044\n",
      "195/750 [======>.......................] - ETA: 6s - loss: 0.2596 - accuracy: 0.9038\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "671/750 [=========================>....] - ETA: 0s - loss: 0.2594 - accuracy: 0.9041\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "565/750 [=====================>........] - ETA: 1s - loss: 0.3263 - accuracy: 0.8835\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 84/750 [==>...........................] - ETA: 7s - loss: 0.2516 - accuracy: 0.9053\n",
      "579/750 [======================>.......] - ETA: 1s - loss: 0.3260 - accuracy: 0.8840\n",
      "213/750 [=======>......................] - ETA: 6s - loss: 0.2608 - accuracy: 0.9035\n",
      "269/750 [=========>....................] - ETA: 5s - loss: 0.3281 - accuracy: 0.8826\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "218/750 [=======>......................] - ETA: 5s - loss: 0.2606 - accuracy: 0.9036\n",
      "318/750 [===========>..................] - ETA: 4s - loss: 0.3272 - accuracy: 0.8835\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "589/750 [======================>.......] - ETA: 1s - loss: 0.3268 - accuracy: 0.8836\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 99/750 [==>...........................] - ETA: 7s - loss: 0.2488 - accuracy: 0.9070\n",
      "102/750 [===>..........................] - ETA: 7s - loss: 0.2508 - accuracy: 0.9067\n",
      "220/750 [=======>......................] - ETA: 6s - loss: 0.2607 - accuracy: 0.9033\n",
      "103/750 [===>..........................] - ETA: 7s - loss: 0.2498 - accuracy: 0.9072\n",
      "696/750 [==========================>...] - ETA: 0s - loss: 0.2605 - accuracy: 0.9038\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "108/750 [===>..........................] - ETA: 8s - loss: 0.2490 - accuracy: 0.9074\n",
      "113/750 [===>..........................] - ETA: 8s - loss: 0.2505 - accuracy: 0.9072\n",
      "607/750 [=======================>......] - ETA: 1s - loss: 0.3277 - accuracy: 0.8834\n",
      "114/750 [===>..........................] - ETA: 8s - loss: 0.2513 - accuracy: 0.9071\n",
      "610/750 [=======================>......] - ETA: 1s - loss: 0.3277 - accuracy: 0.8834\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2609 - accuracy: 0.9039\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "115/750 [===>..........................] - ETA: 9s - loss: 0.2509 - accuracy: 0.9073\n",
      "611/750 [=======================>......] - ETA: 1s - loss: 0.3277 - accuracy: 0.8834\n",
      "613/750 [=======================>......] - ETA: 1s - loss: 0.3272 - accuracy: 0.8836\n",
      "240/750 [========>.....................] - ETA: 6s - loss: 0.2593 - accuracy: 0.9042\n",
      "600/750 [=======================>......] - ETA: 1s - loss: 0.3285 - accuracy: 0.8832\n",
      "118/750 [===>..........................] - ETA: 10s - loss: 0.2493 - accuracy: 0.9080\n",
      "359/750 [=============>................] - ETA: 4s - loss: 0.3269 - accuracy: 0.8833\n",
      "123/750 [===>..........................] - ETA: 10s - loss: 0.2490 - accuracy: 0.9076\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2608 - accuracy: 0.9040\n",
      "124/750 [===>..........................] - ETA: 10s - loss: 0.2486 - accuracy: 0.9079\n",
      "250/750 [=========>....................] - ETA: 7s - loss: 0.2582 - accuracy: 0.9044\n",
      "128/750 [====>.........................] - ETA: 10s - loss: 0.2476 - accuracy: 0.9082\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.3273 - accuracy: 0.8836\n",
      "256/750 [=========>....................] - ETA: 7s - loss: 0.2583 - accuracy: 0.9046\n",
      "136/750 [====>.........................] - ETA: 10s - loss: 0.2479 - accuracy: 0.9074\n",
      "348/750 [============>.................] - ETA: 4s - loss: 0.3275 - accuracy: 0.8831\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "245/750 [========>.....................] - ETA: 6s - loss: 0.2588 - accuracy: 0.9043\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "415/750 [===============>..............] - ETA: 3s - loss: 0.3258 - accuracy: 0.8832\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.3272 - accuracy: 0.8836\n",
      "260/750 [=========>....................] - ETA: 7s - loss: 0.2573 - accuracy: 0.9050\n",
      "137/750 [====>.........................] - ETA: 13s - loss: 0.2484 - accuracy: 0.9068\n",
      "141/750 [====>.........................] - ETA: 13s - loss: 0.2476 - accuracy: 0.9074\n",
      "636/750 [========================>.....] - ETA: 1s - loss: 0.3268 - accuracy: 0.8838\n",
      "151/750 [=====>........................] - ETA: 13s - loss: 0.2483 - accuracy: 0.9072\n",
      "650/750 [=========================>....] - ETA: 1s - loss: 0.3267 - accuracy: 0.8838\n",
      "279/750 [==========>...................] - ETA: 7s - loss: 0.2604 - accuracy: 0.9037\n",
      "158/750 [=====>........................] - ETA: 12s - loss: 0.2485 - accuracy: 0.9069\n",
      "657/750 [=========================>....] - ETA: 1s - loss: 0.3267 - accuracy: 0.8838\n",
      "284/750 [==========>...................] - ETA: 7s - loss: 0.2609 - accuracy: 0.9034\n",
      "164/750 [=====>........................] - ETA: 12s - loss: 0.2479 - accuracy: 0.9069\n",
      "289/750 [==========>...................] - ETA: 7s - loss: 0.2606 - accuracy: 0.9037\n",
      "623/750 [=======================>......] - ETA: 1s - loss: 0.3270 - accuracy: 0.8837\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "663/750 [=========================>....] - ETA: 1s - loss: 0.3267 - accuracy: 0.8837\n",
      "295/750 [==========>...................] - ETA: 7s - loss: 0.2602 - accuracy: 0.9035\n",
      " 23/750 [..............................] - ETA: 7s - loss: 0.2486 - accuracy: 0.9069\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "171/750 [=====>........................] - ETA: 12s - loss: 0.2457 - accuracy: 0.9081\n",
      "300/750 [===========>..................] - ETA: 7s - loss: 0.2602 - accuracy: 0.9032\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.3256 - accuracy: 0.8838\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "179/750 [======>.......................] - ETA: 12s - loss: 0.2482 - accuracy: 0.9072\n",
      "670/750 [=========================>....] - ETA: 1s - loss: 0.3267 - accuracy: 0.8838\n",
      "673/750 [=========================>....] - ETA: 1s - loss: 0.3271 - accuracy: 0.8839\n",
      "182/750 [======>.......................] - ETA: 12s - loss: 0.2478 - accuracy: 0.9076\n",
      "675/750 [==========================>...] - ETA: 1s - loss: 0.3273 - accuracy: 0.8839\n",
      "488/750 [==================>...........] - ETA: 2s - loss: 0.3248 - accuracy: 0.8833\n",
      "189/750 [======>.......................] - ETA: 12s - loss: 0.2495 - accuracy: 0.9070\n",
      "684/750 [==========================>...] - ETA: 0s - loss: 0.3282 - accuracy: 0.8838\n",
      "195/750 [======>.......................] - ETA: 11s - loss: 0.2488 - accuracy: 0.9073\n",
      "329/750 [============>.................] - ETA: 7s - loss: 0.2599 - accuracy: 0.9034\n",
      " 36/750 [>.............................] - ETA: 6s - loss: 0.2549 - accuracy: 0.9062\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "203/750 [=======>......................] - ETA: 11s - loss: 0.2511 - accuracy: 0.9065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:03:50,659 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6038679552; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/750 [===================>..........] - ETA: 2s - loss: 0.3249 - accuracy: 0.8837\n",
      "216/750 [=======>......................] - ETA: 10s - loss: 0.2496 - accuracy: 0.9070\n",
      "336/750 [============>.................] - ETA: 7s - loss: 0.2590 - accuracy: 0.9038\n",
      "222/750 [=======>......................] - ETA: 10s - loss: 0.2496 - accuracy: 0.9067\n",
      "342/750 [============>.................] - ETA: 7s - loss: 0.2588 - accuracy: 0.9038\n",
      "347/750 [============>.................] - ETA: 6s - loss: 0.2579 - accuracy: 0.9042\n",
      " 92/750 [==>...........................] - ETA: 7s - loss: 0.2505 - accuracy: 0.9064\n",
      "227/750 [========>.....................] - ETA: 10s - loss: 0.2489 - accuracy: 0.9072\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.3289 - accuracy: 0.8833\n",
      "355/750 [=============>................] - ETA: 6s - loss: 0.2578 - accuracy: 0.9042\n",
      "235/750 [========>.....................] - ETA: 10s - loss: 0.2501 - accuracy: 0.9071\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.8830\n",
      "363/750 [=============>................] - ETA: 6s - loss: 0.2573 - accuracy: 0.9044\n",
      "244/750 [========>.....................] - ETA: 10s - loss: 0.2508 - accuracy: 0.9071\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.3293 - accuracy: 0.8831\n",
      "371/750 [=============>................] - ETA: 6s - loss: 0.2572 - accuracy: 0.9044\n",
      "373/750 [=============>................] - ETA: 6s - loss: 0.2574 - accuracy: 0.9044\n",
      "248/750 [========>.....................] - ETA: 10s - loss: 0.2513 - accuracy: 0.9072\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.3292 - accuracy: 0.8831\n",
      "374/750 [=============>................] - ETA: 6s - loss: 0.2571 - accuracy: 0.9045\n",
      "255/750 [=========>....................] - ETA: 9s - loss: 0.2519 - accuracy: 0.9071 \n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.3290 - accuracy: 0.8831\n",
      "381/750 [==============>...............] - ETA: 6s - loss: 0.2571 - accuracy: 0.9043\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.3292 - accuracy: 0.8829\n",
      "389/750 [==============>...............] - ETA: 6s - loss: 0.2575 - accuracy: 0.9042\n",
      "397/750 [==============>...............] - ETA: 5s - loss: 0.2585 - accuracy: 0.9039\n",
      " 45/750 [>.............................] - ETA: 7s - loss: 0.2554 - accuracy: 0.9045\n",
      "430/750 [================>.............] - ETA: 5s - loss: 0.2571 - accuracy: 0.9040\n",
      " 68/750 [=>............................] - ETA: 6s - loss: 0.2510 - accuracy: 0.9058\n",
      "435/750 [================>.............] - ETA: 5s - loss: 0.2571 - accuracy: 0.9041\n",
      "443/750 [================>.............] - ETA: 5s - loss: 0.2581 - accuracy: 0.9036\n",
      "447/750 [================>.............] - ETA: 4s - loss: 0.2570 - accuracy: 0.9040\n",
      "457/750 [=================>............] - ETA: 4s - loss: 0.2562 - accuracy: 0.9046\n",
      "667/750 [=========================>....] - ETA: 1s - loss: 0.3263 - accuracy: 0.8839\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "469/750 [=================>............] - ETA: 4s - loss: 0.2567 - accuracy: 0.9046\n",
      "265/750 [=========>....................] - ETA: 9s - loss: 0.2518 - accuracy: 0.9068\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "474/750 [=================>............] - ETA: 4s - loss: 0.2565 - accuracy: 0.9048\n",
      "322/750 [===========>..................] - ETA: 7s - loss: 0.2511 - accuracy: 0.9069\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "593/750 [======================>.......] - ETA: 1s - loss: 0.3278 - accuracy: 0.8834\n",
      "478/750 [==================>...........] - ETA: 4s - loss: 0.2559 - accuracy: 0.9050\n",
      "488/750 [==================>...........] - ETA: 4s - loss: 0.2551 - accuracy: 0.9051\n",
      "492/750 [==================>...........] - ETA: 4s - loss: 0.2555 - accuracy: 0.9051\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.3282 - accuracy: 0.8838\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "376/750 [==============>...............] - ETA: 6s - loss: 0.2520 - accuracy: 0.9064\n",
      "502/750 [===================>..........] - ETA: 3s - loss: 0.2552 - accuracy: 0.9052\n",
      "511/750 [===================>..........] - ETA: 3s - loss: 0.2547 - accuracy: 0.9054\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.3288 - accuracy: 0.8834\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "520/750 [===================>..........] - ETA: 3s - loss: 0.2548 - accuracy: 0.9053\n",
      "402/750 [===============>..............] - ETA: 5s - loss: 0.2520 - accuracy: 0.9066\n",
      "533/750 [====================>.........] - ETA: 3s - loss: 0.2551 - accuracy: 0.9053\n",
      "413/750 [===============>..............] - ETA: 5s - loss: 0.2516 - accuracy: 0.9067\n",
      "416/750 [===============>..............] - ETA: 5s - loss: 0.2514 - accuracy: 0.9067\n",
      "554/750 [=====================>........] - ETA: 3s - loss: 0.2566 - accuracy: 0.9049\n",
      "270/750 [=========>....................] - ETA: 9s - loss: 0.2518 - accuracy: 0.9065\n",
      "560/750 [=====================>........] - ETA: 2s - loss: 0.2559 - accuracy: 0.9052\n",
      "563/750 [=====================>........] - ETA: 2s - loss: 0.2559 - accuracy: 0.9052\n",
      "565/750 [=====================>........] - ETA: 2s - loss: 0.2561 - accuracy: 0.9051\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.3297 - accuracy: 0.8828 - val_loss: 0.3453 - val_accuracy: 0.8777\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 10/30\n",
      "  7/750 [..............................] - ETA: 10s - loss: 0.3462 - accuracy: 0.8728\n",
      "574/750 [=====================>........] - ETA: 2s - loss: 0.2560 - accuracy: 0.9051\n",
      "  8/750 [..............................] - ETA: 22s - loss: 0.3420 - accuracy: 0.8789\n",
      "580/750 [======================>.......] - ETA: 2s - loss: 0.2556 - accuracy: 0.9052\n",
      "  9/750 [..............................] - ETA: 26s - loss: 0.3348 - accuracy: 0.8819\n",
      " 15/750 [..............................] - ETA: 17s - loss: 0.3212 - accuracy: 0.8854\n",
      "586/750 [======================>.......] - ETA: 2s - loss: 0.2553 - accuracy: 0.9055\n",
      " 20/750 [..............................] - ETA: 15s - loss: 0.3239 - accuracy: 0.8844\n",
      "604/750 [=======================>......] - ETA: 2s - loss: 0.2552 - accuracy: 0.9053\n",
      "344/750 [============>.................] - ETA: 7s - loss: 0.2519 - accuracy: 0.9064\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "410/750 [===============>..............] - ETA: 5s - loss: 0.2520 - accuracy: 0.9064\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 27/750 [>.............................] - ETA: 15s - loss: 0.3267 - accuracy: 0.8814\n",
      " 32/750 [>.............................] - ETA: 14s - loss: 0.3197 - accuracy: 0.8848\n",
      " 41/750 [>.............................] - ETA: 13s - loss: 0.3155 - accuracy: 0.8864\n",
      " 49/750 [>.............................] - ETA: 12s - loss: 0.3212 - accuracy: 0.8858\n",
      "632/750 [========================>.....] - ETA: 1s - loss: 0.2557 - accuracy: 0.9052\n",
      "505/750 [===================>..........] - ETA: 4s - loss: 0.2505 - accuracy: 0.9072\n",
      " 62/750 [=>............................] - ETA: 10s - loss: 0.3308 - accuracy: 0.8828\n",
      "640/750 [========================>.....] - ETA: 1s - loss: 0.2555 - accuracy: 0.9052\n",
      "290/750 [==========>...................] - ETA: 8s - loss: 0.2502 - accuracy: 0.9068\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "620/750 [=======================>......] - ETA: 2s - loss: 0.2551 - accuracy: 0.9054\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 74/750 [=>............................] - ETA: 10s - loss: 0.3274 - accuracy: 0.8849\n",
      "649/750 [========================>.....] - ETA: 1s - loss: 0.2551 - accuracy: 0.9053\n",
      " 75/750 [==>...........................] - ETA: 10s - loss: 0.3262 - accuracy: 0.8852\n",
      " 81/750 [==>...........................] - ETA: 10s - loss: 0.3291 - accuracy: 0.8846\n",
      "303/750 [===========>..................] - ETA: 8s - loss: 0.2506 - accuracy: 0.9068\n",
      "546/750 [====================>.........] - ETA: 3s - loss: 0.2566 - accuracy: 0.9049\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "530/750 [====================>.........] - ETA: 3s - loss: 0.2514 - accuracy: 0.9071\n",
      " 91/750 [==>...........................] - ETA: 10s - loss: 0.3269 - accuracy: 0.8860\n",
      "664/750 [=========================>....] - ETA: 1s - loss: 0.2549 - accuracy: 0.9055\n",
      "100/750 [===>..........................] - ETA: 9s - loss: 0.3286 - accuracy: 0.8848 \n",
      "665/750 [=========================>....] - ETA: 1s - loss: 0.2551 - accuracy: 0.9054\n",
      "676/750 [==========================>...] - ETA: 1s - loss: 0.2540 - accuracy: 0.9058\n",
      "107/750 [===>..........................] - ETA: 10s - loss: 0.3299 - accuracy: 0.8841\n",
      "329/750 [============>.................] - ETA: 7s - loss: 0.2506 - accuracy: 0.9072\n",
      "118/750 [===>..........................] - ETA: 9s - loss: 0.3339 - accuracy: 0.8832 \n",
      "122/750 [===>..........................] - ETA: 9s - loss: 0.3329 - accuracy: 0.8836\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.2538 - accuracy: 0.9061\n",
      "336/750 [============>.................] - ETA: 7s - loss: 0.2518 - accuracy: 0.9064\n",
      "576/750 [======================>.......] - ETA: 2s - loss: 0.2527 - accuracy: 0.9060\n",
      "131/750 [====>.........................] - ETA: 9s - loss: 0.3337 - accuracy: 0.8831\n",
      "143/750 [====>.........................] - ETA: 9s - loss: 0.3327 - accuracy: 0.8831\n",
      "365/750 [=============>................] - ETA: 6s - loss: 0.2524 - accuracy: 0.9060\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "152/750 [=====>........................] - ETA: 8s - loss: 0.3342 - accuracy: 0.8836\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2532 - accuracy: 0.9064\n",
      "602/750 [=======================>......] - ETA: 2s - loss: 0.2519 - accuracy: 0.9065\n",
      "158/750 [=====>........................] - ETA: 8s - loss: 0.3325 - accuracy: 0.8845\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2535 - accuracy: 0.9063\n",
      "170/750 [=====>........................] - ETA: 8s - loss: 0.3295 - accuracy: 0.8848\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2536 - accuracy: 0.9063\n",
      "627/750 [========================>.....] - ETA: 2s - loss: 0.2517 - accuracy: 0.9065\n",
      "393/750 [==============>...............] - ETA: 6s - loss: 0.2525 - accuracy: 0.9064\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "380/750 [==============>...............] - ETA: 6s - loss: 0.2520 - accuracy: 0.9065\n",
      "177/750 [======>.......................] - ETA: 8s - loss: 0.3289 - accuracy: 0.8844\n",
      "186/750 [======>.......................] - ETA: 8s - loss: 0.3290 - accuracy: 0.8846\n",
      "195/750 [======>.......................] - ETA: 8s - loss: 0.3289 - accuracy: 0.8851\n",
      "651/750 [=========================>....] - ETA: 1s - loss: 0.2520 - accuracy: 0.9068\n",
      "206/750 [=======>......................] - ETA: 7s - loss: 0.3277 - accuracy: 0.8850\n",
      "425/750 [================>.............] - ETA: 5s - loss: 0.2509 - accuracy: 0.9068\n",
      "217/750 [=======>......................] - ETA: 7s - loss: 0.3273 - accuracy: 0.8845\n",
      "225/750 [========>.....................] - ETA: 7s - loss: 0.3275 - accuracy: 0.8840\n",
      "431/750 [================>.............] - ETA: 5s - loss: 0.2510 - accuracy: 0.9066\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "236/750 [========>.....................] - ETA: 7s - loss: 0.3272 - accuracy: 0.8837\n",
      "449/750 [================>.............] - ETA: 5s - loss: 0.2505 - accuracy: 0.9071\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "246/750 [========>.....................] - ETA: 7s - loss: 0.3273 - accuracy: 0.8834\n",
      "469/750 [=================>............] - ETA: 4s - loss: 0.2511 - accuracy: 0.9071\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "667/750 [=========================>....] - ETA: 1s - loss: 0.2512 - accuracy: 0.9069\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "256/750 [=========>....................] - ETA: 6s - loss: 0.3267 - accuracy: 0.8831\n",
      "262/750 [=========>....................] - ETA: 6s - loss: 0.3261 - accuracy: 0.8831\n",
      "473/750 [=================>............] - ETA: 4s - loss: 0.2510 - accuracy: 0.9069\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "270/750 [=========>....................] - ETA: 6s - loss: 0.3259 - accuracy: 0.8832\n",
      "499/750 [==================>...........] - ETA: 4s - loss: 0.2507 - accuracy: 0.9069\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "694/750 [==========================>...] - ETA: 0s - loss: 0.2517 - accuracy: 0.9069\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "304/750 [===========>..................] - ETA: 6s - loss: 0.3241 - accuracy: 0.8837\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2506 - accuracy: 0.9072\n",
      "518/750 [===================>..........] - ETA: 3s - loss: 0.2512 - accuracy: 0.9072\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2510 - accuracy: 0.9070\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "317/750 [===========>..................] - ETA: 5s - loss: 0.3247 - accuracy: 0.8837\n",
      "324/750 [===========>..................] - ETA: 5s - loss: 0.3246 - accuracy: 0.8838\n",
      "542/750 [====================>.........] - ETA: 3s - loss: 0.2514 - accuracy: 0.9070\n",
      "  1/750 [..............................] - ETA: 5s - loss: 0.3008 - accuracy: 0.8906\n",
      "351/750 [=============>................] - ETA: 5s - loss: 0.3247 - accuracy: 0.8844\n",
      "  6/750 [..............................] - ETA: 9s - loss: 0.2704 - accuracy: 0.8984\n",
      " 10/750 [..............................] - ETA: 10s - loss: 0.2675 - accuracy: 0.9047\n",
      " 26/750 [>.............................] - ETA: 8s - loss: 0.2406 - accuracy: 0.9093 \n",
      "750/750 [==============================] - 14s 18ms/step - loss: 0.2538 - accuracy: 0.9062 - val_loss: 0.3926 - val_accuracy: 0.8769\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 11/30\n",
      "381/750 [==============>...............] - ETA: 4s - loss: 0.3234 - accuracy: 0.8849\n",
      " 36/750 [>.............................] - ETA: 8s - loss: 0.2331 - accuracy: 0.9167\n",
      "568/750 [=====================>........] - ETA: 3s - loss: 0.2525 - accuracy: 0.9063\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 14/750 [..............................] - ETA: 10s - loss: 0.2519 - accuracy: 0.9062\n",
      " 42/750 [>.............................] - ETA: 9s - loss: 0.2302 - accuracy: 0.9182\n",
      "392/750 [==============>...............] - ETA: 4s - loss: 0.3242 - accuracy: 0.8848\n",
      " 51/750 [=>............................] - ETA: 9s - loss: 0.2234 - accuracy: 0.9203\n",
      "589/750 [======================>.......] - ETA: 2s - loss: 0.2519 - accuracy: 0.9064\n",
      "402/750 [===============>..............] - ETA: 4s - loss: 0.3231 - accuracy: 0.8850\n",
      " 60/750 [=>............................] - ETA: 8s - loss: 0.2244 - accuracy: 0.9203\n",
      "600/750 [=======================>......] - ETA: 2s - loss: 0.2520 - accuracy: 0.9064\n",
      "340/750 [============>.................] - ETA: 5s - loss: 0.3243 - accuracy: 0.8841\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "415/750 [===============>..............] - ETA: 4s - loss: 0.3216 - accuracy: 0.8858\n",
      " 72/750 [=>............................] - ETA: 8s - loss: 0.2229 - accuracy: 0.9212\n",
      "420/750 [===============>..............] - ETA: 4s - loss: 0.3221 - accuracy: 0.8856\n",
      " 79/750 [==>...........................] - ETA: 8s - loss: 0.2223 - accuracy: 0.9209\n",
      "426/750 [================>.............] - ETA: 4s - loss: 0.3228 - accuracy: 0.8855\n",
      " 92/750 [==>...........................] - ETA: 8s - loss: 0.2268 - accuracy: 0.9176\n",
      "105/750 [===>..........................] - ETA: 7s - loss: 0.2267 - accuracy: 0.9171\n",
      "641/750 [========================>.....] - ETA: 1s - loss: 0.2517 - accuracy: 0.9068\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "294/750 [==========>...................] - ETA: 6s - loss: 0.3243 - accuracy: 0.8837\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "613/750 [=======================>......] - ETA: 2s - loss: 0.2520 - accuracy: 0.9063\n",
      "128/750 [====>.........................] - ETA: 7s - loss: 0.2299 - accuracy: 0.9158\n",
      "549/750 [====================>.........] - ETA: 3s - loss: 0.2524 - accuracy: 0.9064\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "476/750 [==================>...........] - ETA: 3s - loss: 0.3217 - accuracy: 0.8861\n",
      "657/750 [=========================>....] - ETA: 1s - loss: 0.2518 - accuracy: 0.9069\n",
      "750/750 [==============================] - 14s 19ms/step - loss: 0.2506 - accuracy: 0.9072 - val_loss: 0.3255 - val_accuracy: 0.8879\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 10/30\n",
      "  5/750 [..............................] - ETA: 16s - loss: 0.2112 - accuracy: 0.9250\n",
      "676/750 [==========================>...] - ETA: 1s - loss: 0.2514 - accuracy: 0.9068\n",
      " 16/750 [..............................] - ETA: 10s - loss: 0.2439 - accuracy: 0.9199\n",
      "500/750 [===================>..........] - ETA: 3s - loss: 0.3225 - accuracy: 0.8861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:04:00,660 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6038175744; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/750 [===>..........................] - ETA: 7s - loss: 0.2270 - accuracy: 0.9173\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 18/750 [..............................] - ETA: 11s - loss: 0.2393 - accuracy: 0.9210\n",
      " 38/750 [>.............................] - ETA: 10s - loss: 0.2363 - accuracy: 0.9178\n",
      "520/750 [===================>..........] - ETA: 3s - loss: 0.3232 - accuracy: 0.8856\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.2514 - accuracy: 0.9070\n",
      "144/750 [====>.........................] - ETA: 7s - loss: 0.2295 - accuracy: 0.9159\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 49/750 [>.............................] - ETA: 9s - loss: 0.2385 - accuracy: 0.9145\n",
      "530/750 [====================>.........] - ETA: 2s - loss: 0.3223 - accuracy: 0.8858\n",
      "368/750 [=============>................] - ETA: 5s - loss: 0.3250 - accuracy: 0.8843\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "150/750 [=====>........................] - ETA: 7s - loss: 0.2324 - accuracy: 0.9148\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2508 - accuracy: 0.9071\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 74/750 [=>............................] - ETA: 8s - loss: 0.2386 - accuracy: 0.9139\n",
      "174/750 [=====>........................] - ETA: 7s - loss: 0.2332 - accuracy: 0.9147\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "219/750 [=======>......................] - ETA: 7s - loss: 0.2406 - accuracy: 0.9128\n",
      "389/750 [==============>...............] - ETA: 4s - loss: 0.3243 - accuracy: 0.8849\n",
      "198/750 [======>.......................] - ETA: 7s - loss: 0.2367 - accuracy: 0.9135\n",
      "569/750 [=====================>........] - ETA: 2s - loss: 0.3223 - accuracy: 0.8860\n",
      "193/750 [======>.......................] - ETA: 7s - loss: 0.2366 - accuracy: 0.9139\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.3226 - accuracy: 0.8859\n",
      "588/750 [======================>.......] - ETA: 2s - loss: 0.3224 - accuracy: 0.8858\n",
      "217/750 [=======>......................] - ETA: 6s - loss: 0.2404 - accuracy: 0.9127\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "119/750 [===>..........................] - ETA: 8s - loss: 0.2373 - accuracy: 0.9143\n",
      "593/750 [======================>.......] - ETA: 2s - loss: 0.3223 - accuracy: 0.8859\n",
      "122/750 [===>..........................] - ETA: 8s - loss: 0.2362 - accuracy: 0.9150\n",
      "602/750 [=======================>......] - ETA: 2s - loss: 0.3226 - accuracy: 0.8857\n",
      "608/750 [=======================>......] - ETA: 1s - loss: 0.3223 - accuracy: 0.8857\n",
      "449/750 [================>.............] - ETA: 4s - loss: 0.3228 - accuracy: 0.8857\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "238/750 [========>.....................] - ETA: 6s - loss: 0.2374 - accuracy: 0.9134\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "140/750 [====>.........................] - ETA: 8s - loss: 0.2358 - accuracy: 0.9145\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.3228 - accuracy: 0.8853\n",
      "144/750 [====>.........................] - ETA: 8s - loss: 0.2371 - accuracy: 0.9138\n",
      "281/750 [==========>...................] - ETA: 6s - loss: 0.2381 - accuracy: 0.9144\n",
      "444/750 [================>.............] - ETA: 4s - loss: 0.3231 - accuracy: 0.8855\n",
      "149/750 [====>.........................] - ETA: 7s - loss: 0.2394 - accuracy: 0.9136\n",
      "466/750 [=================>............] - ETA: 3s - loss: 0.3228 - accuracy: 0.8857\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "251/750 [=========>....................] - ETA: 6s - loss: 0.2377 - accuracy: 0.9144\n",
      "265/750 [=========>....................] - ETA: 6s - loss: 0.2381 - accuracy: 0.9146\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "305/750 [===========>..................] - ETA: 5s - loss: 0.2398 - accuracy: 0.9134\n",
      "271/750 [=========>....................] - ETA: 6s - loss: 0.2388 - accuracy: 0.9144\n",
      "173/750 [=====>........................] - ETA: 7s - loss: 0.2393 - accuracy: 0.9135\n",
      "657/750 [=========================>....] - ETA: 1s - loss: 0.3215 - accuracy: 0.8859\n",
      "174/750 [=====>........................] - ETA: 7s - loss: 0.2395 - accuracy: 0.9133\n",
      "659/750 [=========================>....] - ETA: 1s - loss: 0.3217 - accuracy: 0.8858\n",
      "317/750 [===========>..................] - ETA: 5s - loss: 0.2397 - accuracy: 0.9135\n",
      "490/750 [==================>...........] - ETA: 3s - loss: 0.3225 - accuracy: 0.8861\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "178/750 [======>.......................] - ETA: 7s - loss: 0.2387 - accuracy: 0.9133\n",
      "663/750 [=========================>....] - ETA: 1s - loss: 0.3214 - accuracy: 0.8859\n",
      "667/750 [=========================>....] - ETA: 1s - loss: 0.3214 - accuracy: 0.8859\n",
      "319/750 [===========>..................] - ETA: 5s - loss: 0.2403 - accuracy: 0.9132\n",
      "670/750 [=========================>....] - ETA: 1s - loss: 0.3214 - accuracy: 0.8860\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.3208 - accuracy: 0.8862\n",
      "206/750 [=======>......................] - ETA: 7s - loss: 0.2401 - accuracy: 0.9132\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.3207 - accuracy: 0.8865\n",
      "515/750 [===================>..........] - ETA: 3s - loss: 0.3228 - accuracy: 0.8859\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.3208 - accuracy: 0.8864\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.3210 - accuracy: 0.8863\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.3211 - accuracy: 0.8863\n",
      "239/750 [========>.....................] - ETA: 6s - loss: 0.2421 - accuracy: 0.9118\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.3208 - accuracy: 0.8863\n",
      "390/750 [==============>...............] - ETA: 4s - loss: 0.2420 - accuracy: 0.9112\n",
      "398/750 [==============>...............] - ETA: 4s - loss: 0.2422 - accuracy: 0.9113\n",
      "261/750 [=========>....................] - ETA: 6s - loss: 0.2427 - accuracy: 0.9109\n",
      "267/750 [=========>....................] - ETA: 6s - loss: 0.2421 - accuracy: 0.9112\n",
      "272/750 [=========>....................] - ETA: 6s - loss: 0.2412 - accuracy: 0.9112\n",
      "278/750 [==========>...................] - ETA: 6s - loss: 0.2408 - accuracy: 0.9113\n",
      " 30/750 [>.............................] - ETA: 10s - loss: 0.2353 - accuracy: 0.9208\n",
      "283/750 [==========>...................] - ETA: 6s - loss: 0.2398 - accuracy: 0.9116\n",
      "291/750 [==========>...................] - ETA: 5s - loss: 0.2420 - accuracy: 0.9110\n",
      "436/750 [================>.............] - ETA: 3s - loss: 0.2423 - accuracy: 0.9112\n",
      "564/750 [=====================>........] - ETA: 2s - loss: 0.3223 - accuracy: 0.8860\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "301/750 [===========>..................] - ETA: 5s - loss: 0.2420 - accuracy: 0.9112\n",
      "447/750 [================>.............] - ETA: 3s - loss: 0.2428 - accuracy: 0.9111\n",
      "378/750 [==============>...............] - ETA: 4s - loss: 0.2420 - accuracy: 0.9115\n",
      " 66/750 [=>............................] - ETA: 9s - loss: 0.2404 - accuracy: 0.9126\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "349/750 [============>.................] - ETA: 5s - loss: 0.2431 - accuracy: 0.9119\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "411/750 [===============>..............] - ETA: 4s - loss: 0.2431 - accuracy: 0.9111\n",
      "419/750 [===============>..............] - ETA: 4s - loss: 0.2420 - accuracy: 0.9112\n",
      " 99/750 [==>...........................] - ETA: 8s - loss: 0.2374 - accuracy: 0.9140\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "426/750 [================>.............] - ETA: 4s - loss: 0.2420 - accuracy: 0.9115\n",
      "649/750 [========================>.....] - ETA: 1s - loss: 0.3220 - accuracy: 0.8858\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "363/750 [=============>................] - ETA: 4s - loss: 0.2400 - accuracy: 0.9115\n",
      "298/750 [==========>...................] - ETA: 5s - loss: 0.2400 - accuracy: 0.9132\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "533/750 [====================>.........] - ETA: 2s - loss: 0.2460 - accuracy: 0.9101\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "478/750 [==================>...........] - ETA: 3s - loss: 0.2446 - accuracy: 0.9104\n",
      "401/750 [===============>..............] - ETA: 4s - loss: 0.2390 - accuracy: 0.9121\n",
      "548/750 [====================>.........] - ETA: 2s - loss: 0.2459 - accuracy: 0.9099\n",
      "403/750 [===============>..............] - ETA: 4s - loss: 0.2390 - accuracy: 0.9122\n",
      "407/750 [===============>..............] - ETA: 4s - loss: 0.2385 - accuracy: 0.9124\n",
      "415/750 [===============>..............] - ETA: 4s - loss: 0.2387 - accuracy: 0.9123\n",
      "111/750 [===>..........................] - ETA: 8s - loss: 0.2372 - accuracy: 0.9141\n",
      "431/750 [================>.............] - ETA: 4s - loss: 0.2400 - accuracy: 0.9118\n",
      "510/750 [===================>..........] - ETA: 3s - loss: 0.2448 - accuracy: 0.9099\n",
      "134/750 [====>.........................] - ETA: 8s - loss: 0.2358 - accuracy: 0.9150\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.3206 - accuracy: 0.8861 - val_loss: 0.3431 - val_accuracy: 0.8802\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 11/30\n",
      "  3/750 [..............................] - ETA: 20s - loss: 0.2581 - accuracy: 0.9115\n",
      "372/750 [=============>................] - ETA: 4s - loss: 0.2391 - accuracy: 0.9118\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 10/750 [..............................] - ETA: 13s - loss: 0.2845 - accuracy: 0.9031\n",
      " 12/750 [..............................] - ETA: 17s - loss: 0.2788 - accuracy: 0.9062\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.3208 - accuracy: 0.8861\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "168/750 [=====>........................] - ETA: 7s - loss: 0.2380 - accuracy: 0.9135\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "470/750 [=================>............] - ETA: 3s - loss: 0.2396 - accuracy: 0.9117\n",
      " 21/750 [..............................] - ETA: 13s - loss: 0.3051 - accuracy: 0.8839\n",
      "475/750 [==================>...........] - ETA: 3s - loss: 0.2393 - accuracy: 0.9117\n",
      " 27/750 [>.............................] - ETA: 11s - loss: 0.2945 - accuracy: 0.8877\n",
      " 32/750 [>.............................] - ETA: 10s - loss: 0.2940 - accuracy: 0.8887\n",
      "222/750 [=======>......................] - ETA: 6s - loss: 0.2402 - accuracy: 0.9131\n",
      "559/750 [=====================>........] - ETA: 2s - loss: 0.2460 - accuracy: 0.9099\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "193/750 [======>.......................] - ETA: 7s - loss: 0.2413 - accuracy: 0.9120\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.2452 - accuracy: 0.9101\n",
      " 43/750 [>.............................] - ETA: 11s - loss: 0.2974 - accuracy: 0.8906\n",
      "635/750 [========================>.....] - ETA: 1s - loss: 0.2452 - accuracy: 0.9102\n",
      "494/750 [==================>...........] - ETA: 3s - loss: 0.2407 - accuracy: 0.9112\n",
      "641/750 [========================>.....] - ETA: 1s - loss: 0.2455 - accuracy: 0.9100\n",
      "597/750 [======================>.......] - ETA: 1s - loss: 0.2459 - accuracy: 0.9098\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 55/750 [=>............................] - ETA: 9s - loss: 0.2973 - accuracy: 0.8923 \n",
      "645/750 [========================>.....] - ETA: 1s - loss: 0.2450 - accuracy: 0.9102\n",
      "217/750 [=======>......................] - ETA: 7s - loss: 0.2400 - accuracy: 0.9132\n",
      "664/750 [=========================>....] - ETA: 1s - loss: 0.2447 - accuracy: 0.9102\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.2455 - accuracy: 0.9099\n",
      " 76/750 [==>...........................] - ETA: 8s - loss: 0.2982 - accuracy: 0.8945\n",
      "673/750 [=========================>....] - ETA: 0s - loss: 0.2444 - accuracy: 0.9104\n",
      "624/750 [=======================>......] - ETA: 1s - loss: 0.2463 - accuracy: 0.9099\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "435/750 [================>.............] - ETA: 3s - loss: 0.2409 - accuracy: 0.9116\n",
      "244/750 [========>.....................] - ETA: 6s - loss: 0.2420 - accuracy: 0.9123\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "100/750 [===>..........................] - ETA: 8s - loss: 0.3050 - accuracy: 0.8931\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.2456 - accuracy: 0.9099\n",
      "466/750 [=================>............] - ETA: 3s - loss: 0.2404 - accuracy: 0.9114\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "108/750 [===>..........................] - ETA: 8s - loss: 0.3034 - accuracy: 0.8928\n",
      "115/750 [===>..........................] - ETA: 8s - loss: 0.3072 - accuracy: 0.8908\n",
      "319/750 [===========>..................] - ETA: 5s - loss: 0.2410 - accuracy: 0.9114\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.2443 - accuracy: 0.9103\n",
      "121/750 [===>..........................] - ETA: 8s - loss: 0.3062 - accuracy: 0.8911\n",
      "490/750 [==================>...........] - ETA: 3s - loss: 0.2407 - accuracy: 0.9109\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "132/750 [====>.........................] - ETA: 8s - loss: 0.3083 - accuracy: 0.8904\n",
      "141/750 [====>.........................] - ETA: 8s - loss: 0.3112 - accuracy: 0.8896\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 0.2411 - accuracy: 0.9112\n",
      "610/750 [=======================>......] - ETA: 1s - loss: 0.2412 - accuracy: 0.9112\n",
      "152/750 [=====>........................] - ETA: 7s - loss: 0.3114 - accuracy: 0.8904\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2457 - accuracy: 0.9100\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.2458 - accuracy: 0.9100\n",
      "520/750 [===================>..........] - ETA: 2s - loss: 0.2401 - accuracy: 0.9112\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2460 - accuracy: 0.9098\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2453 - accuracy: 0.9100\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "389/750 [==============>...............] - ETA: 4s - loss: 0.2388 - accuracy: 0.9123\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "203/750 [=======>......................] - ETA: 6s - loss: 0.3143 - accuracy: 0.8895\n",
      "215/750 [=======>......................] - ETA: 6s - loss: 0.3161 - accuracy: 0.8888\n",
      "685/750 [==========================>...] - ETA: 0s - loss: 0.2421 - accuracy: 0.9107\n",
      "223/750 [=======>......................] - ETA: 6s - loss: 0.3162 - accuracy: 0.8889\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.2425 - accuracy: 0.9106\n",
      "699/750 [==========================>...] - ETA: 0s - loss: 0.2426 - accuracy: 0.9105\n",
      "255/750 [=========>....................] - ETA: 6s - loss: 0.3200 - accuracy: 0.8871\n",
      "444/750 [================>.............] - ETA: 3s - loss: 0.2405 - accuracy: 0.9118\n",
      "561/750 [=====================>........] - ETA: 2s - loss: 0.2407 - accuracy: 0.9110\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "257/750 [=========>....................] - ETA: 6s - loss: 0.3204 - accuracy: 0.8869\n",
      "267/750 [=========>....................] - ETA: 6s - loss: 0.3202 - accuracy: 0.8866\n",
      "273/750 [=========>....................] - ETA: 6s - loss: 0.3187 - accuracy: 0.8872\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2413 - accuracy: 0.9111\n",
      " 66/750 [=>............................] - ETA: 9s - loss: 0.3014 - accuracy: 0.8918\n",
      "349/750 [============>.................] - ETA: 5s - loss: 0.2403 - accuracy: 0.9118\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "289/750 [==========>...................] - ETA: 5s - loss: 0.3172 - accuracy: 0.8882\n",
      "292/750 [==========>...................] - ETA: 5s - loss: 0.3175 - accuracy: 0.8877\n",
      " 97/750 [==>...........................] - ETA: 8s - loss: 0.3030 - accuracy: 0.8935\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "297/750 [==========>...................] - ETA: 5s - loss: 0.3171 - accuracy: 0.8878\n",
      "303/750 [===========>..................] - ETA: 5s - loss: 0.3170 - accuracy: 0.8877\n",
      "632/750 [========================>.....] - ETA: 1s - loss: 0.2418 - accuracy: 0.9110\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "307/750 [===========>..................] - ETA: 5s - loss: 0.3161 - accuracy: 0.8881\n",
      "283/750 [==========>...................] - ETA: 5s - loss: 0.3172 - accuracy: 0.8882\n",
      "547/750 [====================>.........] - ETA: 2s - loss: 0.2393 - accuracy: 0.9115\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 30/750 [>.............................] - ETA: 9s - loss: 0.2049 - accuracy: 0.9193 \n",
      "335/750 [============>.................] - ETA: 5s - loss: 0.3168 - accuracy: 0.8877\n",
      " 36/750 [>.............................] - ETA: 10s - loss: 0.2167 - accuracy: 0.9167\n",
      "533/750 [====================>.........] - ETA: 2s - loss: 0.2399 - accuracy: 0.9113\n",
      "340/750 [============>.................] - ETA: 5s - loss: 0.3162 - accuracy: 0.8880\n",
      " 46/750 [>.............................] - ETA: 10s - loss: 0.2196 - accuracy: 0.9181\n",
      "355/750 [=============>................] - ETA: 5s - loss: 0.3170 - accuracy: 0.8880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:04:10,757 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6037803008; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65/750 [=>............................] - ETA: 9s - loss: 0.2299 - accuracy: 0.9156 \n",
      " 67/750 [=>............................] - ETA: 9s - loss: 0.2283 - accuracy: 0.9163\n",
      "380/750 [==============>...............] - ETA: 4s - loss: 0.3177 - accuracy: 0.8877\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.2457 - accuracy: 0.9100 - val_loss: 0.3480 - val_accuracy: 0.8863\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 12/30\n",
      "  5/750 [..............................] - ETA: 12s - loss: 0.1833 - accuracy: 0.9312\n",
      "368/750 [=============>................] - ETA: 5s - loss: 0.3170 - accuracy: 0.8878\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 16/750 [..............................] - ETA: 14s - loss: 0.2005 - accuracy: 0.9170\n",
      "406/750 [===============>..............] - ETA: 4s - loss: 0.3183 - accuracy: 0.8876\n",
      "  9/750 [..............................] - ETA: 10s - loss: 0.2024 - accuracy: 0.9167\n",
      "414/750 [===============>..............] - ETA: 4s - loss: 0.3179 - accuracy: 0.8878\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2412 - accuracy: 0.9111\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "172/750 [=====>........................] - ETA: 7s - loss: 0.3138 - accuracy: 0.8896\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 49/750 [>.............................] - ETA: 10s - loss: 0.2209 - accuracy: 0.9177\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "423/750 [===============>..............] - ETA: 4s - loss: 0.3173 - accuracy: 0.8879\n",
      "128/750 [====>.........................] - ETA: 8s - loss: 0.2348 - accuracy: 0.9137\n",
      "433/750 [================>.............] - ETA: 4s - loss: 0.3171 - accuracy: 0.8880\n",
      "570/750 [=====================>........] - ETA: 2s - loss: 0.2409 - accuracy: 0.9107\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "195/750 [======>.......................] - ETA: 6s - loss: 0.3118 - accuracy: 0.8903\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "646/750 [========================>.....] - ETA: 1s - loss: 0.2421 - accuracy: 0.9108\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "447/750 [================>.............] - ETA: 3s - loss: 0.3171 - accuracy: 0.8881\n",
      "597/750 [======================>.......] - ETA: 1s - loss: 0.2413 - accuracy: 0.9109\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 58/750 [=>............................] - ETA: 10s - loss: 0.2264 - accuracy: 0.9159\n",
      "451/750 [=================>............] - ETA: 3s - loss: 0.3174 - accuracy: 0.8880\n",
      "148/750 [====>.........................] - ETA: 8s - loss: 0.2329 - accuracy: 0.9141\n",
      "469/750 [=================>............] - ETA: 3s - loss: 0.3180 - accuracy: 0.8880\n",
      "161/750 [=====>........................] - ETA: 7s - loss: 0.2316 - accuracy: 0.9151\n",
      "671/750 [=========================>....] - ETA: 0s - loss: 0.2426 - accuracy: 0.9107\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 79/750 [==>...........................] - ETA: 9s - loss: 0.2276 - accuracy: 0.9167\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2410 - accuracy: 0.9111 - val_loss: 0.3484 - val_accuracy: 0.8848\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 11/30\n",
      " 12/750 [..............................] - ETA: 3s - loss: 0.2030 - accuracy: 0.9258\n",
      "166/750 [=====>........................] - ETA: 7s - loss: 0.2313 - accuracy: 0.9152\n",
      "619/750 [=======================>......] - ETA: 1s - loss: 0.2412 - accuracy: 0.9113\n",
      " 22/750 [..............................] - ETA: 6s - loss: 0.2100 - accuracy: 0.9226\n",
      "479/750 [==================>...........] - ETA: 3s - loss: 0.3184 - accuracy: 0.8880\n",
      "175/750 [======>.......................] - ETA: 7s - loss: 0.2298 - accuracy: 0.9160\n",
      "241/750 [========>.....................] - ETA: 6s - loss: 0.3209 - accuracy: 0.8873\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 25/750 [>.............................] - ETA: 8s - loss: 0.2087 - accuracy: 0.9206\n",
      "103/750 [===>..........................] - ETA: 8s - loss: 0.2286 - accuracy: 0.9167\n",
      "462/750 [=================>............] - ETA: 3s - loss: 0.3179 - accuracy: 0.8881\n",
      "114/750 [===>..........................] - ETA: 8s - loss: 0.2278 - accuracy: 0.9171\n",
      "199/750 [======>.......................] - ETA: 7s - loss: 0.2332 - accuracy: 0.9140\n",
      " 48/750 [>.............................] - ETA: 8s - loss: 0.2209 - accuracy: 0.9176\n",
      "510/750 [===================>..........] - ETA: 3s - loss: 0.3170 - accuracy: 0.8881\n",
      "321/750 [===========>..................] - ETA: 5s - loss: 0.3162 - accuracy: 0.8881\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 51/750 [=>............................] - ETA: 10s - loss: 0.2220 - accuracy: 0.9170\n",
      "497/750 [==================>...........] - ETA: 3s - loss: 0.3180 - accuracy: 0.8879\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "144/750 [====>.........................] - ETA: 8s - loss: 0.2328 - accuracy: 0.9141\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 61/750 [=>............................] - ETA: 9s - loss: 0.2267 - accuracy: 0.9152\n",
      "225/750 [========>.....................] - ETA: 7s - loss: 0.2318 - accuracy: 0.9154\n",
      " 71/750 [=>............................] - ETA: 9s - loss: 0.2293 - accuracy: 0.9131\n",
      "228/750 [========>.....................] - ETA: 7s - loss: 0.2316 - accuracy: 0.9154\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2410 - accuracy: 0.9111\n",
      "553/750 [=====================>........] - ETA: 2s - loss: 0.3159 - accuracy: 0.8887\n",
      "523/750 [===================>..........] - ETA: 2s - loss: 0.3170 - accuracy: 0.8882\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2421 - accuracy: 0.9108\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "105/750 [===>..........................] - ETA: 8s - loss: 0.2319 - accuracy: 0.9128\n",
      "114/750 [===>..........................] - ETA: 8s - loss: 0.2330 - accuracy: 0.9124\n",
      "577/750 [======================>.......] - ETA: 2s - loss: 0.3146 - accuracy: 0.8893\n",
      "397/750 [==============>...............] - ETA: 4s - loss: 0.3193 - accuracy: 0.8874\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "215/750 [=======>......................] - ETA: 7s - loss: 0.2328 - accuracy: 0.9148\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "119/750 [===>..........................] - ETA: 8s - loss: 0.2353 - accuracy: 0.9114\n",
      "582/750 [======================>.......] - ETA: 2s - loss: 0.3150 - accuracy: 0.8893\n",
      "278/750 [==========>...................] - ETA: 6s - loss: 0.2311 - accuracy: 0.9149\n",
      "290/750 [==========>...................] - ETA: 6s - loss: 0.2317 - accuracy: 0.9146\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 0.3143 - accuracy: 0.8897\n",
      "295/750 [==========>...................] - ETA: 6s - loss: 0.2322 - accuracy: 0.9142\n",
      "609/750 [=======================>......] - ETA: 1s - loss: 0.3141 - accuracy: 0.8897\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.3140 - accuracy: 0.8896\n",
      "327/750 [============>.................] - ETA: 5s - loss: 0.2368 - accuracy: 0.9135\n",
      "562/750 [=====================>........] - ETA: 2s - loss: 0.3154 - accuracy: 0.8889\n",
      "271/750 [=========>....................] - ETA: 6s - loss: 0.2326 - accuracy: 0.9147\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "264/750 [=========>....................] - ETA: 6s - loss: 0.2328 - accuracy: 0.9148\n",
      "342/750 [============>.................] - ETA: 5s - loss: 0.2367 - accuracy: 0.9136\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "661/750 [=========================>....] - ETA: 1s - loss: 0.3138 - accuracy: 0.8898\n",
      "355/750 [=============>................] - ETA: 5s - loss: 0.2368 - accuracy: 0.9138\n",
      "358/750 [=============>................] - ETA: 5s - loss: 0.2368 - accuracy: 0.9135\n",
      " 99/750 [==>...........................] - ETA: 8s - loss: 0.2297 - accuracy: 0.9126\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "645/750 [========================>.....] - ETA: 1s - loss: 0.3135 - accuracy: 0.8897\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "210/750 [=======>......................] - ETA: 7s - loss: 0.2254 - accuracy: 0.9147\n",
      "681/750 [==========================>...] - ETA: 0s - loss: 0.3132 - accuracy: 0.8898\n",
      "683/750 [==========================>...] - ETA: 0s - loss: 0.3132 - accuracy: 0.8898\n",
      "373/750 [=============>................] - ETA: 5s - loss: 0.2373 - accuracy: 0.9132\n",
      "694/750 [==========================>...] - ETA: 0s - loss: 0.3128 - accuracy: 0.8898\n",
      "378/750 [==============>...............] - ETA: 5s - loss: 0.2376 - accuracy: 0.9128\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.3171 - accuracy: 0.8881\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.3128 - accuracy: 0.8897\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.3130 - accuracy: 0.8896\n",
      "400/750 [===============>..............] - ETA: 4s - loss: 0.2368 - accuracy: 0.9131\n",
      "348/750 [============>.................] - ETA: 5s - loss: 0.2365 - accuracy: 0.9138\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.3129 - accuracy: 0.8897\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.3125 - accuracy: 0.8899\n",
      " 38/750 [>.............................] - ETA: 8s - loss: 0.2202 - accuracy: 0.9178\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "257/750 [=========>....................] - ETA: 6s - loss: 0.2250 - accuracy: 0.9157\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.3120 - accuracy: 0.8900\n",
      "260/750 [=========>....................] - ETA: 6s - loss: 0.2252 - accuracy: 0.9154\n",
      "269/750 [=========>....................] - ETA: 6s - loss: 0.2258 - accuracy: 0.9152\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.3114 - accuracy: 0.8903\n",
      "272/750 [=========>....................] - ETA: 6s - loss: 0.2251 - accuracy: 0.9155\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.3114 - accuracy: 0.8903\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.3114 - accuracy: 0.8903\n",
      "274/750 [=========>....................] - ETA: 6s - loss: 0.2254 - accuracy: 0.9155\n",
      "426/750 [================>.............] - ETA: 4s - loss: 0.2372 - accuracy: 0.9128\n",
      "277/750 [==========>...................] - ETA: 6s - loss: 0.2255 - accuracy: 0.9156\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.3113 - accuracy: 0.8903\n",
      "370/750 [=============>................] - ETA: 5s - loss: 0.2367 - accuracy: 0.9134\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.3118 - accuracy: 0.8898\n",
      "412/750 [===============>..............] - ETA: 4s - loss: 0.2374 - accuracy: 0.9129\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.3115 - accuracy: 0.8902\n",
      "174/750 [=====>........................] - ETA: 7s - loss: 0.2287 - accuracy: 0.9138\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "419/750 [===============>..............] - ETA: 4s - loss: 0.2376 - accuracy: 0.9128\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "300/750 [===========>..................] - ETA: 6s - loss: 0.2259 - accuracy: 0.9158\n",
      "453/750 [=================>............] - ETA: 4s - loss: 0.2393 - accuracy: 0.9119\n",
      "128/750 [====>.........................] - ETA: 8s - loss: 0.2331 - accuracy: 0.9128\n",
      "448/750 [================>.............] - ETA: 4s - loss: 0.2393 - accuracy: 0.9120\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "567/750 [=====================>........] - ETA: 2s - loss: 0.3149 - accuracy: 0.8891\n",
      "196/750 [======>.......................] - ETA: 7s - loss: 0.2245 - accuracy: 0.9157\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "316/750 [===========>..................] - ETA: 6s - loss: 0.2271 - accuracy: 0.9151\n",
      "591/750 [======================>.......] - ETA: 2s - loss: 0.3150 - accuracy: 0.8892\n",
      "463/750 [=================>............] - ETA: 4s - loss: 0.2389 - accuracy: 0.9118\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "473/750 [=================>............] - ETA: 4s - loss: 0.2390 - accuracy: 0.9117\n",
      "670/750 [=========================>....] - ETA: 1s - loss: 0.3130 - accuracy: 0.8900\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "248/750 [========>.....................] - ETA: 6s - loss: 0.2239 - accuracy: 0.9162\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "350/750 [=============>................] - ETA: 6s - loss: 0.2257 - accuracy: 0.9154\n",
      "499/750 [==================>...........] - ETA: 3s - loss: 0.2389 - accuracy: 0.9121\n",
      "182/750 [======>.......................] - ETA: 7s - loss: 0.2270 - accuracy: 0.9146\n",
      "503/750 [===================>..........] - ETA: 3s - loss: 0.2392 - accuracy: 0.9120\n",
      "314/750 [===========>..................] - ETA: 6s - loss: 0.2271 - accuracy: 0.9150\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "494/750 [==================>...........] - ETA: 3s - loss: 0.2388 - accuracy: 0.9121\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "145/750 [====>.........................] - ETA: 8s - loss: 0.2299 - accuracy: 0.9133\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "377/750 [==============>...............] - ETA: 5s - loss: 0.2277 - accuracy: 0.9152\n",
      "525/750 [====================>.........] - ETA: 3s - loss: 0.2385 - accuracy: 0.9124\n",
      "226/750 [========>.....................] - ETA: 7s - loss: 0.2255 - accuracy: 0.9152\n",
      "530/750 [====================>.........] - ETA: 3s - loss: 0.2384 - accuracy: 0.9126\n",
      "545/750 [====================>.........] - ETA: 3s - loss: 0.2389 - accuracy: 0.9128\n",
      "515/750 [===================>..........] - ETA: 3s - loss: 0.2397 - accuracy: 0.9120\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "550/750 [=====================>........] - ETA: 3s - loss: 0.2386 - accuracy: 0.9128\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.3116 - accuracy: 0.8901\n",
      "558/750 [=====================>........] - ETA: 2s - loss: 0.2386 - accuracy: 0.9130\n",
      "568/750 [=====================>........] - ETA: 2s - loss: 0.2382 - accuracy: 0.9133\n",
      "393/750 [==============>...............] - ETA: 5s - loss: 0.2269 - accuracy: 0.9152\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "220/750 [=======>......................] - ETA: 7s - loss: 0.2265 - accuracy: 0.9148\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.2385 - accuracy: 0.9130\n",
      "432/750 [================>.............] - ETA: 4s - loss: 0.2292 - accuracy: 0.9148\n",
      "579/750 [======================>.......] - ETA: 2s - loss: 0.2385 - accuracy: 0.9130\n",
      "293/750 [==========>...................] - ETA: 6s - loss: 0.2254 - accuracy: 0.9158\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "448/750 [================>.............] - ETA: 4s - loss: 0.2282 - accuracy: 0.9151\n",
      "589/750 [======================>.......] - ETA: 2s - loss: 0.2390 - accuracy: 0.9128\n",
      "601/750 [=======================>......] - ETA: 2s - loss: 0.2395 - accuracy: 0.9127\n",
      "609/750 [=======================>......] - ETA: 2s - loss: 0.2394 - accuracy: 0.9125\n",
      "615/750 [=======================>......] - ETA: 2s - loss: 0.2395 - accuracy: 0.9124\n",
      "325/750 [============>.................] - ETA: 6s - loss: 0.2260 - accuracy: 0.9153\n",
      "475/750 [==================>...........] - ETA: 4s - loss: 0.2285 - accuracy: 0.9151\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.2394 - accuracy: 0.9124\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.3118 - accuracy: 0.8898 - val_loss: 0.3486 - val_accuracy: 0.8754\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 12/30\n",
      "  1/750 [..............................] - ETA: 16s - loss: 0.3634 - accuracy: 0.8438\n",
      "341/750 [============>.................] - ETA: 6s - loss: 0.2262 - accuracy: 0.9150\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 12/750 [..............................] - ETA: 8s - loss: 0.3196 - accuracy: 0.8906\n",
      "356/750 [=============>................] - ETA: 6s - loss: 0.2252 - accuracy: 0.9159\n",
      " 19/750 [..............................] - ETA: 11s - loss: 0.3115 - accuracy: 0.8923\n",
      "504/750 [===================>..........] - ETA: 3s - loss: 0.2285 - accuracy: 0.9151\n",
      " 27/750 [>.............................] - ETA: 10s - loss: 0.3128 - accuracy: 0.8889\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.2387 - accuracy: 0.9124\n",
      "648/750 [========================>.....] - ETA: 1s - loss: 0.2384 - accuracy: 0.9125\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 30/750 [>.............................] - ETA: 11s - loss: 0.3075 - accuracy: 0.8901\n",
      " 39/750 [>.............................] - ETA: 10s - loss: 0.3101 - accuracy: 0.8878\n",
      " 47/750 [>.............................] - ETA: 10s - loss: 0.3131 - accuracy: 0.8893\n",
      "675/750 [==========================>...] - ETA: 1s - loss: 0.2390 - accuracy: 0.9124\n",
      "527/750 [====================>.........] - ETA: 3s - loss: 0.2290 - accuracy: 0.9148\n",
      "535/750 [====================>.........] - ETA: 3s - loss: 0.2293 - accuracy: 0.9145\n",
      " 52/750 [=>............................] - ETA: 11s - loss: 0.3133 - accuracy: 0.8882\n",
      "678/750 [==========================>...] - ETA: 1s - loss: 0.2390 - accuracy: 0.9124\n",
      "402/750 [===============>..............] - ETA: 5s - loss: 0.2278 - accuracy: 0.9149\n",
      "346/750 [============>.................] - ETA: 6s - loss: 0.2259 - accuracy: 0.9154\n",
      "546/750 [====================>.........] - ETA: 3s - loss: 0.2303 - accuracy: 0.9142\n",
      " 55/750 [=>............................] - ETA: 11s - loss: 0.3096 - accuracy: 0.8895\n",
      "683/750 [==========================>...] - ETA: 1s - loss: 0.2388 - accuracy: 0.9124\n",
      "692/750 [==========================>...] - ETA: 0s - loss: 0.2388 - accuracy: 0.9124\n",
      "555/750 [=====================>........] - ETA: 3s - loss: 0.2307 - accuracy: 0.9140\n",
      " 66/750 [=>............................] - ETA: 10s - loss: 0.3141 - accuracy: 0.8871\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.2388 - accuracy: 0.9124\n",
      " 74/750 [=>............................] - ETA: 10s - loss: 0.3063 - accuracy: 0.8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:04:20,763 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6037581824; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2390 - accuracy: 0.9124\n",
      " 82/750 [==>...........................] - ETA: 10s - loss: 0.3033 - accuracy: 0.8916\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2388 - accuracy: 0.9125\n",
      " 94/750 [==>...........................] - ETA: 9s - loss: 0.3030 - accuracy: 0.8925 \n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2385 - accuracy: 0.9126\n",
      " 98/750 [==>...........................] - ETA: 9s - loss: 0.3038 - accuracy: 0.8929\n",
      "100/750 [===>..........................] - ETA: 10s - loss: 0.3039 - accuracy: 0.8931\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2386 - accuracy: 0.9126\n",
      "103/750 [===>..........................] - ETA: 10s - loss: 0.3086 - accuracy: 0.8918\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2390 - accuracy: 0.9125\n",
      "427/750 [================>.............] - ETA: 5s - loss: 0.2295 - accuracy: 0.9146\n",
      "114/750 [===>..........................] - ETA: 9s - loss: 0.3090 - accuracy: 0.8924\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2388 - accuracy: 0.9127\n",
      "367/750 [=============>................] - ETA: 5s - loss: 0.2260 - accuracy: 0.9157\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "416/750 [===============>..............] - ETA: 5s - loss: 0.2281 - accuracy: 0.9152\n",
      "118/750 [===>..........................] - ETA: 10s - loss: 0.3083 - accuracy: 0.8926\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2386 - accuracy: 0.9127\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2386 - accuracy: 0.9127\n",
      "128/750 [====>.........................] - ETA: 9s - loss: 0.3088 - accuracy: 0.8926 \n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2387 - accuracy: 0.9126\n",
      "418/750 [===============>..............] - ETA: 5s - loss: 0.2282 - accuracy: 0.9153\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "134/750 [====>.........................] - ETA: 9s - loss: 0.3092 - accuracy: 0.8921\n",
      "136/750 [====>.........................] - ETA: 9s - loss: 0.3076 - accuracy: 0.8927\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.2322 - accuracy: 0.9141\n",
      "469/750 [=================>............] - ETA: 4s - loss: 0.2282 - accuracy: 0.9152\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "441/750 [================>.............] - ETA: 4s - loss: 0.2287 - accuracy: 0.9151\n",
      "635/750 [========================>.....] - ETA: 1s - loss: 0.2326 - accuracy: 0.9140\n",
      "159/750 [=====>........................] - ETA: 8s - loss: 0.3068 - accuracy: 0.8931\n",
      "451/750 [=================>............] - ETA: 4s - loss: 0.2285 - accuracy: 0.9152\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "171/750 [=====>........................] - ETA: 8s - loss: 0.3064 - accuracy: 0.8930\n",
      "175/750 [======>.......................] - ETA: 8s - loss: 0.3058 - accuracy: 0.8932\n",
      "178/750 [======>.......................] - ETA: 8s - loss: 0.3058 - accuracy: 0.8931\n",
      "669/750 [=========================>....] - ETA: 1s - loss: 0.2327 - accuracy: 0.9138\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "183/750 [======>.......................] - ETA: 8s - loss: 0.3064 - accuracy: 0.8931\n",
      "195/750 [======>.......................] - ETA: 7s - loss: 0.3044 - accuracy: 0.8931\n",
      "212/750 [=======>......................] - ETA: 7s - loss: 0.3077 - accuracy: 0.8908\n",
      "496/750 [==================>...........] - ETA: 3s - loss: 0.2287 - accuracy: 0.9151\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "223/750 [=======>......................] - ETA: 7s - loss: 0.3078 - accuracy: 0.8911\n",
      "492/750 [==================>...........] - ETA: 3s - loss: 0.2277 - accuracy: 0.9154\n",
      "146/750 [====>.........................] - ETA: 9s - loss: 0.3071 - accuracy: 0.8926\n",
      "227/750 [========>.....................] - ETA: 8s - loss: 0.3066 - accuracy: 0.8912\n",
      "237/750 [========>.....................] - ETA: 7s - loss: 0.3079 - accuracy: 0.8908\n",
      "241/750 [========>.....................] - ETA: 7s - loss: 0.3068 - accuracy: 0.8914\n",
      "523/750 [===================>..........] - ETA: 3s - loss: 0.2291 - accuracy: 0.9148\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "243/750 [========>.....................] - ETA: 8s - loss: 0.3067 - accuracy: 0.8913\n",
      "251/750 [=========>....................] - ETA: 8s - loss: 0.3055 - accuracy: 0.8918\n",
      "559/750 [=====================>........] - ETA: 2s - loss: 0.2307 - accuracy: 0.9141\n",
      "256/750 [=========>....................] - ETA: 7s - loss: 0.3057 - accuracy: 0.8917\n",
      "564/750 [=====================>........] - ETA: 2s - loss: 0.2314 - accuracy: 0.9138\n",
      "221/750 [=======>......................] - ETA: 7s - loss: 0.3081 - accuracy: 0.8909\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "260/750 [=========>....................] - ETA: 8s - loss: 0.3056 - accuracy: 0.8921\n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.2316 - accuracy: 0.9140\n",
      "265/750 [=========>....................] - ETA: 8s - loss: 0.3042 - accuracy: 0.8930\n",
      "272/750 [=========>....................] - ETA: 7s - loss: 0.3042 - accuracy: 0.8933\n",
      "596/750 [======================>.......] - ETA: 2s - loss: 0.2321 - accuracy: 0.9140\n",
      "281/750 [==========>...................] - ETA: 7s - loss: 0.3054 - accuracy: 0.8928\n",
      "  6/750 [..............................] - ETA: 9s - loss: 0.2268 - accuracy: 0.9193\n",
      "594/750 [======================>.......] - ETA: 2s - loss: 0.2318 - accuracy: 0.9140\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "283/750 [==========>...................] - ETA: 7s - loss: 0.3059 - accuracy: 0.8924\n",
      "287/750 [==========>...................] - ETA: 7s - loss: 0.3054 - accuracy: 0.8927\n",
      " 16/750 [..............................] - ETA: 5s - loss: 0.2667 - accuracy: 0.9033\n",
      " 24/750 [..............................] - ETA: 5s - loss: 0.2468 - accuracy: 0.9095\n",
      "603/750 [=======================>......] - ETA: 2s - loss: 0.2324 - accuracy: 0.9140\n",
      "611/750 [=======================>......] - ETA: 2s - loss: 0.2321 - accuracy: 0.9140\n",
      "296/750 [==========>...................] - ETA: 7s - loss: 0.3080 - accuracy: 0.8919\n",
      " 31/750 [>.............................] - ETA: 7s - loss: 0.2347 - accuracy: 0.9138\n",
      "305/750 [===========>..................] - ETA: 7s - loss: 0.3073 - accuracy: 0.8923\n",
      " 37/750 [>.............................] - ETA: 8s - loss: 0.2430 - accuracy: 0.9117\n",
      "616/750 [=======================>......] - ETA: 2s - loss: 0.2321 - accuracy: 0.9140\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 14s 19ms/step - loss: 0.2387 - accuracy: 0.9126 - val_loss: 0.3896 - val_accuracy: 0.8737\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 13/30\n",
      "314/750 [===========>..................] - ETA: 7s - loss: 0.3060 - accuracy: 0.8928\n",
      " 40/750 [>.............................] - ETA: 9s - loss: 0.2430 - accuracy: 0.9109\n",
      "316/750 [===========>..................] - ETA: 7s - loss: 0.3061 - accuracy: 0.8928\n",
      " 49/750 [>.............................] - ETA: 9s - loss: 0.2367 - accuracy: 0.9133\n",
      "322/750 [===========>..................] - ETA: 6s - loss: 0.3064 - accuracy: 0.8928\n",
      " 53/750 [=>............................] - ETA: 10s - loss: 0.2358 - accuracy: 0.9142\n",
      "325/750 [============>.................] - ETA: 6s - loss: 0.3060 - accuracy: 0.8929\n",
      "332/750 [============>.................] - ETA: 6s - loss: 0.3064 - accuracy: 0.8927\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.2327 - accuracy: 0.9140\n",
      "337/750 [============>.................] - ETA: 6s - loss: 0.3066 - accuracy: 0.8925\n",
      "342/750 [============>.................] - ETA: 6s - loss: 0.3058 - accuracy: 0.8926\n",
      "346/750 [============>.................] - ETA: 6s - loss: 0.3057 - accuracy: 0.8927\n",
      " 78/750 [==>...........................] - ETA: 11s - loss: 0.2325 - accuracy: 0.9139\n",
      "679/750 [==========================>...] - ETA: 1s - loss: 0.2327 - accuracy: 0.9138\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.2332 - accuracy: 0.9135\n",
      "350/750 [=============>................] - ETA: 6s - loss: 0.3065 - accuracy: 0.8924\n",
      " 55/750 [=>............................] - ETA: 11s - loss: 0.2338 - accuracy: 0.9153\n",
      " 80/750 [==>...........................] - ETA: 11s - loss: 0.2327 - accuracy: 0.9139\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.2334 - accuracy: 0.9135\n",
      " 68/750 [=>............................] - ETA: 12s - loss: 0.2343 - accuracy: 0.9134\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 83/750 [==>...........................] - ETA: 12s - loss: 0.2303 - accuracy: 0.9147\n",
      "360/750 [=============>................] - ETA: 6s - loss: 0.3062 - accuracy: 0.8924\n",
      " 85/750 [==>...........................] - ETA: 12s - loss: 0.2310 - accuracy: 0.9145\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2344 - accuracy: 0.9134\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 93/750 [==>...........................] - ETA: 12s - loss: 0.2339 - accuracy: 0.9138\n",
      "379/750 [==============>...............] - ETA: 6s - loss: 0.3058 - accuracy: 0.8924\n",
      "106/750 [===>..........................] - ETA: 11s - loss: 0.2348 - accuracy: 0.9139\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2344 - accuracy: 0.9134\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "117/750 [===>..........................] - ETA: 10s - loss: 0.2335 - accuracy: 0.9133\n",
      "391/750 [==============>...............] - ETA: 6s - loss: 0.3042 - accuracy: 0.8931\n",
      "124/750 [===>..........................] - ETA: 10s - loss: 0.2341 - accuracy: 0.9136\n",
      "400/750 [===============>..............] - ETA: 5s - loss: 0.3032 - accuracy: 0.8934\n",
      "134/750 [====>.........................] - ETA: 10s - loss: 0.2352 - accuracy: 0.9135\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2336 - accuracy: 0.9135\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "410/750 [===============>..............] - ETA: 5s - loss: 0.3031 - accuracy: 0.8934\n",
      "144/750 [====>.........................] - ETA: 9s - loss: 0.2320 - accuracy: 0.9140 \n",
      "365/750 [=============>................] - ETA: 6s - loss: 0.3064 - accuracy: 0.8921\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2340 - accuracy: 0.9134\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "420/750 [===============>..............] - ETA: 5s - loss: 0.3030 - accuracy: 0.8933\n",
      "428/750 [================>.............] - ETA: 5s - loss: 0.3025 - accuracy: 0.8932\n",
      "151/750 [=====>........................] - ETA: 9s - loss: 0.2320 - accuracy: 0.9147\n",
      "154/750 [=====>........................] - ETA: 9s - loss: 0.2305 - accuracy: 0.9154\n",
      "148/750 [====>.........................] - ETA: 9s - loss: 0.2321 - accuracy: 0.9142\n",
      "435/750 [================>.............] - ETA: 5s - loss: 0.3033 - accuracy: 0.8929\n",
      "159/750 [=====>........................] - ETA: 9s - loss: 0.2313 - accuracy: 0.9155\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 0.2337 - accuracy: 0.9135 - val_loss: 0.3451 - val_accuracy: 0.8874\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 12/30\n",
      "448/750 [================>.............] - ETA: 4s - loss: 0.3031 - accuracy: 0.8929\n",
      "169/750 [=====>........................] - ETA: 9s - loss: 0.2293 - accuracy: 0.9161\n",
      "177/750 [======>.......................] - ETA: 9s - loss: 0.2284 - accuracy: 0.9168\n",
      "451/750 [=================>............] - ETA: 4s - loss: 0.3029 - accuracy: 0.8931\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 17/750 [..............................] - ETA: 12s - loss: 0.2245 - accuracy: 0.9210\n",
      " 23/750 [..............................] - ETA: 13s - loss: 0.2126 - accuracy: 0.9253\n",
      "189/750 [======>.......................] - ETA: 9s - loss: 0.2273 - accuracy: 0.9171\n",
      " 25/750 [>.............................] - ETA: 14s - loss: 0.2089 - accuracy: 0.9250\n",
      "470/750 [=================>............] - ETA: 4s - loss: 0.3034 - accuracy: 0.8927\n",
      "197/750 [======>.......................] - ETA: 9s - loss: 0.2265 - accuracy: 0.9174\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 36/750 [>.............................] - ETA: 13s - loss: 0.2287 - accuracy: 0.9154\n",
      "475/750 [==================>...........] - ETA: 4s - loss: 0.3035 - accuracy: 0.8926\n",
      " 46/750 [>.............................] - ETA: 11s - loss: 0.2243 - accuracy: 0.9164\n",
      "211/750 [=======>......................] - ETA: 8s - loss: 0.2282 - accuracy: 0.9167\n",
      " 54/750 [=>............................] - ETA: 11s - loss: 0.2212 - accuracy: 0.9201\n",
      "488/750 [==================>...........] - ETA: 4s - loss: 0.3028 - accuracy: 0.8925\n",
      " 57/750 [=>............................] - ETA: 11s - loss: 0.2220 - accuracy: 0.9194\n",
      "479/750 [==================>...........] - ETA: 4s - loss: 0.3033 - accuracy: 0.8925\n",
      "492/750 [==================>...........] - ETA: 4s - loss: 0.3028 - accuracy: 0.8927\n",
      "499/750 [==================>...........] - ETA: 4s - loss: 0.3027 - accuracy: 0.8928\n",
      "228/750 [========>.....................] - ETA: 8s - loss: 0.2291 - accuracy: 0.9165\n",
      "508/750 [===================>..........] - ETA: 3s - loss: 0.3020 - accuracy: 0.8928\n",
      " 81/750 [==>...........................] - ETA: 11s - loss: 0.2192 - accuracy: 0.9198\n",
      " 92/750 [==>...........................] - ETA: 10s - loss: 0.2206 - accuracy: 0.9186\n",
      "522/750 [===================>..........] - ETA: 3s - loss: 0.3022 - accuracy: 0.8930\n",
      " 96/750 [==>...........................] - ETA: 10s - loss: 0.2235 - accuracy: 0.9186\n",
      "528/750 [====================>.........] - ETA: 3s - loss: 0.3025 - accuracy: 0.8929\n",
      "537/750 [====================>.........] - ETA: 3s - loss: 0.3033 - accuracy: 0.8928\n",
      "237/750 [========>.....................] - ETA: 8s - loss: 0.2286 - accuracy: 0.9166\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "515/750 [===================>..........] - ETA: 3s - loss: 0.3026 - accuracy: 0.8928\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "546/750 [====================>.........] - ETA: 3s - loss: 0.3034 - accuracy: 0.8927\n",
      "276/750 [==========>...................] - ETA: 7s - loss: 0.2277 - accuracy: 0.9163\n",
      "252/750 [=========>....................] - ETA: 7s - loss: 0.2312 - accuracy: 0.9154\n",
      "122/750 [===>..........................] - ETA: 9s - loss: 0.2218 - accuracy: 0.9193 \n",
      "554/750 [=====================>........] - ETA: 3s - loss: 0.3041 - accuracy: 0.8922\n",
      "267/750 [=========>....................] - ETA: 7s - loss: 0.2301 - accuracy: 0.9154\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "124/750 [===>..........................] - ETA: 10s - loss: 0.2221 - accuracy: 0.9194\n",
      "560/750 [=====================>........] - ETA: 3s - loss: 0.3041 - accuracy: 0.8921\n",
      "222/750 [=======>......................] - ETA: 8s - loss: 0.2285 - accuracy: 0.9170\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "137/750 [====>.........................] - ETA: 9s - loss: 0.2234 - accuracy: 0.9185\n",
      "565/750 [=====================>........] - ETA: 3s - loss: 0.3040 - accuracy: 0.8922\n",
      "272/750 [=========>....................] - ETA: 7s - loss: 0.2291 - accuracy: 0.9158\n",
      "142/750 [====>.........................] - ETA: 9s - loss: 0.2233 - accuracy: 0.9187\n",
      "568/750 [=====================>........] - ETA: 3s - loss: 0.3038 - accuracy: 0.8923\n",
      "148/750 [====>.........................] - ETA: 9s - loss: 0.2214 - accuracy: 0.9196\n",
      "297/750 [==========>...................] - ETA: 7s - loss: 0.2289 - accuracy: 0.9162\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "583/750 [======================>.......] - ETA: 2s - loss: 0.3042 - accuracy: 0.8923\n",
      "  7/750 [..............................] - ETA: 6s - loss: 0.2296 - accuracy: 0.9263\n",
      "579/750 [======================>.......] - ETA: 2s - loss: 0.3038 - accuracy: 0.8924\n",
      " 11/750 [..............................] - ETA: 9s - loss: 0.2252 - accuracy: 0.9247\n",
      "586/750 [======================>.......] - ETA: 2s - loss: 0.3040 - accuracy: 0.8925\n",
      "325/750 [============>.................] - ETA: 6s - loss: 0.2305 - accuracy: 0.9159\n",
      "306/750 [===========>..................] - ETA: 7s - loss: 0.2307 - accuracy: 0.9157\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "158/750 [=====>........................] - ETA: 10s - loss: 0.2206 - accuracy: 0.9195\n",
      "594/750 [======================>.......] - ETA: 2s - loss: 0.3039 - accuracy: 0.8923\n",
      "171/750 [=====>........................] - ETA: 9s - loss: 0.2203 - accuracy: 0.9191\n",
      "601/750 [=======================>......] - ETA: 2s - loss: 0.3034 - accuracy: 0.8925\n",
      "317/750 [===========>..................] - ETA: 7s - loss: 0.2306 - accuracy: 0.9157\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "609/750 [=======================>......] - ETA: 2s - loss: 0.3037 - accuracy: 0.8926\n",
      "619/750 [=======================>......] - ETA: 2s - loss: 0.3043 - accuracy: 0.8922\n",
      "331/750 [============>.................] - ETA: 7s - loss: 0.2300 - accuracy: 0.9161\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "628/750 [========================>.....] - ETA: 2s - loss: 0.3047 - accuracy: 0.8921\n",
      "347/750 [============>.................] - ETA: 6s - loss: 0.2313 - accuracy: 0.9156\n",
      "201/750 [=======>......................] - ETA: 8s - loss: 0.2209 - accuracy: 0.9187\n",
      "633/750 [========================>.....] - ETA: 1s - loss: 0.3044 - accuracy: 0.8923\n",
      "640/750 [========================>.....] - ETA: 1s - loss: 0.3047 - accuracy: 0.8921\n",
      "646/750 [========================>.....] - ETA: 1s - loss: 0.3046 - accuracy: 0.8921\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.3047 - accuracy: 0.8919\n",
      "388/750 [==============>...............] - ETA: 5s - loss: 0.2319 - accuracy: 0.9148\n",
      " 75/750 [==>...........................] - ETA: 10s - loss: 0.2189 - accuracy: 0.9194\n",
      "368/750 [=============>................] - ETA: 6s - loss: 0.2302 - accuracy: 0.9159\n",
      "659/750 [=========================>....] - ETA: 1s - loss: 0.3047 - accuracy: 0.8920\n",
      "235/750 [========>.....................] - ETA: 8s - loss: 0.2229 - accuracy: 0.9175\n",
      "669/750 [=========================>....] - ETA: 1s - loss: 0.3041 - accuracy: 0.8922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:04:30,775 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6036242432; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70/750 [=>............................] - ETA: 10s - loss: 0.2174 - accuracy: 0.9192\n",
      "244/750 [========>.....................] - ETA: 8s - loss: 0.2216 - accuracy: 0.9178\n",
      "679/750 [==========================>...] - ETA: 1s - loss: 0.3044 - accuracy: 0.8920\n",
      "251/750 [=========>....................] - ETA: 8s - loss: 0.2216 - accuracy: 0.9180\n",
      "688/750 [==========================>...] - ETA: 1s - loss: 0.3048 - accuracy: 0.8918\n",
      "377/750 [==============>...............] - ETA: 6s - loss: 0.2308 - accuracy: 0.9153\n",
      "691/750 [==========================>...] - ETA: 0s - loss: 0.3051 - accuracy: 0.8917\n",
      "425/750 [================>.............] - ETA: 5s - loss: 0.2328 - accuracy: 0.9142\n",
      "428/750 [================>.............] - ETA: 5s - loss: 0.2329 - accuracy: 0.9142\n",
      "114/750 [===>..........................] - ETA: 10s - loss: 0.2234 - accuracy: 0.9189\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.3058 - accuracy: 0.8916\n",
      "431/750 [================>.............] - ETA: 5s - loss: 0.2335 - accuracy: 0.9142\n",
      "397/750 [==============>...............] - ETA: 5s - loss: 0.2327 - accuracy: 0.9144\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "280/750 [==========>...................] - ETA: 7s - loss: 0.2204 - accuracy: 0.9174\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.3055 - accuracy: 0.8918\n",
      "436/750 [================>.............] - ETA: 5s - loss: 0.2330 - accuracy: 0.9143\n",
      "440/750 [================>.............] - ETA: 5s - loss: 0.2332 - accuracy: 0.9141\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.3058 - accuracy: 0.8916\n",
      "450/750 [=================>............] - ETA: 4s - loss: 0.2333 - accuracy: 0.9139\n",
      "422/750 [===============>..............] - ETA: 5s - loss: 0.2328 - accuracy: 0.9142\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.3061 - accuracy: 0.8916\n",
      "366/750 [=============>................] - ETA: 6s - loss: 0.2300 - accuracy: 0.9159\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.3061 - accuracy: 0.8917\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.3061 - accuracy: 0.8917\n",
      "152/750 [=====>........................] - ETA: 10s - loss: 0.2214 - accuracy: 0.9195\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.8915\n",
      "474/750 [=================>............] - ETA: 4s - loss: 0.2314 - accuracy: 0.9143\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.3061 - accuracy: 0.8917\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.8915\n",
      "462/750 [=================>............] - ETA: 4s - loss: 0.3030 - accuracy: 0.8928\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "335/750 [============>.................] - ETA: 6s - loss: 0.2228 - accuracy: 0.9170\n",
      "348/750 [============>.................] - ETA: 6s - loss: 0.2233 - accuracy: 0.9168\n",
      "463/750 [=================>............] - ETA: 4s - loss: 0.2315 - accuracy: 0.9143\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "197/750 [======>.......................] - ETA: 9s - loss: 0.2216 - accuracy: 0.9183\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "372/750 [=============>................] - ETA: 5s - loss: 0.2237 - accuracy: 0.9166\n",
      "539/750 [====================>.........] - ETA: 3s - loss: 0.2325 - accuracy: 0.9145\n",
      "497/750 [==================>...........] - ETA: 4s - loss: 0.2316 - accuracy: 0.9143\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "552/750 [=====================>........] - ETA: 3s - loss: 0.2320 - accuracy: 0.9145\n",
      "403/750 [===============>..............] - ETA: 5s - loss: 0.2236 - accuracy: 0.9166\n",
      "407/750 [===============>..............] - ETA: 5s - loss: 0.2236 - accuracy: 0.9165\n",
      "409/750 [===============>..............] - ETA: 5s - loss: 0.2237 - accuracy: 0.9165\n",
      "580/750 [======================>.......] - ETA: 2s - loss: 0.2325 - accuracy: 0.9145\n",
      "591/750 [======================>.......] - ETA: 2s - loss: 0.2324 - accuracy: 0.9146\n",
      "425/750 [================>.............] - ETA: 4s - loss: 0.2223 - accuracy: 0.9170\n",
      "528/750 [====================>.........] - ETA: 3s - loss: 0.2322 - accuracy: 0.9145\n",
      "535/750 [====================>.........] - ETA: 3s - loss: 0.2323 - accuracy: 0.9145\n",
      "437/750 [================>.............] - ETA: 4s - loss: 0.2227 - accuracy: 0.9169\n",
      "227/750 [========>.....................] - ETA: 8s - loss: 0.2224 - accuracy: 0.9179\n",
      "518/750 [===================>..........] - ETA: 3s - loss: 0.2321 - accuracy: 0.9145\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "447/750 [================>.............] - ETA: 4s - loss: 0.2224 - accuracy: 0.9171\n",
      "277/750 [==========>...................] - ETA: 7s - loss: 0.2211 - accuracy: 0.9172\n",
      "570/750 [=====================>........] - ETA: 2s - loss: 0.2323 - accuracy: 0.9146\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "262/750 [=========>....................] - ETA: 7s - loss: 0.2212 - accuracy: 0.9179\n",
      "223/750 [=======>......................] - ETA: 8s - loss: 0.2216 - accuracy: 0.9180\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "479/750 [==================>...........] - ETA: 4s - loss: 0.2228 - accuracy: 0.9170\n",
      "654/750 [=========================>....] - ETA: 1s - loss: 0.2315 - accuracy: 0.9146\n",
      "750/750 [==============================] - 14s 19ms/step - loss: 0.3062 - accuracy: 0.8915 - val_loss: 0.3351 - val_accuracy: 0.8818\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 13/30\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.2556 - accuracy: 0.9219\n",
      "500/750 [===================>..........] - ETA: 3s - loss: 0.2230 - accuracy: 0.9169\n",
      "  2/750 [..............................] - ETA: 1:36 - loss: 0.2915 - accuracy: 0.8984\n",
      " 18/750 [..............................] - ETA: 10s - loss: 0.3087 - accuracy: 0.8854\n",
      "297/750 [==========>...................] - ETA: 7s - loss: 0.2202 - accuracy: 0.9181\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "597/750 [======================>.......] - ETA: 2s - loss: 0.2324 - accuracy: 0.9144\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 23/750 [..............................] - ETA: 12s - loss: 0.3125 - accuracy: 0.8852\n",
      "528/750 [====================>.........] - ETA: 3s - loss: 0.2235 - accuracy: 0.9166\n",
      " 34/750 [>.............................] - ETA: 10s - loss: 0.3038 - accuracy: 0.8897\n",
      "329/750 [============>.................] - ETA: 6s - loss: 0.2227 - accuracy: 0.9172\n",
      "319/750 [===========>..................] - ETA: 6s - loss: 0.2217 - accuracy: 0.9174\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "539/750 [====================>.........] - ETA: 3s - loss: 0.2232 - accuracy: 0.9168\n",
      " 41/750 [>.............................] - ETA: 9s - loss: 0.3039 - accuracy: 0.8868 \n",
      "541/750 [====================>.........] - ETA: 3s - loss: 0.2232 - accuracy: 0.9169\n",
      " 47/750 [>.............................] - ETA: 10s - loss: 0.3024 - accuracy: 0.8913\n",
      "307/750 [===========>..................] - ETA: 7s - loss: 0.2206 - accuracy: 0.9178\n",
      "616/750 [=======================>......] - ETA: 2s - loss: 0.2324 - accuracy: 0.9143\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "548/750 [====================>.........] - ETA: 2s - loss: 0.2233 - accuracy: 0.9168\n",
      " 49/750 [>.............................] - ETA: 11s - loss: 0.3008 - accuracy: 0.8916\n",
      " 58/750 [=>............................] - ETA: 11s - loss: 0.3023 - accuracy: 0.8928\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.9139\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.2322 - accuracy: 0.9146\n",
      " 64/750 [=>............................] - ETA: 11s - loss: 0.3045 - accuracy: 0.8896\n",
      " 72/750 [=>............................] - ETA: 11s - loss: 0.3046 - accuracy: 0.8902\n",
      "637/750 [========================>.....] - ETA: 1s - loss: 0.2322 - accuracy: 0.9145\n",
      " 83/750 [==>...........................] - ETA: 10s - loss: 0.3030 - accuracy: 0.8914\n",
      " 90/750 [==>...........................] - ETA: 10s - loss: 0.3025 - accuracy: 0.8908\n",
      "656/750 [=========================>....] - ETA: 1s - loss: 0.2315 - accuracy: 0.9146\n",
      "392/750 [==============>...............] - ETA: 5s - loss: 0.2239 - accuracy: 0.9165\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "667/750 [=========================>....] - ETA: 1s - loss: 0.2321 - accuracy: 0.9143\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.9140\n",
      " 97/750 [==>...........................] - ETA: 11s - loss: 0.3039 - accuracy: 0.8914\n",
      "677/750 [==========================>...] - ETA: 1s - loss: 0.2322 - accuracy: 0.9141\n",
      "601/750 [=======================>......] - ETA: 2s - loss: 0.2232 - accuracy: 0.9169\n",
      "696/750 [==========================>...] - ETA: 0s - loss: 0.2325 - accuracy: 0.9140\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "606/750 [=======================>......] - ETA: 2s - loss: 0.2236 - accuracy: 0.9168\n",
      "699/750 [==========================>...] - ETA: 0s - loss: 0.2326 - accuracy: 0.9139\n",
      "431/750 [================>.............] - ETA: 4s - loss: 0.2220 - accuracy: 0.9171\n",
      "116/750 [===>..........................] - ETA: 11s - loss: 0.3060 - accuracy: 0.8904\n",
      "110/750 [===>..........................] - ETA: 11s - loss: 0.3040 - accuracy: 0.8908\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "126/750 [====>.........................] - ETA: 11s - loss: 0.3031 - accuracy: 0.8920\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.2246 - accuracy: 0.9165\n",
      "382/750 [==============>...............] - ETA: 5s - loss: 0.2231 - accuracy: 0.9165\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2329 - accuracy: 0.9139\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "129/750 [====>.........................] - ETA: 11s - loss: 0.3033 - accuracy: 0.8916\n",
      "135/750 [====>.........................] - ETA: 11s - loss: 0.3030 - accuracy: 0.8919\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.2328 - accuracy: 0.9139\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.2243 - accuracy: 0.9167\n",
      "138/750 [====>.........................] - ETA: 11s - loss: 0.3041 - accuracy: 0.8912\n",
      "637/750 [========================>.....] - ETA: 1s - loss: 0.2243 - accuracy: 0.9165\n",
      "417/750 [===============>..............] - ETA: 5s - loss: 0.2234 - accuracy: 0.9167\n",
      "145/750 [====>.........................] - ETA: 10s - loss: 0.3043 - accuracy: 0.8914\n",
      "649/750 [========================>.....] - ETA: 1s - loss: 0.2248 - accuracy: 0.9164\n",
      "367/750 [=============>................] - ETA: 5s - loss: 0.2229 - accuracy: 0.9167\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2331 - accuracy: 0.9140\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "150/750 [=====>........................] - ETA: 10s - loss: 0.3051 - accuracy: 0.8911\n",
      "655/750 [=========================>....] - ETA: 1s - loss: 0.2248 - accuracy: 0.9165\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2331 - accuracy: 0.9140\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "158/750 [=====>........................] - ETA: 10s - loss: 0.3078 - accuracy: 0.8906\n",
      "660/750 [=========================>....] - ETA: 1s - loss: 0.2250 - accuracy: 0.9165\n",
      "161/750 [=====>........................] - ETA: 10s - loss: 0.3082 - accuracy: 0.8907\n",
      "666/750 [=========================>....] - ETA: 1s - loss: 0.2249 - accuracy: 0.9165\n",
      "168/750 [=====>........................] - ETA: 10s - loss: 0.3090 - accuracy: 0.8903\n",
      "676/750 [==========================>...] - ETA: 1s - loss: 0.2242 - accuracy: 0.9168\n",
      "177/750 [======>.......................] - ETA: 10s - loss: 0.3079 - accuracy: 0.8908\n",
      "679/750 [==========================>...] - ETA: 1s - loss: 0.2248 - accuracy: 0.9166\n",
      "183/750 [======>.......................] - ETA: 10s - loss: 0.3068 - accuracy: 0.8913\n",
      "683/750 [==========================>...] - ETA: 1s - loss: 0.2248 - accuracy: 0.9166\n",
      "688/750 [==========================>...] - ETA: 0s - loss: 0.2249 - accuracy: 0.9166\n",
      "465/750 [=================>............] - ETA: 4s - loss: 0.2226 - accuracy: 0.9170\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "188/750 [======>.......................] - ETA: 10s - loss: 0.3071 - accuracy: 0.8914\n",
      "690/750 [==========================>...] - ETA: 0s - loss: 0.2250 - accuracy: 0.9165\n",
      "192/750 [======>.......................] - ETA: 10s - loss: 0.3071 - accuracy: 0.8914\n",
      "692/750 [==========================>...] - ETA: 0s - loss: 0.2249 - accuracy: 0.9165\n",
      "195/750 [======>.......................] - ETA: 10s - loss: 0.3081 - accuracy: 0.8912\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.2247 - accuracy: 0.9166\n",
      "488/750 [==================>...........] - ETA: 3s - loss: 0.2226 - accuracy: 0.9169\n",
      "198/750 [======>.......................] - ETA: 10s - loss: 0.3073 - accuracy: 0.8914\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.2249 - accuracy: 0.9165\n",
      "199/750 [======>.......................] - ETA: 10s - loss: 0.3071 - accuracy: 0.8913\n",
      "203/750 [=======>......................] - ETA: 11s - loss: 0.3080 - accuracy: 0.8909\n",
      "207/750 [=======>......................] - ETA: 10s - loss: 0.3073 - accuracy: 0.8908\n",
      "580/750 [======================>.......] - ETA: 2s - loss: 0.2232 - accuracy: 0.9169\n",
      "216/750 [=======>......................] - ETA: 10s - loss: 0.3062 - accuracy: 0.8911\n",
      "221/750 [=======>......................] - ETA: 10s - loss: 0.3057 - accuracy: 0.8915\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2255 - accuracy: 0.9163\n",
      "224/750 [=======>......................] - ETA: 10s - loss: 0.3056 - accuracy: 0.8914\n",
      "232/750 [========>.....................] - ETA: 10s - loss: 0.3037 - accuracy: 0.8925\n",
      "519/750 [===================>..........] - ETA: 3s - loss: 0.2235 - accuracy: 0.9165\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "241/750 [========>.....................] - ETA: 9s - loss: 0.3016 - accuracy: 0.8938\n",
      "572/750 [=====================>........] - ETA: 2s - loss: 0.2236 - accuracy: 0.9168\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "245/750 [========>.....................] - ETA: 9s - loss: 0.3011 - accuracy: 0.8938\n",
      "261/750 [=========>....................] - ETA: 9s - loss: 0.3021 - accuracy: 0.8941\n",
      "  7/750 [..............................] - ETA: 6s - loss: 0.2233 - accuracy: 0.9152\n",
      "271/750 [=========>....................] - ETA: 8s - loss: 0.3019 - accuracy: 0.8943\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 0.2331 - accuracy: 0.9140 - val_loss: 0.3599 - val_accuracy: 0.8881\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 14/30\n",
      "272/750 [=========>....................] - ETA: 8s - loss: 0.3016 - accuracy: 0.8943\n",
      " 18/750 [..............................] - ETA: 12s - loss: 0.2427 - accuracy: 0.9115\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 24/750 [..............................] - ETA: 15s - loss: 0.2421 - accuracy: 0.9121\n",
      "282/750 [==========>...................] - ETA: 8s - loss: 0.3000 - accuracy: 0.8947\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "593/750 [======================>.......] - ETA: 2s - loss: 0.2232 - accuracy: 0.9169\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      " 22/750 [..............................] - ETA: 14s - loss: 0.2477 - accuracy: 0.9105\n",
      " 36/750 [>.............................] - ETA: 13s - loss: 0.2206 - accuracy: 0.9149\n",
      " 42/750 [>.............................] - ETA: 13s - loss: 0.2174 - accuracy: 0.9167\n",
      "308/750 [===========>..................] - ETA: 8s - loss: 0.2989 - accuracy: 0.8950\n",
      " 53/750 [=>............................] - ETA: 11s - loss: 0.2256 - accuracy: 0.9157\n",
      "319/750 [===========>..................] - ETA: 7s - loss: 0.2987 - accuracy: 0.8950\n",
      "616/750 [=======================>......] - ETA: 2s - loss: 0.2240 - accuracy: 0.9168\n",
      "320/750 [===========>..................] - ETA: 7s - loss: 0.2992 - accuracy: 0.8950\n",
      " 70/750 [=>............................] - ETA: 10s - loss: 0.2289 - accuracy: 0.9134\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "330/750 [============>.................] - ETA: 7s - loss: 0.2999 - accuracy: 0.8946\n",
      "333/750 [============>.................] - ETA: 7s - loss: 0.2996 - accuracy: 0.8949\n",
      " 71/750 [=>............................] - ETA: 11s - loss: 0.2278 - accuracy: 0.9140\n",
      " 74/750 [=>............................] - ETA: 12s - loss: 0.2290 - accuracy: 0.9136\n",
      "343/750 [============>.................] - ETA: 7s - loss: 0.2998 - accuracy: 0.8952\n",
      " 80/750 [==>...........................] - ETA: 12s - loss: 0.2283 - accuracy: 0.9133\n",
      "346/750 [============>.................] - ETA: 7s - loss: 0.2996 - accuracy: 0.8952\n",
      " 91/750 [==>...........................] - ETA: 11s - loss: 0.2318 - accuracy: 0.9116\n",
      "354/750 [=============>................] - ETA: 7s - loss: 0.3003 - accuracy: 0.8943\n",
      "357/750 [=============>................] - ETA: 7s - loss: 0.3001 - accuracy: 0.8941\n",
      "107/750 [===>..........................] - ETA: 10s - loss: 0.2297 - accuracy: 0.9133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:04:40,798 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6035099648; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/750 [=============>................] - ETA: 7s - loss: 0.2996 - accuracy: 0.8949\n",
      "379/750 [==============>...............] - ETA: 6s - loss: 0.3019 - accuracy: 0.8940\n",
      "112/750 [===>..........................] - ETA: 10s - loss: 0.2290 - accuracy: 0.9135\n",
      "387/750 [==============>...............] - ETA: 6s - loss: 0.3019 - accuracy: 0.8941\n",
      "118/750 [===>..........................] - ETA: 10s - loss: 0.2281 - accuracy: 0.9141\n",
      "128/750 [====>.........................] - ETA: 10s - loss: 0.2249 - accuracy: 0.9158\n",
      "397/750 [==============>...............] - ETA: 6s - loss: 0.3006 - accuracy: 0.8946\n",
      "151/750 [=====>........................] - ETA: 9s - loss: 0.2224 - accuracy: 0.9161 \n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2255 - accuracy: 0.9163\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "132/750 [====>.........................] - ETA: 10s - loss: 0.2238 - accuracy: 0.9163\n",
      "406/750 [===============>..............] - ETA: 6s - loss: 0.3013 - accuracy: 0.8942\n",
      "156/750 [=====>........................] - ETA: 9s - loss: 0.2214 - accuracy: 0.9160\n",
      "140/750 [====>.........................] - ETA: 10s - loss: 0.2224 - accuracy: 0.9162\n",
      "420/750 [===============>..............] - ETA: 5s - loss: 0.3016 - accuracy: 0.8940\n",
      "168/750 [=====>........................] - ETA: 9s - loss: 0.2215 - accuracy: 0.9157\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 0.2262 - accuracy: 0.9163 - val_loss: 0.3374 - val_accuracy: 0.8878\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 13/30\n",
      "426/750 [================>.............] - ETA: 5s - loss: 0.3020 - accuracy: 0.8939\n",
      "172/750 [=====>........................] - ETA: 9s - loss: 0.2209 - accuracy: 0.9157\n",
      "364/750 [=============>................] - ETA: 7s - loss: 0.3001 - accuracy: 0.8944\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2263 - accuracy: 0.9162\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "430/750 [================>.............] - ETA: 5s - loss: 0.3020 - accuracy: 0.8938\n",
      "181/750 [======>.......................] - ETA: 9s - loss: 0.2187 - accuracy: 0.9164\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2264 - accuracy: 0.9162\n",
      " 15/750 [..............................] - ETA: 14s - loss: 0.2199 - accuracy: 0.9198\n",
      "437/750 [================>.............] - ETA: 5s - loss: 0.3026 - accuracy: 0.8937\n",
      "190/750 [======>.......................] - ETA: 8s - loss: 0.2217 - accuracy: 0.9165\n",
      "442/750 [================>.............] - ETA: 5s - loss: 0.3022 - accuracy: 0.8936\n",
      "196/750 [======>.......................] - ETA: 8s - loss: 0.2209 - accuracy: 0.9169\n",
      " 27/750 [>.............................] - ETA: 14s - loss: 0.2089 - accuracy: 0.9207\n",
      "456/750 [=================>............] - ETA: 5s - loss: 0.3021 - accuracy: 0.8931\n",
      "204/750 [=======>......................] - ETA: 8s - loss: 0.2213 - accuracy: 0.9164\n",
      "210/750 [=======>......................] - ETA: 8s - loss: 0.2205 - accuracy: 0.9164\n",
      "213/750 [=======>......................] - ETA: 8s - loss: 0.2202 - accuracy: 0.9164\n",
      "465/750 [=================>............] - ETA: 5s - loss: 0.3026 - accuracy: 0.8931\n",
      " 48/750 [>.............................] - ETA: 13s - loss: 0.2150 - accuracy: 0.9173\n",
      "477/750 [==================>...........] - ETA: 4s - loss: 0.3030 - accuracy: 0.8929\n",
      "224/750 [=======>......................] - ETA: 8s - loss: 0.2230 - accuracy: 0.9158\n",
      "482/750 [==================>...........] - ETA: 4s - loss: 0.3028 - accuracy: 0.8929\n",
      "486/750 [==================>...........] - ETA: 4s - loss: 0.3032 - accuracy: 0.8926\n",
      "238/750 [========>.....................] - ETA: 8s - loss: 0.2220 - accuracy: 0.9163\n",
      "495/750 [==================>...........] - ETA: 4s - loss: 0.3037 - accuracy: 0.8927\n",
      "248/750 [========>.....................] - ETA: 8s - loss: 0.2220 - accuracy: 0.9161\n",
      " 85/750 [==>...........................] - ETA: 11s - loss: 0.2120 - accuracy: 0.9199\n",
      "280/750 [==========>...................] - ETA: 7s - loss: 0.2227 - accuracy: 0.9162\n",
      "105/750 [===>..........................] - ETA: 11s - loss: 0.2119 - accuracy: 0.9180\n",
      "534/750 [====================>.........] - ETA: 3s - loss: 0.3031 - accuracy: 0.8924\n",
      "116/750 [===>..........................] - ETA: 10s - loss: 0.2129 - accuracy: 0.9173\n",
      "544/750 [====================>.........] - ETA: 3s - loss: 0.3040 - accuracy: 0.8921\n",
      "522/750 [===================>..........] - ETA: 4s - loss: 0.3032 - accuracy: 0.8923\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "124/750 [===>..........................] - ETA: 10s - loss: 0.2135 - accuracy: 0.9166\n",
      "553/750 [=====================>........] - ETA: 3s - loss: 0.3034 - accuracy: 0.8924\n",
      "244/750 [========>.....................] - ETA: 8s - loss: 0.2224 - accuracy: 0.9160\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "136/750 [====>.........................] - ETA: 10s - loss: 0.2127 - accuracy: 0.9176\n",
      "562/750 [=====================>........] - ETA: 3s - loss: 0.3027 - accuracy: 0.8926\n",
      "271/750 [=========>....................] - ETA: 7s - loss: 0.2234 - accuracy: 0.9158\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "145/750 [====>.........................] - ETA: 9s - loss: 0.2119 - accuracy: 0.9180 \n",
      "571/750 [=====================>........] - ETA: 3s - loss: 0.3020 - accuracy: 0.8929\n",
      "  5/750 [..............................] - ETA: 9s - loss: 0.1695 - accuracy: 0.9344\n",
      "583/750 [======================>.......] - ETA: 2s - loss: 0.3018 - accuracy: 0.8930\n",
      "252/750 [=========>....................] - ETA: 8s - loss: 0.2220 - accuracy: 0.9161\n",
      "591/750 [======================>.......] - ETA: 2s - loss: 0.3012 - accuracy: 0.8931\n",
      "347/750 [============>.................] - ETA: 6s - loss: 0.2238 - accuracy: 0.9158\n",
      " 10/750 [..............................] - ETA: 11s - loss: 0.2247 - accuracy: 0.9172\n",
      "180/750 [======>.......................] - ETA: 8s - loss: 0.2104 - accuracy: 0.9191\n",
      "603/750 [=======================>......] - ETA: 2s - loss: 0.3010 - accuracy: 0.8932\n",
      "355/750 [=============>................] - ETA: 6s - loss: 0.2242 - accuracy: 0.9158\n",
      "613/750 [=======================>......] - ETA: 2s - loss: 0.3009 - accuracy: 0.8934\n",
      "367/750 [=============>................] - ETA: 5s - loss: 0.2257 - accuracy: 0.9155\n",
      " 19/750 [..............................] - ETA: 16s - loss: 0.2133 - accuracy: 0.9211\n",
      "296/750 [==========>...................] - ETA: 7s - loss: 0.2211 - accuracy: 0.9166\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "628/750 [========================>.....] - ETA: 2s - loss: 0.3010 - accuracy: 0.8933\n",
      "632/750 [========================>.....] - ETA: 1s - loss: 0.3008 - accuracy: 0.8932\n",
      " 43/750 [>.............................] - ETA: 12s - loss: 0.2162 - accuracy: 0.9179\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "319/750 [===========>..................] - ETA: 6s - loss: 0.2223 - accuracy: 0.9166\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "641/750 [========================>.....] - ETA: 1s - loss: 0.3008 - accuracy: 0.8932\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.2999 - accuracy: 0.8935\n",
      "232/750 [========>.....................] - ETA: 7s - loss: 0.2071 - accuracy: 0.9214\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.3000 - accuracy: 0.8935\n",
      "324/750 [===========>..................] - ETA: 6s - loss: 0.2222 - accuracy: 0.9167\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "663/750 [=========================>....] - ETA: 1s - loss: 0.3003 - accuracy: 0.8935\n",
      "412/750 [===============>..............] - ETA: 5s - loss: 0.2262 - accuracy: 0.9163\n",
      " 72/750 [=>............................] - ETA: 11s - loss: 0.2084 - accuracy: 0.9217\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "668/750 [=========================>....] - ETA: 1s - loss: 0.3002 - accuracy: 0.8935\n",
      "338/750 [============>.................] - ETA: 6s - loss: 0.2231 - accuracy: 0.9161\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 74/750 [=>............................] - ETA: 12s - loss: 0.2091 - accuracy: 0.9215\n",
      "253/750 [=========>....................] - ETA: 7s - loss: 0.2083 - accuracy: 0.9211\n",
      "679/750 [==========================>...] - ETA: 1s - loss: 0.2994 - accuracy: 0.8937\n",
      "685/750 [==========================>...] - ETA: 1s - loss: 0.2991 - accuracy: 0.8937\n",
      "691/750 [==========================>...] - ETA: 0s - loss: 0.2986 - accuracy: 0.8939\n",
      "271/750 [=========>....................] - ETA: 6s - loss: 0.2104 - accuracy: 0.9205\n",
      "274/750 [=========>....................] - ETA: 6s - loss: 0.2112 - accuracy: 0.9205\n",
      "696/750 [==========================>...] - ETA: 0s - loss: 0.2988 - accuracy: 0.8938\n",
      " 97/750 [==>...........................] - ETA: 12s - loss: 0.2141 - accuracy: 0.9183\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2990 - accuracy: 0.8938\n",
      "452/750 [=================>............] - ETA: 4s - loss: 0.2275 - accuracy: 0.9162\n",
      "284/750 [==========>...................] - ETA: 6s - loss: 0.2129 - accuracy: 0.9201\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2989 - accuracy: 0.8938\n",
      "459/750 [=================>............] - ETA: 4s - loss: 0.2275 - accuracy: 0.9162\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2990 - accuracy: 0.8938\n",
      "466/750 [=================>............] - ETA: 4s - loss: 0.2280 - accuracy: 0.9161\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2987 - accuracy: 0.8938\n",
      "475/750 [==================>...........] - ETA: 4s - loss: 0.2266 - accuracy: 0.9165\n",
      "397/750 [==============>...............] - ETA: 5s - loss: 0.2259 - accuracy: 0.9160\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2982 - accuracy: 0.8939\n",
      "501/750 [===================>..........] - ETA: 3s - loss: 0.2268 - accuracy: 0.9168\n",
      "329/750 [============>.................] - ETA: 6s - loss: 0.2134 - accuracy: 0.9203\n",
      "421/750 [===============>..............] - ETA: 4s - loss: 0.2269 - accuracy: 0.9161\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "513/750 [===================>..........] - ETA: 3s - loss: 0.2263 - accuracy: 0.9169\n",
      "526/750 [====================>.........] - ETA: 3s - loss: 0.2266 - accuracy: 0.9170\n",
      "169/750 [=====>........................] - ETA: 8s - loss: 0.2112 - accuracy: 0.9189\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "350/750 [=============>................] - ETA: 5s - loss: 0.2131 - accuracy: 0.9202\n",
      "354/750 [=============>................] - ETA: 5s - loss: 0.2133 - accuracy: 0.9202\n",
      "362/750 [=============>................] - ETA: 5s - loss: 0.2142 - accuracy: 0.9198\n",
      "545/750 [====================>.........] - ETA: 2s - loss: 0.2281 - accuracy: 0.9165\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2979 - accuracy: 0.8940\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "447/750 [================>.............] - ETA: 4s - loss: 0.2279 - accuracy: 0.9160\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.2283 - accuracy: 0.9164\n",
      "551/750 [=====================>........] - ETA: 2s - loss: 0.2281 - accuracy: 0.9165\n",
      "198/750 [======>.......................] - ETA: 8s - loss: 0.2096 - accuracy: 0.9196\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "442/750 [================>.............] - ETA: 4s - loss: 0.2282 - accuracy: 0.9160\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "213/750 [=======>......................] - ETA: 7s - loss: 0.2087 - accuracy: 0.9211\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "495/750 [==================>...........] - ETA: 3s - loss: 0.2259 - accuracy: 0.9170\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "239/750 [========>.....................] - ETA: 7s - loss: 0.2076 - accuracy: 0.9213\n",
      "466/750 [=================>............] - ETA: 3s - loss: 0.2163 - accuracy: 0.9189\n",
      "750/750 [==============================] - 14s 19ms/step - loss: 0.2983 - accuracy: 0.8938 - val_loss: 0.3325 - val_accuracy: 0.8834\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 14/30\n",
      "  1/750 [..............................] - ETA: 6s - loss: 0.3591 - accuracy: 0.8594\n",
      " 12/750 [..............................] - ETA: 7s - loss: 0.2777 - accuracy: 0.9062 \n",
      "675/750 [==========================>...] - ETA: 1s - loss: 0.2293 - accuracy: 0.9159\n",
      "501/750 [===================>..........] - ETA: 3s - loss: 0.2165 - accuracy: 0.9186\n",
      " 26/750 [>.............................] - ETA: 6s - loss: 0.2787 - accuracy: 0.9044\n",
      "275/750 [==========>...................] - ETA: 6s - loss: 0.2119 - accuracy: 0.9205\n",
      "539/750 [====================>.........] - ETA: 3s - loss: 0.2279 - accuracy: 0.9167\n",
      " 35/750 [>.............................] - ETA: 6s - loss: 0.2728 - accuracy: 0.9058\n",
      "690/750 [==========================>...] - ETA: 0s - loss: 0.2294 - accuracy: 0.9158\n",
      " 43/750 [>.............................] - ETA: 7s - loss: 0.2920 - accuracy: 0.8972\n",
      "522/750 [===================>..........] - ETA: 3s - loss: 0.2162 - accuracy: 0.9189\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 55/750 [=>............................] - ETA: 7s - loss: 0.2879 - accuracy: 0.9003\n",
      "243/750 [========>.....................] - ETA: 7s - loss: 0.2067 - accuracy: 0.9216\n",
      "573/750 [=====================>........] - ETA: 2s - loss: 0.2280 - accuracy: 0.9164\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "548/750 [====================>.........] - ETA: 2s - loss: 0.2160 - accuracy: 0.9192\n",
      " 59/750 [=>............................] - ETA: 8s - loss: 0.2871 - accuracy: 0.9012\n",
      "264/750 [=========>....................] - ETA: 6s - loss: 0.2083 - accuracy: 0.9211\n",
      " 76/750 [==>...........................] - ETA: 7s - loss: 0.2868 - accuracy: 0.9038\n",
      "593/750 [======================>.......] - ETA: 2s - loss: 0.2279 - accuracy: 0.9167\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 84/750 [==>...........................] - ETA: 7s - loss: 0.2881 - accuracy: 0.9035\n",
      " 87/750 [==>...........................] - ETA: 7s - loss: 0.2916 - accuracy: 0.9018\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2290 - accuracy: 0.9157\n",
      "602/750 [=======================>......] - ETA: 2s - loss: 0.2280 - accuracy: 0.9166\n",
      " 98/750 [==>...........................] - ETA: 7s - loss: 0.2923 - accuracy: 0.9008\n",
      "587/750 [======================>.......] - ETA: 2s - loss: 0.2159 - accuracy: 0.9198\n",
      "374/750 [=============>................] - ETA: 5s - loss: 0.2137 - accuracy: 0.9197\n",
      "623/750 [=======================>......] - ETA: 1s - loss: 0.2287 - accuracy: 0.9162\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "102/750 [===>..........................] - ETA: 7s - loss: 0.2921 - accuracy: 0.9000\n",
      "294/750 [==========>...................] - ETA: 6s - loss: 0.2128 - accuracy: 0.9201\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "107/750 [===>..........................] - ETA: 8s - loss: 0.2902 - accuracy: 0.9011\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.2290 - accuracy: 0.9160\n",
      "119/750 [===>..........................] - ETA: 8s - loss: 0.2896 - accuracy: 0.9006\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 0.2158 - accuracy: 0.9197\n",
      "317/750 [===========>..................] - ETA: 6s - loss: 0.2133 - accuracy: 0.9202\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "645/750 [========================>.....] - ETA: 1s - loss: 0.2290 - accuracy: 0.9160\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "125/750 [====>.........................] - ETA: 7s - loss: 0.2895 - accuracy: 0.9003\n",
      "611/750 [=======================>......] - ETA: 1s - loss: 0.2159 - accuracy: 0.9195\n",
      "309/750 [===========>..................] - ETA: 6s - loss: 0.2143 - accuracy: 0.9193\n",
      "129/750 [====>.........................] - ETA: 8s - loss: 0.2876 - accuracy: 0.9008\n",
      "667/750 [=========================>....] - ETA: 1s - loss: 0.2291 - accuracy: 0.9160\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.2155 - accuracy: 0.9198\n",
      "137/750 [====>.........................] - ETA: 8s - loss: 0.2889 - accuracy: 0.9001\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.2157 - accuracy: 0.9197\n",
      "144/750 [====>.........................] - ETA: 8s - loss: 0.2876 - accuracy: 0.9007\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.2155 - accuracy: 0.9197\n",
      "648/750 [========================>.....] - ETA: 1s - loss: 0.2165 - accuracy: 0.9192\n",
      "341/750 [============>.................] - ETA: 5s - loss: 0.2126 - accuracy: 0.9203\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.2294 - accuracy: 0.9158\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "175/750 [======>.......................] - ETA: 7s - loss: 0.2914 - accuracy: 0.8979\n",
      "667/750 [=========================>....] - ETA: 1s - loss: 0.2163 - accuracy: 0.9191\n",
      "176/750 [======>.......................] - ETA: 8s - loss: 0.2921 - accuracy: 0.8978\n",
      "670/750 [=========================>....] - ETA: 1s - loss: 0.2165 - accuracy: 0.9191\n",
      "450/750 [=================>............] - ETA: 4s - loss: 0.2164 - accuracy: 0.9190\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2281 - accuracy: 0.9160\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "472/750 [=================>............] - ETA: 3s - loss: 0.2163 - accuracy: 0.9190\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:04:50,896 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6035144704; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726/750 [============================>.] - ETA: 0s - loss: 0.2281 - accuracy: 0.9159\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2160 - accuracy: 0.9190\n",
      "397/750 [==============>...............] - ETA: 4s - loss: 0.2154 - accuracy: 0.9194\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "223/750 [=======>......................] - ETA: 7s - loss: 0.2931 - accuracy: 0.8969\n",
      "421/750 [===============>..............] - ETA: 4s - loss: 0.2165 - accuracy: 0.9190\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "229/750 [========>.....................] - ETA: 7s - loss: 0.2915 - accuracy: 0.8977\n",
      "158/750 [=====>........................] - ETA: 8s - loss: 0.2899 - accuracy: 0.8996\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9189\n",
      "233/750 [========>.....................] - ETA: 8s - loss: 0.2915 - accuracy: 0.8974\n",
      "239/750 [========>.....................] - ETA: 8s - loss: 0.2911 - accuracy: 0.8975\n",
      "534/750 [====================>.........] - ETA: 2s - loss: 0.2159 - accuracy: 0.9192\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2290 - accuracy: 0.9156\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "556/750 [=====================>........] - ETA: 2s - loss: 0.2172 - accuracy: 0.9191\n",
      "196/750 [======>.......................] - ETA: 7s - loss: 0.2930 - accuracy: 0.8980\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "441/750 [================>.............] - ETA: 4s - loss: 0.2173 - accuracy: 0.9188\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "240/750 [========>.....................] - ETA: 8s - loss: 0.2913 - accuracy: 0.8972\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9190\n",
      "247/750 [========>.....................] - ETA: 8s - loss: 0.2894 - accuracy: 0.8978\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9191\n",
      "254/750 [=========>....................] - ETA: 7s - loss: 0.2893 - accuracy: 0.8973\n",
      "263/750 [=========>....................] - ETA: 7s - loss: 0.2881 - accuracy: 0.8980\n",
      "216/750 [=======>......................] - ETA: 7s - loss: 0.2931 - accuracy: 0.8970\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "268/750 [=========>....................] - ETA: 7s - loss: 0.2879 - accuracy: 0.8980\n",
      " 13/750 [..............................] - ETA: 6s - loss: 0.2345 - accuracy: 0.9099\n",
      "490/750 [==================>...........] - ETA: 3s - loss: 0.2171 - accuracy: 0.9187\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "275/750 [==========>...................] - ETA: 7s - loss: 0.2879 - accuracy: 0.8979\n",
      " 19/750 [..............................] - ETA: 7s - loss: 0.2234 - accuracy: 0.9202\n",
      "302/750 [===========>..................] - ETA: 6s - loss: 0.2876 - accuracy: 0.8980\n",
      " 51/750 [=>............................] - ETA: 9s - loss: 0.2161 - accuracy: 0.9219\n",
      "314/750 [===========>..................] - ETA: 6s - loss: 0.2886 - accuracy: 0.8978\n",
      " 66/750 [=>............................] - ETA: 8s - loss: 0.2133 - accuracy: 0.9245\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.2290 - accuracy: 0.9157 - val_loss: 0.4184 - val_accuracy: 0.8786\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 15/30\n",
      "  1/750 [..............................] - ETA: 17s - loss: 0.1485 - accuracy: 0.9062\n",
      " 73/750 [=>............................] - ETA: 8s - loss: 0.2104 - accuracy: 0.9262\n",
      "331/750 [============>.................] - ETA: 6s - loss: 0.2908 - accuracy: 0.8970\n",
      " 29/750 [>.............................] - ETA: 8s - loss: 0.2287 - accuracy: 0.9197\n",
      "341/750 [============>.................] - ETA: 6s - loss: 0.2897 - accuracy: 0.8979\n",
      " 45/750 [>.............................] - ETA: 7s - loss: 0.2189 - accuracy: 0.9215\n",
      "349/750 [============>.................] - ETA: 6s - loss: 0.2905 - accuracy: 0.8976\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.2159 - accuracy: 0.9191\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 42/750 [>.............................] - ETA: 7s - loss: 0.2233 - accuracy: 0.9182\n",
      "361/750 [=============>................] - ETA: 5s - loss: 0.2917 - accuracy: 0.8971\n",
      "366/750 [=============>................] - ETA: 5s - loss: 0.2913 - accuracy: 0.8973\n",
      "574/750 [=====================>........] - ETA: 2s - loss: 0.2165 - accuracy: 0.9194\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "377/750 [==============>...............] - ETA: 5s - loss: 0.2920 - accuracy: 0.8970\n",
      "127/750 [====>.........................] - ETA: 7s - loss: 0.2181 - accuracy: 0.9203\n",
      "382/750 [==============>...............] - ETA: 5s - loss: 0.2913 - accuracy: 0.8973\n",
      "141/750 [====>.........................] - ETA: 7s - loss: 0.2185 - accuracy: 0.9202\n",
      "599/750 [======================>.......] - ETA: 2s - loss: 0.2157 - accuracy: 0.9198\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 95/750 [==>...........................] - ETA: 8s - loss: 0.2173 - accuracy: 0.9220\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "154/750 [=====>........................] - ETA: 7s - loss: 0.2197 - accuracy: 0.9204\n",
      "157/750 [=====>........................] - ETA: 7s - loss: 0.2190 - accuracy: 0.9206\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.2162 - accuracy: 0.9190 - val_loss: 0.3534 - val_accuracy: 0.8814\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 14/30\n",
      "  1/750 [..............................] - ETA: 6s - loss: 0.1598 - accuracy: 0.9219\n",
      "616/750 [=======================>......] - ETA: 1s - loss: 0.2161 - accuracy: 0.9195\n",
      "101/750 [===>..........................] - ETA: 7s - loss: 0.2154 - accuracy: 0.9223\n",
      " 16/750 [..............................] - ETA: 13s - loss: 0.2138 - accuracy: 0.9180\n",
      "291/750 [==========>...................] - ETA: 7s - loss: 0.2880 - accuracy: 0.8978\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "119/750 [===>..........................] - ETA: 7s - loss: 0.2185 - accuracy: 0.9207\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 30/750 [>.............................] - ETA: 9s - loss: 0.2087 - accuracy: 0.9224 \n",
      " 40/750 [>.............................] - ETA: 8s - loss: 0.2171 - accuracy: 0.9176\n",
      "454/750 [=================>............] - ETA: 4s - loss: 0.2922 - accuracy: 0.8973\n",
      "321/750 [===========>..................] - ETA: 6s - loss: 0.2897 - accuracy: 0.8976\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "148/750 [====>.........................] - ETA: 7s - loss: 0.2191 - accuracy: 0.9204\n",
      " 49/750 [>.............................] - ETA: 9s - loss: 0.2101 - accuracy: 0.9196\n",
      "459/750 [=================>............] - ETA: 4s - loss: 0.2917 - accuracy: 0.8974\n",
      "664/750 [=========================>....] - ETA: 1s - loss: 0.2166 - accuracy: 0.9191\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 52/750 [=>............................] - ETA: 9s - loss: 0.2080 - accuracy: 0.9201\n",
      "462/750 [=================>............] - ETA: 4s - loss: 0.2914 - accuracy: 0.8974\n",
      "466/750 [=================>............] - ETA: 4s - loss: 0.2909 - accuracy: 0.8975\n",
      "468/750 [=================>............] - ETA: 4s - loss: 0.2913 - accuracy: 0.8972\n",
      " 59/750 [=>............................] - ETA: 10s - loss: 0.2077 - accuracy: 0.9200\n",
      "226/750 [========>.....................] - ETA: 6s - loss: 0.2238 - accuracy: 0.9204\n",
      " 63/750 [=>............................] - ETA: 10s - loss: 0.2046 - accuracy: 0.9214\n",
      "476/750 [==================>...........] - ETA: 4s - loss: 0.2916 - accuracy: 0.8971\n",
      " 71/750 [=>............................] - ETA: 10s - loss: 0.2072 - accuracy: 0.9188\n",
      "487/750 [==================>...........] - ETA: 3s - loss: 0.2913 - accuracy: 0.8974\n",
      "688/750 [==========================>...] - ETA: 0s - loss: 0.2160 - accuracy: 0.9191\n",
      " 79/750 [==>...........................] - ETA: 10s - loss: 0.2084 - accuracy: 0.9191\n",
      "490/750 [==================>...........] - ETA: 3s - loss: 0.2911 - accuracy: 0.8975\n",
      "178/750 [======>.......................] - ETA: 6s - loss: 0.2234 - accuracy: 0.9197\n",
      " 84/750 [==>...........................] - ETA: 10s - loss: 0.2087 - accuracy: 0.9191\n",
      " 93/750 [==>...........................] - ETA: 10s - loss: 0.2090 - accuracy: 0.9195\n",
      "506/750 [===================>..........] - ETA: 3s - loss: 0.2914 - accuracy: 0.8974\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2161 - accuracy: 0.9189\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "102/750 [===>..........................] - ETA: 10s - loss: 0.2136 - accuracy: 0.9182\n",
      "512/750 [===================>..........] - ETA: 3s - loss: 0.2916 - accuracy: 0.8972\n",
      "109/750 [===>..........................] - ETA: 9s - loss: 0.2156 - accuracy: 0.9179 \n",
      "518/750 [===================>..........] - ETA: 3s - loss: 0.2920 - accuracy: 0.8968\n",
      "526/750 [====================>.........] - ETA: 3s - loss: 0.2916 - accuracy: 0.8968\n",
      "392/750 [==============>...............] - ETA: 5s - loss: 0.2905 - accuracy: 0.8979\n",
      "212/750 [=======>......................] - ETA: 6s - loss: 0.2251 - accuracy: 0.9203\n",
      "142/750 [====>.........................] - ETA: 8s - loss: 0.2110 - accuracy: 0.9198\n",
      "548/750 [====================>.........] - ETA: 2s - loss: 0.2904 - accuracy: 0.8974\n",
      "551/750 [=====================>........] - ETA: 2s - loss: 0.2906 - accuracy: 0.8971\n",
      "151/750 [=====>........................] - ETA: 8s - loss: 0.2112 - accuracy: 0.9194\n",
      "557/750 [=====================>........] - ETA: 2s - loss: 0.2904 - accuracy: 0.8972\n",
      "563/750 [=====================>........] - ETA: 2s - loss: 0.2901 - accuracy: 0.8972\n",
      "566/750 [=====================>........] - ETA: 2s - loss: 0.2904 - accuracy: 0.8970\n",
      "424/750 [===============>..............] - ETA: 4s - loss: 0.2902 - accuracy: 0.8981\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "248/750 [========>.....................] - ETA: 6s - loss: 0.2234 - accuracy: 0.9203\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "157/750 [=====>........................] - ETA: 8s - loss: 0.2118 - accuracy: 0.9192\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.2899 - accuracy: 0.8972\n",
      "597/750 [======================>.......] - ETA: 2s - loss: 0.2904 - accuracy: 0.8967\n",
      "346/750 [============>.................] - ETA: 5s - loss: 0.2205 - accuracy: 0.9205\n",
      "599/750 [======================>.......] - ETA: 2s - loss: 0.2904 - accuracy: 0.8968\n",
      "357/750 [=============>................] - ETA: 5s - loss: 0.2204 - accuracy: 0.9205\n",
      "540/750 [====================>.........] - ETA: 3s - loss: 0.2906 - accuracy: 0.8974\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9189\n",
      "604/750 [=======================>......] - ETA: 2s - loss: 0.2907 - accuracy: 0.8967\n",
      "195/750 [======>.......................] - ETA: 7s - loss: 0.2110 - accuracy: 0.9205\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "441/750 [================>.............] - ETA: 4s - loss: 0.2920 - accuracy: 0.8976\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "611/750 [=======================>......] - ETA: 2s - loss: 0.2904 - accuracy: 0.8968\n",
      "216/750 [=======>......................] - ETA: 7s - loss: 0.2114 - accuracy: 0.9206\n",
      "620/750 [=======================>......] - ETA: 1s - loss: 0.2903 - accuracy: 0.8967\n",
      "383/750 [==============>...............] - ETA: 4s - loss: 0.2201 - accuracy: 0.9200\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.2900 - accuracy: 0.8966\n",
      "223/750 [=======>......................] - ETA: 7s - loss: 0.2106 - accuracy: 0.9210\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "274/750 [=========>....................] - ETA: 6s - loss: 0.2216 - accuracy: 0.9206\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.2893 - accuracy: 0.8967\n",
      "403/750 [===============>..............] - ETA: 4s - loss: 0.2207 - accuracy: 0.9200\n",
      "499/750 [==================>...........] - ETA: 3s - loss: 0.2914 - accuracy: 0.8974\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "237/750 [========>.....................] - ETA: 7s - loss: 0.2100 - accuracy: 0.9215\n",
      "649/750 [========================>.....] - ETA: 1s - loss: 0.2906 - accuracy: 0.8962\n",
      "  5/750 [..............................] - ETA: 28s - loss: 0.2004 - accuracy: 0.9156\n",
      "254/750 [=========>....................] - ETA: 6s - loss: 0.2091 - accuracy: 0.9222\n",
      "663/750 [=========================>....] - ETA: 1s - loss: 0.2910 - accuracy: 0.8960\n",
      "302/750 [===========>..................] - ETA: 5s - loss: 0.2217 - accuracy: 0.9205\n",
      "274/750 [=========>....................] - ETA: 6s - loss: 0.2102 - accuracy: 0.9220\n",
      "318/750 [===========>..................] - ETA: 5s - loss: 0.2214 - accuracy: 0.9207\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "291/750 [==========>...................] - ETA: 6s - loss: 0.2108 - accuracy: 0.9218\n",
      "459/750 [=================>............] - ETA: 3s - loss: 0.2182 - accuracy: 0.9206\n",
      " 56/750 [=>............................] - ETA: 10s - loss: 0.2087 - accuracy: 0.9199\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.2912 - accuracy: 0.8957\n",
      "467/750 [=================>............] - ETA: 3s - loss: 0.2181 - accuracy: 0.9206\n",
      "343/750 [============>.................] - ETA: 5s - loss: 0.2204 - accuracy: 0.9206\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "301/750 [===========>..................] - ETA: 6s - loss: 0.2102 - accuracy: 0.9218\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.2912 - accuracy: 0.8957\n",
      "473/750 [=================>............] - ETA: 3s - loss: 0.2185 - accuracy: 0.9209\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2916 - accuracy: 0.8955\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2916 - accuracy: 0.8956\n",
      "692/750 [==========================>...] - ETA: 0s - loss: 0.2913 - accuracy: 0.8956\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "366/750 [=============>................] - ETA: 4s - loss: 0.2201 - accuracy: 0.9204\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2914 - accuracy: 0.8957\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2916 - accuracy: 0.8955\n",
      "377/750 [==============>...............] - ETA: 4s - loss: 0.2203 - accuracy: 0.9199\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2920 - accuracy: 0.8954\n",
      "125/750 [====>.........................] - ETA: 9s - loss: 0.2119 - accuracy: 0.9186\n",
      "386/750 [==============>...............] - ETA: 4s - loss: 0.2207 - accuracy: 0.9197\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2921 - accuracy: 0.8953\n",
      "351/750 [=============>................] - ETA: 5s - loss: 0.2106 - accuracy: 0.9221\n",
      "590/750 [======================>.......] - ETA: 2s - loss: 0.2898 - accuracy: 0.8972\n",
      "356/750 [=============>................] - ETA: 5s - loss: 0.2110 - accuracy: 0.9221\n",
      "365/750 [=============>................] - ETA: 5s - loss: 0.2117 - accuracy: 0.9215\n",
      "375/750 [==============>...............] - ETA: 5s - loss: 0.2118 - accuracy: 0.9212\n",
      "380/750 [==============>...............] - ETA: 5s - loss: 0.2123 - accuracy: 0.9208\n",
      "295/750 [==========>...................] - ETA: 5s - loss: 0.2218 - accuracy: 0.9206\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "120/750 [===>..........................] - ETA: 9s - loss: 0.2149 - accuracy: 0.9180\n",
      "384/750 [==============>...............] - ETA: 5s - loss: 0.2122 - accuracy: 0.9208\n",
      "562/750 [=====================>........] - ETA: 2s - loss: 0.2194 - accuracy: 0.9202\n",
      "315/750 [===========>..................] - ETA: 5s - loss: 0.2107 - accuracy: 0.9219\n",
      "453/750 [=================>............] - ETA: 3s - loss: 0.2180 - accuracy: 0.9207\n",
      "671/750 [=========================>....] - ETA: 1s - loss: 0.2909 - accuracy: 0.8959\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "408/750 [===============>..............] - ETA: 4s - loss: 0.2121 - accuracy: 0.9208\n",
      "411/750 [===============>..............] - ETA: 4s - loss: 0.2118 - accuracy: 0.9208\n",
      "583/750 [======================>.......] - ETA: 2s - loss: 0.2203 - accuracy: 0.9199\n",
      "587/750 [======================>.......] - ETA: 2s - loss: 0.2204 - accuracy: 0.9198\n",
      "596/750 [======================>.......] - ETA: 2s - loss: 0.2214 - accuracy: 0.9194\n",
      "491/750 [==================>...........] - ETA: 3s - loss: 0.2185 - accuracy: 0.9209\n",
      "602/750 [=======================>......] - ETA: 2s - loss: 0.2215 - accuracy: 0.9195\n",
      "454/750 [=================>............] - ETA: 4s - loss: 0.2101 - accuracy: 0.9217\n",
      "514/750 [===================>..........] - ETA: 3s - loss: 0.2191 - accuracy: 0.9208\n",
      "518/750 [===================>..........] - ETA: 3s - loss: 0.2193 - accuracy: 0.9206\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "466/750 [=================>............] - ETA: 4s - loss: 0.2104 - accuracy: 0.9214\n",
      "479/750 [==================>...........] - ETA: 3s - loss: 0.2098 - accuracy: 0.9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:05:00,914 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6034767872; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654/750 [=========================>....] - ETA: 1s - loss: 0.2222 - accuracy: 0.9190\n",
      "529/750 [====================>.........] - ETA: 2s - loss: 0.2189 - accuracy: 0.9208\n",
      "499/750 [==================>...........] - ETA: 3s - loss: 0.2098 - accuracy: 0.9220\n",
      "502/750 [===================>..........] - ETA: 3s - loss: 0.2100 - accuracy: 0.9221\n",
      "546/750 [====================>.........] - ETA: 2s - loss: 0.2193 - accuracy: 0.9202\n",
      "570/750 [=====================>........] - ETA: 2s - loss: 0.2198 - accuracy: 0.9202\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "677/750 [==========================>...] - ETA: 0s - loss: 0.2225 - accuracy: 0.9192\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.2920 - accuracy: 0.8954 - val_loss: 0.3347 - val_accuracy: 0.8814\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 15/30\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.3005 - accuracy: 0.8906\n",
      " 11/750 [..............................] - ETA: 3s - loss: 0.2931 - accuracy: 0.8935\n",
      "424/750 [===============>..............] - ETA: 4s - loss: 0.2114 - accuracy: 0.9210\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "248/750 [========>.....................] - ETA: 6s - loss: 0.2095 - accuracy: 0.9219\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "171/750 [=====>........................] - ETA: 8s - loss: 0.2126 - accuracy: 0.9196\n",
      "539/750 [====================>.........] - ETA: 2s - loss: 0.2094 - accuracy: 0.9222\n",
      " 19/750 [..............................] - ETA: 8s - loss: 0.2779 - accuracy: 0.9005\n",
      " 34/750 [>.............................] - ETA: 7s - loss: 0.2884 - accuracy: 0.8948\n",
      "341/750 [============>.................] - ETA: 5s - loss: 0.2118 - accuracy: 0.9217\n",
      " 39/750 [>.............................] - ETA: 8s - loss: 0.2835 - accuracy: 0.8962\n",
      "546/750 [====================>.........] - ETA: 2s - loss: 0.2089 - accuracy: 0.9224\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.2219 - accuracy: 0.9195\n",
      " 48/750 [>.............................] - ETA: 8s - loss: 0.2857 - accuracy: 0.8962\n",
      "442/750 [================>.............] - ETA: 4s - loss: 0.2104 - accuracy: 0.9213\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "578/750 [======================>.......] - ETA: 2s - loss: 0.2090 - accuracy: 0.9223\n",
      " 59/750 [=>............................] - ETA: 8s - loss: 0.2844 - accuracy: 0.8935\n",
      " 69/750 [=>............................] - ETA: 8s - loss: 0.2898 - accuracy: 0.8918\n",
      "395/750 [==============>...............] - ETA: 5s - loss: 0.2129 - accuracy: 0.9205\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.2215 - accuracy: 0.9194\n",
      "591/750 [======================>.......] - ETA: 2s - loss: 0.2078 - accuracy: 0.9227\n",
      " 72/750 [=>............................] - ETA: 8s - loss: 0.2915 - accuracy: 0.8911\n",
      "268/750 [=========>....................] - ETA: 6s - loss: 0.2098 - accuracy: 0.9219\n",
      "642/750 [========================>.....] - ETA: 1s - loss: 0.2221 - accuracy: 0.9192\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 85/750 [==>...........................] - ETA: 8s - loss: 0.2954 - accuracy: 0.8904\n",
      "610/750 [=======================>......] - ETA: 1s - loss: 0.2080 - accuracy: 0.9226\n",
      "403/750 [===============>..............] - ETA: 4s - loss: 0.2126 - accuracy: 0.9206\n",
      "495/750 [==================>...........] - ETA: 3s - loss: 0.2094 - accuracy: 0.9220\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 94/750 [==>...........................] - ETA: 8s - loss: 0.2984 - accuracy: 0.8888\n",
      "620/750 [=======================>......] - ETA: 1s - loss: 0.2078 - accuracy: 0.9225\n",
      "105/750 [===>..........................] - ETA: 7s - loss: 0.2954 - accuracy: 0.8896\n",
      "628/750 [========================>.....] - ETA: 1s - loss: 0.2089 - accuracy: 0.9221\n",
      "670/750 [=========================>....] - ETA: 1s - loss: 0.2225 - accuracy: 0.9191\n",
      "112/750 [===>..........................] - ETA: 7s - loss: 0.2923 - accuracy: 0.8899\n",
      "120/750 [===>..........................] - ETA: 7s - loss: 0.2901 - accuracy: 0.8915\n",
      "128/750 [====>.........................] - ETA: 7s - loss: 0.2884 - accuracy: 0.8925\n",
      "323/750 [===========>..................] - ETA: 5s - loss: 0.2104 - accuracy: 0.9221\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "140/750 [====>.........................] - ETA: 7s - loss: 0.2884 - accuracy: 0.8930\n",
      "458/750 [=================>............] - ETA: 4s - loss: 0.2108 - accuracy: 0.9214\n",
      "148/750 [====>.........................] - ETA: 7s - loss: 0.2856 - accuracy: 0.8942\n",
      "339/750 [============>.................] - ETA: 5s - loss: 0.2120 - accuracy: 0.9216\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2233 - accuracy: 0.9191\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "159/750 [=====>........................] - ETA: 7s - loss: 0.2860 - accuracy: 0.8948\n",
      "682/750 [==========================>...] - ETA: 0s - loss: 0.2082 - accuracy: 0.9226\n",
      "167/750 [=====>........................] - ETA: 7s - loss: 0.2849 - accuracy: 0.8950\n",
      "178/750 [======>.......................] - ETA: 6s - loss: 0.2847 - accuracy: 0.8957\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.2081 - accuracy: 0.9226\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2245 - accuracy: 0.9185\n",
      "191/750 [======>.......................] - ETA: 6s - loss: 0.2827 - accuracy: 0.8969\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2240 - accuracy: 0.9186\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "193/750 [======>.......................] - ETA: 6s - loss: 0.2834 - accuracy: 0.8968\n",
      "205/750 [=======>......................] - ETA: 6s - loss: 0.2824 - accuracy: 0.8976\n",
      "217/750 [=======>......................] - ETA: 6s - loss: 0.2806 - accuracy: 0.8978\n",
      "230/750 [========>.....................] - ETA: 6s - loss: 0.2796 - accuracy: 0.8984\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2103 - accuracy: 0.9220\n",
      "235/750 [========>.....................] - ETA: 6s - loss: 0.2800 - accuracy: 0.8986\n",
      "242/750 [========>.....................] - ETA: 5s - loss: 0.2816 - accuracy: 0.8982\n",
      "248/750 [========>.....................] - ETA: 5s - loss: 0.2819 - accuracy: 0.8977\n",
      "254/750 [=========>....................] - ETA: 5s - loss: 0.2813 - accuracy: 0.8979\n",
      " 25/750 [>.............................] - ETA: 10s - loss: 0.1979 - accuracy: 0.9262\n",
      "263/750 [=========>....................] - ETA: 5s - loss: 0.2813 - accuracy: 0.8983\n",
      " 32/750 [>.............................] - ETA: 9s - loss: 0.1922 - accuracy: 0.9292 \n",
      "277/750 [==========>...................] - ETA: 5s - loss: 0.2804 - accuracy: 0.8983\n",
      "288/750 [==========>...................] - ETA: 5s - loss: 0.2803 - accuracy: 0.8984\n",
      " 52/750 [=>............................] - ETA: 8s - loss: 0.1920 - accuracy: 0.9279\n",
      "566/750 [=====================>........] - ETA: 2s - loss: 0.2086 - accuracy: 0.9226\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "291/750 [==========>...................] - ETA: 5s - loss: 0.2802 - accuracy: 0.8984\n",
      "303/750 [===========>..................] - ETA: 5s - loss: 0.2810 - accuracy: 0.8980\n",
      "665/750 [=========================>....] - ETA: 1s - loss: 0.2085 - accuracy: 0.9224\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "312/750 [===========>..................] - ETA: 5s - loss: 0.2822 - accuracy: 0.8972\n",
      "588/750 [======================>.......] - ETA: 2s - loss: 0.2081 - accuracy: 0.9226\n",
      "321/750 [===========>..................] - ETA: 5s - loss: 0.2817 - accuracy: 0.8974\n",
      " 97/750 [==>...........................] - ETA: 8s - loss: 0.2055 - accuracy: 0.9217\n",
      "102/750 [===>..........................] - ETA: 7s - loss: 0.2088 - accuracy: 0.9210\n",
      "354/750 [=============>................] - ETA: 4s - loss: 0.2823 - accuracy: 0.8978\n",
      "120/750 [===>..........................] - ETA: 7s - loss: 0.2129 - accuracy: 0.9184\n",
      "600/750 [=======================>......] - ETA: 2s - loss: 0.2077 - accuracy: 0.9227\n",
      "367/750 [=============>................] - ETA: 4s - loss: 0.2829 - accuracy: 0.8978\n",
      "381/750 [==============>...............] - ETA: 4s - loss: 0.2827 - accuracy: 0.8976\n",
      "387/750 [==============>...............] - ETA: 4s - loss: 0.2832 - accuracy: 0.8975\n",
      "147/750 [====>.........................] - ETA: 6s - loss: 0.2210 - accuracy: 0.9158\n",
      "522/750 [===================>..........] - ETA: 3s - loss: 0.2088 - accuracy: 0.9223\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "392/750 [==============>...............] - ETA: 4s - loss: 0.2838 - accuracy: 0.8974\n",
      "401/750 [===============>..............] - ETA: 4s - loss: 0.2838 - accuracy: 0.8970\n",
      " 11/750 [..............................] - ETA: 14s - loss: 0.1899 - accuracy: 0.9276\n",
      " 18/750 [..............................] - ETA: 11s - loss: 0.1794 - accuracy: 0.9323\n",
      "676/750 [==========================>...] - ETA: 0s - loss: 0.2082 - accuracy: 0.9226\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2101 - accuracy: 0.9221 - val_loss: 0.3352 - val_accuracy: 0.8914\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 15/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 19s - loss: 0.2311 - accuracy: 0.8906\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 41/750 [>.............................] - ETA: 9s - loss: 0.1947 - accuracy: 0.9238\n",
      "434/750 [================>.............] - ETA: 3s - loss: 0.2855 - accuracy: 0.8963\n",
      "  7/750 [..............................] - ETA: 6s - loss: 0.1645 - accuracy: 0.9420\n",
      "419/750 [===============>..............] - ETA: 3s - loss: 0.2843 - accuracy: 0.8969\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 13/750 [..............................] - ETA: 13s - loss: 0.1946 - accuracy: 0.9267\n",
      "455/750 [=================>............] - ETA: 3s - loss: 0.2862 - accuracy: 0.8962\n",
      "458/750 [=================>............] - ETA: 3s - loss: 0.2866 - accuracy: 0.8961\n",
      "231/750 [========>.....................] - ETA: 6s - loss: 0.2212 - accuracy: 0.9190\n",
      " 48/750 [>.............................] - ETA: 9s - loss: 0.1989 - accuracy: 0.9238\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "471/750 [=================>............] - ETA: 3s - loss: 0.2861 - accuracy: 0.8962\n",
      "241/750 [========>.....................] - ETA: 5s - loss: 0.2215 - accuracy: 0.9185\n",
      "250/750 [=========>....................] - ETA: 5s - loss: 0.2246 - accuracy: 0.9175\n",
      "447/750 [================>.............] - ETA: 3s - loss: 0.2860 - accuracy: 0.8963\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 72/750 [=>............................] - ETA: 8s - loss: 0.1951 - accuracy: 0.9236\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "501/750 [===================>..........] - ETA: 2s - loss: 0.2859 - accuracy: 0.8963\n",
      "648/750 [========================>.....] - ETA: 1s - loss: 0.2082 - accuracy: 0.9225\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 98/750 [==>...........................] - ETA: 7s - loss: 0.1957 - accuracy: 0.9241\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "125/750 [====>.........................] - ETA: 7s - loss: 0.1976 - accuracy: 0.9243\n",
      "523/750 [===================>..........] - ETA: 2s - loss: 0.2871 - accuracy: 0.8963\n",
      "489/750 [==================>...........] - ETA: 3s - loss: 0.2867 - accuracy: 0.8960\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "530/750 [====================>.........] - ETA: 2s - loss: 0.2871 - accuracy: 0.8963\n",
      "108/750 [===>..........................] - ETA: 7s - loss: 0.1994 - accuracy: 0.9242\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.2862 - accuracy: 0.8966\n",
      "152/750 [=====>........................] - ETA: 7s - loss: 0.1979 - accuracy: 0.9248\n",
      "558/750 [=====================>........] - ETA: 2s - loss: 0.2861 - accuracy: 0.8967\n",
      "145/750 [====>.........................] - ETA: 7s - loss: 0.1977 - accuracy: 0.9242\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "562/750 [=====================>........] - ETA: 2s - loss: 0.2860 - accuracy: 0.8968\n",
      "323/750 [===========>..................] - ETA: 5s - loss: 0.2236 - accuracy: 0.9183\n",
      "339/750 [============>.................] - ETA: 4s - loss: 0.2238 - accuracy: 0.9183\n",
      "580/750 [======================>.......] - ETA: 2s - loss: 0.2853 - accuracy: 0.8973\n",
      "349/750 [============>.................] - ETA: 4s - loss: 0.2249 - accuracy: 0.9182\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2096 - accuracy: 0.9223\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "161/750 [=====>........................] - ETA: 7s - loss: 0.2004 - accuracy: 0.9246\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "589/750 [======================>.......] - ETA: 1s - loss: 0.2855 - accuracy: 0.8972\n",
      "352/750 [=============>................] - ETA: 4s - loss: 0.2253 - accuracy: 0.9181\n",
      "175/750 [======>.......................] - ETA: 7s - loss: 0.2005 - accuracy: 0.9250\n",
      "596/750 [======================>.......] - ETA: 1s - loss: 0.2853 - accuracy: 0.8974\n",
      "354/750 [=============>................] - ETA: 4s - loss: 0.2252 - accuracy: 0.9181\n",
      "194/750 [======>.......................] - ETA: 7s - loss: 0.2008 - accuracy: 0.9255\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.2850 - accuracy: 0.8975\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2099 - accuracy: 0.9222\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "185/750 [======>.......................] - ETA: 7s - loss: 0.2006 - accuracy: 0.9256\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "615/750 [=======================>......] - ETA: 1s - loss: 0.2853 - accuracy: 0.8973\n",
      "200/750 [=======>......................] - ETA: 7s - loss: 0.2006 - accuracy: 0.9253\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.2856 - accuracy: 0.8972\n",
      "221/750 [=======>......................] - ETA: 6s - loss: 0.2005 - accuracy: 0.9248\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "631/750 [========================>.....] - ETA: 1s - loss: 0.2855 - accuracy: 0.8974\n",
      "413/750 [===============>..............] - ETA: 4s - loss: 0.2242 - accuracy: 0.9179\n",
      "233/750 [========>.....................] - ETA: 6s - loss: 0.1990 - accuracy: 0.9256\n",
      "249/750 [========>.....................] - ETA: 6s - loss: 0.2002 - accuracy: 0.9252\n",
      "269/750 [=========>....................] - ETA: 5s - loss: 0.2245 - accuracy: 0.9180\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 25/750 [>.............................] - ETA: 11s - loss: 0.1904 - accuracy: 0.9262\n",
      "676/750 [==========================>...] - ETA: 0s - loss: 0.2858 - accuracy: 0.8977\n",
      "450/750 [=================>............] - ETA: 3s - loss: 0.2225 - accuracy: 0.9185\n",
      " 31/750 [>.............................] - ETA: 10s - loss: 0.1862 - accuracy: 0.9289\n",
      "685/750 [==========================>...] - ETA: 0s - loss: 0.2861 - accuracy: 0.8972\n",
      "299/750 [==========>...................] - ETA: 5s - loss: 0.2244 - accuracy: 0.9175\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "694/750 [==========================>...] - ETA: 0s - loss: 0.2854 - accuracy: 0.8976\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.2853 - accuracy: 0.8976\n",
      "571/750 [=====================>........] - ETA: 2s - loss: 0.2858 - accuracy: 0.8970\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.2858 - accuracy: 0.8974\n",
      "295/750 [==========>...................] - ETA: 6s - loss: 0.1989 - accuracy: 0.9253\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2853 - accuracy: 0.8976\n",
      "667/750 [=========================>....] - ETA: 0s - loss: 0.2857 - accuracy: 0.8977\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "303/750 [===========>..................] - ETA: 6s - loss: 0.1998 - accuracy: 0.9248\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2853 - accuracy: 0.8975\n",
      "326/750 [============>.................] - ETA: 5s - loss: 0.1997 - accuracy: 0.9252\n",
      "115/750 [===>..........................] - ETA: 7s - loss: 0.1989 - accuracy: 0.9239\n",
      "527/750 [====================>.........] - ETA: 2s - loss: 0.2205 - accuracy: 0.9189\n",
      "369/750 [=============>................] - ETA: 4s - loss: 0.2263 - accuracy: 0.9179\n",
      "350/750 [=============>................] - ETA: 5s - loss: 0.2011 - accuracy: 0.9250\n",
      "399/750 [==============>...............] - ETA: 4s - loss: 0.2240 - accuracy: 0.9181\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "367/750 [=============>................] - ETA: 5s - loss: 0.2009 - accuracy: 0.9249\n",
      "513/750 [===================>..........] - ETA: 2s - loss: 0.2213 - accuracy: 0.9189\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:05:10,919 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6034448384; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/750 [==============>...............] - ETA: 4s - loss: 0.2016 - accuracy: 0.9246\n",
      "429/750 [================>.............] - ETA: 4s - loss: 0.2025 - accuracy: 0.9245\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "422/750 [===============>..............] - ETA: 4s - loss: 0.2030 - accuracy: 0.9243\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "472/750 [=================>............] - ETA: 3s - loss: 0.2211 - accuracy: 0.9190\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "455/750 [=================>............] - ETA: 3s - loss: 0.2019 - accuracy: 0.9248\n",
      "461/750 [=================>............] - ETA: 3s - loss: 0.2032 - accuracy: 0.9243\n",
      "244/750 [========>.....................] - ETA: 6s - loss: 0.2005 - accuracy: 0.9250\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "464/750 [=================>............] - ETA: 3s - loss: 0.2027 - accuracy: 0.9247\n",
      "446/750 [================>.............] - ETA: 3s - loss: 0.2019 - accuracy: 0.9247\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "503/750 [===================>..........] - ETA: 3s - loss: 0.2216 - accuracy: 0.9189\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.2205 - accuracy: 0.9190\n",
      "476/750 [==================>...........] - ETA: 3s - loss: 0.2035 - accuracy: 0.9246\n",
      "657/750 [=========================>....] - ETA: 1s - loss: 0.2202 - accuracy: 0.9191\n",
      "660/750 [=========================>....] - ETA: 1s - loss: 0.2201 - accuracy: 0.9191\n",
      "643/750 [========================>.....] - ETA: 1s - loss: 0.2206 - accuracy: 0.9191\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "517/750 [===================>..........] - ETA: 2s - loss: 0.2208 - accuracy: 0.9190\n",
      "483/750 [==================>...........] - ETA: 3s - loss: 0.2036 - accuracy: 0.9246\n",
      "489/750 [==================>...........] - ETA: 3s - loss: 0.2206 - accuracy: 0.9189\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "544/750 [====================>.........] - ETA: 2s - loss: 0.2196 - accuracy: 0.9192\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "493/750 [==================>...........] - ETA: 3s - loss: 0.2030 - accuracy: 0.9247\n",
      "496/750 [==================>...........] - ETA: 3s - loss: 0.2033 - accuracy: 0.9246\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.2860 - accuracy: 0.8975 - val_loss: 0.3279 - val_accuracy: 0.8829\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 16/30\n",
      "  9/750 [..............................] - ETA: 5s - loss: 0.2873 - accuracy: 0.8889\n",
      "564/750 [=====================>........] - ETA: 2s - loss: 0.2211 - accuracy: 0.9187\n",
      "505/750 [===================>..........] - ETA: 3s - loss: 0.2034 - accuracy: 0.9246\n",
      " 13/750 [..............................] - ETA: 7s - loss: 0.2756 - accuracy: 0.8978\n",
      " 23/750 [..............................] - ETA: 9s - loss: 0.2934 - accuracy: 0.8927 \n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.2190 - accuracy: 0.9194\n",
      "342/750 [============>.................] - ETA: 5s - loss: 0.2004 - accuracy: 0.9252\n",
      " 33/750 [>.............................] - ETA: 9s - loss: 0.2795 - accuracy: 0.8991\n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.2213 - accuracy: 0.9185\n",
      " 38/750 [>.............................] - ETA: 10s - loss: 0.2776 - accuracy: 0.8997\n",
      "530/750 [====================>.........] - ETA: 3s - loss: 0.2029 - accuracy: 0.9249\n",
      "335/750 [============>.................] - ETA: 5s - loss: 0.2001 - accuracy: 0.9254\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2192 - accuracy: 0.9193\n",
      "598/750 [======================>.......] - ETA: 1s - loss: 0.2216 - accuracy: 0.9185\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "536/750 [====================>.........] - ETA: 2s - loss: 0.2028 - accuracy: 0.9249\n",
      " 49/750 [>.............................] - ETA: 9s - loss: 0.2761 - accuracy: 0.8967 \n",
      "538/750 [====================>.........] - ETA: 2s - loss: 0.2031 - accuracy: 0.9247\n",
      "356/750 [=============>................] - ETA: 5s - loss: 0.2008 - accuracy: 0.9250\n",
      " 56/750 [=>............................] - ETA: 10s - loss: 0.2737 - accuracy: 0.8970\n",
      "615/750 [=======================>......] - ETA: 1s - loss: 0.2218 - accuracy: 0.9186\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 64/750 [=>............................] - ETA: 9s - loss: 0.2740 - accuracy: 0.8972 \n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2188 - accuracy: 0.9194\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 75/750 [==>...........................] - ETA: 9s - loss: 0.2686 - accuracy: 0.9010\n",
      "628/750 [========================>.....] - ETA: 1s - loss: 0.2215 - accuracy: 0.9187\n",
      " 87/750 [==>...........................] - ETA: 8s - loss: 0.2691 - accuracy: 0.9012\n",
      "584/750 [======================>.......] - ETA: 2s - loss: 0.2028 - accuracy: 0.9248\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.2205 - accuracy: 0.9192\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 91/750 [==>...........................] - ETA: 8s - loss: 0.2678 - accuracy: 0.9016\n",
      " 98/750 [==>...........................] - ETA: 9s - loss: 0.2695 - accuracy: 0.9011\n",
      "102/750 [===>..........................] - ETA: 9s - loss: 0.2671 - accuracy: 0.9018\n",
      "604/750 [=======================>......] - ETA: 2s - loss: 0.2029 - accuracy: 0.9247\n",
      "120/750 [===>..........................] - ETA: 8s - loss: 0.2680 - accuracy: 0.9009\n",
      "273/750 [=========>....................] - ETA: 6s - loss: 0.2005 - accuracy: 0.9254\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "122/750 [===>..........................] - ETA: 8s - loss: 0.2674 - accuracy: 0.9011\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.2039 - accuracy: 0.9241\n",
      "677/750 [==========================>...] - ETA: 0s - loss: 0.2195 - accuracy: 0.9192\n",
      "138/750 [====>.........................] - ETA: 8s - loss: 0.2674 - accuracy: 0.9009\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.2186 - accuracy: 0.9196\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "150/750 [=====>........................] - ETA: 7s - loss: 0.2684 - accuracy: 0.9003\n",
      "289/750 [==========>...................] - ETA: 6s - loss: 0.2000 - accuracy: 0.9249\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "155/750 [=====>........................] - ETA: 7s - loss: 0.2687 - accuracy: 0.8999\n",
      "568/750 [=====================>........] - ETA: 2s - loss: 0.2023 - accuracy: 0.9248\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "160/750 [=====>........................] - ETA: 8s - loss: 0.2691 - accuracy: 0.8995\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2189 - accuracy: 0.9194\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "169/750 [=====>........................] - ETA: 7s - loss: 0.2715 - accuracy: 0.8990\n",
      "667/750 [=========================>....] - ETA: 1s - loss: 0.2034 - accuracy: 0.9245\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "314/750 [===========>..................] - ETA: 5s - loss: 0.1999 - accuracy: 0.9249\n",
      "179/750 [======>.......................] - ETA: 7s - loss: 0.2713 - accuracy: 0.8993\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9193\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "186/750 [======>.......................] - ETA: 7s - loss: 0.2733 - accuracy: 0.8989\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.2036 - accuracy: 0.9243\n",
      "195/750 [======>.......................] - ETA: 7s - loss: 0.2731 - accuracy: 0.8994\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.2036 - accuracy: 0.9242\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 0.2035 - accuracy: 0.9243\n",
      "209/750 [=======>......................] - ETA: 7s - loss: 0.2760 - accuracy: 0.8988\n",
      "527/750 [====================>.........] - ETA: 3s - loss: 0.2031 - accuracy: 0.9248\n",
      "215/750 [=======>......................] - ETA: 7s - loss: 0.2756 - accuracy: 0.8986\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2042 - accuracy: 0.9239\n",
      "225/750 [========>.....................] - ETA: 6s - loss: 0.2745 - accuracy: 0.8985\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2043 - accuracy: 0.9238\n",
      "230/750 [========>.....................] - ETA: 6s - loss: 0.2748 - accuracy: 0.8990\n",
      "  1/750 [..............................] - ETA: 6s - loss: 0.1147 - accuracy: 0.9688\n",
      "398/750 [==============>...............] - ETA: 4s - loss: 0.2034 - accuracy: 0.9239\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "519/750 [===================>..........] - ETA: 3s - loss: 0.2028 - accuracy: 0.9247\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "250/750 [=========>....................] - ETA: 6s - loss: 0.2763 - accuracy: 0.8992\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2033 - accuracy: 0.9244\n",
      " 26/750 [>.............................] - ETA: 9s - loss: 0.2071 - accuracy: 0.9135 \n",
      " 52/750 [=>............................] - ETA: 7s - loss: 0.2036 - accuracy: 0.9186\n",
      "299/750 [==========>...................] - ETA: 5s - loss: 0.2774 - accuracy: 0.8997\n",
      "449/750 [================>.............] - ETA: 3s - loss: 0.2016 - accuracy: 0.9248\n",
      "303/750 [===========>..................] - ETA: 5s - loss: 0.2764 - accuracy: 0.8999\n",
      "309/750 [===========>..................] - ETA: 5s - loss: 0.2758 - accuracy: 0.9003\n",
      " 74/750 [=>............................] - ETA: 8s - loss: 0.2015 - accuracy: 0.9198\n",
      "468/750 [=================>............] - ETA: 3s - loss: 0.2029 - accuracy: 0.9246\n",
      "314/750 [===========>..................] - ETA: 5s - loss: 0.2762 - accuracy: 0.9003\n",
      "326/750 [============>.................] - ETA: 5s - loss: 0.2761 - accuracy: 0.9004\n",
      "241/750 [========>.....................] - ETA: 6s - loss: 0.2763 - accuracy: 0.8990\n",
      "338/750 [============>.................] - ETA: 5s - loss: 0.2745 - accuracy: 0.9008\n",
      "106/750 [===>..........................] - ETA: 7s - loss: 0.2024 - accuracy: 0.9217\n",
      "344/750 [============>.................] - ETA: 5s - loss: 0.2750 - accuracy: 0.9007\n",
      "352/750 [=============>................] - ETA: 5s - loss: 0.2754 - accuracy: 0.9007\n",
      "360/750 [=============>................] - ETA: 5s - loss: 0.2750 - accuracy: 0.9009\n",
      "655/750 [=========================>....] - ETA: 1s - loss: 0.2036 - accuracy: 0.9243\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 0.2759 - accuracy: 0.9008\n",
      "648/750 [========================>.....] - ETA: 1s - loss: 0.2036 - accuracy: 0.9242\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "488/750 [==================>...........] - ETA: 3s - loss: 0.2034 - accuracy: 0.9246\n",
      "548/750 [====================>.........] - ETA: 2s - loss: 0.2029 - accuracy: 0.9246\n",
      "398/750 [==============>...............] - ETA: 4s - loss: 0.2780 - accuracy: 0.9002\n",
      "176/750 [======>.......................] - ETA: 6s - loss: 0.2005 - accuracy: 0.9219\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2188 - accuracy: 0.9195 - val_loss: 0.4283 - val_accuracy: 0.8855\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 17/30\n",
      "408/750 [===============>..............] - ETA: 4s - loss: 0.2784 - accuracy: 0.9002\n",
      " 20/750 [..............................] - ETA: 9s - loss: 0.1987 - accuracy: 0.9187\n",
      "419/750 [===============>..............] - ETA: 4s - loss: 0.2775 - accuracy: 0.9005\n",
      "194/750 [======>.......................] - ETA: 6s - loss: 0.2027 - accuracy: 0.9220\n",
      " 19/750 [..............................] - ETA: 4s - loss: 0.2002 - accuracy: 0.9169\n",
      "422/750 [===============>..............] - ETA: 4s - loss: 0.2775 - accuracy: 0.9005\n",
      "426/750 [================>.............] - ETA: 4s - loss: 0.2779 - accuracy: 0.9004\n",
      "202/750 [=======>......................] - ETA: 6s - loss: 0.2040 - accuracy: 0.9214\n",
      " 42/750 [>.............................] - ETA: 7s - loss: 0.2065 - accuracy: 0.9167\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2033 - accuracy: 0.9244 - val_loss: 0.3476 - val_accuracy: 0.8920\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 16/30\n",
      "432/750 [================>.............] - ETA: 4s - loss: 0.2782 - accuracy: 0.9004\n",
      "207/750 [=======>......................] - ETA: 6s - loss: 0.2027 - accuracy: 0.9221\n",
      "  5/750 [..............................] - ETA: 20s - loss: 0.1885 - accuracy: 0.9250\n",
      "436/750 [================>.............] - ETA: 4s - loss: 0.2781 - accuracy: 0.9002\n",
      "214/750 [=======>......................] - ETA: 6s - loss: 0.2029 - accuracy: 0.9220\n",
      "594/750 [======================>.......] - ETA: 2s - loss: 0.2027 - accuracy: 0.9248\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 10/750 [..............................] - ETA: 22s - loss: 0.1939 - accuracy: 0.9281\n",
      "444/750 [================>.............] - ETA: 3s - loss: 0.2780 - accuracy: 0.9003\n",
      "447/750 [================>.............] - ETA: 3s - loss: 0.2777 - accuracy: 0.9005\n",
      " 68/750 [=>............................] - ETA: 8s - loss: 0.1934 - accuracy: 0.9223\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 26/750 [>.............................] - ETA: 11s - loss: 0.2125 - accuracy: 0.9255\n",
      "453/750 [=================>............] - ETA: 3s - loss: 0.2777 - accuracy: 0.9005\n",
      "240/750 [========>.....................] - ETA: 6s - loss: 0.2055 - accuracy: 0.9207\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.2033 - accuracy: 0.9244\n",
      " 33/750 [>.............................] - ETA: 11s - loss: 0.2045 - accuracy: 0.9290\n",
      "467/750 [=================>............] - ETA: 3s - loss: 0.2776 - accuracy: 0.9007\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2034 - accuracy: 0.9243\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 37/750 [>.............................] - ETA: 11s - loss: 0.2052 - accuracy: 0.9265\n",
      "475/750 [==================>...........] - ETA: 3s - loss: 0.2771 - accuracy: 0.9009\n",
      "256/750 [=========>....................] - ETA: 5s - loss: 0.2048 - accuracy: 0.9207\n",
      " 94/750 [==>...........................] - ETA: 8s - loss: 0.2025 - accuracy: 0.9220\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 48/750 [>.............................] - ETA: 10s - loss: 0.1929 - accuracy: 0.9297\n",
      "485/750 [==================>...........] - ETA: 3s - loss: 0.2762 - accuracy: 0.9011\n",
      "259/750 [=========>....................] - ETA: 5s - loss: 0.2039 - accuracy: 0.9210\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.2039 - accuracy: 0.9242\n",
      " 52/750 [=>............................] - ETA: 11s - loss: 0.1912 - accuracy: 0.9300\n",
      "489/750 [==================>...........] - ETA: 3s - loss: 0.2765 - accuracy: 0.9008\n",
      " 66/750 [=>............................] - ETA: 9s - loss: 0.1911 - accuracy: 0.9306 \n",
      "493/750 [==================>...........] - ETA: 3s - loss: 0.2765 - accuracy: 0.9009\n",
      "273/750 [=========>....................] - ETA: 5s - loss: 0.2037 - accuracy: 0.9214\n",
      " 80/750 [==>...........................] - ETA: 9s - loss: 0.1939 - accuracy: 0.9305\n",
      "123/750 [===>..........................] - ETA: 7s - loss: 0.2022 - accuracy: 0.9219\n",
      "501/750 [===================>..........] - ETA: 3s - loss: 0.2763 - accuracy: 0.9008\n",
      " 81/750 [==>...........................] - ETA: 9s - loss: 0.1933 - accuracy: 0.9304\n",
      "304/750 [===========>..................] - ETA: 5s - loss: 0.2027 - accuracy: 0.9213\n",
      "268/750 [=========>....................] - ETA: 5s - loss: 0.2039 - accuracy: 0.9214\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "117/750 [===>..........................] - ETA: 7s - loss: 0.2030 - accuracy: 0.9220\n",
      "148/750 [====>.........................] - ETA: 6s - loss: 0.2043 - accuracy: 0.9209\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "533/750 [====================>.........] - ETA: 2s - loss: 0.2776 - accuracy: 0.9007\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.2037 - accuracy: 0.9240\n",
      "104/750 [===>..........................] - ETA: 9s - loss: 0.1948 - accuracy: 0.9276\n",
      "535/750 [====================>.........] - ETA: 2s - loss: 0.2775 - accuracy: 0.9008\n",
      "293/750 [==========>...................] - ETA: 5s - loss: 0.2024 - accuracy: 0.9219\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "172/750 [=====>........................] - ETA: 6s - loss: 0.2020 - accuracy: 0.9214\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "117/750 [===>..........................] - ETA: 8s - loss: 0.1927 - accuracy: 0.9286\n",
      "544/750 [====================>.........] - ETA: 2s - loss: 0.2767 - accuracy: 0.9009\n",
      "127/750 [====>.........................] - ETA: 8s - loss: 0.1926 - accuracy: 0.9286\n",
      "551/750 [=====================>........] - ETA: 2s - loss: 0.2766 - accuracy: 0.9010\n",
      "333/750 [============>.................] - ETA: 5s - loss: 0.2024 - accuracy: 0.9215\n",
      "130/750 [====>.........................] - ETA: 8s - loss: 0.1935 - accuracy: 0.9282\n",
      "559/750 [=====================>........] - ETA: 2s - loss: 0.2770 - accuracy: 0.9010\n",
      "164/750 [=====>........................] - ETA: 6s - loss: 0.2037 - accuracy: 0.9210\n",
      "132/750 [====>.........................] - ETA: 8s - loss: 0.1940 - accuracy: 0.9280\n",
      "135/750 [====>.........................] - ETA: 8s - loss: 0.1944 - accuracy: 0.9278\n",
      "674/750 [=========================>....] - ETA: 1s - loss: 0.2035 - accuracy: 0.9244\n",
      "185/750 [======>.......................] - ETA: 6s - loss: 0.2024 - accuracy: 0.9215\n",
      "139/750 [====>.........................] - ETA: 8s - loss: 0.1929 - accuracy: 0.9282\n",
      "567/750 [=====================>........] - ETA: 2s - loss: 0.2766 - accuracy: 0.9009\n",
      "576/750 [======================>.......] - ETA: 2s - loss: 0.2765 - accuracy: 0.9010\n",
      "357/750 [=============>................] - ETA: 4s - loss: 0.2045 - accuracy: 0.9216\n",
      "156/750 [=====>........................] - ETA: 8s - loss: 0.1966 - accuracy: 0.9260\n",
      "218/750 [=======>......................] - ETA: 6s - loss: 0.2024 - accuracy: 0.9220\n",
      "164/750 [=====>........................] - ETA: 8s - loss: 0.1963 - accuracy: 0.9258\n",
      "173/750 [=====>........................] - ETA: 8s - loss: 0.1966 - accuracy: 0.9259\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.2763 - accuracy: 0.9008\n",
      "226/750 [========>.....................] - ETA: 6s - loss: 0.2030 - accuracy: 0.9219\n",
      "183/750 [======>.......................] - ETA: 7s - loss: 0.1980 - accuracy: 0.9250\n",
      "611/750 [=======================>......] - ETA: 1s - loss: 0.2769 - accuracy: 0.9006\n",
      "244/750 [========>.....................] - ETA: 6s - loss: 0.2060 - accuracy: 0.9206\n",
      "187/750 [======>.......................] - ETA: 8s - loss: 0.1978 - accuracy: 0.9253\n",
      "623/750 [=======================>......] - ETA: 1s - loss: 0.2768 - accuracy: 0.9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:05:20,974 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6079197184; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/750 [..............................] - ETA: 5s - loss: 0.1655 - accuracy: 0.9688\n",
      "394/750 [==============>...............] - ETA: 4s - loss: 0.2047 - accuracy: 0.9218\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.2770 - accuracy: 0.9005\n",
      "518/750 [===================>..........] - ETA: 3s - loss: 0.2768 - accuracy: 0.9008\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "205/750 [=======>......................] - ETA: 8s - loss: 0.1979 - accuracy: 0.9256\n",
      "207/750 [=======>......................] - ETA: 8s - loss: 0.1985 - accuracy: 0.9251\n",
      "635/750 [========================>.....] - ETA: 1s - loss: 0.2775 - accuracy: 0.9003\n",
      "309/750 [===========>..................] - ETA: 5s - loss: 0.2028 - accuracy: 0.9213\n",
      "641/750 [========================>.....] - ETA: 1s - loss: 0.2777 - accuracy: 0.9004\n",
      "313/750 [===========>..................] - ETA: 5s - loss: 0.2031 - accuracy: 0.9212\n",
      "430/750 [================>.............] - ETA: 4s - loss: 0.2062 - accuracy: 0.9220\n",
      "221/750 [=======>......................] - ETA: 8s - loss: 0.1969 - accuracy: 0.9256\n",
      "649/750 [========================>.....] - ETA: 1s - loss: 0.2782 - accuracy: 0.9001\n",
      "228/750 [========>.....................] - ETA: 8s - loss: 0.1975 - accuracy: 0.9254\n",
      "654/750 [=========================>....] - ETA: 1s - loss: 0.2785 - accuracy: 0.9001\n",
      "342/750 [============>.................] - ETA: 5s - loss: 0.2034 - accuracy: 0.9214\n",
      "659/750 [=========================>....] - ETA: 1s - loss: 0.2786 - accuracy: 0.8999\n",
      "103/750 [===>..........................] - ETA: 8s - loss: 0.1943 - accuracy: 0.9278\n",
      "337/750 [============>.................] - ETA: 5s - loss: 0.2020 - accuracy: 0.9217\n",
      "235/750 [========>.....................] - ETA: 8s - loss: 0.1977 - accuracy: 0.9251\n",
      "665/750 [=========================>....] - ETA: 1s - loss: 0.2782 - accuracy: 0.9001\n",
      "450/750 [=================>............] - ETA: 4s - loss: 0.2067 - accuracy: 0.9221\n",
      "351/750 [=============>................] - ETA: 4s - loss: 0.2029 - accuracy: 0.9218\n",
      "239/750 [========>.....................] - ETA: 8s - loss: 0.1981 - accuracy: 0.9253\n",
      "365/750 [=============>................] - ETA: 4s - loss: 0.2045 - accuracy: 0.9215\n",
      "666/750 [=========================>....] - ETA: 1s - loss: 0.2783 - accuracy: 0.9001\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 0.2045 - accuracy: 0.9220\n",
      "672/750 [=========================>....] - ETA: 1s - loss: 0.2789 - accuracy: 0.8998\n",
      "247/750 [========>.....................] - ETA: 8s - loss: 0.1980 - accuracy: 0.9253\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.2784 - accuracy: 0.9000\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "679/750 [==========================>...] - ETA: 1s - loss: 0.2799 - accuracy: 0.8997\n",
      "680/750 [==========================>...] - ETA: 1s - loss: 0.2797 - accuracy: 0.8998\n",
      "397/750 [==============>...............] - ETA: 4s - loss: 0.2059 - accuracy: 0.9217\n",
      "194/750 [======>.......................] - ETA: 7s - loss: 0.1977 - accuracy: 0.9256\n",
      "422/750 [===============>..............] - ETA: 4s - loss: 0.2063 - accuracy: 0.9217\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "685/750 [==========================>...] - ETA: 0s - loss: 0.2796 - accuracy: 0.8998\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.2796 - accuracy: 0.8997\n",
      "418/750 [===============>..............] - ETA: 4s - loss: 0.2063 - accuracy: 0.9217\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "436/750 [================>.............] - ETA: 4s - loss: 0.2069 - accuracy: 0.9219\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.2805 - accuracy: 0.8993\n",
      "200/750 [=======>......................] - ETA: 8s - loss: 0.1977 - accuracy: 0.9257\n",
      "275/750 [==========>...................] - ETA: 8s - loss: 0.1960 - accuracy: 0.9256\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2805 - accuracy: 0.8994\n",
      "216/750 [=======>......................] - ETA: 8s - loss: 0.1973 - accuracy: 0.9255\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "447/750 [================>.............] - ETA: 4s - loss: 0.2063 - accuracy: 0.9223\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.2808 - accuracy: 0.8993\n",
      "591/750 [======================>.......] - ETA: 2s - loss: 0.2769 - accuracy: 0.9005\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2802 - accuracy: 0.8995\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2803 - accuracy: 0.8995\n",
      "471/750 [=================>............] - ETA: 4s - loss: 0.2088 - accuracy: 0.9215\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "245/750 [========>.....................] - ETA: 8s - loss: 0.1985 - accuracy: 0.9251\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "469/750 [=================>............] - ETA: 4s - loss: 0.2090 - accuracy: 0.9214\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2809 - accuracy: 0.8992\n",
      "520/750 [===================>..........] - ETA: 3s - loss: 0.2092 - accuracy: 0.9218\n",
      "304/750 [===========>..................] - ETA: 8s - loss: 0.1959 - accuracy: 0.9258\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2808 - accuracy: 0.8993\n",
      "522/750 [===================>..........] - ETA: 3s - loss: 0.2092 - accuracy: 0.9218\n",
      " 90/750 [==>...........................] - ETA: 9s - loss: 0.1885 - accuracy: 0.9318\n",
      "496/750 [==================>...........] - ETA: 3s - loss: 0.2094 - accuracy: 0.9215\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "320/750 [===========>..................] - ETA: 7s - loss: 0.1944 - accuracy: 0.9268\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2805 - accuracy: 0.8994\n",
      "260/750 [=========>....................] - ETA: 9s - loss: 0.1978 - accuracy: 0.9251\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "324/750 [===========>..................] - ETA: 7s - loss: 0.1949 - accuracy: 0.9267\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2808 - accuracy: 0.8994\n",
      "499/750 [==================>...........] - ETA: 3s - loss: 0.2091 - accuracy: 0.9215\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "326/750 [============>.................] - ETA: 7s - loss: 0.1945 - accuracy: 0.9267\n",
      "337/750 [============>.................] - ETA: 7s - loss: 0.1953 - accuracy: 0.9264\n",
      "352/750 [=============>................] - ETA: 7s - loss: 0.1945 - accuracy: 0.9268\n",
      "359/750 [=============>................] - ETA: 6s - loss: 0.1938 - accuracy: 0.9272\n",
      "300/750 [===========>..................] - ETA: 8s - loss: 0.1947 - accuracy: 0.9260\n",
      "270/750 [=========>....................] - ETA: 8s - loss: 0.1965 - accuracy: 0.9255\n",
      "144/750 [====>.........................] - ETA: 8s - loss: 0.1920 - accuracy: 0.9282\n",
      "549/750 [====================>.........] - ETA: 3s - loss: 0.2099 - accuracy: 0.9216\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "368/750 [=============>................] - ETA: 6s - loss: 0.1936 - accuracy: 0.9275\n",
      "585/750 [======================>.......] - ETA: 2s - loss: 0.2102 - accuracy: 0.9217\n",
      "377/750 [==============>...............] - ETA: 6s - loss: 0.1933 - accuracy: 0.9277\n",
      "290/750 [==========>...................] - ETA: 8s - loss: 0.1966 - accuracy: 0.9255\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "572/750 [=====================>........] - ETA: 2s - loss: 0.2102 - accuracy: 0.9216\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "402/750 [===============>..............] - ETA: 5s - loss: 0.1941 - accuracy: 0.9271\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.2115 - accuracy: 0.9215\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.2105 - accuracy: 0.9215\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "392/750 [==============>...............] - ETA: 6s - loss: 0.1944 - accuracy: 0.9271\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.2122 - accuracy: 0.9214\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "475/750 [==================>...........] - ETA: 4s - loss: 0.1940 - accuracy: 0.9276\n",
      "517/750 [===================>..........] - ETA: 3s - loss: 0.2084 - accuracy: 0.9219\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2125 - accuracy: 0.9216\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2129 - accuracy: 0.9214\n",
      "750/750 [==============================] - 14s 18ms/step - loss: 0.2805 - accuracy: 0.8995 - val_loss: 0.3242 - val_accuracy: 0.8863\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 17/30\n",
      "  6/750 [..............................] - ETA: 7s - loss: 0.2679 - accuracy: 0.8958\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2132 - accuracy: 0.9213\n",
      " 11/750 [..............................] - ETA: 17s - loss: 0.2831 - accuracy: 0.8963\n",
      " 28/750 [>.............................] - ETA: 10s - loss: 0.2916 - accuracy: 0.8951\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2137 - accuracy: 0.9211\n",
      "430/750 [================>.............] - ETA: 5s - loss: 0.1952 - accuracy: 0.9271\n",
      " 41/750 [>.............................] - ETA: 9s - loss: 0.2870 - accuracy: 0.8967\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2139 - accuracy: 0.9210\n",
      " 50/750 [=>............................] - ETA: 9s - loss: 0.2802 - accuracy: 0.9000\n",
      "673/750 [=========================>....] - ETA: 1s - loss: 0.2123 - accuracy: 0.9214\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 51/750 [=>............................] - ETA: 9s - loss: 0.2811 - accuracy: 0.8989\n",
      " 58/750 [=>............................] - ETA: 10s - loss: 0.2748 - accuracy: 0.8984\n",
      " 69/750 [=>............................] - ETA: 9s - loss: 0.2687 - accuracy: 0.9006\n",
      " 79/750 [==>...........................] - ETA: 9s - loss: 0.2708 - accuracy: 0.9003\n",
      " 93/750 [==>...........................] - ETA: 8s - loss: 0.2761 - accuracy: 0.8989\n",
      "601/750 [=======================>......] - ETA: 2s - loss: 0.1936 - accuracy: 0.9279\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.2119 - accuracy: 0.9215\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 0.2117 - accuracy: 0.9217\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "102/750 [===>..........................] - ETA: 8s - loss: 0.2745 - accuracy: 0.8991\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.2122 - accuracy: 0.9216\n",
      "110/750 [===>..........................] - ETA: 8s - loss: 0.2738 - accuracy: 0.8990\n",
      "112/750 [===>..........................] - ETA: 8s - loss: 0.2723 - accuracy: 0.8996\n",
      "619/750 [=======================>......] - ETA: 2s - loss: 0.1934 - accuracy: 0.9281\n",
      "421/750 [===============>..............] - ETA: 5s - loss: 0.1944 - accuracy: 0.9273\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "128/750 [====>.........................] - ETA: 8s - loss: 0.2729 - accuracy: 0.8995\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.1939 - accuracy: 0.9280\n",
      "140/750 [====>.........................] - ETA: 7s - loss: 0.2703 - accuracy: 0.9004\n",
      "642/750 [========================>.....] - ETA: 1s - loss: 0.1938 - accuracy: 0.9281\n",
      "154/750 [=====>........................] - ETA: 7s - loss: 0.2708 - accuracy: 0.9003\n",
      "651/750 [=========================>....] - ETA: 1s - loss: 0.1938 - accuracy: 0.9282\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2131 - accuracy: 0.9213\n",
      "165/750 [=====>........................] - ETA: 7s - loss: 0.2691 - accuracy: 0.9009\n",
      "448/750 [================>.............] - ETA: 5s - loss: 0.1951 - accuracy: 0.9273\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "173/750 [=====>........................] - ETA: 6s - loss: 0.2699 - accuracy: 0.9004\n",
      "587/750 [======================>.......] - ETA: 2s - loss: 0.1934 - accuracy: 0.9280\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "179/750 [======>.......................] - ETA: 6s - loss: 0.2726 - accuracy: 0.8994\n",
      "466/750 [=================>............] - ETA: 4s - loss: 0.1941 - accuracy: 0.9275\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "193/750 [======>.......................] - ETA: 6s - loss: 0.2722 - accuracy: 0.8999\n",
      "690/750 [==========================>...] - ETA: 0s - loss: 0.1955 - accuracy: 0.9275\n",
      "204/750 [=======>......................] - ETA: 6s - loss: 0.2732 - accuracy: 0.9000\n",
      "510/750 [===================>..........] - ETA: 3s - loss: 0.1941 - accuracy: 0.9276\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.1960 - accuracy: 0.9274\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2137 - accuracy: 0.9212\n",
      "212/750 [=======>......................] - ETA: 6s - loss: 0.2733 - accuracy: 0.8996\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.2628 - accuracy: 0.8750\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.1964 - accuracy: 0.9272\n",
      "  6/750 [..............................] - ETA: 7s - loss: 0.2361 - accuracy: 0.9245\n",
      "493/750 [==================>...........] - ETA: 4s - loss: 0.1936 - accuracy: 0.9277\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.1961 - accuracy: 0.9273\n",
      "222/750 [=======>......................] - ETA: 6s - loss: 0.2721 - accuracy: 0.9005\n",
      "  7/750 [..............................] - ETA: 17s - loss: 0.2156 - accuracy: 0.9286\n",
      "232/750 [========>.....................] - ETA: 6s - loss: 0.2732 - accuracy: 0.9009\n",
      " 11/750 [..............................] - ETA: 19s - loss: 0.2271 - accuracy: 0.9247\n",
      "477/750 [==================>...........] - ETA: 4s - loss: 0.1943 - accuracy: 0.9275\n",
      "237/750 [========>.....................] - ETA: 6s - loss: 0.2750 - accuracy: 0.9004\n",
      " 19/750 [..............................] - ETA: 16s - loss: 0.2197 - accuracy: 0.9194\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.1970 - accuracy: 0.9267\n",
      "246/750 [========>.....................] - ETA: 6s - loss: 0.2747 - accuracy: 0.9007\n",
      " 40/750 [>.............................] - ETA: 9s - loss: 0.2105 - accuracy: 0.9258 \n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.1972 - accuracy: 0.9266\n",
      "256/750 [=========>....................] - ETA: 5s - loss: 0.2732 - accuracy: 0.9012\n",
      " 45/750 [>.............................] - ETA: 10s - loss: 0.2109 - accuracy: 0.9233\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.1970 - accuracy: 0.9268\n",
      "261/750 [=========>....................] - ETA: 5s - loss: 0.2746 - accuracy: 0.9008\n",
      " 57/750 [=>............................] - ETA: 9s - loss: 0.2107 - accuracy: 0.9243 \n",
      "544/750 [====================>.........] - ETA: 3s - loss: 0.1930 - accuracy: 0.9279\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "272/750 [=========>....................] - ETA: 5s - loss: 0.2763 - accuracy: 0.9000\n",
      "281/750 [==========>...................] - ETA: 5s - loss: 0.2756 - accuracy: 0.8999\n",
      "290/750 [==========>...................] - ETA: 5s - loss: 0.2759 - accuracy: 0.8999\n",
      "574/750 [=====================>........] - ETA: 2s - loss: 0.1938 - accuracy: 0.9279\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "302/750 [===========>..................] - ETA: 5s - loss: 0.2754 - accuracy: 0.8998\n",
      "309/750 [===========>..................] - ETA: 5s - loss: 0.2751 - accuracy: 0.8998\n",
      "316/750 [===========>..................] - ETA: 5s - loss: 0.2748 - accuracy: 0.9002\n",
      "325/750 [============>.................] - ETA: 5s - loss: 0.2764 - accuracy: 0.8999\n",
      "343/750 [============>.................] - ETA: 4s - loss: 0.2763 - accuracy: 0.8996\n",
      "351/750 [=============>................] - ETA: 4s - loss: 0.2759 - accuracy: 0.9001\n",
      "354/750 [=============>................] - ETA: 4s - loss: 0.2767 - accuracy: 0.8999\n",
      "614/750 [=======================>......] - ETA: 2s - loss: 0.1936 - accuracy: 0.9279\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "364/750 [=============>................] - ETA: 4s - loss: 0.2774 - accuracy: 0.8999\n",
      "368/750 [=============>................] - ETA: 4s - loss: 0.2774 - accuracy: 0.8999\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 0.2766 - accuracy: 0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:05:31,007 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6078152704; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/750 [==============>...............] - ETA: 4s - loss: 0.2771 - accuracy: 0.9006\n",
      "524/750 [===================>..........] - ETA: 3s - loss: 0.1943 - accuracy: 0.9274\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "402/750 [===============>..............] - ETA: 4s - loss: 0.2773 - accuracy: 0.9006\n",
      "204/750 [=======>......................] - ETA: 6s - loss: 0.2125 - accuracy: 0.9220\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.1965 - accuracy: 0.9270\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.2140 - accuracy: 0.9209 - val_loss: 0.4342 - val_accuracy: 0.8839\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 18/30\n",
      "427/750 [================>.............] - ETA: 3s - loss: 0.2768 - accuracy: 0.9005\n",
      "226/750 [========>.....................] - ETA: 6s - loss: 0.2108 - accuracy: 0.9232\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.1972 - accuracy: 0.9268 - val_loss: 0.3369 - val_accuracy: 0.8893\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 17/30\n",
      "430/750 [================>.............] - ETA: 3s - loss: 0.2768 - accuracy: 0.9005\n",
      "437/750 [================>.............] - ETA: 3s - loss: 0.2777 - accuracy: 0.9006\n",
      "445/750 [================>.............] - ETA: 3s - loss: 0.2780 - accuracy: 0.9007\n",
      "453/750 [=================>............] - ETA: 3s - loss: 0.2783 - accuracy: 0.9004\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.1966 - accuracy: 0.9269\n",
      "475/750 [==================>...........] - ETA: 3s - loss: 0.2776 - accuracy: 0.9008\n",
      "276/750 [==========>...................] - ETA: 5s - loss: 0.2118 - accuracy: 0.9239\n",
      "673/750 [=========================>....] - ETA: 1s - loss: 0.1948 - accuracy: 0.9277\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 73/750 [=>............................] - ETA: 8s - loss: 0.2087 - accuracy: 0.9244\n",
      " 68/750 [=>............................] - ETA: 8s - loss: 0.2072 - accuracy: 0.9242\n",
      " 47/750 [>.............................] - ETA: 10s - loss: 0.1896 - accuracy: 0.9315\n",
      "292/750 [==========>...................] - ETA: 5s - loss: 0.2116 - accuracy: 0.9239\n",
      " 57/750 [=>............................] - ETA: 9s - loss: 0.1832 - accuracy: 0.9337\n",
      "296/750 [==========>...................] - ETA: 5s - loss: 0.2114 - accuracy: 0.9241\n",
      "500/750 [===================>..........] - ETA: 3s - loss: 0.2764 - accuracy: 0.9015\n",
      " 67/750 [=>............................] - ETA: 9s - loss: 0.1828 - accuracy: 0.9338\n",
      "505/750 [===================>..........] - ETA: 2s - loss: 0.2768 - accuracy: 0.9013\n",
      " 96/750 [==>...........................] - ETA: 8s - loss: 0.2067 - accuracy: 0.9248\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 78/750 [==>...........................] - ETA: 8s - loss: 0.1818 - accuracy: 0.9335\n",
      "321/750 [===========>..................] - ETA: 5s - loss: 0.2114 - accuracy: 0.9243\n",
      "685/750 [==========================>...] - ETA: 0s - loss: 0.1953 - accuracy: 0.9276\n",
      "106/750 [===>..........................] - ETA: 8s - loss: 0.2093 - accuracy: 0.9239\n",
      "528/750 [====================>.........] - ETA: 2s - loss: 0.2764 - accuracy: 0.9016\n",
      "331/750 [============>.................] - ETA: 4s - loss: 0.2120 - accuracy: 0.9240\n",
      "123/750 [===>..........................] - ETA: 7s - loss: 0.2125 - accuracy: 0.9220\n",
      "336/750 [============>.................] - ETA: 4s - loss: 0.2129 - accuracy: 0.9238\n",
      "112/750 [===>..........................] - ETA: 8s - loss: 0.2089 - accuracy: 0.9238\n",
      "101/750 [===>..........................] - ETA: 8s - loss: 0.1838 - accuracy: 0.9310\n",
      "349/750 [============>.................] - ETA: 4s - loss: 0.2123 - accuracy: 0.9244\n",
      "420/750 [===============>..............] - ETA: 3s - loss: 0.2760 - accuracy: 0.9009\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "111/750 [===>..........................] - ETA: 8s - loss: 0.1827 - accuracy: 0.9313\n",
      "552/750 [=====================>........] - ETA: 2s - loss: 0.2746 - accuracy: 0.9020\n",
      "149/750 [====>.........................] - ETA: 7s - loss: 0.2143 - accuracy: 0.9217\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "117/750 [===>..........................] - ETA: 8s - loss: 0.1841 - accuracy: 0.9310\n",
      "560/750 [=====================>........] - ETA: 2s - loss: 0.2742 - accuracy: 0.9022\n",
      "123/750 [===>..........................] - ETA: 8s - loss: 0.1849 - accuracy: 0.9308\n",
      "167/750 [=====>........................] - ETA: 7s - loss: 0.2166 - accuracy: 0.9213\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "578/750 [======================>.......] - ETA: 2s - loss: 0.2742 - accuracy: 0.9021\n",
      "382/750 [==============>...............] - ETA: 4s - loss: 0.2131 - accuracy: 0.9240\n",
      "149/750 [====>.........................] - ETA: 7s - loss: 0.1833 - accuracy: 0.9308\n",
      "590/750 [======================>.......] - ETA: 1s - loss: 0.2744 - accuracy: 0.9022\n",
      "195/750 [======>.......................] - ETA: 6s - loss: 0.2138 - accuracy: 0.9218\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "596/750 [======================>.......] - ETA: 1s - loss: 0.2741 - accuracy: 0.9024\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.2737 - accuracy: 0.9026\n",
      "468/750 [=================>............] - ETA: 3s - loss: 0.2782 - accuracy: 0.9007\n",
      "610/750 [=======================>......] - ETA: 1s - loss: 0.2735 - accuracy: 0.9027\n",
      "218/750 [=======>......................] - ETA: 6s - loss: 0.2122 - accuracy: 0.9224\n",
      "214/750 [=======>......................] - ETA: 6s - loss: 0.2118 - accuracy: 0.9222\n",
      "  1/750 [..............................] - ETA: 9s - loss: 0.2407 - accuracy: 0.9062\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.2732 - accuracy: 0.9029\n",
      "437/750 [================>.............] - ETA: 3s - loss: 0.2129 - accuracy: 0.9243\n",
      "  5/750 [..............................] - ETA: 13s - loss: 0.1743 - accuracy: 0.9344\n",
      "496/750 [==================>...........] - ETA: 3s - loss: 0.2771 - accuracy: 0.9013\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "637/750 [========================>.....] - ETA: 1s - loss: 0.2732 - accuracy: 0.9030\n",
      "248/750 [========>.....................] - ETA: 5s - loss: 0.2140 - accuracy: 0.9224\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "209/750 [=======>......................] - ETA: 6s - loss: 0.1819 - accuracy: 0.9315\n",
      "649/750 [========================>.....] - ETA: 1s - loss: 0.2742 - accuracy: 0.9026\n",
      "461/750 [=================>............] - ETA: 3s - loss: 0.2130 - accuracy: 0.9242\n",
      "221/750 [=======>......................] - ETA: 6s - loss: 0.1827 - accuracy: 0.9307\n",
      "470/750 [=================>............] - ETA: 3s - loss: 0.2137 - accuracy: 0.9240\n",
      " 24/750 [..............................] - ETA: 10s - loss: 0.1777 - accuracy: 0.9368\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "478/750 [==================>...........] - ETA: 3s - loss: 0.2138 - accuracy: 0.9242\n",
      " 41/750 [>.............................] - ETA: 9s - loss: 0.1884 - accuracy: 0.9325 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "268/750 [=========>....................] - ETA: 5s - loss: 0.2115 - accuracy: 0.9236\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "238/750 [========>.....................] - ETA: 6s - loss: 0.1827 - accuracy: 0.9307\n",
      "674/750 [=========================>....] - ETA: 0s - loss: 0.2752 - accuracy: 0.9023\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.2746 - accuracy: 0.9026\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.2745 - accuracy: 0.9025\n",
      "692/750 [==========================>...] - ETA: 0s - loss: 0.2748 - accuracy: 0.9025\n",
      "545/750 [====================>.........] - ETA: 2s - loss: 0.2748 - accuracy: 0.9022\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.2748 - accuracy: 0.9024\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2749 - accuracy: 0.9024\n",
      "285/750 [==========>...................] - ETA: 5s - loss: 0.2124 - accuracy: 0.9235\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2749 - accuracy: 0.9023\n",
      "525/750 [====================>.........] - ETA: 2s - loss: 0.2140 - accuracy: 0.9242\n",
      "567/750 [=====================>........] - ETA: 2s - loss: 0.2741 - accuracy: 0.9021\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.9022\n",
      "317/750 [===========>..................] - ETA: 5s - loss: 0.2112 - accuracy: 0.9244\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "299/750 [==========>...................] - ETA: 5s - loss: 0.1852 - accuracy: 0.9299\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2760 - accuracy: 0.9019\n",
      "542/750 [====================>.........] - ETA: 2s - loss: 0.2142 - accuracy: 0.9240\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2764 - accuracy: 0.9017\n",
      "561/750 [=====================>........] - ETA: 2s - loss: 0.2128 - accuracy: 0.9245\n",
      "571/750 [=====================>........] - ETA: 2s - loss: 0.2125 - accuracy: 0.9246\n",
      "352/750 [=============>................] - ETA: 4s - loss: 0.2129 - accuracy: 0.9242\n",
      "351/750 [=============>................] - ETA: 4s - loss: 0.1860 - accuracy: 0.9300\n",
      "356/750 [=============>................] - ETA: 4s - loss: 0.1857 - accuracy: 0.9302\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 0.2124 - accuracy: 0.9246\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.2735 - accuracy: 0.9028\n",
      "371/750 [=============>................] - ETA: 4s - loss: 0.2124 - accuracy: 0.9241\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "361/750 [=============>................] - ETA: 4s - loss: 0.1857 - accuracy: 0.9301\n",
      "366/750 [=============>................] - ETA: 4s - loss: 0.1850 - accuracy: 0.9304\n",
      "615/750 [=======================>......] - ETA: 1s - loss: 0.2128 - accuracy: 0.9243\n",
      "377/750 [==============>...............] - ETA: 4s - loss: 0.1844 - accuracy: 0.9307\n",
      "392/750 [==============>...............] - ETA: 4s - loss: 0.2122 - accuracy: 0.9242\n",
      "389/750 [==============>...............] - ETA: 4s - loss: 0.1843 - accuracy: 0.9308\n",
      "519/750 [===================>..........] - ETA: 2s - loss: 0.2139 - accuracy: 0.9243\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "407/750 [===============>..............] - ETA: 4s - loss: 0.2129 - accuracy: 0.9240\n",
      "403/750 [===============>..............] - ETA: 3s - loss: 0.1839 - accuracy: 0.9310\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.2133 - accuracy: 0.9239\n",
      "201/750 [=======>......................] - ETA: 6s - loss: 0.1824 - accuracy: 0.9316\n",
      "406/750 [===============>..............] - ETA: 3s - loss: 0.1845 - accuracy: 0.9308\n",
      "429/750 [================>.............] - ETA: 3s - loss: 0.2134 - accuracy: 0.9242\n",
      "230/750 [========>.....................] - ETA: 6s - loss: 0.1829 - accuracy: 0.9306\n",
      "420/750 [===============>..............] - ETA: 3s - loss: 0.1859 - accuracy: 0.9307\n",
      "427/750 [================>.............] - ETA: 3s - loss: 0.1857 - accuracy: 0.9307\n",
      "683/750 [==========================>...] - ETA: 0s - loss: 0.2134 - accuracy: 0.9239\n",
      "451/750 [=================>............] - ETA: 3s - loss: 0.2123 - accuracy: 0.9243\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.2133 - accuracy: 0.9240\n",
      "452/750 [=================>............] - ETA: 3s - loss: 0.1862 - accuracy: 0.9306\n",
      "280/750 [==========>...................] - ETA: 5s - loss: 0.1844 - accuracy: 0.9301\n",
      "673/750 [=========================>....] - ETA: 0s - loss: 0.2131 - accuracy: 0.9239\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "288/750 [==========>...................] - ETA: 5s - loss: 0.1847 - accuracy: 0.9299\n",
      "471/750 [=================>............] - ETA: 3s - loss: 0.1869 - accuracy: 0.9302\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.2759 - accuracy: 0.9020 - val_loss: 0.3242 - val_accuracy: 0.8863\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 18/30\n",
      "  1/750 [..............................] - ETA: 5s - loss: 0.1676 - accuracy: 0.9375\n",
      "  8/750 [..............................] - ETA: 23s - loss: 0.2990 - accuracy: 0.8965\n",
      " 99/750 [==>...........................] - ETA: 8s - loss: 0.1844 - accuracy: 0.9312\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2131 - accuracy: 0.9239\n",
      "345/750 [============>.................] - ETA: 4s - loss: 0.1857 - accuracy: 0.9299\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 18/750 [..............................] - ETA: 18s - loss: 0.2613 - accuracy: 0.9010\n",
      " 28/750 [>.............................] - ETA: 14s - loss: 0.2652 - accuracy: 0.9012\n",
      "417/750 [===============>..............] - ETA: 3s - loss: 0.1856 - accuracy: 0.9307\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "511/750 [===================>..........] - ETA: 3s - loss: 0.1874 - accuracy: 0.9301\n",
      "134/750 [====>.........................] - ETA: 8s - loss: 0.1880 - accuracy: 0.9293\n",
      "550/750 [=====================>........] - ETA: 2s - loss: 0.2140 - accuracy: 0.9240\n",
      " 52/750 [=>............................] - ETA: 11s - loss: 0.2666 - accuracy: 0.9044\n",
      "526/750 [====================>.........] - ETA: 2s - loss: 0.1876 - accuracy: 0.9301\n",
      " 55/750 [=>............................] - ETA: 11s - loss: 0.2671 - accuracy: 0.9040\n",
      "172/750 [=====>........................] - ETA: 7s - loss: 0.1811 - accuracy: 0.9319\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 64/750 [=>............................] - ETA: 11s - loss: 0.2685 - accuracy: 0.9033\n",
      " 72/750 [=>............................] - ETA: 10s - loss: 0.2698 - accuracy: 0.9028\n",
      "191/750 [======>.......................] - ETA: 7s - loss: 0.1816 - accuracy: 0.9320\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "598/750 [======================>.......] - ETA: 1s - loss: 0.2120 - accuracy: 0.9247\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 75/750 [==>...........................] - ETA: 11s - loss: 0.2648 - accuracy: 0.9048\n",
      " 81/750 [==>...........................] - ETA: 11s - loss: 0.2664 - accuracy: 0.9039\n",
      "551/750 [=====================>........] - ETA: 2s - loss: 0.1885 - accuracy: 0.9299\n",
      " 85/750 [==>...........................] - ETA: 11s - loss: 0.2685 - accuracy: 0.9039\n",
      "554/750 [=====================>........] - ETA: 2s - loss: 0.1886 - accuracy: 0.9299\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.2134 - accuracy: 0.9240\n",
      " 86/750 [==>...........................] - ETA: 12s - loss: 0.2672 - accuracy: 0.9046\n",
      "442/750 [================>.............] - ETA: 3s - loss: 0.1865 - accuracy: 0.9305\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "492/750 [==================>...........] - ETA: 3s - loss: 0.1868 - accuracy: 0.9300\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.2131 - accuracy: 0.9239\n",
      " 93/750 [==>...........................] - ETA: 12s - loss: 0.2651 - accuracy: 0.9059\n",
      "563/750 [=====================>........] - ETA: 2s - loss: 0.1885 - accuracy: 0.9300\n",
      "249/750 [========>.....................] - ETA: 6s - loss: 0.1834 - accuracy: 0.9305\n",
      " 99/750 [==>...........................] - ETA: 12s - loss: 0.2663 - accuracy: 0.9048\n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.1889 - accuracy: 0.9299\n",
      "470/750 [=================>............] - ETA: 3s - loss: 0.1869 - accuracy: 0.9302\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "104/750 [===>..........................] - ETA: 12s - loss: 0.2639 - accuracy: 0.9053\n",
      " 12/750 [..............................] - ETA: 23s - loss: 0.2798 - accuracy: 0.8971\n",
      "497/750 [==================>...........] - ETA: 3s - loss: 0.1872 - accuracy: 0.9300\n",
      " 45/750 [>.............................] - ETA: 12s - loss: 0.2685 - accuracy: 0.9049\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "269/750 [=========>....................] - ETA: 5s - loss: 0.1842 - accuracy: 0.9303\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "658/750 [=========================>....] - ETA: 1s - loss: 0.2128 - accuracy: 0.9238\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.2132 - accuracy: 0.9240\n",
      "113/750 [===>..........................] - ETA: 11s - loss: 0.2656 - accuracy: 0.9047\n",
      "585/750 [======================>.......] - ETA: 2s - loss: 0.1896 - accuracy: 0.9295\n",
      "122/750 [===>..........................] - ETA: 11s - loss: 0.2667 - accuracy: 0.9046\n",
      "544/750 [====================>.........] - ETA: 2s - loss: 0.1886 - accuracy: 0.9300\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "127/750 [====>.........................] - ETA: 11s - loss: 0.2682 - accuracy: 0.9048\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.2134 - accuracy: 0.9238\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "135/750 [====>.........................] - ETA: 11s - loss: 0.2689 - accuracy: 0.9049\n",
      "143/750 [====>.........................] - ETA: 10s - loss: 0.2703 - accuracy: 0.9046\n",
      "616/750 [=======================>......] - ETA: 1s - loss: 0.1900 - accuracy: 0.9290\n",
      "545/750 [====================>.........] - ETA: 2s - loss: 0.1887 - accuracy: 0.9300\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2133 - accuracy: 0.9238\n",
      "149/750 [====>.........................] - ETA: 10s - loss: 0.2701 - accuracy: 0.9044\n",
      "632/750 [========================>.....] - ETA: 1s - loss: 0.1901 - accuracy: 0.9291\n",
      "322/750 [===========>..................] - ETA: 5s - loss: 0.1842 - accuracy: 0.9301\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2135 - accuracy: 0.9238\n",
      "162/750 [=====>........................] - ETA: 10s - loss: 0.2685 - accuracy: 0.9045\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.1899 - accuracy: 0.9293\n",
      "175/750 [======>.......................] - ETA: 9s - loss: 0.2677 - accuracy: 0.9046\n",
      "651/750 [=========================>....] - ETA: 1s - loss: 0.1894 - accuracy: 0.9296\n",
      "559/750 [=====================>........] - ETA: 2s - loss: 0.1884 - accuracy: 0.9300\n",
      "195/750 [======>.......................] - ETA: 9s - loss: 0.2656 - accuracy: 0.9053\n",
      "  8/750 [..............................] - ETA: 6s - loss: 0.2207 - accuracy: 0.9180\n",
      " 12/750 [..............................] - ETA: 8s - loss: 0.1858 - accuracy: 0.9349\n",
      "206/750 [=======>......................] - ETA: 8s - loss: 0.2639 - accuracy: 0.9059\n",
      "601/750 [=======================>......] - ETA: 2s - loss: 0.1892 - accuracy: 0.9293\n",
      "218/750 [=======>......................] - ETA: 8s - loss: 0.2658 - accuracy: 0.9056\n",
      " 21/750 [..............................] - ETA: 10s - loss: 0.2002 - accuracy: 0.9301\n",
      "615/750 [=======================>......] - ETA: 1s - loss: 0.1898 - accuracy: 0.9291\n",
      "221/750 [=======>......................] - ETA: 8s - loss: 0.2655 - accuracy: 0.9056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:05:41,101 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6090522624; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/750 [========>.....................] - ETA: 8s - loss: 0.2652 - accuracy: 0.9057\n",
      " 39/750 [>.............................] - ETA: 10s - loss: 0.2010 - accuracy: 0.9299\n",
      "505/750 [===================>..........] - ETA: 3s - loss: 0.1871 - accuracy: 0.9301\n",
      "234/750 [========>.....................] - ETA: 8s - loss: 0.2659 - accuracy: 0.9058\n",
      " 40/750 [>.............................] - ETA: 12s - loss: 0.2032 - accuracy: 0.9293\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.1897 - accuracy: 0.9296\n",
      "238/750 [========>.....................] - ETA: 8s - loss: 0.2661 - accuracy: 0.9057\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.1896 - accuracy: 0.9296\n",
      "245/750 [========>.....................] - ETA: 8s - loss: 0.2677 - accuracy: 0.9050\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.1891 - accuracy: 0.9297\n",
      "255/750 [=========>....................] - ETA: 7s - loss: 0.2685 - accuracy: 0.9045\n",
      "265/750 [=========>....................] - ETA: 7s - loss: 0.2674 - accuracy: 0.9042\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.1897 - accuracy: 0.9293\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.1899 - accuracy: 0.9294\n",
      "279/750 [==========>...................] - ETA: 7s - loss: 0.2675 - accuracy: 0.9046\n",
      " 94/750 [==>...........................] - ETA: 9s - loss: 0.2062 - accuracy: 0.9265\n",
      "699/750 [==========================>...] - ETA: 0s - loss: 0.1896 - accuracy: 0.9296\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.1902 - accuracy: 0.9294\n",
      "287/750 [==========>...................] - ETA: 7s - loss: 0.2677 - accuracy: 0.9043\n",
      " 98/750 [==>...........................] - ETA: 9s - loss: 0.2036 - accuracy: 0.9271\n",
      "298/750 [==========>...................] - ETA: 7s - loss: 0.2661 - accuracy: 0.9049\n",
      "107/750 [===>..........................] - ETA: 9s - loss: 0.2091 - accuracy: 0.9261\n",
      "113/750 [===>..........................] - ETA: 9s - loss: 0.2099 - accuracy: 0.9257\n",
      "672/750 [=========================>....] - ETA: 1s - loss: 0.1899 - accuracy: 0.9294\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "115/750 [===>..........................] - ETA: 9s - loss: 0.2093 - accuracy: 0.9261\n",
      "321/750 [===========>..................] - ETA: 6s - loss: 0.2670 - accuracy: 0.9043\n",
      "125/750 [====>.........................] - ETA: 9s - loss: 0.2105 - accuracy: 0.9254\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2138 - accuracy: 0.9238 - val_loss: 0.4490 - val_accuracy: 0.8791\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 19/30\n",
      "  1/750 [..............................] - ETA: 9s - loss: 0.3007 - accuracy: 0.8906\n",
      "134/750 [====>.........................] - ETA: 9s - loss: 0.2117 - accuracy: 0.9250\n",
      "153/750 [=====>........................] - ETA: 8s - loss: 0.2101 - accuracy: 0.9244\n",
      " 19/750 [..............................] - ETA: 9s - loss: 0.2039 - accuracy: 0.9317 \n",
      " 82/750 [==>...........................] - ETA: 10s - loss: 0.2103 - accuracy: 0.9257\n",
      "344/750 [============>.................] - ETA: 6s - loss: 0.2660 - accuracy: 0.9044\n",
      "159/750 [=====>........................] - ETA: 8s - loss: 0.2106 - accuracy: 0.9240\n",
      "349/750 [============>.................] - ETA: 6s - loss: 0.2670 - accuracy: 0.9041\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 24/750 [..............................] - ETA: 12s - loss: 0.1955 - accuracy: 0.9297\n",
      "357/750 [=============>................] - ETA: 6s - loss: 0.2675 - accuracy: 0.9043\n",
      "368/750 [=============>................] - ETA: 5s - loss: 0.2677 - accuracy: 0.9040\n",
      "179/750 [======>.......................] - ETA: 8s - loss: 0.2088 - accuracy: 0.9244\n",
      "380/750 [==============>...............] - ETA: 5s - loss: 0.2674 - accuracy: 0.9042\n",
      "384/750 [==============>...............] - ETA: 5s - loss: 0.2675 - accuracy: 0.9041\n",
      "393/750 [==============>...............] - ETA: 5s - loss: 0.2676 - accuracy: 0.9040\n",
      "169/750 [=====>........................] - ETA: 8s - loss: 0.2106 - accuracy: 0.9239\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 65/750 [=>............................] - ETA: 10s - loss: 0.2159 - accuracy: 0.9233\n",
      "403/750 [===============>..............] - ETA: 5s - loss: 0.2673 - accuracy: 0.9039\n",
      "413/750 [===============>..............] - ETA: 5s - loss: 0.2673 - accuracy: 0.9041\n",
      "197/750 [======>.......................] - ETA: 7s - loss: 0.2084 - accuracy: 0.9250\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "591/750 [======================>.......] - ETA: 2s - loss: 0.1893 - accuracy: 0.9296\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 76/750 [==>...........................] - ETA: 9s - loss: 0.2079 - accuracy: 0.9262 \n",
      "426/750 [================>.............] - ETA: 4s - loss: 0.2671 - accuracy: 0.9040\n",
      "432/750 [================>.............] - ETA: 4s - loss: 0.2666 - accuracy: 0.9045\n",
      "441/750 [================>.............] - ETA: 4s - loss: 0.2667 - accuracy: 0.9046\n",
      "439/750 [================>.............] - ETA: 4s - loss: 0.2665 - accuracy: 0.9046\n",
      "448/750 [================>.............] - ETA: 4s - loss: 0.2686 - accuracy: 0.9038\n",
      "452/750 [=================>............] - ETA: 4s - loss: 0.2686 - accuracy: 0.9038\n",
      "457/750 [=================>............] - ETA: 4s - loss: 0.2686 - accuracy: 0.9037\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1900 - accuracy: 0.9296 - val_loss: 0.3518 - val_accuracy: 0.8957\n",
      "459/750 [=================>............] - ETA: 4s - loss: 0.2685 - accuracy: 0.9036\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 18/30\n",
      " 49/750 [>.............................] - ETA: 11s - loss: 0.2120 - accuracy: 0.9267\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "261/750 [=========>....................] - ETA: 7s - loss: 0.2070 - accuracy: 0.9258\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  7/750 [..............................] - ETA: 9s - loss: 0.2090 - accuracy: 0.9196 \n",
      "466/750 [=================>............] - ETA: 4s - loss: 0.2691 - accuracy: 0.9033\n",
      "277/750 [==========>...................] - ETA: 6s - loss: 0.2061 - accuracy: 0.9259\n",
      "476/750 [==================>...........] - ETA: 4s - loss: 0.2698 - accuracy: 0.9032\n",
      " 16/750 [..............................] - ETA: 15s - loss: 0.1834 - accuracy: 0.9268\n",
      "482/750 [==================>...........] - ETA: 4s - loss: 0.2702 - accuracy: 0.9028\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.1896 - accuracy: 0.9294\n",
      " 20/750 [..............................] - ETA: 14s - loss: 0.1877 - accuracy: 0.9281\n",
      "484/750 [==================>...........] - ETA: 4s - loss: 0.2708 - accuracy: 0.9025\n",
      " 21/750 [..............................] - ETA: 17s - loss: 0.1871 - accuracy: 0.9278\n",
      "301/750 [===========>..................] - ETA: 6s - loss: 0.2061 - accuracy: 0.9259\n",
      "492/750 [==================>...........] - ETA: 4s - loss: 0.2709 - accuracy: 0.9026\n",
      "498/750 [==================>...........] - ETA: 3s - loss: 0.2708 - accuracy: 0.9028\n",
      "306/750 [===========>..................] - ETA: 6s - loss: 0.2060 - accuracy: 0.9261\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 46/750 [>.............................] - ETA: 13s - loss: 0.1793 - accuracy: 0.9321\n",
      "507/750 [===================>..........] - ETA: 3s - loss: 0.2706 - accuracy: 0.9029\n",
      "510/750 [===================>..........] - ETA: 3s - loss: 0.2706 - accuracy: 0.9028\n",
      " 55/750 [=>............................] - ETA: 13s - loss: 0.1725 - accuracy: 0.9361\n",
      " 59/750 [=>............................] - ETA: 13s - loss: 0.1718 - accuracy: 0.9367\n",
      "520/750 [===================>..........] - ETA: 3s - loss: 0.2705 - accuracy: 0.9028\n",
      "  9/750 [..............................] - ETA: 18s - loss: 0.1898 - accuracy: 0.9271\n",
      " 64/750 [=>............................] - ETA: 14s - loss: 0.1757 - accuracy: 0.9360\n",
      "528/750 [====================>.........] - ETA: 3s - loss: 0.2701 - accuracy: 0.9030\n",
      "219/750 [=======>......................] - ETA: 7s - loss: 0.2034 - accuracy: 0.9266\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 67/750 [=>............................] - ETA: 14s - loss: 0.1768 - accuracy: 0.9356\n",
      "529/750 [====================>.........] - ETA: 3s - loss: 0.2701 - accuracy: 0.9029\n",
      "216/750 [=======>......................] - ETA: 7s - loss: 0.2037 - accuracy: 0.9266\n",
      " 69/750 [=>............................] - ETA: 14s - loss: 0.1757 - accuracy: 0.9359\n",
      "533/750 [====================>.........] - ETA: 3s - loss: 0.2698 - accuracy: 0.9031\n",
      "232/750 [========>.....................] - ETA: 7s - loss: 0.2039 - accuracy: 0.9262\n",
      " 78/750 [==>...........................] - ETA: 14s - loss: 0.1735 - accuracy: 0.9367\n",
      "541/750 [====================>.........] - ETA: 3s - loss: 0.2693 - accuracy: 0.9032\n",
      " 48/750 [>.............................] - ETA: 15s - loss: 0.1767 - accuracy: 0.9329\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 87/750 [==>...........................] - ETA: 14s - loss: 0.1718 - accuracy: 0.9371\n",
      "555/750 [=====================>........] - ETA: 3s - loss: 0.2693 - accuracy: 0.9030\n",
      "350/750 [=============>................] - ETA: 6s - loss: 0.2072 - accuracy: 0.9255\n",
      "248/750 [========>.....................] - ETA: 7s - loss: 0.2026 - accuracy: 0.9269\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 92/750 [==>...........................] - ETA: 14s - loss: 0.1741 - accuracy: 0.9363\n",
      "558/750 [=====================>........] - ETA: 3s - loss: 0.2697 - accuracy: 0.9028\n",
      " 99/750 [==>...........................] - ETA: 13s - loss: 0.1711 - accuracy: 0.9372\n",
      "564/750 [=====================>........] - ETA: 3s - loss: 0.2695 - accuracy: 0.9030\n",
      "368/750 [=============>................] - ETA: 6s - loss: 0.2067 - accuracy: 0.9259\n",
      "105/750 [===>..........................] - ETA: 13s - loss: 0.1733 - accuracy: 0.9366\n",
      "372/750 [=============>................] - ETA: 6s - loss: 0.2061 - accuracy: 0.9261\n",
      "267/750 [=========>....................] - ETA: 7s - loss: 0.2067 - accuracy: 0.9261\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "111/750 [===>..........................] - ETA: 12s - loss: 0.1732 - accuracy: 0.9362\n",
      "122/750 [===>..........................] - ETA: 11s - loss: 0.1764 - accuracy: 0.9348\n",
      "579/750 [======================>.......] - ETA: 2s - loss: 0.2690 - accuracy: 0.9033\n",
      "585/750 [======================>.......] - ETA: 2s - loss: 0.2693 - accuracy: 0.9033\n",
      "287/750 [==========>...................] - ETA: 6s - loss: 0.2068 - accuracy: 0.9257\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "127/750 [====>.........................] - ETA: 11s - loss: 0.1783 - accuracy: 0.9342\n",
      "590/750 [======================>.......] - ETA: 2s - loss: 0.2696 - accuracy: 0.9032\n",
      "132/750 [====>.........................] - ETA: 11s - loss: 0.1795 - accuracy: 0.9335\n",
      "137/750 [====>.........................] - ETA: 11s - loss: 0.1800 - accuracy: 0.9332\n",
      "600/750 [=======================>......] - ETA: 2s - loss: 0.2696 - accuracy: 0.9034\n",
      "148/750 [====>.........................] - ETA: 10s - loss: 0.1825 - accuracy: 0.9332\n",
      "607/750 [=======================>......] - ETA: 2s - loss: 0.2692 - accuracy: 0.9035\n",
      "611/750 [=======================>......] - ETA: 2s - loss: 0.2687 - accuracy: 0.9038\n",
      "414/750 [===============>..............] - ETA: 5s - loss: 0.2086 - accuracy: 0.9254\n",
      "157/750 [=====>........................] - ETA: 10s - loss: 0.1822 - accuracy: 0.9333\n",
      "618/750 [=======================>......] - ETA: 2s - loss: 0.2696 - accuracy: 0.9036\n",
      "416/750 [===============>..............] - ETA: 5s - loss: 0.2086 - accuracy: 0.9253\n",
      "421/750 [===============>..............] - ETA: 5s - loss: 0.2085 - accuracy: 0.9252\n",
      "164/750 [=====>........................] - ETA: 10s - loss: 0.1812 - accuracy: 0.9334\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.2697 - accuracy: 0.9037\n",
      "313/750 [===========>..................] - ETA: 6s - loss: 0.2066 - accuracy: 0.9260\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "172/750 [=====>........................] - ETA: 10s - loss: 0.1820 - accuracy: 0.9330\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.2699 - accuracy: 0.9036\n",
      "179/750 [======>.......................] - ETA: 10s - loss: 0.1831 - accuracy: 0.9327\n",
      "644/750 [========================>.....] - ETA: 1s - loss: 0.2701 - accuracy: 0.9035\n",
      "192/750 [======>.......................] - ETA: 9s - loss: 0.1816 - accuracy: 0.9325\n",
      "655/750 [=========================>....] - ETA: 1s - loss: 0.2699 - accuracy: 0.9035\n",
      "343/750 [============>.................] - ETA: 6s - loss: 0.2067 - accuracy: 0.9256\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "203/750 [=======>......................] - ETA: 9s - loss: 0.1814 - accuracy: 0.9335\n",
      "661/750 [=========================>....] - ETA: 1s - loss: 0.2698 - accuracy: 0.9035\n",
      "673/750 [=========================>....] - ETA: 1s - loss: 0.2702 - accuracy: 0.9033\n",
      "338/750 [============>.................] - ETA: 6s - loss: 0.2056 - accuracy: 0.9261\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "359/750 [=============>................] - ETA: 6s - loss: 0.2060 - accuracy: 0.9258\n",
      "225/750 [========>.....................] - ETA: 8s - loss: 0.1791 - accuracy: 0.9344\n",
      "682/750 [==========================>...] - ETA: 1s - loss: 0.2702 - accuracy: 0.9033\n",
      "230/750 [========>.....................] - ETA: 8s - loss: 0.1802 - accuracy: 0.9336\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.2702 - accuracy: 0.9032\n",
      "379/750 [==============>...............] - ETA: 6s - loss: 0.2064 - accuracy: 0.9260\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2713 - accuracy: 0.9029\n",
      "398/750 [==============>...............] - ETA: 5s - loss: 0.2069 - accuracy: 0.9259\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2713 - accuracy: 0.9028\n",
      "525/750 [====================>.........] - ETA: 3s - loss: 0.2106 - accuracy: 0.9249\n",
      "386/750 [==============>...............] - ETA: 5s - loss: 0.2062 - accuracy: 0.9262\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2709 - accuracy: 0.9029\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.9029\n",
      "408/750 [===============>..............] - ETA: 5s - loss: 0.2086 - accuracy: 0.9255\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2704 - accuracy: 0.9030\n",
      "596/750 [======================>.......] - ETA: 2s - loss: 0.2697 - accuracy: 0.9032\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.2704 - accuracy: 0.9031\n",
      "292/750 [==========>...................] - ETA: 6s - loss: 0.1825 - accuracy: 0.9338\n",
      "444/750 [================>.............] - ETA: 4s - loss: 0.2076 - accuracy: 0.9255\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "303/750 [===========>..................] - ETA: 6s - loss: 0.1823 - accuracy: 0.9336\n",
      "592/750 [======================>.......] - ETA: 2s - loss: 0.2100 - accuracy: 0.9250\n",
      "326/750 [============>.................] - ETA: 6s - loss: 0.1829 - accuracy: 0.9330\n",
      "601/750 [=======================>......] - ETA: 2s - loss: 0.2104 - accuracy: 0.9249\n",
      "453/750 [=================>............] - ETA: 4s - loss: 0.2076 - accuracy: 0.9253\n",
      "461/750 [=================>............] - ETA: 4s - loss: 0.2070 - accuracy: 0.9256\n",
      "278/750 [==========>...................] - ETA: 7s - loss: 0.1821 - accuracy: 0.9337\n",
      "475/750 [==================>...........] - ETA: 4s - loss: 0.2080 - accuracy: 0.9254\n",
      "361/750 [=============>................] - ETA: 5s - loss: 0.1831 - accuracy: 0.9328\n",
      "493/750 [==================>...........] - ETA: 3s - loss: 0.2087 - accuracy: 0.9251\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "369/750 [=============>................] - ETA: 5s - loss: 0.1829 - accuracy: 0.9327\n",
      "376/750 [==============>...............] - ETA: 5s - loss: 0.1820 - accuracy: 0.9329\n",
      "394/750 [==============>...............] - ETA: 5s - loss: 0.1839 - accuracy: 0.9323\n",
      "675/750 [==========================>...] - ETA: 1s - loss: 0.2095 - accuracy: 0.9251\n",
      "401/750 [===============>..............] - ETA: 4s - loss: 0.1841 - accuracy: 0.9320\n",
      "679/750 [==========================>...] - ETA: 1s - loss: 0.2092 - accuracy: 0.9253\n",
      "314/750 [===========>..................] - ETA: 6s - loss: 0.1828 - accuracy: 0.9333\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "516/750 [===================>..........] - ETA: 3s - loss: 0.2105 - accuracy: 0.9250\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "417/750 [===============>..............] - ETA: 4s - loss: 0.1833 - accuracy: 0.9322\n",
      "422/750 [===============>..............] - ETA: 4s - loss: 0.1839 - accuracy: 0.9320\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2093 - accuracy: 0.9253\n",
      "428/750 [================>.............] - ETA: 4s - loss: 0.1828 - accuracy: 0.9324\n",
      "439/750 [================>.............] - ETA: 4s - loss: 0.1836 - accuracy: 0.9321\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2089 - accuracy: 0.9254\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.2102 - accuracy: 0.9251\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "450/750 [=================>............] - ETA: 4s - loss: 0.1833 - accuracy: 0.9324\n",
      "210/750 [=======>......................] - ETA: 8s - loss: 0.1801 - accuracy: 0.9344\n",
      "462/750 [=================>............] - ETA: 4s - loss: 0.1823 - accuracy: 0.9325\n",
      "750/750 [==============================] - 14s 18ms/step - loss: 0.2705 - accuracy: 0.9031 - val_loss: 0.3345 - val_accuracy: 0.8824\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 19/30\n",
      "  1/750 [..............................] - ETA: 5s - loss: 0.3001 - accuracy: 0.9062\n",
      "544/750 [====================>.........] - ETA: 3s - loss: 0.2104 - accuracy: 0.9249\n",
      "469/750 [=================>............] - ETA: 3s - loss: 0.1822 - accuracy: 0.9325\n",
      "  4/750 [..............................] - ETA: 21s - loss: 0.2759 - accuracy: 0.9141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:05:51,111 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6090145792; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478/750 [==================>...........] - ETA: 3s - loss: 0.1824 - accuracy: 0.9325\n",
      " 14/750 [..............................] - ETA: 11s - loss: 0.2676 - accuracy: 0.9107\n",
      " 27/750 [>.............................] - ETA: 9s - loss: 0.2653 - accuracy: 0.9068 \n",
      "501/750 [===================>..........] - ETA: 3s - loss: 0.1825 - accuracy: 0.9324\n",
      " 38/750 [>.............................] - ETA: 8s - loss: 0.2661 - accuracy: 0.9054\n",
      "352/750 [=============>................] - ETA: 5s - loss: 0.1833 - accuracy: 0.9327\n",
      "249/750 [========>.....................] - ETA: 7s - loss: 0.1815 - accuracy: 0.9337\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "558/750 [=====================>........] - ETA: 2s - loss: 0.2103 - accuracy: 0.9252\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 49/750 [>.............................] - ETA: 8s - loss: 0.2558 - accuracy: 0.9091\n",
      "526/750 [====================>.........] - ETA: 3s - loss: 0.1830 - accuracy: 0.9324\n",
      "570/750 [=====================>........] - ETA: 2s - loss: 0.2099 - accuracy: 0.9251\n",
      " 60/750 [=>............................] - ETA: 7s - loss: 0.2578 - accuracy: 0.9076\n",
      "532/750 [====================>.........] - ETA: 2s - loss: 0.1834 - accuracy: 0.9323\n",
      "261/750 [=========>....................] - ETA: 7s - loss: 0.1821 - accuracy: 0.9335\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 66/750 [=>............................] - ETA: 8s - loss: 0.2544 - accuracy: 0.9093\n",
      "584/750 [======================>.......] - ETA: 2s - loss: 0.2107 - accuracy: 0.9248\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 77/750 [==>...........................] - ETA: 8s - loss: 0.2577 - accuracy: 0.9075\n",
      "551/750 [=====================>........] - ETA: 2s - loss: 0.1832 - accuracy: 0.9324\n",
      "283/750 [==========>...................] - ETA: 7s - loss: 0.1820 - accuracy: 0.9340\n",
      " 91/750 [==>...........................] - ETA: 7s - loss: 0.2591 - accuracy: 0.9095\n",
      "561/750 [=====================>........] - ETA: 2s - loss: 0.1829 - accuracy: 0.9325\n",
      " 95/750 [==>...........................] - ETA: 7s - loss: 0.2622 - accuracy: 0.9087\n",
      "573/750 [=====================>........] - ETA: 2s - loss: 0.1826 - accuracy: 0.9326\n",
      "110/750 [===>..........................] - ETA: 7s - loss: 0.2590 - accuracy: 0.9102\n",
      "408/750 [===============>..............] - ETA: 4s - loss: 0.1843 - accuracy: 0.9319\n",
      "623/750 [=======================>......] - ETA: 1s - loss: 0.2109 - accuracy: 0.9249\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "114/750 [===>..........................] - ETA: 7s - loss: 0.2599 - accuracy: 0.9097\n",
      "130/750 [====>.........................] - ETA: 7s - loss: 0.2601 - accuracy: 0.9103\n",
      "316/750 [===========>..................] - ETA: 6s - loss: 0.1824 - accuracy: 0.9333\n",
      "136/750 [====>.........................] - ETA: 6s - loss: 0.2590 - accuracy: 0.9108\n",
      "640/750 [========================>.....] - ETA: 1s - loss: 0.2097 - accuracy: 0.9251\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "144/750 [====>.........................] - ETA: 7s - loss: 0.2582 - accuracy: 0.9104\n",
      "650/750 [=========================>....] - ETA: 1s - loss: 0.2096 - accuracy: 0.9251\n",
      "157/750 [=====>........................] - ETA: 6s - loss: 0.2587 - accuracy: 0.9102\n",
      "633/750 [========================>.....] - ETA: 1s - loss: 0.1821 - accuracy: 0.9326\n",
      "332/750 [============>.................] - ETA: 6s - loss: 0.1820 - accuracy: 0.9333\n",
      "662/750 [=========================>....] - ETA: 1s - loss: 0.2093 - accuracy: 0.9252\n",
      "169/750 [=====>........................] - ETA: 6s - loss: 0.2574 - accuracy: 0.9102\n",
      "175/750 [======>.......................] - ETA: 6s - loss: 0.2579 - accuracy: 0.9101\n",
      " 11/750 [..............................] - ETA: 9s - loss: 0.2147 - accuracy: 0.9261 \n",
      "339/750 [============>.................] - ETA: 6s - loss: 0.1826 - accuracy: 0.9331\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.2092 - accuracy: 0.9252\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "654/750 [=========================>....] - ETA: 1s - loss: 0.1834 - accuracy: 0.9321\n",
      "187/750 [======>.......................] - ETA: 6s - loss: 0.2574 - accuracy: 0.9102\n",
      " 24/750 [..............................] - ETA: 7s - loss: 0.1961 - accuracy: 0.9277\n",
      "661/750 [=========================>....] - ETA: 1s - loss: 0.1837 - accuracy: 0.9320\n",
      "205/750 [=======>......................] - ETA: 5s - loss: 0.2577 - accuracy: 0.9101\n",
      "208/750 [=======>......................] - ETA: 6s - loss: 0.2578 - accuracy: 0.9101\n",
      " 39/750 [>.............................] - ETA: 7s - loss: 0.1978 - accuracy: 0.9275\n",
      " 45/750 [>.............................] - ETA: 7s - loss: 0.1989 - accuracy: 0.9292\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2090 - accuracy: 0.9254\n",
      "219/750 [=======>......................] - ETA: 5s - loss: 0.2606 - accuracy: 0.9089\n",
      " 52/750 [=>............................] - ETA: 7s - loss: 0.1932 - accuracy: 0.9306\n",
      " 58/750 [=>............................] - ETA: 6s - loss: 0.1908 - accuracy: 0.9305\n",
      " 62/750 [=>............................] - ETA: 7s - loss: 0.1919 - accuracy: 0.9304\n",
      " 67/750 [=>............................] - ETA: 7s - loss: 0.1932 - accuracy: 0.9293\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2085 - accuracy: 0.9255\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2088 - accuracy: 0.9254\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.1843 - accuracy: 0.9318\n",
      "255/750 [=========>....................] - ETA: 5s - loss: 0.2603 - accuracy: 0.9089\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.1847 - accuracy: 0.9318\n",
      "270/750 [=========>....................] - ETA: 5s - loss: 0.2625 - accuracy: 0.9073\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.1846 - accuracy: 0.9319\n",
      "275/750 [==========>...................] - ETA: 5s - loss: 0.2630 - accuracy: 0.9068\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.9319\n",
      "287/750 [==========>...................] - ETA: 5s - loss: 0.2639 - accuracy: 0.9065\n",
      "595/750 [======================>.......] - ETA: 2s - loss: 0.1818 - accuracy: 0.9327\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "301/750 [===========>..................] - ETA: 5s - loss: 0.2639 - accuracy: 0.9068\n",
      "606/750 [=======================>......] - ETA: 1s - loss: 0.1822 - accuracy: 0.9326\n",
      "152/750 [=====>........................] - ETA: 6s - loss: 0.1961 - accuracy: 0.9300\n",
      "333/750 [============>.................] - ETA: 4s - loss: 0.2637 - accuracy: 0.9072\n",
      "342/750 [============>.................] - ETA: 4s - loss: 0.2657 - accuracy: 0.9058\n",
      "347/750 [============>.................] - ETA: 4s - loss: 0.2658 - accuracy: 0.9057\n",
      "490/750 [==================>...........] - ETA: 3s - loss: 0.1826 - accuracy: 0.9324\n",
      "360/750 [=============>................] - ETA: 4s - loss: 0.2659 - accuracy: 0.9057\n",
      "363/750 [=============>................] - ETA: 4s - loss: 0.2655 - accuracy: 0.9059\n",
      "194/750 [======>.......................] - ETA: 6s - loss: 0.1977 - accuracy: 0.9292\n",
      "676/750 [==========================>...] - ETA: 0s - loss: 0.1835 - accuracy: 0.9322\n",
      "369/750 [=============>................] - ETA: 4s - loss: 0.2656 - accuracy: 0.9061\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 0.2655 - accuracy: 0.9064\n",
      "324/750 [===========>..................] - ETA: 4s - loss: 0.2644 - accuracy: 0.9069\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "510/750 [===================>..........] - ETA: 3s - loss: 0.1823 - accuracy: 0.9325\n",
      "382/750 [==============>...............] - ETA: 4s - loss: 0.2656 - accuracy: 0.9062\n",
      "394/750 [==============>...............] - ETA: 4s - loss: 0.2643 - accuracy: 0.9065\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.1843 - accuracy: 0.9319\n",
      "398/750 [==============>...............] - ETA: 4s - loss: 0.2643 - accuracy: 0.9064\n",
      "409/750 [===============>..............] - ETA: 4s - loss: 0.2635 - accuracy: 0.9066\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.1846 - accuracy: 0.9317\n",
      "539/750 [====================>.........] - ETA: 2s - loss: 0.1834 - accuracy: 0.9323\n",
      "421/750 [===============>..............] - ETA: 3s - loss: 0.2637 - accuracy: 0.9064\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2084 - accuracy: 0.9255 - val_loss: 0.4869 - val_accuracy: 0.8857\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 20/30\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.1436 - accuracy: 0.9531\n",
      "429/750 [================>.............] - ETA: 3s - loss: 0.2630 - accuracy: 0.9067\n",
      "442/750 [================>.............] - ETA: 3s - loss: 0.2630 - accuracy: 0.9066\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1847 - accuracy: 0.9319 - val_loss: 0.3514 - val_accuracy: 0.8918\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 19/30\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.1562 - accuracy: 0.9219\n",
      "450/750 [=================>............] - ETA: 3s - loss: 0.2634 - accuracy: 0.9063\n",
      "289/750 [==========>...................] - ETA: 5s - loss: 0.1984 - accuracy: 0.9297\n",
      "461/750 [=================>............] - ETA: 3s - loss: 0.2633 - accuracy: 0.9065\n",
      "296/750 [==========>...................] - ETA: 5s - loss: 0.1983 - accuracy: 0.9295\n",
      " 15/750 [..............................] - ETA: 10s - loss: 0.1669 - accuracy: 0.9292\n",
      " 33/750 [>.............................] - ETA: 7s - loss: 0.1865 - accuracy: 0.9332\n",
      "468/750 [=================>............] - ETA: 3s - loss: 0.2639 - accuracy: 0.9062\n",
      "299/750 [==========>...................] - ETA: 5s - loss: 0.1981 - accuracy: 0.9296\n",
      " 16/750 [..............................] - ETA: 13s - loss: 0.1686 - accuracy: 0.9297\n",
      "241/750 [========>.....................] - ETA: 6s - loss: 0.1987 - accuracy: 0.9295\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      " 24/750 [..............................] - ETA: 12s - loss: 0.1813 - accuracy: 0.9303\n",
      "475/750 [==================>...........] - ETA: 3s - loss: 0.2645 - accuracy: 0.9057\n",
      "313/750 [===========>..................] - ETA: 5s - loss: 0.1981 - accuracy: 0.9293\n",
      " 73/750 [=>............................] - ETA: 7s - loss: 0.1877 - accuracy: 0.9317\n",
      " 31/750 [>.............................] - ETA: 10s - loss: 0.1796 - accuracy: 0.9294\n",
      "484/750 [==================>...........] - ETA: 3s - loss: 0.2647 - accuracy: 0.9055\n",
      " 35/750 [>.............................] - ETA: 10s - loss: 0.1745 - accuracy: 0.9304\n",
      " 39/750 [>.............................] - ETA: 11s - loss: 0.1734 - accuracy: 0.9303\n",
      "489/750 [==================>...........] - ETA: 3s - loss: 0.2650 - accuracy: 0.9052\n",
      " 50/750 [=>............................] - ETA: 10s - loss: 0.1761 - accuracy: 0.9337\n",
      "498/750 [==================>...........] - ETA: 3s - loss: 0.2645 - accuracy: 0.9054\n",
      " 98/750 [==>...........................] - ETA: 7s - loss: 0.1920 - accuracy: 0.9290\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 57/750 [=>............................] - ETA: 9s - loss: 0.1747 - accuracy: 0.9342 \n",
      "505/750 [===================>..........] - ETA: 2s - loss: 0.2653 - accuracy: 0.9051\n",
      "354/750 [=============>................] - ETA: 4s - loss: 0.1992 - accuracy: 0.9287\n",
      " 67/750 [=>............................] - ETA: 9s - loss: 0.1737 - accuracy: 0.9345\n",
      "515/750 [===================>..........] - ETA: 2s - loss: 0.2655 - accuracy: 0.9051\n",
      "114/750 [===>..........................] - ETA: 7s - loss: 0.1926 - accuracy: 0.9293\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 83/750 [==>...........................] - ETA: 8s - loss: 0.1729 - accuracy: 0.9352\n",
      "531/750 [====================>.........] - ETA: 2s - loss: 0.2641 - accuracy: 0.9059\n",
      "624/750 [=======================>......] - ETA: 1s - loss: 0.1821 - accuracy: 0.9325\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "542/750 [====================>.........] - ETA: 2s - loss: 0.2646 - accuracy: 0.9056\n",
      "130/750 [====>.........................] - ETA: 6s - loss: 0.1940 - accuracy: 0.9291\n",
      "557/750 [=====================>........] - ETA: 2s - loss: 0.2638 - accuracy: 0.9057\n",
      "115/750 [===>..........................] - ETA: 7s - loss: 0.1738 - accuracy: 0.9360\n",
      "564/750 [=====================>........] - ETA: 2s - loss: 0.2644 - accuracy: 0.9056\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.1819 - accuracy: 0.9327\n",
      "140/750 [====>.........................] - ETA: 6s - loss: 0.1949 - accuracy: 0.9297\n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.2642 - accuracy: 0.9059\n",
      "172/750 [=====>........................] - ETA: 6s - loss: 0.1936 - accuracy: 0.9305\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "139/750 [====>.........................] - ETA: 6s - loss: 0.1791 - accuracy: 0.9337\n",
      "144/750 [====>.........................] - ETA: 6s - loss: 0.1786 - accuracy: 0.9344\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.2633 - accuracy: 0.9067\n",
      " 13/750 [..............................] - ETA: 8s - loss: 0.1740 - accuracy: 0.9255 \n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.1842 - accuracy: 0.9320\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "199/750 [======>.......................] - ETA: 6s - loss: 0.1983 - accuracy: 0.9289\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "176/750 [======>.......................] - ETA: 6s - loss: 0.1820 - accuracy: 0.9329\n",
      "628/750 [========================>.....] - ETA: 1s - loss: 0.2636 - accuracy: 0.9066\n",
      "637/750 [========================>.....] - ETA: 1s - loss: 0.2639 - accuracy: 0.9064\n",
      "222/750 [=======>......................] - ETA: 6s - loss: 0.1961 - accuracy: 0.9298\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.2637 - accuracy: 0.9066\n",
      "655/750 [=========================>....] - ETA: 1s - loss: 0.2631 - accuracy: 0.9071\n",
      "668/750 [=========================>....] - ETA: 0s - loss: 0.2640 - accuracy: 0.9066\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.2636 - accuracy: 0.9067\n",
      "254/750 [=========>....................] - ETA: 5s - loss: 0.1971 - accuracy: 0.9294\n",
      "241/750 [========>.....................] - ETA: 5s - loss: 0.1844 - accuracy: 0.9311\n",
      "269/750 [=========>....................] - ETA: 5s - loss: 0.1985 - accuracy: 0.9294\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "251/750 [=========>....................] - ETA: 5s - loss: 0.1836 - accuracy: 0.9310\n",
      "280/750 [==========>...................] - ETA: 5s - loss: 0.1994 - accuracy: 0.9291\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2642 - accuracy: 0.9066\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2642 - accuracy: 0.9067\n",
      "596/750 [======================>.......] - ETA: 1s - loss: 0.2633 - accuracy: 0.9068\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "290/750 [==========>...................] - ETA: 4s - loss: 0.1819 - accuracy: 0.9320\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2648 - accuracy: 0.9064\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2654 - accuracy: 0.9061\n",
      "151/750 [=====>........................] - ETA: 7s - loss: 0.1798 - accuracy: 0.9339\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2653 - accuracy: 0.9061\n",
      "342/750 [============>.................] - ETA: 4s - loss: 0.1991 - accuracy: 0.9286\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "619/750 [=======================>......] - ETA: 1s - loss: 0.2002 - accuracy: 0.9275\n",
      "340/750 [============>.................] - ETA: 4s - loss: 0.1812 - accuracy: 0.9328\n",
      "347/750 [============>.................] - ETA: 4s - loss: 0.1813 - accuracy: 0.9328\n",
      "367/750 [=============>................] - ETA: 4s - loss: 0.1988 - accuracy: 0.9287\n",
      "358/750 [=============>................] - ETA: 4s - loss: 0.1819 - accuracy: 0.9328\n",
      "367/750 [=============>................] - ETA: 4s - loss: 0.1819 - accuracy: 0.9327\n",
      "380/750 [==============>...............] - ETA: 4s - loss: 0.1981 - accuracy: 0.9287\n",
      "377/750 [==============>...............] - ETA: 4s - loss: 0.1821 - accuracy: 0.9327\n",
      "659/750 [=========================>....] - ETA: 1s - loss: 0.1999 - accuracy: 0.9274\n",
      "324/750 [===========>..................] - ETA: 4s - loss: 0.1825 - accuracy: 0.9319\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "398/750 [==============>...............] - ETA: 4s - loss: 0.1976 - accuracy: 0.9290\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "403/750 [===============>..............] - ETA: 3s - loss: 0.1817 - accuracy: 0.9325\n",
      "420/750 [===============>..............] - ETA: 3s - loss: 0.1967 - accuracy: 0.9294\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "431/750 [================>.............] - ETA: 3s - loss: 0.1812 - accuracy: 0.9330\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "446/750 [================>.............] - ETA: 3s - loss: 0.1810 - accuracy: 0.9330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:06:01,209 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 6089183232; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457/750 [=================>............] - ETA: 3s - loss: 0.1806 - accuracy: 0.9332\n",
      "295/750 [==========>...................] - ETA: 5s - loss: 0.1831 - accuracy: 0.9315\n",
      "473/750 [=================>............] - ETA: 3s - loss: 0.1981 - accuracy: 0.9288\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 0.2653 - accuracy: 0.9061 - val_loss: 0.3182 - val_accuracy: 0.8856\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 20/30\n",
      "  9/750 [..............................] - ETA: 4s - loss: 0.2559 - accuracy: 0.9097 \n",
      "235/750 [========>.....................] - ETA: 5s - loss: 0.1844 - accuracy: 0.9312\n",
      " 22/750 [..............................] - ETA: 6s - loss: 0.2582 - accuracy: 0.9077\n",
      "497/750 [==================>...........] - ETA: 2s - loss: 0.1806 - accuracy: 0.9331\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 34/750 [>.............................] - ETA: 6s - loss: 0.2571 - accuracy: 0.9044\n",
      "511/750 [===================>..........] - ETA: 2s - loss: 0.1798 - accuracy: 0.9334\n",
      "478/750 [==================>...........] - ETA: 3s - loss: 0.1801 - accuracy: 0.9335\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 43/750 [>.............................] - ETA: 6s - loss: 0.2531 - accuracy: 0.9073\n",
      " 95/750 [==>...........................] - ETA: 7s - loss: 0.1771 - accuracy: 0.9347\n",
      "518/750 [===================>..........] - ETA: 2s - loss: 0.1798 - accuracy: 0.9334\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 48/750 [>.............................] - ETA: 7s - loss: 0.2596 - accuracy: 0.9053\n",
      "352/750 [=============>................] - ETA: 4s - loss: 0.1820 - accuracy: 0.9326\n",
      " 61/750 [=>............................] - ETA: 7s - loss: 0.2587 - accuracy: 0.9057\n",
      "123/750 [===>..........................] - ETA: 7s - loss: 0.1743 - accuracy: 0.9358\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "527/750 [====================>.........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9331\n",
      " 67/750 [=>............................] - ETA: 8s - loss: 0.2615 - accuracy: 0.9037\n",
      "535/750 [====================>.........] - ETA: 2s - loss: 0.1799 - accuracy: 0.9334\n",
      "612/750 [=======================>......] - ETA: 1s - loss: 0.2010 - accuracy: 0.9272\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "533/750 [====================>.........] - ETA: 2s - loss: 0.1800 - accuracy: 0.9333\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "553/750 [=====================>........] - ETA: 2s - loss: 0.2003 - accuracy: 0.9278\n",
      " 69/750 [=>............................] - ETA: 9s - loss: 0.2631 - accuracy: 0.9038\n",
      "539/750 [====================>.........] - ETA: 2s - loss: 0.1798 - accuracy: 0.9335\n",
      "573/750 [=====================>........] - ETA: 2s - loss: 0.2002 - accuracy: 0.9275\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "545/750 [====================>.........] - ETA: 2s - loss: 0.1797 - accuracy: 0.9335\n",
      " 76/750 [==>...........................] - ETA: 11s - loss: 0.2581 - accuracy: 0.9050\n",
      " 78/750 [==>...........................] - ETA: 12s - loss: 0.2595 - accuracy: 0.9048\n",
      "164/750 [=====>........................] - ETA: 6s - loss: 0.1805 - accuracy: 0.9336\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.1794 - accuracy: 0.9334\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 0.2004 - accuracy: 0.9275\n",
      " 80/750 [==>...........................] - ETA: 13s - loss: 0.2577 - accuracy: 0.9057\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.2009 - accuracy: 0.9270\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "199/750 [======>.......................] - ETA: 6s - loss: 0.1840 - accuracy: 0.9318\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 87/750 [==>...........................] - ETA: 12s - loss: 0.2593 - accuracy: 0.9037\n",
      "560/750 [=====================>........] - ETA: 2s - loss: 0.1792 - accuracy: 0.9335\n",
      " 95/750 [==>...........................] - ETA: 12s - loss: 0.2569 - accuracy: 0.9062\n",
      "649/750 [========================>.....] - ETA: 1s - loss: 0.2004 - accuracy: 0.9274\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "102/750 [===>..........................] - ETA: 12s - loss: 0.2562 - accuracy: 0.9064\n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.1790 - accuracy: 0.9335\n",
      "222/750 [=======>......................] - ETA: 5s - loss: 0.1846 - accuracy: 0.9316\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "108/750 [===>..........................] - ETA: 12s - loss: 0.2579 - accuracy: 0.9055\n",
      "110/750 [===>..........................] - ETA: 12s - loss: 0.2574 - accuracy: 0.9054\n",
      "118/750 [===>..........................] - ETA: 11s - loss: 0.2567 - accuracy: 0.9065\n",
      "669/750 [=========================>....] - ETA: 0s - loss: 0.1997 - accuracy: 0.9275\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "130/750 [====>.........................] - ETA: 11s - loss: 0.2603 - accuracy: 0.9061\n",
      "136/750 [====>.........................] - ETA: 10s - loss: 0.2608 - accuracy: 0.9056\n",
      "613/750 [=======================>......] - ETA: 1s - loss: 0.1791 - accuracy: 0.9335\n",
      "272/750 [=========>....................] - ETA: 5s - loss: 0.1812 - accuracy: 0.9320\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "144/750 [====>.........................] - ETA: 10s - loss: 0.2599 - accuracy: 0.9044\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2013 - accuracy: 0.9268\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "154/750 [=====>........................] - ETA: 10s - loss: 0.2604 - accuracy: 0.9048\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.1792 - accuracy: 0.9336\n",
      "166/750 [=====>........................] - ETA: 9s - loss: 0.2604 - accuracy: 0.9054\n",
      "597/750 [======================>.......] - ETA: 1s - loss: 0.1790 - accuracy: 0.9336\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2018 - accuracy: 0.9266\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "177/750 [======>.......................] - ETA: 9s - loss: 0.2600 - accuracy: 0.9055\n",
      " 34/750 [>.............................] - ETA: 6s - loss: 0.1839 - accuracy: 0.9288\n",
      "651/750 [=========================>....] - ETA: 1s - loss: 0.1787 - accuracy: 0.9340\n",
      " 35/750 [>.............................] - ETA: 8s - loss: 0.1825 - accuracy: 0.9290\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2010 - accuracy: 0.9269\n",
      "333/750 [============>.................] - ETA: 4s - loss: 0.1812 - accuracy: 0.9324\n",
      " 59/750 [=>............................] - ETA: 7s - loss: 0.1878 - accuracy: 0.9272\n",
      " 75/750 [==>...........................] - ETA: 7s - loss: 0.1882 - accuracy: 0.9269\n",
      "620/750 [=======================>......] - ETA: 1s - loss: 0.1791 - accuracy: 0.9335\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "227/750 [========>.....................] - ETA: 7s - loss: 0.2593 - accuracy: 0.9071\n",
      " 85/750 [==>...........................] - ETA: 6s - loss: 0.1916 - accuracy: 0.9265\n",
      "239/750 [========>.....................] - ETA: 7s - loss: 0.2577 - accuracy: 0.9078\n",
      " 96/750 [==>...........................] - ETA: 6s - loss: 0.1902 - accuracy: 0.9269\n",
      "248/750 [========>.....................] - ETA: 7s - loss: 0.2583 - accuracy: 0.9076\n",
      "278/750 [==========>...................] - ETA: 6s - loss: 0.2575 - accuracy: 0.9084\n",
      "280/750 [==========>...................] - ETA: 6s - loss: 0.2578 - accuracy: 0.9083\n",
      "134/750 [====>.........................] - ETA: 6s - loss: 0.1865 - accuracy: 0.9288\n",
      "392/750 [==============>...............] - ETA: 4s - loss: 0.1822 - accuracy: 0.9326\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "284/750 [==========>...................] - ETA: 6s - loss: 0.2581 - accuracy: 0.9081\n",
      "290/750 [==========>...................] - ETA: 6s - loss: 0.2585 - accuracy: 0.9084\n",
      "145/750 [====>.........................] - ETA: 5s - loss: 0.1887 - accuracy: 0.9286\n",
      "297/750 [==========>...................] - ETA: 6s - loss: 0.2585 - accuracy: 0.9083\n",
      "306/750 [===========>..................] - ETA: 6s - loss: 0.2592 - accuracy: 0.9083\n",
      "163/750 [=====>........................] - ETA: 5s - loss: 0.1887 - accuracy: 0.9288\n",
      "324/750 [===========>..................] - ETA: 5s - loss: 0.2596 - accuracy: 0.9082\n",
      "417/750 [===============>..............] - ETA: 3s - loss: 0.1820 - accuracy: 0.9324\n",
      "339/750 [============>.................] - ETA: 5s - loss: 0.2598 - accuracy: 0.9078\n",
      "353/750 [=============>................] - ETA: 5s - loss: 0.2609 - accuracy: 0.9076\n",
      "202/750 [=======>......................] - ETA: 4s - loss: 0.1888 - accuracy: 0.9293\n",
      "443/750 [================>.............] - ETA: 3s - loss: 0.1812 - accuracy: 0.9331\n",
      "359/750 [=============>................] - ETA: 4s - loss: 0.2613 - accuracy: 0.9073\n",
      "369/750 [=============>................] - ETA: 4s - loss: 0.2607 - accuracy: 0.9074\n",
      "474/750 [=================>............] - ETA: 3s - loss: 0.1795 - accuracy: 0.9336\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "255/750 [=========>....................] - ETA: 4s - loss: 0.1919 - accuracy: 0.9285\n",
      "406/750 [===============>..............] - ETA: 4s - loss: 0.2590 - accuracy: 0.9079\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.2019 - accuracy: 0.9265 - val_loss: 0.4710 - val_accuracy: 0.8818\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 21/30\n",
      "  6/750 [..............................] - ETA: 9s - loss: 0.2103 - accuracy: 0.9323\n",
      "425/750 [================>.............] - ETA: 3s - loss: 0.2592 - accuracy: 0.9076\n",
      "288/750 [==========>...................] - ETA: 4s - loss: 0.1933 - accuracy: 0.9281\n",
      " 13/750 [..............................] - ETA: 11s - loss: 0.1884 - accuracy: 0.9315\n",
      "442/750 [================>.............] - ETA: 3s - loss: 0.2594 - accuracy: 0.9075\n",
      "304/750 [===========>..................] - ETA: 3s - loss: 0.1936 - accuracy: 0.9277\n",
      " 47/750 [>.............................] - ETA: 7s - loss: 0.1885 - accuracy: 0.9255\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 0.1799 - accuracy: 0.9333 - val_loss: 0.3765 - val_accuracy: 0.8895\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 20/30\n",
      "  7/750 [..............................] - ETA: 7s - loss: 0.1949 - accuracy: 0.9420\n",
      "454/750 [=================>............] - ETA: 3s - loss: 0.2595 - accuracy: 0.9076\n",
      " 23/750 [..............................] - ETA: 5s - loss: 0.1689 - accuracy: 0.9443\n",
      " 37/750 [>.............................] - ETA: 5s - loss: 0.1574 - accuracy: 0.9464\n",
      "482/750 [==================>...........] - ETA: 3s - loss: 0.2602 - accuracy: 0.9076\n",
      " 43/750 [>.............................] - ETA: 6s - loss: 0.1530 - accuracy: 0.9466\n",
      "491/750 [==================>...........] - ETA: 2s - loss: 0.2615 - accuracy: 0.9071\n",
      " 53/750 [=>............................] - ETA: 8s - loss: 0.1875 - accuracy: 0.9275\n",
      " 59/750 [=>............................] - ETA: 6s - loss: 0.1617 - accuracy: 0.9447\n",
      "123/750 [===>..........................] - ETA: 6s - loss: 0.1880 - accuracy: 0.9271\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "505/750 [===================>..........] - ETA: 2s - loss: 0.2625 - accuracy: 0.9069\n",
      "537/750 [====================>.........] - ETA: 2s - loss: 0.1799 - accuracy: 0.9335\n",
      " 66/750 [=>............................] - ETA: 6s - loss: 0.1695 - accuracy: 0.9420\n",
      "510/750 [===================>..........] - ETA: 2s - loss: 0.2618 - accuracy: 0.9071\n",
      " 73/750 [=>............................] - ETA: 7s - loss: 0.1671 - accuracy: 0.9422\n",
      "523/750 [===================>..........] - ETA: 2s - loss: 0.2617 - accuracy: 0.9073\n",
      "566/750 [=====================>........] - ETA: 2s - loss: 0.1789 - accuracy: 0.9337\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "530/750 [====================>.........] - ETA: 2s - loss: 0.2619 - accuracy: 0.9070\n",
      "534/750 [====================>.........] - ETA: 2s - loss: 0.2617 - accuracy: 0.9069\n",
      "379/750 [==============>...............] - ETA: 3s - loss: 0.1964 - accuracy: 0.9273\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.2619 - accuracy: 0.9067\n",
      "383/750 [==============>...............] - ETA: 3s - loss: 0.1972 - accuracy: 0.9271\n",
      "101/750 [===>..........................] - ETA: 7s - loss: 0.1744 - accuracy: 0.9370\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.2617 - accuracy: 0.9065\n",
      "389/750 [==============>...............] - ETA: 3s - loss: 0.1978 - accuracy: 0.9270\n",
      "396/750 [==============>...............] - ETA: 3s - loss: 0.1985 - accuracy: 0.9270\n",
      "403/750 [===============>..............] - ETA: 3s - loss: 0.1986 - accuracy: 0.9271\n",
      "115/750 [===>..........................] - ETA: 7s - loss: 0.1678 - accuracy: 0.9391\n",
      "409/750 [===============>..............] - ETA: 3s - loss: 0.1981 - accuracy: 0.9273\n",
      "128/750 [====>.........................] - ETA: 6s - loss: 0.1707 - accuracy: 0.9379\n",
      "696/750 [==========================>...] - ETA: 0s - loss: 0.1799 - accuracy: 0.9332\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "195/750 [======>.......................] - ETA: 4s - loss: 0.1902 - accuracy: 0.9288\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "134/750 [====>.........................] - ETA: 6s - loss: 0.1722 - accuracy: 0.9373\n",
      "556/750 [=====================>........] - ETA: 2s - loss: 0.2613 - accuracy: 0.9068\n",
      "597/750 [======================>.......] - ETA: 1s - loss: 0.2607 - accuracy: 0.9071\n",
      "155/750 [=====>........................] - ETA: 6s - loss: 0.1727 - accuracy: 0.9372\n",
      "164/750 [=====>........................] - ETA: 5s - loss: 0.1739 - accuracy: 0.9368\n",
      "616/750 [=======================>......] - ETA: 1s - loss: 0.2609 - accuracy: 0.9068\n",
      "167/750 [=====>........................] - ETA: 6s - loss: 0.1744 - accuracy: 0.9368\n",
      "641/750 [========================>.....] - ETA: 1s - loss: 0.1791 - accuracy: 0.9337\n",
      "576/750 [======================>.......] - ETA: 2s - loss: 0.2619 - accuracy: 0.9067\n",
      "215/750 [=======>......................] - ETA: 4s - loss: 0.1892 - accuracy: 0.9297\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "634/750 [========================>.....] - ETA: 1s - loss: 0.2610 - accuracy: 0.9071\n",
      "477/750 [==================>...........] - ETA: 2s - loss: 0.1977 - accuracy: 0.9274\n",
      "484/750 [==================>...........] - ETA: 2s - loss: 0.1975 - accuracy: 0.9276\n",
      "202/750 [=======>......................] - ETA: 5s - loss: 0.1757 - accuracy: 0.9353\n",
      "649/750 [========================>.....] - ETA: 1s - loss: 0.2615 - accuracy: 0.9069\n",
      "505/750 [===================>..........] - ETA: 2s - loss: 0.1989 - accuracy: 0.9273\n",
      "513/750 [===================>..........] - ETA: 2s - loss: 0.1982 - accuracy: 0.9275\n",
      "662/750 [=========================>....] - ETA: 0s - loss: 0.2612 - accuracy: 0.9070\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.2616 - accuracy: 0.9068\n",
      "522/750 [===================>..........] - ETA: 2s - loss: 0.1980 - accuracy: 0.9275\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.2620 - accuracy: 0.9067\n",
      "272/750 [=========>....................] - ETA: 4s - loss: 0.1922 - accuracy: 0.9283\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "551/750 [=====================>........] - ETA: 1s - loss: 0.1990 - accuracy: 0.9275\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.1807 - accuracy: 0.9330\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2607 - accuracy: 0.9070\n",
      "578/750 [======================>.......] - ETA: 1s - loss: 0.1986 - accuracy: 0.9277\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.2608 - accuracy: 0.9070\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.1799 - accuracy: 0.9333\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "179/750 [======>.......................] - ETA: 5s - loss: 0.1937 - accuracy: 0.9270\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.1988 - accuracy: 0.9277\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2607 - accuracy: 0.9071\n",
      "330/750 [============>.................] - ETA: 3s - loss: 0.1773 - accuracy: 0.9346\n",
      "631/750 [========================>.....] - ETA: 1s - loss: 0.1987 - accuracy: 0.9279\n",
      "618/750 [=======================>......] - ETA: 1s - loss: 0.1986 - accuracy: 0.9280\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "231/750 [========>.....................] - ETA: 4s - loss: 0.1920 - accuracy: 0.9290\n",
      " 88/750 [==>...........................] - ETA: 7s - loss: 0.1707 - accuracy: 0.9393\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "246/750 [========>.....................] - ETA: 4s - loss: 0.1733 - accuracy: 0.9361\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "382/750 [==============>...............] - ETA: 3s - loss: 0.1758 - accuracy: 0.9352\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.1998 - accuracy: 0.9276\n",
      "276/750 [==========>...................] - ETA: 4s - loss: 0.1760 - accuracy: 0.9348\n",
      "148/750 [====>.........................] - ETA: 6s - loss: 0.1726 - accuracy: 0.9374\n",
      "398/750 [==============>...............] - ETA: 3s - loss: 0.1750 - accuracy: 0.9360\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "321/750 [===========>..................] - ETA: 3s - loss: 0.1777 - accuracy: 0.9343\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.2338 - accuracy: 0.9375\n",
      "343/750 [============>.................] - ETA: 3s - loss: 0.1767 - accuracy: 0.9346\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "481/750 [==================>...........] - ETA: 2s - loss: 0.1755 - accuracy: 0.9352\n",
      "352/750 [=============>................] - ETA: 3s - loss: 0.1958 - accuracy: 0.9273\n",
      " 33/750 [>.............................] - ETA: 4s - loss: 0.2510 - accuracy: 0.9105\n",
      "223/750 [=======>......................] - ETA: 4s - loss: 0.1733 - accuracy: 0.9363\n",
      "362/750 [=============>................] - ETA: 3s - loss: 0.1962 - accuracy: 0.9273\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 52/750 [=>............................] - ETA: 4s - loss: 0.2459 - accuracy: 0.9132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:06:11,241 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7120936960; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/750 [=============>................] - ETA: 3s - loss: 0.1759 - accuracy: 0.9350\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "526/750 [====================>.........] - ETA: 1s - loss: 0.1753 - accuracy: 0.9354\n",
      " 80/750 [==>...........................] - ETA: 4s - loss: 0.2477 - accuracy: 0.9127\n",
      "468/750 [=================>............] - ETA: 2s - loss: 0.1765 - accuracy: 0.9350\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "424/750 [===============>..............] - ETA: 2s - loss: 0.1757 - accuracy: 0.9354\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "288/750 [==========>...................] - ETA: 4s - loss: 0.1767 - accuracy: 0.9346\n",
      "436/750 [================>.............] - ETA: 2s - loss: 0.1756 - accuracy: 0.9352\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "135/750 [====>.........................] - ETA: 4s - loss: 0.2535 - accuracy: 0.9110\n",
      "302/750 [===========>..................] - ETA: 4s - loss: 0.1771 - accuracy: 0.9345\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.2606 - accuracy: 0.9071 - val_loss: 0.3150 - val_accuracy: 0.8870\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 21/30\n",
      "453/750 [=================>............] - ETA: 2s - loss: 0.1760 - accuracy: 0.9351\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "146/750 [====>.........................] - ETA: 4s - loss: 0.2547 - accuracy: 0.9101\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 0.2002 - accuracy: 0.9278 - val_loss: 0.4735 - val_accuracy: 0.8836\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 22/30\n",
      " 16/750 [..............................] - ETA: 4s - loss: 0.2427 - accuracy: 0.9180\n",
      "158/750 [=====>........................] - ETA: 4s - loss: 0.2548 - accuracy: 0.9100\n",
      " 16/750 [..............................] - ETA: 5s - loss: 0.1828 - accuracy: 0.9326\n",
      "498/750 [==================>...........] - ETA: 2s - loss: 0.1761 - accuracy: 0.9351\n",
      "176/750 [======>.......................] - ETA: 4s - loss: 0.2520 - accuracy: 0.9109\n",
      "198/750 [======>.......................] - ETA: 3s - loss: 0.2535 - accuracy: 0.9109\n",
      " 46/750 [>.............................] - ETA: 5s - loss: 0.1843 - accuracy: 0.9321\n",
      "654/750 [=========================>....] - ETA: 0s - loss: 0.1733 - accuracy: 0.9364\n",
      "206/750 [=======>......................] - ETA: 3s - loss: 0.2530 - accuracy: 0.9113\n",
      " 56/750 [=>............................] - ETA: 5s - loss: 0.1828 - accuracy: 0.9314\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "118/750 [===>..........................] - ETA: 4s - loss: 0.2492 - accuracy: 0.9125\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 59/750 [=>............................] - ETA: 6s - loss: 0.1885 - accuracy: 0.9288\n",
      "510/750 [===================>..........] - ETA: 2s - loss: 0.1761 - accuracy: 0.9351\n",
      "225/750 [========>.....................] - ETA: 4s - loss: 0.2529 - accuracy: 0.9114\n",
      " 80/750 [==>...........................] - ETA: 5s - loss: 0.1848 - accuracy: 0.9305\n",
      "570/750 [=====================>........] - ETA: 1s - loss: 0.1750 - accuracy: 0.9355\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "542/750 [====================>.........] - ETA: 1s - loss: 0.1754 - accuracy: 0.9353\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "255/750 [=========>....................] - ETA: 3s - loss: 0.2520 - accuracy: 0.9118\n",
      "102/750 [===>..........................] - ETA: 5s - loss: 0.1812 - accuracy: 0.9334\n",
      "275/750 [==========>...................] - ETA: 3s - loss: 0.2516 - accuracy: 0.9117\n",
      "103/750 [===>..........................] - ETA: 4s - loss: 0.2504 - accuracy: 0.9116\n",
      "289/750 [==========>...................] - ETA: 3s - loss: 0.2515 - accuracy: 0.9120\n",
      "295/750 [==========>...................] - ETA: 3s - loss: 0.2511 - accuracy: 0.9123\n",
      "300/750 [===========>..................] - ETA: 3s - loss: 0.2518 - accuracy: 0.9119\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.1736 - accuracy: 0.9360\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "186/750 [======>.......................] - ETA: 5s - loss: 0.1760 - accuracy: 0.9357\n",
      "143/750 [====>.........................] - ETA: 5s - loss: 0.1853 - accuracy: 0.9306\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "169/750 [=====>........................] - ETA: 5s - loss: 0.1859 - accuracy: 0.9312\n",
      "185/750 [======>.......................] - ETA: 4s - loss: 0.1877 - accuracy: 0.9312\n",
      "612/750 [=======================>......] - ETA: 1s - loss: 0.1743 - accuracy: 0.9360\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "192/750 [======>.......................] - ETA: 4s - loss: 0.1875 - accuracy: 0.9314\n",
      "216/750 [=======>......................] - ETA: 3s - loss: 0.2539 - accuracy: 0.9111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "641/750 [========================>.....] - ETA: 0s - loss: 0.1738 - accuracy: 0.9363\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "355/750 [=============>................] - ETA: 3s - loss: 0.2519 - accuracy: 0.9114\n",
      "673/750 [=========================>....] - ETA: 0s - loss: 0.1732 - accuracy: 0.9362\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "675/750 [==========================>...] - ETA: 0s - loss: 0.1992 - accuracy: 0.9279\n",
      "261/750 [=========>....................] - ETA: 4s - loss: 0.1900 - accuracy: 0.9307\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.1736 - accuracy: 0.9364\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.1738 - accuracy: 0.9362\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.1742 - accuracy: 0.9360\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "326/750 [============>.................] - ETA: 3s - loss: 0.1922 - accuracy: 0.9299\n",
      "598/750 [======================>.......] - ETA: 1s - loss: 0.1746 - accuracy: 0.9358\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.1743 - accuracy: 0.9360\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "485/750 [==================>...........] - ETA: 2s - loss: 0.2541 - accuracy: 0.9099\n",
      "500/750 [===================>..........] - ETA: 2s - loss: 0.2534 - accuracy: 0.9103\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.1744 - accuracy: 0.9359\n",
      "514/750 [===================>..........] - ETA: 1s - loss: 0.2532 - accuracy: 0.9103\n",
      " 95/750 [==>...........................] - ETA: 5s - loss: 0.1792 - accuracy: 0.9334\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "248/750 [========>.....................] - ETA: 4s - loss: 0.1899 - accuracy: 0.9310\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "408/750 [===============>..............] - ETA: 2s - loss: 0.1935 - accuracy: 0.9292\n",
      "376/750 [==============>...............] - ETA: 3s - loss: 0.1933 - accuracy: 0.9290\n",
      "553/750 [=====================>........] - ETA: 1s - loss: 0.2537 - accuracy: 0.9104\n",
      "574/750 [=====================>........] - ETA: 1s - loss: 0.2544 - accuracy: 0.9098\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.1731 - accuracy: 0.9364\n",
      "105/750 [===>..........................] - ETA: 5s - loss: 0.1635 - accuracy: 0.9393\n",
      "392/750 [==============>...............] - ETA: 2s - loss: 0.1931 - accuracy: 0.9291\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "600/750 [=======================>......] - ETA: 1s - loss: 0.2538 - accuracy: 0.9100\n",
      "309/750 [===========>..................] - ETA: 3s - loss: 0.1924 - accuracy: 0.9300\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.1491 - accuracy: 0.9375\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "631/750 [========================>.....] - ETA: 0s - loss: 0.2551 - accuracy: 0.9097\n",
      "334/750 [============>.................] - ETA: 3s - loss: 0.1934 - accuracy: 0.9295\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "479/750 [==================>...........] - ETA: 2s - loss: 0.1941 - accuracy: 0.9295\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 26/750 [>.............................] - ETA: 6s - loss: 0.1591 - accuracy: 0.9423\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "665/750 [=========================>....] - ETA: 0s - loss: 0.2551 - accuracy: 0.9098\n",
      "364/750 [=============>................] - ETA: 3s - loss: 0.1934 - accuracy: 0.9294\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "201/750 [=======>......................] - ETA: 4s - loss: 0.1578 - accuracy: 0.9429\n",
      "677/750 [==========================>...] - ETA: 0s - loss: 0.2558 - accuracy: 0.9095\n",
      "525/750 [====================>.........] - ETA: 1s - loss: 0.2542 - accuracy: 0.9102\n",
      " 81/750 [==>...........................] - ETA: 5s - loss: 0.1669 - accuracy: 0.9379\n",
      "463/750 [=================>............] - ETA: 2s - loss: 0.1943 - accuracy: 0.9293\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2557 - accuracy: 0.9093\n",
      "577/750 [======================>.......] - ETA: 1s - loss: 0.1937 - accuracy: 0.9290\n",
      "422/750 [===============>..............] - ETA: 2s - loss: 0.1937 - accuracy: 0.9295\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "447/750 [================>.............] - ETA: 2s - loss: 0.1937 - accuracy: 0.9297\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "146/750 [====>.........................] - ETA: 4s - loss: 0.1573 - accuracy: 0.9439\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 0.1745 - accuracy: 0.9359 - val_loss: 0.3638 - val_accuracy: 0.8929\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 21/30\n",
      "152/750 [=====>........................] - ETA: 5s - loss: 0.1854 - accuracy: 0.9311\n",
      " 10/750 [..............................] - ETA: 8s - loss: 0.1816 - accuracy: 0.9344 \n",
      "176/750 [======>.......................] - ETA: 4s - loss: 0.1528 - accuracy: 0.9450\n",
      " 48/750 [>.............................] - ETA: 6s - loss: 0.1537 - accuracy: 0.9434\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "224/750 [=======>......................] - ETA: 4s - loss: 0.1889 - accuracy: 0.9306\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 66/750 [=>............................] - ETA: 5s - loss: 0.1641 - accuracy: 0.9387\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "118/750 [===>..........................] - ETA: 5s - loss: 0.1582 - accuracy: 0.9423\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.1946 - accuracy: 0.9289\n",
      "228/750 [========>.....................] - ETA: 4s - loss: 0.1588 - accuracy: 0.9426\n",
      "562/750 [=====================>........] - ETA: 1s - loss: 0.1938 - accuracy: 0.9291\n",
      "548/750 [====================>.........] - ETA: 1s - loss: 0.1932 - accuracy: 0.9291\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "255/750 [=========>....................] - ETA: 4s - loss: 0.1592 - accuracy: 0.9426\n",
      "428/750 [================>.............] - ETA: 2s - loss: 0.1667 - accuracy: 0.9405\n",
      "276/750 [==========>...................] - ETA: 4s - loss: 0.1915 - accuracy: 0.9301\n",
      "750/750 [==============================] - 7s 10ms/step - loss: 0.2565 - accuracy: 0.9087 - val_loss: 0.3132 - val_accuracy: 0.8873\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 22/30\n",
      "299/750 [==========>...................] - ETA: 3s - loss: 0.1627 - accuracy: 0.9418\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 10/750 [..............................] - ETA: 4s - loss: 0.2900 - accuracy: 0.9000\n",
      " 20/750 [..............................] - ETA: 6s - loss: 0.2554 - accuracy: 0.9148\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 0.1946 - accuracy: 0.9289\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "161/750 [=====>........................] - ETA: 4s - loss: 0.1540 - accuracy: 0.9447\n",
      " 53/750 [=>............................] - ETA: 5s - loss: 0.2424 - accuracy: 0.9154\n",
      " 61/750 [=>............................] - ETA: 4s - loss: 0.2460 - accuracy: 0.9137\n",
      "187/750 [======>.......................] - ETA: 4s - loss: 0.1546 - accuracy: 0.9444\n",
      "618/750 [=======================>......] - ETA: 1s - loss: 0.1944 - accuracy: 0.9290\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "216/750 [=======>......................] - ETA: 4s - loss: 0.1587 - accuracy: 0.9432\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "647/750 [========================>.....] - ETA: 0s - loss: 0.1942 - accuracy: 0.9290\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "350/750 [=============>................] - ETA: 3s - loss: 0.1932 - accuracy: 0.9296\n",
      "525/750 [====================>.........] - ETA: 1s - loss: 0.1666 - accuracy: 0.9407\n",
      "664/750 [=========================>....] - ETA: 0s - loss: 0.1949 - accuracy: 0.9287\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "565/750 [=====================>........] - ETA: 1s - loss: 0.1673 - accuracy: 0.9403\n",
      "132/750 [====>.........................] - ETA: 5s - loss: 0.2532 - accuracy: 0.9098\n",
      "  9/750 [..............................] - ETA: 4s - loss: 0.2231 - accuracy: 0.9149\n",
      "270/750 [=========>....................] - ETA: 3s - loss: 0.1623 - accuracy: 0.9415\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.1942 - accuracy: 0.9291\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "164/750 [=====>........................] - ETA: 4s - loss: 0.2541 - accuracy: 0.9088\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.1943 - accuracy: 0.9291\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "179/750 [======>.......................] - ETA: 4s - loss: 0.2516 - accuracy: 0.9095\n",
      " 70/750 [=>............................] - ETA: 4s - loss: 0.1865 - accuracy: 0.9301\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.1946 - accuracy: 0.9290\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "193/750 [======>.......................] - ETA: 4s - loss: 0.2510 - accuracy: 0.9094\n",
      "327/750 [============>.................] - ETA: 3s - loss: 0.1642 - accuracy: 0.9414\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.1674 - accuracy: 0.9400\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2567 - accuracy: 0.9087\n",
      " 92/750 [==>...........................] - ETA: 4s - loss: 0.1848 - accuracy: 0.9321\n",
      "488/750 [==================>...........] - ETA: 2s - loss: 0.1670 - accuracy: 0.9407\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "228/750 [========>.....................] - ETA: 3s - loss: 0.2525 - accuracy: 0.9090\n",
      "117/750 [===>..........................] - ETA: 4s - loss: 0.1884 - accuracy: 0.9304\n",
      "500/750 [===================>..........] - ETA: 1s - loss: 0.1674 - accuracy: 0.9405\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "125/750 [====>.........................] - ETA: 4s - loss: 0.1909 - accuracy: 0.9304\n",
      "513/750 [===================>..........] - ETA: 1s - loss: 0.1673 - accuracy: 0.9404\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "252/750 [=========>....................] - ETA: 3s - loss: 0.2524 - accuracy: 0.9094\n",
      "262/750 [=========>....................] - ETA: 3s - loss: 0.2514 - accuracy: 0.9095\n",
      "141/750 [====>.........................] - ETA: 4s - loss: 0.1954 - accuracy: 0.9282\n",
      "145/750 [====>.........................] - ETA: 4s - loss: 0.1943 - accuracy: 0.9289\n",
      " 84/750 [==>...........................] - ETA: 4s - loss: 0.1837 - accuracy: 0.9310\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "245/750 [========>.....................] - ETA: 3s - loss: 0.2521 - accuracy: 0.9097\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "278/750 [==========>...................] - ETA: 3s - loss: 0.2526 - accuracy: 0.9091\n",
      "169/750 [=====>........................] - ETA: 4s - loss: 0.1940 - accuracy: 0.9294\n",
      "175/750 [======>.......................] - ETA: 4s - loss: 0.1940 - accuracy: 0.9296\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.1698 - accuracy: 0.9390\n",
      "310/750 [===========>..................] - ETA: 3s - loss: 0.2520 - accuracy: 0.9101\n",
      "180/750 [======>.......................] - ETA: 4s - loss: 0.1923 - accuracy: 0.9302\n",
      "395/750 [==============>...............] - ETA: 2s - loss: 0.1668 - accuracy: 0.9402\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 0.1950 - accuracy: 0.9287\n",
      "353/750 [=============>................] - ETA: 3s - loss: 0.2499 - accuracy: 0.9104\n",
      "227/750 [========>.....................] - ETA: 3s - loss: 0.1942 - accuracy: 0.9312\n",
      "323/750 [===========>..................] - ETA: 3s - loss: 0.2514 - accuracy: 0.9102\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 2s - loss: 0.2229 - accuracy: 0.9219\n",
      "629/750 [========================>.....] - ETA: 0s - loss: 0.1669 - accuracy: 0.9401\n",
      "357/750 [=============>................] - ETA: 3s - loss: 0.2496 - accuracy: 0.9105\n",
      "340/750 [============>.................] - ETA: 3s - loss: 0.2505 - accuracy: 0.9105\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "250/750 [=========>....................] - ETA: 3s - loss: 0.1928 - accuracy: 0.9321\n",
      " 28/750 [>.............................] - ETA: 4s - loss: 0.2046 - accuracy: 0.9241\n",
      "382/750 [==============>...............] - ETA: 2s - loss: 0.2480 - accuracy: 0.9111\n",
      "400/750 [===============>..............] - ETA: 2s - loss: 0.2487 - accuracy: 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:06:21,244 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7163469824; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/750 [=============>................] - ETA: 3s - loss: 0.2482 - accuracy: 0.9111\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "682/750 [==========================>...] - ETA: 0s - loss: 0.1688 - accuracy: 0.9393\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "471/750 [=================>............] - ETA: 2s - loss: 0.1670 - accuracy: 0.9405\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.1660 - accuracy: 0.9375\n",
      "581/750 [======================>.......] - ETA: 1s - loss: 0.1670 - accuracy: 0.9403\n",
      "413/750 [===============>..............] - ETA: 2s - loss: 0.2495 - accuracy: 0.9100\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "455/750 [=================>............] - ETA: 2s - loss: 0.2510 - accuracy: 0.9095\n",
      "440/750 [================>.............] - ETA: 2s - loss: 0.2496 - accuracy: 0.9101\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "133/750 [====>.........................] - ETA: 4s - loss: 0.1921 - accuracy: 0.9294\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "479/750 [==================>...........] - ETA: 2s - loss: 0.2530 - accuracy: 0.9091\n",
      "386/750 [==============>...............] - ETA: 2s - loss: 0.1914 - accuracy: 0.9315\n",
      "402/750 [===============>..............] - ETA: 2s - loss: 0.1920 - accuracy: 0.9314\n",
      " 41/750 [>.............................] - ETA: 5s - loss: 0.1478 - accuracy: 0.9432\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "418/750 [===============>..............] - ETA: 2s - loss: 0.1922 - accuracy: 0.9311\n",
      " 70/750 [=>............................] - ETA: 5s - loss: 0.1528 - accuracy: 0.9442\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "114/750 [===>..........................] - ETA: 5s - loss: 0.2541 - accuracy: 0.9094\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "443/750 [================>.............] - ETA: 2s - loss: 0.1927 - accuracy: 0.9308\n",
      "448/750 [================>.............] - ETA: 2s - loss: 0.1923 - accuracy: 0.9310\n",
      "455/750 [=================>............] - ETA: 2s - loss: 0.1912 - accuracy: 0.9315\n",
      "546/750 [====================>.........] - ETA: 1s - loss: 0.2540 - accuracy: 0.9091\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "607/750 [=======================>......] - ETA: 1s - loss: 0.2528 - accuracy: 0.9093\n",
      "428/750 [================>.............] - ETA: 2s - loss: 0.2500 - accuracy: 0.9098\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.1694 - accuracy: 0.9392 - val_loss: 0.3691 - val_accuracy: 0.8960\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 22/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "294/750 [==========>...................] - ETA: 3s - loss: 0.1936 - accuracy: 0.9318\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "202/750 [=======>......................] - ETA: 4s - loss: 0.1602 - accuracy: 0.9411\n",
      " 15/750 [..............................] - ETA: 9s - loss: 0.1599 - accuracy: 0.9344\n",
      "654/750 [=========================>....] - ETA: 0s - loss: 0.2520 - accuracy: 0.9096\n",
      "699/750 [==========================>...] - ETA: 0s - loss: 0.1686 - accuracy: 0.9394\n",
      "556/750 [=====================>........] - ETA: 1s - loss: 0.1912 - accuracy: 0.9313\n",
      " 52/750 [=>............................] - ETA: 5s - loss: 0.1420 - accuracy: 0.9471\n",
      "683/750 [==========================>...] - ETA: 0s - loss: 0.2525 - accuracy: 0.9098\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.2529 - accuracy: 0.9093\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.2525 - accuracy: 0.9098\n",
      "210/750 [=======>......................] - ETA: 4s - loss: 0.1605 - accuracy: 0.9412\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "646/750 [========================>.....] - ETA: 0s - loss: 0.2521 - accuracy: 0.9095\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "527/750 [====================>.........] - ETA: 1s - loss: 0.2532 - accuracy: 0.9093\n",
      "625/750 [========================>.....] - ETA: 0s - loss: 0.1930 - accuracy: 0.9308\n",
      "668/750 [=========================>....] - ETA: 0s - loss: 0.2528 - accuracy: 0.9094\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "573/750 [=====================>........] - ETA: 1s - loss: 0.1909 - accuracy: 0.9312\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "127/750 [====>.........................] - ETA: 5s - loss: 0.1556 - accuracy: 0.9427\n",
      "325/750 [============>.................] - ETA: 3s - loss: 0.1636 - accuracy: 0.9405\n",
      "657/750 [=========================>....] - ETA: 0s - loss: 0.1938 - accuracy: 0.9305\n",
      " 24/750 [..............................] - ETA: 7s - loss: 0.1387 - accuracy: 0.9460\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2523 - accuracy: 0.9099\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "162/750 [=====>........................] - ETA: 4s - loss: 0.1535 - accuracy: 0.9431\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2518 - accuracy: 0.9100\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "179/750 [======>.......................] - ETA: 4s - loss: 0.1550 - accuracy: 0.9425\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2518 - accuracy: 0.9099\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "193/750 [======>.......................] - ETA: 4s - loss: 0.1572 - accuracy: 0.9418\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "598/750 [======================>.......] - ETA: 1s - loss: 0.1914 - accuracy: 0.9309\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 86/750 [==>...........................] - ETA: 5s - loss: 0.1556 - accuracy: 0.9430\n",
      "488/750 [==================>...........] - ETA: 2s - loss: 0.1917 - accuracy: 0.9314\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "226/750 [========>.....................] - ETA: 4s - loss: 0.1618 - accuracy: 0.9408\n",
      "502/750 [===================>..........] - ETA: 1s - loss: 0.1925 - accuracy: 0.9309\n",
      "517/750 [===================>..........] - ETA: 1s - loss: 0.1922 - accuracy: 0.9310\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "431/750 [================>.............] - ETA: 2s - loss: 0.1627 - accuracy: 0.9410\n",
      "269/750 [=========>....................] - ETA: 3s - loss: 0.1611 - accuracy: 0.9413\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 97/750 [==>...........................] - ETA: 5s - loss: 0.1568 - accuracy: 0.9428\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "240/750 [========>.....................] - ETA: 4s - loss: 0.1644 - accuracy: 0.9405\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "277/750 [==========>...................] - ETA: 3s - loss: 0.1936 - accuracy: 0.9319\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.1951 - accuracy: 0.9297\n",
      " 12/750 [..............................] - ETA: 6s - loss: 0.2011 - accuracy: 0.9310\n",
      "500/750 [===================>..........] - ETA: 2s - loss: 0.1627 - accuracy: 0.9409\n",
      " 26/750 [>.............................] - ETA: 5s - loss: 0.2234 - accuracy: 0.9213\n",
      "397/750 [==============>...............] - ETA: 2s - loss: 0.1618 - accuracy: 0.9411\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "529/750 [====================>.........] - ETA: 1s - loss: 0.1627 - accuracy: 0.9410\n",
      "355/750 [=============>................] - ETA: 3s - loss: 0.1631 - accuracy: 0.9412\n",
      " 53/750 [=>............................] - ETA: 5s - loss: 0.2394 - accuracy: 0.9172\n",
      "309/750 [===========>..................] - ETA: 3s - loss: 0.1614 - accuracy: 0.9418\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "545/750 [====================>.........] - ETA: 1s - loss: 0.1624 - accuracy: 0.9412\n",
      "340/750 [============>.................] - ETA: 3s - loss: 0.1637 - accuracy: 0.9409\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 71/750 [=>............................] - ETA: 5s - loss: 0.2506 - accuracy: 0.9113\n",
      "553/750 [=====================>........] - ETA: 1s - loss: 0.1630 - accuracy: 0.9409\n",
      " 79/750 [==>...........................] - ETA: 5s - loss: 0.2477 - accuracy: 0.9110\n",
      "252/750 [=========>....................] - ETA: 4s - loss: 0.1635 - accuracy: 0.9408\n",
      "383/750 [==============>...............] - ETA: 2s - loss: 0.1625 - accuracy: 0.9413\n",
      "574/750 [=====================>........] - ETA: 1s - loss: 0.1629 - accuracy: 0.9407\n",
      "369/750 [=============>................] - ETA: 3s - loss: 0.1627 - accuracy: 0.9413\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "109/750 [===>..........................] - ETA: 5s - loss: 0.2480 - accuracy: 0.9111\n",
      "587/750 [======================>.......] - ETA: 1s - loss: 0.1634 - accuracy: 0.9407\n",
      "472/750 [=================>............] - ETA: 2s - loss: 0.1636 - accuracy: 0.9408\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.1524 - accuracy: 0.9375\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "418/750 [===============>..............] - ETA: 2s - loss: 0.1629 - accuracy: 0.9410\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 22/750 [..............................] - ETA: 11s - loss: 0.2016 - accuracy: 0.9325\n",
      " 29/750 [>.............................] - ETA: 11s - loss: 0.2019 - accuracy: 0.9273\n",
      "447/750 [================>.............] - ETA: 2s - loss: 0.1631 - accuracy: 0.9409\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "146/750 [====>.........................] - ETA: 5s - loss: 0.2435 - accuracy: 0.9129\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.1632 - accuracy: 0.9406\n",
      " 32/750 [>.............................] - ETA: 13s - loss: 0.1987 - accuracy: 0.9277\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.1633 - accuracy: 0.9405\n",
      "155/750 [=====>........................] - ETA: 6s - loss: 0.2425 - accuracy: 0.9142\n",
      " 38/750 [>.............................] - ETA: 13s - loss: 0.1892 - accuracy: 0.9338\n",
      " 47/750 [>.............................] - ETA: 12s - loss: 0.1835 - accuracy: 0.9352\n",
      " 60/750 [=>............................] - ETA: 10s - loss: 0.1821 - accuracy: 0.9359\n",
      "177/750 [======>.......................] - ETA: 6s - loss: 0.2432 - accuracy: 0.9132\n",
      " 71/750 [=>............................] - ETA: 10s - loss: 0.1878 - accuracy: 0.9340\n",
      " 39/750 [>.............................] - ETA: 5s - loss: 0.2285 - accuracy: 0.9191\n",
      " 86/750 [==>...........................] - ETA: 8s - loss: 0.1889 - accuracy: 0.9331\n",
      " 67/750 [=>............................] - ETA: 5s - loss: 0.2507 - accuracy: 0.9116\n",
      "118/750 [===>..........................] - ETA: 5s - loss: 0.2463 - accuracy: 0.9115\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.1653 - accuracy: 0.9395\n",
      "226/750 [========>.....................] - ETA: 5s - loss: 0.2453 - accuracy: 0.9125\n",
      "131/750 [====>.........................] - ETA: 7s - loss: 0.1884 - accuracy: 0.9339\n",
      "541/750 [====================>.........] - ETA: 1s - loss: 0.1628 - accuracy: 0.9410\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.1634 - accuracy: 0.9406\n",
      "257/750 [=========>....................] - ETA: 5s - loss: 0.2453 - accuracy: 0.9127\n",
      "750/750 [==============================] - 7s 10ms/step - loss: 0.1948 - accuracy: 0.9297 - val_loss: 0.4917 - val_accuracy: 0.8807\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 24/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.1655 - accuracy: 0.9396\n",
      "282/750 [==========>...................] - ETA: 4s - loss: 0.2450 - accuracy: 0.9130\n",
      "295/750 [==========>...................] - ETA: 3s - loss: 0.1610 - accuracy: 0.9416\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "201/750 [=======>......................] - ETA: 6s - loss: 0.2433 - accuracy: 0.9131\n",
      "287/750 [==========>...................] - ETA: 4s - loss: 0.2439 - accuracy: 0.9133\n",
      "300/750 [===========>..................] - ETA: 4s - loss: 0.2439 - accuracy: 0.9133\n",
      "204/750 [=======>......................] - ETA: 5s - loss: 0.1845 - accuracy: 0.9333\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 0.1649 - accuracy: 0.9399\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "621/750 [=======================>......] - ETA: 1s - loss: 0.1635 - accuracy: 0.9404\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "219/750 [=======>......................] - ETA: 5s - loss: 0.1827 - accuracy: 0.9332\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "642/750 [========================>.....] - ETA: 0s - loss: 0.1634 - accuracy: 0.9403\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "355/750 [=============>................] - ETA: 3s - loss: 0.2458 - accuracy: 0.9118\n",
      "673/750 [=========================>....] - ETA: 0s - loss: 0.1642 - accuracy: 0.9400\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "568/750 [=====================>........] - ETA: 1s - loss: 0.1629 - accuracy: 0.9407\n",
      "329/750 [============>.................] - ETA: 4s - loss: 0.2460 - accuracy: 0.9124\n",
      "650/750 [=========================>....] - ETA: 0s - loss: 0.1636 - accuracy: 0.9402\n",
      " 13/750 [..............................] - ETA: 6s - loss: 0.2219 - accuracy: 0.9231\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.1657 - accuracy: 0.9394\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "174/750 [=====>........................] - ETA: 6s - loss: 0.1845 - accuracy: 0.9340\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.1941 - accuracy: 0.9301\n",
      "452/750 [=================>............] - ETA: 2s - loss: 0.2452 - accuracy: 0.9131\n",
      "343/750 [============>.................] - ETA: 3s - loss: 0.1917 - accuracy: 0.9309\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.1659 - accuracy: 0.9394\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "189/750 [======>.......................] - ETA: 5s - loss: 0.1857 - accuracy: 0.9330\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "367/750 [=============>................] - ETA: 3s - loss: 0.1917 - accuracy: 0.9304\n",
      "594/750 [======================>.......] - ETA: 1s - loss: 0.1636 - accuracy: 0.9406\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 39/750 [>.............................] - ETA: 6s - loss: 0.1536 - accuracy: 0.9431\n",
      "379/750 [==============>...............] - ETA: 3s - loss: 0.1919 - accuracy: 0.9300\n",
      "480/750 [==================>...........] - ETA: 2s - loss: 0.2453 - accuracy: 0.9131\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 66/750 [=>............................] - ETA: 5s - loss: 0.1645 - accuracy: 0.9418\n",
      "393/750 [==============>...............] - ETA: 3s - loss: 0.1917 - accuracy: 0.9298\n",
      "514/750 [===================>..........] - ETA: 1s - loss: 0.1628 - accuracy: 0.9411\n",
      "507/750 [===================>..........] - ETA: 2s - loss: 0.2469 - accuracy: 0.9124\n",
      "271/750 [=========>....................] - ETA: 4s - loss: 0.1849 - accuracy: 0.9324\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 87/750 [==>...........................] - ETA: 6s - loss: 0.1604 - accuracy: 0.9420\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "240/750 [========>.....................] - ETA: 5s - loss: 0.1835 - accuracy: 0.9324\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "523/750 [===================>..........] - ETA: 2s - loss: 0.2468 - accuracy: 0.9125\n",
      "100/750 [===>..........................] - ETA: 5s - loss: 0.1568 - accuracy: 0.9433\n",
      " 20/750 [..............................] - ETA: 4s - loss: 0.1593 - accuracy: 0.9391\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "501/750 [===================>..........] - ETA: 2s - loss: 0.2466 - accuracy: 0.9125\n",
      " 29/750 [>.............................] - ETA: 5s - loss: 0.1551 - accuracy: 0.9440\n",
      "560/750 [=====================>........] - ETA: 1s - loss: 0.2472 - accuracy: 0.9124\n",
      "392/750 [==============>...............] - ETA: 3s - loss: 0.1915 - accuracy: 0.9298\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "570/750 [=====================>........] - ETA: 1s - loss: 0.2477 - accuracy: 0.9122\n",
      " 53/750 [=>............................] - ETA: 6s - loss: 0.1575 - accuracy: 0.9431\n",
      "322/750 [===========>..................] - ETA: 3s - loss: 0.1905 - accuracy: 0.9310\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "500/750 [===================>..........] - ETA: 2s - loss: 0.1934 - accuracy: 0.9294\n",
      "336/750 [============>.................] - ETA: 3s - loss: 0.1920 - accuracy: 0.9308\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 72/750 [=>............................] - ETA: 5s - loss: 0.1621 - accuracy: 0.9425\n",
      " 77/750 [==>...........................] - ETA: 6s - loss: 0.1622 - accuracy: 0.9424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:06:31,252 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7163322368; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526/750 [====================>.........] - ETA: 2s - loss: 0.1941 - accuracy: 0.9293\n",
      "361/750 [=============>................] - ETA: 3s - loss: 0.1912 - accuracy: 0.9306\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "559/750 [=====================>........] - ETA: 1s - loss: 0.1923 - accuracy: 0.9298\n",
      "239/750 [========>.....................] - ETA: 4s - loss: 0.1618 - accuracy: 0.9395\n",
      "679/750 [==========================>...] - ETA: 0s - loss: 0.2470 - accuracy: 0.9127\n",
      "578/750 [======================>.......] - ETA: 1s - loss: 0.1921 - accuracy: 0.9298\n",
      "473/750 [=================>............] - ETA: 2s - loss: 0.1937 - accuracy: 0.9293\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 5s - loss: 0.1970 - accuracy: 0.9375\n",
      "585/750 [======================>.......] - ETA: 1s - loss: 0.1922 - accuracy: 0.9299\n",
      "422/750 [===============>..............] - ETA: 2s - loss: 0.1927 - accuracy: 0.9295\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.2477 - accuracy: 0.9125\n",
      "449/750 [================>.............] - ETA: 2s - loss: 0.1930 - accuracy: 0.9296\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "146/750 [====>.........................] - ETA: 5s - loss: 0.1579 - accuracy: 0.9417\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2475 - accuracy: 0.9126\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.1927 - accuracy: 0.9299\n",
      "152/750 [=====>........................] - ETA: 5s - loss: 0.1585 - accuracy: 0.9413\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.9123\n",
      "653/750 [=========================>....] - ETA: 0s - loss: 0.1926 - accuracy: 0.9301\n",
      "177/750 [======>.......................] - ETA: 4s - loss: 0.1597 - accuracy: 0.9409\n",
      "681/750 [==========================>...] - ETA: 0s - loss: 0.1927 - accuracy: 0.9296\n",
      "117/750 [===>..........................] - ETA: 5s - loss: 0.1542 - accuracy: 0.9432\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "231/750 [========>.....................] - ETA: 4s - loss: 0.1600 - accuracy: 0.9403\n",
      "132/750 [====>.........................] - ETA: 5s - loss: 0.1562 - accuracy: 0.9420\n",
      "549/750 [====================>.........] - ETA: 1s - loss: 0.1922 - accuracy: 0.9298\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "250/750 [=========>....................] - ETA: 4s - loss: 0.1626 - accuracy: 0.9390\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.1655 - accuracy: 0.9396 - val_loss: 0.4040 - val_accuracy: 0.8949\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 23/30\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.1920 - accuracy: 0.9298\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "282/750 [==========>...................] - ETA: 4s - loss: 0.1862 - accuracy: 0.9321\n",
      "444/750 [================>.............] - ETA: 2s - loss: 0.1642 - accuracy: 0.9388\n",
      "287/750 [==========>...................] - ETA: 3s - loss: 0.1628 - accuracy: 0.9394\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "300/750 [===========>..................] - ETA: 3s - loss: 0.1633 - accuracy: 0.9393\n",
      "482/750 [==================>...........] - ETA: 2s - loss: 0.1640 - accuracy: 0.9386\n",
      "204/750 [=======>......................] - ETA: 4s - loss: 0.1596 - accuracy: 0.9408\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.2476 - accuracy: 0.9123 - val_loss: 0.3246 - val_accuracy: 0.8849\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 24/30\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.3307 - accuracy: 0.8281\n",
      "692/750 [==========================>...] - ETA: 0s - loss: 0.2476 - accuracy: 0.9125\n",
      "624/750 [=======================>......] - ETA: 1s - loss: 0.1929 - accuracy: 0.9298\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 30/750 [>.............................] - ETA: 5s - loss: 0.2394 - accuracy: 0.9078\n",
      "216/750 [=======>......................] - ETA: 4s - loss: 0.1607 - accuracy: 0.9401\n",
      "640/750 [========================>.....] - ETA: 0s - loss: 0.1925 - accuracy: 0.9300\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "352/750 [=============>................] - ETA: 3s - loss: 0.1633 - accuracy: 0.9391\n",
      " 65/750 [=>............................] - ETA: 5s - loss: 0.2427 - accuracy: 0.9115\n",
      "552/750 [=====================>........] - ETA: 1s - loss: 0.1632 - accuracy: 0.9388\n",
      " 79/750 [==>...........................] - ETA: 5s - loss: 0.2450 - accuracy: 0.9122\n",
      "667/750 [=========================>....] - ETA: 0s - loss: 0.1920 - accuracy: 0.9301\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 86/750 [==>...........................] - ETA: 5s - loss: 0.2426 - accuracy: 0.9135\n",
      "580/750 [======================>.......] - ETA: 1s - loss: 0.1626 - accuracy: 0.9393\n",
      " 12/750 [..............................] - ETA: 3s - loss: 0.1548 - accuracy: 0.9427\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.1922 - accuracy: 0.9299\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "159/750 [=====>........................] - ETA: 5s - loss: 0.1579 - accuracy: 0.9418\n",
      " 21/750 [..............................] - ETA: 3s - loss: 0.1603 - accuracy: 0.9405\n",
      "453/750 [=================>............] - ETA: 2s - loss: 0.1637 - accuracy: 0.9386\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.1922 - accuracy: 0.9298\n",
      "187/750 [======>.......................] - ETA: 4s - loss: 0.1604 - accuracy: 0.9399\n",
      "594/750 [======================>.......] - ETA: 1s - loss: 0.1625 - accuracy: 0.9393\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 43/750 [>.............................] - ETA: 5s - loss: 0.1776 - accuracy: 0.9335\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "161/750 [=====>........................] - ETA: 4s - loss: 0.2395 - accuracy: 0.9149\n",
      " 53/750 [=>............................] - ETA: 6s - loss: 0.1796 - accuracy: 0.9304\n",
      "379/750 [==============>...............] - ETA: 3s - loss: 0.1634 - accuracy: 0.9389\n",
      "496/750 [==================>...........] - ETA: 2s - loss: 0.1641 - accuracy: 0.9383\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "172/750 [=====>........................] - ETA: 4s - loss: 0.2378 - accuracy: 0.9156\n",
      " 63/750 [=>............................] - ETA: 6s - loss: 0.1873 - accuracy: 0.9286\n",
      "183/750 [======>.......................] - ETA: 4s - loss: 0.2391 - accuracy: 0.9151\n",
      " 72/750 [=>............................] - ETA: 6s - loss: 0.1852 - accuracy: 0.9293\n",
      "513/750 [===================>..........] - ETA: 1s - loss: 0.1641 - accuracy: 0.9384\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "274/750 [=========>....................] - ETA: 4s - loss: 0.1628 - accuracy: 0.9396\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "192/750 [======>.......................] - ETA: 4s - loss: 0.2405 - accuracy: 0.9145\n",
      " 85/750 [==>...........................] - ETA: 6s - loss: 0.1848 - accuracy: 0.9301\n",
      "684/750 [==========================>...] - ETA: 0s - loss: 0.1610 - accuracy: 0.9399\n",
      "206/750 [=======>......................] - ETA: 4s - loss: 0.2411 - accuracy: 0.9144\n",
      "101/750 [===>..........................] - ETA: 5s - loss: 0.1851 - accuracy: 0.9299\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "696/750 [==========================>...] - ETA: 0s - loss: 0.1616 - accuracy: 0.9397\n",
      "219/750 [=======>......................] - ETA: 4s - loss: 0.2409 - accuracy: 0.9145\n",
      " 16/750 [..............................] - ETA: 5s - loss: 0.2195 - accuracy: 0.9209\n",
      "237/750 [========>.....................] - ETA: 4s - loss: 0.2404 - accuracy: 0.9144\n",
      "129/750 [====>.........................] - ETA: 5s - loss: 0.1929 - accuracy: 0.9274\n",
      "566/750 [=====================>........] - ETA: 1s - loss: 0.1626 - accuracy: 0.9391\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "248/750 [========>.....................] - ETA: 4s - loss: 0.2402 - accuracy: 0.9147\n",
      "399/750 [==============>...............] - ETA: 2s - loss: 0.1642 - accuracy: 0.9387\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.9398\n",
      "151/750 [=====>........................] - ETA: 5s - loss: 0.1932 - accuracy: 0.9277\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9398\n",
      "324/750 [===========>..................] - ETA: 3s - loss: 0.1624 - accuracy: 0.9393\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "175/750 [======>.......................] - ETA: 5s - loss: 0.1906 - accuracy: 0.9287\n",
      "339/750 [============>.................] - ETA: 3s - loss: 0.1632 - accuracy: 0.9389\n",
      "527/750 [====================>.........] - ETA: 1s - loss: 0.1632 - accuracy: 0.9386\n",
      "328/750 [============>.................] - ETA: 3s - loss: 0.2442 - accuracy: 0.9128\n",
      "346/750 [============>.................] - ETA: 3s - loss: 0.2439 - accuracy: 0.9133\n",
      "364/750 [=============>................] - ETA: 3s - loss: 0.1636 - accuracy: 0.9388\n",
      "358/750 [=============>................] - ETA: 3s - loss: 0.2449 - accuracy: 0.9131\n",
      "369/750 [=============>................] - ETA: 3s - loss: 0.2456 - accuracy: 0.9125\n",
      "465/750 [=================>............] - ETA: 2s - loss: 0.1643 - accuracy: 0.9385\n",
      "381/750 [==============>...............] - ETA: 3s - loss: 0.2445 - accuracy: 0.9129\n",
      "275/750 [==========>...................] - ETA: 4s - loss: 0.1935 - accuracy: 0.9289\n",
      "421/750 [===============>..............] - ETA: 2s - loss: 0.1646 - accuracy: 0.9384\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.1922 - accuracy: 0.9299\n",
      "436/750 [================>.............] - ETA: 2s - loss: 0.1643 - accuracy: 0.9387\n",
      "138/750 [====>.........................] - ETA: 5s - loss: 0.1924 - accuracy: 0.9271\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.1923 - accuracy: 0.9297\n",
      "307/750 [===========>..................] - ETA: 3s - loss: 0.1987 - accuracy: 0.9272\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.1617 - accuracy: 0.9395\n",
      "433/750 [================>.............] - ETA: 2s - loss: 0.2437 - accuracy: 0.9137\n",
      "442/750 [================>.............] - ETA: 2s - loss: 0.2428 - accuracy: 0.9141\n",
      " 16/750 [..............................] - ETA: 5s - loss: 0.1494 - accuracy: 0.9375\n",
      "457/750 [=================>............] - ETA: 2s - loss: 0.2423 - accuracy: 0.9146\n",
      "473/750 [=================>............] - ETA: 2s - loss: 0.2426 - accuracy: 0.9144\n",
      "352/750 [=============>................] - ETA: 3s - loss: 0.1954 - accuracy: 0.9284\n",
      "115/750 [===>..........................] - ETA: 5s - loss: 0.1869 - accuracy: 0.9295\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "506/750 [===================>..........] - ETA: 2s - loss: 0.2433 - accuracy: 0.9145\n",
      "514/750 [===================>..........] - ETA: 1s - loss: 0.2437 - accuracy: 0.9143\n",
      "402/750 [===============>..............] - ETA: 2s - loss: 0.1935 - accuracy: 0.9289\n",
      "531/750 [====================>.........] - ETA: 1s - loss: 0.2435 - accuracy: 0.9143\n",
      " 90/750 [==>...........................] - ETA: 4s - loss: 0.1490 - accuracy: 0.9391\n",
      "538/750 [====================>.........] - ETA: 1s - loss: 0.2442 - accuracy: 0.9141\n",
      "427/750 [================>.............] - ETA: 2s - loss: 0.1946 - accuracy: 0.9289\n",
      "544/750 [====================>.........] - ETA: 1s - loss: 0.1636 - accuracy: 0.9387\n",
      "547/750 [====================>.........] - ETA: 1s - loss: 0.2444 - accuracy: 0.9139\n",
      "555/750 [=====================>........] - ETA: 1s - loss: 0.2448 - accuracy: 0.9136\n",
      "452/750 [=================>............] - ETA: 2s - loss: 0.1947 - accuracy: 0.9293\n",
      "299/750 [==========>...................] - ETA: 3s - loss: 0.1981 - accuracy: 0.9275\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.2426 - accuracy: 0.9143\n",
      "481/750 [==================>...........] - ETA: 2s - loss: 0.1938 - accuracy: 0.9291\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 0.1618 - accuracy: 0.9398 - val_loss: 0.4013 - val_accuracy: 0.8941\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 24/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 7s - loss: 0.1331 - accuracy: 0.9219\n",
      "174/750 [=====>........................] - ETA: 4s - loss: 0.1531 - accuracy: 0.9405\n",
      "181/750 [======>.......................] - ETA: 4s - loss: 0.1524 - accuracy: 0.9406\n",
      "631/750 [========================>.....] - ETA: 0s - loss: 0.2430 - accuracy: 0.9140\n",
      "188/750 [======>.......................] - ETA: 4s - loss: 0.1519 - accuracy: 0.9410\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.2430 - accuracy: 0.9140\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 31/750 [>.............................] - ETA: 5s - loss: 0.1421 - accuracy: 0.9415\n",
      "646/750 [========================>.....] - ETA: 0s - loss: 0.2429 - accuracy: 0.9137\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "213/750 [=======>......................] - ETA: 4s - loss: 0.1539 - accuracy: 0.9400\n",
      "219/750 [=======>......................] - ETA: 4s - loss: 0.1539 - accuracy: 0.9405\n",
      "662/750 [=========================>....] - ETA: 0s - loss: 0.2439 - accuracy: 0.9135\n",
      " 78/750 [==>...........................] - ETA: 4s - loss: 0.1492 - accuracy: 0.9379\n",
      "230/750 [========>.....................] - ETA: 4s - loss: 0.1544 - accuracy: 0.9408\n",
      "239/750 [========>.....................] - ETA: 4s - loss: 0.1537 - accuracy: 0.9410\n",
      "673/750 [=========================>....] - ETA: 0s - loss: 0.2440 - accuracy: 0.9135\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "245/750 [========>.....................] - ETA: 4s - loss: 0.1521 - accuracy: 0.9416\n",
      "584/750 [======================>.......] - ETA: 1s - loss: 0.1933 - accuracy: 0.9295\n",
      "576/750 [======================>.......] - ETA: 1s - loss: 0.2436 - accuracy: 0.9140\n",
      "250/750 [=========>....................] - ETA: 4s - loss: 0.1532 - accuracy: 0.9411\n",
      "259/750 [=========>....................] - ETA: 4s - loss: 0.1536 - accuracy: 0.9409\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.1925 - accuracy: 0.9298\n",
      "606/750 [=======================>......] - ETA: 1s - loss: 0.1924 - accuracy: 0.9299\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2425 - accuracy: 0.9139\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "278/750 [==========>...................] - ETA: 3s - loss: 0.1530 - accuracy: 0.9419\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.2431 - accuracy: 0.9137\n",
      "283/750 [==========>...................] - ETA: 3s - loss: 0.1535 - accuracy: 0.9420\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2432 - accuracy: 0.9136\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.1919 - accuracy: 0.9301\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2432 - accuracy: 0.9136\n",
      "634/750 [========================>.....] - ETA: 0s - loss: 0.1920 - accuracy: 0.9301\n",
      "651/750 [=========================>....] - ETA: 0s - loss: 0.1920 - accuracy: 0.9302\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.2430 - accuracy: 0.9142\n",
      " 44/750 [>.............................] - ETA: 5s - loss: 0.1535 - accuracy: 0.9339\n",
      "163/750 [=====>........................] - ETA: 5s - loss: 0.1911 - accuracy: 0.9285\n",
      "491/750 [==================>...........] - ETA: 2s - loss: 0.1936 - accuracy: 0.9292\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "682/750 [==========================>...] - ETA: 0s - loss: 0.1921 - accuracy: 0.9302\n",
      "188/750 [======>.......................] - ETA: 5s - loss: 0.1914 - accuracy: 0.9294\n",
      "353/750 [=============>................] - ETA: 3s - loss: 0.1533 - accuracy: 0.9421\n",
      " 61/750 [=>............................] - ETA: 4s - loss: 0.1564 - accuracy: 0.9365\n",
      "520/750 [===================>..........] - ETA: 1s - loss: 0.1924 - accuracy: 0.9294\n",
      "274/750 [=========>....................] - ETA: 3s - loss: 0.1527 - accuracy: 0.9417\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.1918 - accuracy: 0.9303\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "204/750 [=======>......................] - ETA: 4s - loss: 0.1526 - accuracy: 0.9403\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "379/750 [==============>...............] - ETA: 3s - loss: 0.1536 - accuracy: 0.9422\n",
      "100/750 [===>..........................] - ETA: 4s - loss: 0.1488 - accuracy: 0.9395\n",
      "221/750 [=======>......................] - ETA: 4s - loss: 0.1925 - accuracy: 0.9302\n",
      "247/750 [========>.....................] - ETA: 4s - loss: 0.1923 - accuracy: 0.9300\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "130/750 [====>.........................] - ETA: 4s - loss: 0.1521 - accuracy: 0.9398\n",
      "564/750 [=====================>........] - ETA: 1s - loss: 0.1930 - accuracy: 0.9295\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "424/750 [===============>..............] - ETA: 2s - loss: 0.1529 - accuracy: 0.9430\n",
      "394/750 [==============>...............] - ETA: 2s - loss: 0.1526 - accuracy: 0.9425\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.1907 - accuracy: 0.9309\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "152/750 [=====>........................] - ETA: 4s - loss: 0.1539 - accuracy: 0.9395\n",
      "317/750 [===========>..................] - ETA: 3s - loss: 0.1983 - accuracy: 0.9272\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:06:41,344 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7163244544; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/750 [..............................] - ETA: 7s - loss: 0.2516 - accuracy: 0.9167\n",
      "326/750 [============>.................] - ETA: 3s - loss: 0.1509 - accuracy: 0.9428\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 26/750 [>.............................] - ETA: 4s - loss: 0.2311 - accuracy: 0.9159\n",
      "513/750 [===================>..........] - ETA: 1s - loss: 0.1561 - accuracy: 0.9420\n",
      "338/750 [============>.................] - ETA: 3s - loss: 0.1521 - accuracy: 0.9424\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 43/750 [>.............................] - ETA: 4s - loss: 0.2425 - accuracy: 0.9088\n",
      "367/750 [=============>................] - ETA: 3s - loss: 0.1536 - accuracy: 0.9422\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 55/750 [=>............................] - ETA: 5s - loss: 0.2398 - accuracy: 0.9091\n",
      " 69/750 [=>............................] - ETA: 4s - loss: 0.2391 - accuracy: 0.9101\n",
      " 76/750 [==>...........................] - ETA: 4s - loss: 0.2434 - accuracy: 0.9087\n",
      "416/750 [===============>..............] - ETA: 2s - loss: 0.1526 - accuracy: 0.9431\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.1359 - accuracy: 0.9531\n",
      "139/750 [====>.........................] - ETA: 4s - loss: 0.1517 - accuracy: 0.9402\n",
      "575/750 [======================>.......] - ETA: 1s - loss: 0.1553 - accuracy: 0.9424\n",
      "104/750 [===>..........................] - ETA: 6s - loss: 0.2365 - accuracy: 0.9126\n",
      "  8/750 [..............................] - ETA: 5s - loss: 0.1959 - accuracy: 0.9316\n",
      "309/750 [===========>..................] - ETA: 3s - loss: 0.1530 - accuracy: 0.9421\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "440/750 [================>.............] - ETA: 2s - loss: 0.1532 - accuracy: 0.9430\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "586/750 [======================>.......] - ETA: 1s - loss: 0.1555 - accuracy: 0.9423\n",
      " 22/750 [..............................] - ETA: 8s - loss: 0.1880 - accuracy: 0.9311\n",
      "474/750 [=================>............] - ETA: 2s - loss: 0.1543 - accuracy: 0.9427\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "137/750 [====>.........................] - ETA: 5s - loss: 0.2367 - accuracy: 0.9132\n",
      "374/750 [=============>................] - ETA: 3s - loss: 0.1537 - accuracy: 0.9423\n",
      "154/750 [=====>........................] - ETA: 5s - loss: 0.2374 - accuracy: 0.9130\n",
      "167/750 [=====>........................] - ETA: 5s - loss: 0.2373 - accuracy: 0.9133\n",
      " 76/750 [==>...........................] - ETA: 6s - loss: 0.1879 - accuracy: 0.9332\n",
      "123/750 [===>..........................] - ETA: 6s - loss: 0.2350 - accuracy: 0.9139\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "504/750 [===================>..........] - ETA: 2s - loss: 0.1929 - accuracy: 0.9295\n",
      "179/750 [======>.......................] - ETA: 5s - loss: 0.2352 - accuracy: 0.9135\n",
      "525/750 [====================>.........] - ETA: 1s - loss: 0.1558 - accuracy: 0.9421\n",
      "196/750 [======>.......................] - ETA: 4s - loss: 0.2355 - accuracy: 0.9130\n",
      " 99/750 [==>...........................] - ETA: 5s - loss: 0.1867 - accuracy: 0.9347\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "544/750 [====================>.........] - ETA: 1s - loss: 0.1557 - accuracy: 0.9422\n",
      "214/750 [=======>......................] - ETA: 4s - loss: 0.2355 - accuracy: 0.9130\n",
      "100/750 [===>..........................] - ETA: 6s - loss: 0.1857 - accuracy: 0.9350\n",
      "538/750 [====================>.........] - ETA: 1s - loss: 0.1556 - accuracy: 0.9422\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "111/750 [===>..........................] - ETA: 5s - loss: 0.1882 - accuracy: 0.9322\n",
      "121/750 [===>..........................] - ETA: 5s - loss: 0.1873 - accuracy: 0.9319\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.1560 - accuracy: 0.9423\n",
      "129/750 [====>.........................] - ETA: 5s - loss: 0.1857 - accuracy: 0.9334\n",
      "459/750 [=================>............] - ETA: 2s - loss: 0.1546 - accuracy: 0.9425\n",
      "298/750 [==========>...................] - ETA: 3s - loss: 0.1531 - accuracy: 0.9422\n",
      "163/750 [=====>........................] - ETA: 5s - loss: 0.1876 - accuracy: 0.9330\n",
      "600/750 [=======================>......] - ETA: 1s - loss: 0.1558 - accuracy: 0.9423\n",
      "170/750 [=====>........................] - ETA: 5s - loss: 0.1858 - accuracy: 0.9331\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 0.1905 - accuracy: 0.9310 - val_loss: 0.5391 - val_accuracy: 0.8875\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 26/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "288/750 [==========>...................] - ETA: 4s - loss: 0.2375 - accuracy: 0.9128\n",
      "177/750 [======>.......................] - ETA: 4s - loss: 0.1861 - accuracy: 0.9333\n",
      "628/750 [========================>.....] - ETA: 1s - loss: 0.1551 - accuracy: 0.9426\n",
      "613/750 [=======================>......] - ETA: 1s - loss: 0.1555 - accuracy: 0.9425\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "305/750 [===========>..................] - ETA: 3s - loss: 0.2395 - accuracy: 0.9123\n",
      "635/750 [========================>.....] - ETA: 0s - loss: 0.1550 - accuracy: 0.9425\n",
      "219/750 [=======>......................] - ETA: 4s - loss: 0.2362 - accuracy: 0.9128\n",
      "218/750 [=======>......................] - ETA: 4s - loss: 0.1847 - accuracy: 0.9337\n",
      "231/750 [========>.....................] - ETA: 4s - loss: 0.1840 - accuracy: 0.9335\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "233/750 [========>.....................] - ETA: 4s - loss: 0.2355 - accuracy: 0.9127\n",
      "241/750 [========>.....................] - ETA: 4s - loss: 0.1830 - accuracy: 0.9343\n",
      "666/750 [=========================>....] - ETA: 0s - loss: 0.1550 - accuracy: 0.9425\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "244/750 [========>.....................] - ETA: 4s - loss: 0.1828 - accuracy: 0.9342\n",
      "346/750 [============>.................] - ETA: 3s - loss: 0.2433 - accuracy: 0.9115\n",
      "253/750 [=========>....................] - ETA: 4s - loss: 0.1832 - accuracy: 0.9342\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.1557 - accuracy: 0.9424\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "295/750 [==========>...................] - ETA: 3s - loss: 0.2371 - accuracy: 0.9130\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.1562 - accuracy: 0.9422\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.1562 - accuracy: 0.9420\n",
      "277/750 [==========>...................] - ETA: 4s - loss: 0.1861 - accuracy: 0.9341\n",
      "650/750 [=========================>....] - ETA: 0s - loss: 0.1554 - accuracy: 0.9423\n",
      "498/750 [==================>...........] - ETA: 2s - loss: 0.1554 - accuracy: 0.9421\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "681/750 [==========================>...] - ETA: 0s - loss: 0.1556 - accuracy: 0.9422\n",
      "359/750 [=============>................] - ETA: 3s - loss: 0.2420 - accuracy: 0.9122\n",
      "426/750 [================>.............] - ETA: 3s - loss: 0.2405 - accuracy: 0.9126\n",
      "265/750 [=========>....................] - ETA: 4s - loss: 0.1847 - accuracy: 0.9343\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "433/750 [================>.............] - ETA: 3s - loss: 0.2401 - accuracy: 0.9127\n",
      "441/750 [================>.............] - ETA: 2s - loss: 0.2410 - accuracy: 0.9124\n",
      "691/750 [==========================>...] - ETA: 0s - loss: 0.1557 - accuracy: 0.9422\n",
      "202/750 [=======>......................] - ETA: 4s - loss: 0.1859 - accuracy: 0.9332\n",
      "389/750 [==============>...............] - ETA: 3s - loss: 0.2416 - accuracy: 0.9126\n",
      "447/750 [================>.............] - ETA: 2s - loss: 0.2412 - accuracy: 0.9123\n",
      "246/750 [========>.....................] - ETA: 4s - loss: 0.2363 - accuracy: 0.9126\n",
      "  9/750 [..............................] - ETA: 10s - loss: 0.1478 - accuracy: 0.9462\n",
      "463/750 [=================>............] - ETA: 2s - loss: 0.2413 - accuracy: 0.9125\n",
      "376/750 [==============>...............] - ETA: 3s - loss: 0.1840 - accuracy: 0.9330\n",
      "568/750 [=====================>........] - ETA: 1s - loss: 0.1553 - accuracy: 0.9425\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 18/750 [..............................] - ETA: 9s - loss: 0.1484 - accuracy: 0.9488 \n",
      "477/750 [==================>...........] - ETA: 2s - loss: 0.2412 - accuracy: 0.9124\n",
      "410/750 [===============>..............] - ETA: 3s - loss: 0.2405 - accuracy: 0.9129\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "388/750 [==============>...............] - ETA: 3s - loss: 0.1845 - accuracy: 0.9332\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.1562 - accuracy: 0.9422\n",
      "401/750 [===============>..............] - ETA: 3s - loss: 0.1838 - accuracy: 0.9332\n",
      " 46/750 [>.............................] - ETA: 6s - loss: 0.1467 - accuracy: 0.9477\n",
      "502/750 [===================>..........] - ETA: 2s - loss: 0.2413 - accuracy: 0.9124\n",
      "319/750 [===========>..................] - ETA: 4s - loss: 0.1844 - accuracy: 0.9332\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "529/750 [====================>.........] - ETA: 2s - loss: 0.2416 - accuracy: 0.9127\n",
      "520/750 [===================>..........] - ETA: 2s - loss: 0.2417 - accuracy: 0.9124\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "348/750 [============>.................] - ETA: 3s - loss: 0.1830 - accuracy: 0.9335\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 39/750 [>.............................] - ETA: 7s - loss: 0.1451 - accuracy: 0.9503\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "362/750 [=============>................] - ETA: 3s - loss: 0.1840 - accuracy: 0.9330\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 55/750 [=>............................] - ETA: 5s - loss: 0.1868 - accuracy: 0.9330\n",
      "554/750 [=====================>........] - ETA: 1s - loss: 0.2427 - accuracy: 0.9125\n",
      "451/750 [=================>............] - ETA: 3s - loss: 0.1841 - accuracy: 0.9333\n",
      " 74/750 [=>............................] - ETA: 7s - loss: 0.1509 - accuracy: 0.9436\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "424/750 [===============>..............] - ETA: 3s - loss: 0.1848 - accuracy: 0.9329\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "606/750 [=======================>......] - ETA: 1s - loss: 0.2420 - accuracy: 0.9132\n",
      "  1/750 [..............................] - ETA: 2s - loss: 0.1465 - accuracy: 0.9531\n",
      "577/750 [======================>.......] - ETA: 1s - loss: 0.2431 - accuracy: 0.9127\n",
      "620/750 [=======================>......] - ETA: 1s - loss: 0.2421 - accuracy: 0.9128\n",
      " 23/750 [..............................] - ETA: 8s - loss: 0.1490 - accuracy: 0.9490\n",
      "307/750 [===========>..................] - ETA: 4s - loss: 0.1853 - accuracy: 0.9330\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "435/750 [================>.............] - ETA: 3s - loss: 0.1843 - accuracy: 0.9332\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.2420 - accuracy: 0.9131\n",
      "635/750 [========================>.....] - ETA: 1s - loss: 0.2416 - accuracy: 0.9128\n",
      "649/750 [========================>.....] - ETA: 0s - loss: 0.2413 - accuracy: 0.9129\n",
      "467/750 [=================>............] - ETA: 2s - loss: 0.1844 - accuracy: 0.9333\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "137/750 [====>.........................] - ETA: 6s - loss: 0.1535 - accuracy: 0.9445\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "670/750 [=========================>....] - ETA: 0s - loss: 0.2411 - accuracy: 0.9128\n",
      "150/750 [=====>........................] - ETA: 5s - loss: 0.1536 - accuracy: 0.9445\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "683/750 [==========================>...] - ETA: 0s - loss: 0.2409 - accuracy: 0.9128\n",
      "590/750 [======================>.......] - ETA: 1s - loss: 0.1885 - accuracy: 0.9316\n",
      "172/750 [=====>........................] - ETA: 5s - loss: 0.1535 - accuracy: 0.9443\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "243/750 [========>.....................] - ETA: 4s - loss: 0.1532 - accuracy: 0.9443\n",
      "699/750 [==========================>...] - ETA: 0s - loss: 0.2409 - accuracy: 0.9129\n",
      "595/750 [======================>.......] - ETA: 1s - loss: 0.1887 - accuracy: 0.9317\n",
      "123/750 [===>..........................] - ETA: 6s - loss: 0.1543 - accuracy: 0.9450\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2404 - accuracy: 0.9131\n",
      "193/750 [======>.......................] - ETA: 5s - loss: 0.1532 - accuracy: 0.9449\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 99/750 [==>...........................] - ETA: 6s - loss: 0.1550 - accuracy: 0.9441\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "208/750 [=======>......................] - ETA: 5s - loss: 0.1544 - accuracy: 0.9442\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.2402 - accuracy: 0.9129\n",
      "628/750 [========================>.....] - ETA: 1s - loss: 0.1893 - accuracy: 0.9315\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.1884 - accuracy: 0.9318\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "282/750 [==========>...................] - ETA: 4s - loss: 0.1533 - accuracy: 0.9438\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2403 - accuracy: 0.9126\n",
      "635/750 [========================>.....] - ETA: 1s - loss: 0.1894 - accuracy: 0.9315\n",
      "289/750 [==========>...................] - ETA: 4s - loss: 0.1539 - accuracy: 0.9433\n",
      "672/750 [=========================>....] - ETA: 0s - loss: 0.1892 - accuracy: 0.9315\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.1884 - accuracy: 0.9318\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.1895 - accuracy: 0.9316\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.1561 - accuracy: 0.9420 - val_loss: 0.4026 - val_accuracy: 0.8930\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 25/30\n",
      "297/750 [==========>...................] - ETA: 4s - loss: 0.1845 - accuracy: 0.9338\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.1890 - accuracy: 0.9314\n",
      "624/750 [=======================>......] - ETA: 1s - loss: 0.1890 - accuracy: 0.9314\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "305/750 [===========>..................] - ETA: 4s - loss: 0.1534 - accuracy: 0.9436\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.1897 - accuracy: 0.9312\n",
      "226/750 [========>.....................] - ETA: 4s - loss: 0.1539 - accuracy: 0.9439\n",
      "443/750 [================>.............] - ETA: 2s - loss: 0.1518 - accuracy: 0.9441\n",
      "664/750 [=========================>....] - ETA: 0s - loss: 0.1892 - accuracy: 0.9315\n",
      "339/750 [============>.................] - ETA: 4s - loss: 0.1844 - accuracy: 0.9332\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.2406 - accuracy: 0.9124 - val_loss: 0.3132 - val_accuracy: 0.8884\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 26/30\n",
      " 12/750 [..............................] - ETA: 3s - loss: 0.2022 - accuracy: 0.9310\n",
      "250/750 [=========>....................] - ETA: 4s - loss: 0.1530 - accuracy: 0.9443\n",
      " 21/750 [..............................] - ETA: 3s - loss: 0.2209 - accuracy: 0.9263\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.1887 - accuracy: 0.9316\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "277/750 [==========>...................] - ETA: 4s - loss: 0.1532 - accuracy: 0.9440\n",
      " 50/750 [=>............................] - ETA: 4s - loss: 0.2309 - accuracy: 0.9184\n",
      " 79/750 [==>...........................] - ETA: 4s - loss: 0.2274 - accuracy: 0.9205\n",
      "499/750 [==================>...........] - ETA: 2s - loss: 0.1526 - accuracy: 0.9442\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.1672 - accuracy: 0.9375\n",
      "263/750 [=========>....................] - ETA: 4s - loss: 0.1539 - accuracy: 0.9440\n",
      "438/750 [================>.............] - ETA: 3s - loss: 0.1841 - accuracy: 0.9333\n",
      "129/750 [====>.........................] - ETA: 4s - loss: 0.2308 - accuracy: 0.9190\n",
      " 31/750 [>.............................] - ETA: 5s - loss: 0.1635 - accuracy: 0.9355\n",
      " 17/750 [..............................] - ETA: 4s - loss: 0.1633 - accuracy: 0.9301\n",
      "375/750 [==============>...............] - ETA: 3s - loss: 0.1527 - accuracy: 0.9442\n",
      "573/750 [=====================>........] - ETA: 1s - loss: 0.1533 - accuracy: 0.9438\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "479/750 [==================>...........] - ETA: 2s - loss: 0.1845 - accuracy: 0.9333\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.1527 - accuracy: 0.9440\n",
      "422/750 [===============>..............] - ETA: 2s - loss: 0.1525 - accuracy: 0.9441\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "385/750 [==============>...............] - ETA: 3s - loss: 0.1531 - accuracy: 0.9439\n",
      "401/750 [===============>..............] - ETA: 3s - loss: 0.1526 - accuracy: 0.9439\n",
      "322/750 [===========>..................] - ETA: 3s - loss: 0.1530 - accuracy: 0.9435\n",
      "659/750 [=========================>....] - ETA: 0s - loss: 0.1527 - accuracy: 0.9443\n",
      "225/750 [========>.....................] - ETA: 3s - loss: 0.2351 - accuracy: 0.9156\n",
      "104/750 [===>..........................] - ETA: 5s - loss: 0.1788 - accuracy: 0.9340\n",
      "671/750 [=========================>....] - ETA: 0s - loss: 0.1527 - accuracy: 0.9442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:06:51,355 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7162236928; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529/750 [====================>.........] - ETA: 1s - loss: 0.1528 - accuracy: 0.9441\n",
      "514/750 [===================>..........] - ETA: 2s - loss: 0.1527 - accuracy: 0.9442\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "346/750 [============>.................] - ETA: 3s - loss: 0.1537 - accuracy: 0.9436\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 46/750 [>.............................] - ETA: 5s - loss: 0.1546 - accuracy: 0.9399\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "263/750 [=========>....................] - ETA: 3s - loss: 0.2346 - accuracy: 0.9159\n",
      "361/750 [=============>................] - ETA: 3s - loss: 0.1537 - accuracy: 0.9439\n",
      "276/750 [==========>...................] - ETA: 3s - loss: 0.2349 - accuracy: 0.9156\n",
      " 64/750 [=>............................] - ETA: 5s - loss: 0.1680 - accuracy: 0.9368\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "178/750 [======>.......................] - ETA: 5s - loss: 0.1861 - accuracy: 0.9343\n",
      "309/750 [===========>..................] - ETA: 3s - loss: 0.2339 - accuracy: 0.9163\n",
      "417/750 [===============>..............] - ETA: 2s - loss: 0.1517 - accuracy: 0.9444\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.1528 - accuracy: 0.9439\n",
      "322/750 [===========>..................] - ETA: 3s - loss: 0.2327 - accuracy: 0.9168\n",
      "208/750 [=======>......................] - ETA: 4s - loss: 0.1832 - accuracy: 0.9354\n",
      "613/750 [=======================>......] - ETA: 1s - loss: 0.1529 - accuracy: 0.9439\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "352/750 [=============>................] - ETA: 3s - loss: 0.2341 - accuracy: 0.9164\n",
      "647/750 [========================>.....] - ETA: 0s - loss: 0.1525 - accuracy: 0.9442\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "370/750 [=============>................] - ETA: 2s - loss: 0.2330 - accuracy: 0.9168\n",
      "256/750 [=========>....................] - ETA: 4s - loss: 0.1797 - accuracy: 0.9363\n",
      "387/750 [==============>...............] - ETA: 2s - loss: 0.2327 - accuracy: 0.9171\n",
      "466/750 [=================>............] - ETA: 2s - loss: 0.1512 - accuracy: 0.9445\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "143/750 [====>.........................] - ETA: 5s - loss: 0.1832 - accuracy: 0.9354\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "399/750 [==============>...............] - ETA: 2s - loss: 0.2333 - accuracy: 0.9169\n",
      "273/750 [=========>....................] - ETA: 4s - loss: 0.1828 - accuracy: 0.9360\n",
      "153/750 [=====>........................] - ETA: 5s - loss: 0.1840 - accuracy: 0.9350\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.1529 - accuracy: 0.9439\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "587/750 [======================>.......] - ETA: 1s - loss: 0.1530 - accuracy: 0.9439\n",
      "167/750 [=====>........................] - ETA: 5s - loss: 0.1869 - accuracy: 0.9345\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "241/750 [========>.....................] - ETA: 4s - loss: 0.1807 - accuracy: 0.9360\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "414/750 [===============>..............] - ETA: 2s - loss: 0.2334 - accuracy: 0.9168\n",
      "118/750 [===>..........................] - ETA: 5s - loss: 0.1806 - accuracy: 0.9345\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "426/750 [================>.............] - ETA: 2s - loss: 0.2339 - accuracy: 0.9168\n",
      "191/750 [======>.......................] - ETA: 4s - loss: 0.1873 - accuracy: 0.9340\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "438/750 [================>.............] - ETA: 2s - loss: 0.2335 - accuracy: 0.9169\n",
      "328/750 [============>.................] - ETA: 3s - loss: 0.1816 - accuracy: 0.9350\n",
      " 91/750 [==>...........................] - ETA: 5s - loss: 0.1782 - accuracy: 0.9346\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "210/750 [=======>......................] - ETA: 4s - loss: 0.2344 - accuracy: 0.9159\n",
      "452/750 [=================>............] - ETA: 2s - loss: 0.2336 - accuracy: 0.9170\n",
      "461/750 [=================>............] - ETA: 2s - loss: 0.2335 - accuracy: 0.9171\n",
      "543/750 [====================>.........] - ETA: 1s - loss: 0.1527 - accuracy: 0.9442\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.1522 - accuracy: 0.9441\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "480/750 [==================>...........] - ETA: 2s - loss: 0.2330 - accuracy: 0.9174\n",
      "378/750 [==============>...............] - ETA: 3s - loss: 0.1844 - accuracy: 0.9336\n",
      "503/750 [===================>..........] - ETA: 2s - loss: 0.2326 - accuracy: 0.9173\n",
      "513/750 [===================>..........] - ETA: 1s - loss: 0.2324 - accuracy: 0.9174\n",
      "297/750 [==========>...................] - ETA: 3s - loss: 0.1831 - accuracy: 0.9348\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "528/750 [====================>.........] - ETA: 1s - loss: 0.2319 - accuracy: 0.9175\n",
      "542/750 [====================>.........] - ETA: 1s - loss: 0.2324 - accuracy: 0.9173\n",
      "551/750 [=====================>........] - ETA: 1s - loss: 0.2328 - accuracy: 0.9171\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.1521 - accuracy: 0.9441\n",
      "558/750 [=====================>........] - ETA: 1s - loss: 0.2330 - accuracy: 0.9169\n",
      "584/750 [======================>.......] - ETA: 1s - loss: 0.2329 - accuracy: 0.9172\n",
      "475/750 [==================>...........] - ETA: 2s - loss: 0.1837 - accuracy: 0.9335\n",
      "596/750 [======================>.......] - ETA: 1s - loss: 0.2338 - accuracy: 0.9168\n",
      "611/750 [=======================>......] - ETA: 1s - loss: 0.2343 - accuracy: 0.9166\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.1521 - accuracy: 0.9441 - val_loss: 0.4072 - val_accuracy: 0.8976\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 26/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  7/750 [..............................] - ETA: 6s - loss: 0.0979 - accuracy: 0.9665\n",
      "132/750 [====>.........................] - ETA: 5s - loss: 0.1445 - accuracy: 0.9438\n",
      " 16/750 [..............................] - ETA: 5s - loss: 0.1283 - accuracy: 0.9473\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.1522 - accuracy: 0.9440\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "168/750 [=====>........................] - ETA: 4s - loss: 0.1401 - accuracy: 0.9460\n",
      " 56/750 [=>............................] - ETA: 5s - loss: 0.1655 - accuracy: 0.9378\n",
      "172/750 [=====>........................] - ETA: 4s - loss: 0.1425 - accuracy: 0.9450\n",
      "553/750 [=====================>........] - ETA: 1s - loss: 0.1830 - accuracy: 0.9341\n",
      " 80/750 [==>...........................] - ETA: 5s - loss: 0.1768 - accuracy: 0.9350\n",
      "580/750 [======================>.......] - ETA: 1s - loss: 0.1832 - accuracy: 0.9341\n",
      "491/750 [==================>...........] - ETA: 2s - loss: 0.1844 - accuracy: 0.9337\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "212/750 [=======>......................] - ETA: 4s - loss: 0.1447 - accuracy: 0.9438\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.2363 - accuracy: 0.9155\n",
      "224/750 [=======>......................] - ETA: 4s - loss: 0.1458 - accuracy: 0.9437\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.1827 - accuracy: 0.9345\n",
      "130/750 [====>.........................] - ETA: 5s - loss: 0.1802 - accuracy: 0.9357\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2357 - accuracy: 0.9158\n",
      " 28/750 [>.............................] - ETA: 6s - loss: 0.1261 - accuracy: 0.9498\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2357 - accuracy: 0.9158\n",
      "652/750 [=========================>....] - ETA: 0s - loss: 0.1824 - accuracy: 0.9345\n",
      "657/750 [=========================>....] - ETA: 0s - loss: 0.1829 - accuracy: 0.9341\n",
      "567/750 [=====================>........] - ETA: 1s - loss: 0.1836 - accuracy: 0.9339\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "630/750 [========================>.....] - ETA: 0s - loss: 0.2347 - accuracy: 0.9165\n",
      "402/750 [===============>..............] - ETA: 2s - loss: 0.2333 - accuracy: 0.9168\n",
      "679/750 [==========================>...] - ETA: 0s - loss: 0.1828 - accuracy: 0.9342\n",
      "664/750 [=========================>....] - ETA: 0s - loss: 0.1822 - accuracy: 0.9344\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "226/750 [========>.....................] - ETA: 4s - loss: 0.1804 - accuracy: 0.9363\n",
      "513/750 [===================>..........] - ETA: 2s - loss: 0.1837 - accuracy: 0.9339\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "349/750 [============>.................] - ETA: 3s - loss: 0.1466 - accuracy: 0.9444\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 45/750 [>.............................] - ETA: 5s - loss: 0.1275 - accuracy: 0.9493\n",
      "267/750 [=========>....................] - ETA: 4s - loss: 0.1459 - accuracy: 0.9432\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "400/750 [===============>..............] - ETA: 2s - loss: 0.1474 - accuracy: 0.9446\n",
      " 72/750 [=>............................] - ETA: 5s - loss: 0.1417 - accuracy: 0.9453\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "318/750 [===========>..................] - ETA: 3s - loss: 0.1458 - accuracy: 0.9445\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  6/750 [..............................] - ETA: 7s - loss: 0.2329 - accuracy: 0.9193\n",
      " 14/750 [..............................] - ETA: 5s - loss: 0.2327 - accuracy: 0.9196\n",
      " 29/750 [>.............................] - ETA: 5s - loss: 0.2557 - accuracy: 0.9149\n",
      "201/750 [=======>......................] - ETA: 4s - loss: 0.1458 - accuracy: 0.9436\n",
      " 47/750 [>.............................] - ETA: 4s - loss: 0.2415 - accuracy: 0.9162\n",
      "475/750 [==================>...........] - ETA: 2s - loss: 0.1466 - accuracy: 0.9449\n",
      " 50/750 [=>............................] - ETA: 5s - loss: 0.2411 - accuracy: 0.9153\n",
      "635/750 [========================>.....] - ETA: 0s - loss: 0.1826 - accuracy: 0.9346\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "361/750 [=============>................] - ETA: 3s - loss: 0.1458 - accuracy: 0.9448\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "255/750 [=========>....................] - ETA: 4s - loss: 0.1450 - accuracy: 0.9439\n",
      "387/750 [==============>...............] - ETA: 3s - loss: 0.1467 - accuracy: 0.9447\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 81/750 [==>...........................] - ETA: 5s - loss: 0.2373 - accuracy: 0.9145\n",
      "461/750 [=================>............] - ETA: 2s - loss: 0.1472 - accuracy: 0.9447\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "146/750 [====>.........................] - ETA: 5s - loss: 0.1421 - accuracy: 0.9452\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.1835 - accuracy: 0.9339\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "160/750 [=====>........................] - ETA: 4s - loss: 0.1409 - accuracy: 0.9457\n",
      "238/750 [========>.....................] - ETA: 4s - loss: 0.1449 - accuracy: 0.9442\n",
      "415/750 [===============>..............] - ETA: 2s - loss: 0.1472 - accuracy: 0.9449\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "542/750 [====================>.........] - ETA: 1s - loss: 0.1487 - accuracy: 0.9441\n",
      "127/750 [====>.........................] - ETA: 4s - loss: 0.2331 - accuracy: 0.9177\n",
      " 19/750 [..............................] - ETA: 6s - loss: 0.1832 - accuracy: 0.9424\n",
      "111/750 [===>..........................] - ETA: 4s - loss: 0.2338 - accuracy: 0.9168\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "430/750 [================>.............] - ETA: 2s - loss: 0.1472 - accuracy: 0.9450\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "144/750 [====>.........................] - ETA: 4s - loss: 0.2341 - accuracy: 0.9169\n",
      "187/750 [======>.......................] - ETA: 4s - loss: 0.1445 - accuracy: 0.9442\n",
      "445/750 [================>.............] - ETA: 2s - loss: 0.1471 - accuracy: 0.9450\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "154/750 [=====>........................] - ETA: 4s - loss: 0.2319 - accuracy: 0.9175\n",
      " 96/750 [==>...........................] - ETA: 4s - loss: 0.2339 - accuracy: 0.9165\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "458/750 [=================>............] - ETA: 2s - loss: 0.1834 - accuracy: 0.9338\n",
      "162/750 [=====>........................] - ETA: 4s - loss: 0.2320 - accuracy: 0.9168\n",
      " 55/750 [=>............................] - ETA: 6s - loss: 0.1990 - accuracy: 0.9341\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.1841 - accuracy: 0.9339\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "177/750 [======>.......................] - ETA: 4s - loss: 0.2307 - accuracy: 0.9173\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.1486 - accuracy: 0.9438\n",
      "184/750 [======>.......................] - ETA: 4s - loss: 0.2309 - accuracy: 0.9167\n",
      "202/750 [=======>......................] - ETA: 4s - loss: 0.2270 - accuracy: 0.9180\n",
      "630/750 [========================>.....] - ETA: 0s - loss: 0.1497 - accuracy: 0.9435\n",
      "104/750 [===>..........................] - ETA: 5s - loss: 0.1832 - accuracy: 0.9333\n",
      "375/750 [==============>...............] - ETA: 3s - loss: 0.1462 - accuracy: 0.9447\n",
      "502/750 [===================>..........] - ETA: 2s - loss: 0.1488 - accuracy: 0.9440\n",
      "228/750 [========>.....................] - ETA: 4s - loss: 0.2289 - accuracy: 0.9172\n",
      "245/750 [========>.....................] - ETA: 3s - loss: 0.2283 - accuracy: 0.9176\n",
      "294/750 [==========>...................] - ETA: 3s - loss: 0.1462 - accuracy: 0.9438\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "533/750 [====================>.........] - ETA: 1s - loss: 0.1484 - accuracy: 0.9443\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "540/750 [====================>.........] - ETA: 1s - loss: 0.1838 - accuracy: 0.9337\n",
      "186/750 [======>.......................] - ETA: 4s - loss: 0.1782 - accuracy: 0.9376\n",
      "596/750 [======================>.......] - ETA: 1s - loss: 0.1486 - accuracy: 0.9440\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "330/750 [============>.................] - ETA: 3s - loss: 0.2287 - accuracy: 0.9162\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.1492 - accuracy: 0.9437\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 7s 10ms/step - loss: 0.1838 - accuracy: 0.9340 - val_loss: 0.5303 - val_accuracy: 0.8873\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 28/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.1500 - accuracy: 0.9437\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "301/750 [===========>..................] - ETA: 3s - loss: 0.1807 - accuracy: 0.9353\n",
      "580/750 [======================>.......] - ETA: 1s - loss: 0.1485 - accuracy: 0.9441\n",
      "490/750 [==================>...........] - ETA: 2s - loss: 0.1481 - accuracy: 0.9442\n",
      "217/750 [=======>......................] - ETA: 4s - loss: 0.1776 - accuracy: 0.9369\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "437/750 [================>.............] - ETA: 2s - loss: 0.2311 - accuracy: 0.9151\n",
      "452/750 [=================>............] - ETA: 2s - loss: 0.2306 - accuracy: 0.9152\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.1504 - accuracy: 0.9438\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.1495 - accuracy: 0.9441\n",
      "  1/750 [..............................] - ETA: 7s - loss: 0.2706 - accuracy: 0.8906\n",
      "497/750 [==================>...........] - ETA: 1s - loss: 0.2325 - accuracy: 0.9141\n",
      "567/750 [=====================>........] - ETA: 1s - loss: 0.1485 - accuracy: 0.9443\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 38/750 [>.............................] - ETA: 6s - loss: 0.1442 - accuracy: 0.9474\n",
      "537/750 [====================>.........] - ETA: 1s - loss: 0.2321 - accuracy: 0.9145\n",
      " 46/750 [>.............................] - ETA: 6s - loss: 0.1443 - accuracy: 0.9480\n",
      "549/750 [====================>.........] - ETA: 1s - loss: 0.2321 - accuracy: 0.9146\n",
      "671/750 [=========================>....] - ETA: 0s - loss: 0.1502 - accuracy: 0.9436\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:07:01,364 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7162060800; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78/750 [==>...........................] - ETA: 5s - loss: 0.1391 - accuracy: 0.9509\n",
      "510/750 [===================>..........] - ETA: 1s - loss: 0.2325 - accuracy: 0.9143\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "343/750 [============>.................] - ETA: 3s - loss: 0.1823 - accuracy: 0.9353\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "274/750 [=========>....................] - ETA: 3s - loss: 0.1806 - accuracy: 0.9354\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "600/750 [=======================>......] - ETA: 1s - loss: 0.2308 - accuracy: 0.9150\n",
      " 56/750 [=>............................] - ETA: 6s - loss: 0.1405 - accuracy: 0.9487\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "316/750 [===========>..................] - ETA: 3s - loss: 0.1832 - accuracy: 0.9351\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  9/750 [..............................] - ETA: 4s - loss: 0.1838 - accuracy: 0.9410\n",
      " 22/750 [..............................] - ETA: 5s - loss: 0.1522 - accuracy: 0.9482\n",
      "655/750 [=========================>....] - ETA: 0s - loss: 0.2308 - accuracy: 0.9152\n",
      " 40/750 [>.............................] - ETA: 7s - loss: 0.1913 - accuracy: 0.9387\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "581/750 [======================>.......] - ETA: 1s - loss: 0.1813 - accuracy: 0.9350\n",
      "480/750 [==================>...........] - ETA: 2s - loss: 0.1806 - accuracy: 0.9353\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.2312 - accuracy: 0.9148\n",
      "645/750 [========================>.....] - ETA: 0s - loss: 0.2304 - accuracy: 0.9153\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "374/750 [=============>................] - ETA: 2s - loss: 0.1813 - accuracy: 0.9353\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "399/750 [==============>...............] - ETA: 2s - loss: 0.1797 - accuracy: 0.9358\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "464/750 [=================>............] - ETA: 2s - loss: 0.1799 - accuracy: 0.9356\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.2313 - accuracy: 0.9150\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "424/750 [===============>..............] - ETA: 2s - loss: 0.1808 - accuracy: 0.9353\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "281/750 [==========>...................] - ETA: 3s - loss: 0.1418 - accuracy: 0.9473\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.1817 - accuracy: 0.9351\n",
      " 14/750 [..............................] - ETA: 6s - loss: 0.1487 - accuracy: 0.9531\n",
      "118/750 [===>..........................] - ETA: 5s - loss: 0.1368 - accuracy: 0.9499\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "428/750 [================>.............] - ETA: 2s - loss: 0.2317 - accuracy: 0.9150\n",
      "142/750 [====>.........................] - ETA: 5s - loss: 0.1418 - accuracy: 0.9476\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "437/750 [================>.............] - ETA: 2s - loss: 0.1797 - accuracy: 0.9358\n",
      "156/750 [=====>........................] - ETA: 4s - loss: 0.1405 - accuracy: 0.9480\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 93/750 [==>...........................] - ETA: 5s - loss: 0.1374 - accuracy: 0.9504\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "170/750 [=====>........................] - ETA: 4s - loss: 0.1385 - accuracy: 0.9493\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2330 - accuracy: 0.9146\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "203/750 [=======>......................] - ETA: 4s - loss: 0.1791 - accuracy: 0.9367\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.1829 - accuracy: 0.9348\n",
      "630/750 [========================>.....] - ETA: 0s - loss: 0.1802 - accuracy: 0.9356\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "375/750 [==============>...............] - ETA: 2s - loss: 0.1423 - accuracy: 0.9472\n",
      "102/750 [===>..........................] - ETA: 5s - loss: 0.1391 - accuracy: 0.9490\n",
      "407/750 [===============>..............] - ETA: 2s - loss: 0.1416 - accuracy: 0.9472\n",
      "249/750 [========>.....................] - ETA: 3s - loss: 0.1400 - accuracy: 0.9477\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "287/750 [==========>...................] - ETA: 3s - loss: 0.1804 - accuracy: 0.9359\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "533/750 [====================>.........] - ETA: 1s - loss: 0.1811 - accuracy: 0.9349\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 19/750 [..............................] - ETA: 4s - loss: 0.2202 - accuracy: 0.9145\n",
      "438/750 [================>.............] - ETA: 2s - loss: 0.1414 - accuracy: 0.9473\n",
      "199/750 [======>.......................] - ETA: 4s - loss: 0.1365 - accuracy: 0.9493\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "597/750 [======================>.......] - ETA: 1s - loss: 0.1810 - accuracy: 0.9352\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "334/750 [============>.................] - ETA: 3s - loss: 0.1427 - accuracy: 0.9471\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "504/750 [===================>..........] - ETA: 1s - loss: 0.1422 - accuracy: 0.9472\n",
      "615/750 [=======================>......] - ETA: 1s - loss: 0.1802 - accuracy: 0.9354\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.2332 - accuracy: 0.9145 - val_loss: 0.3160 - val_accuracy: 0.8867\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 28/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "125/750 [====>.........................] - ETA: 4s - loss: 0.2247 - accuracy: 0.9165\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.1830 - accuracy: 0.9347\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 55/750 [=>............................] - ETA: 5s - loss: 0.1811 - accuracy: 0.9301\n",
      "300/750 [===========>..................] - ETA: 3s - loss: 0.1428 - accuracy: 0.9472\n",
      "179/750 [======>.......................] - ETA: 4s - loss: 0.2320 - accuracy: 0.9155\n",
      "218/750 [=======>......................] - ETA: 4s - loss: 0.1398 - accuracy: 0.9485\n",
      "594/750 [======================>.......] - ETA: 1s - loss: 0.1429 - accuracy: 0.9470\n",
      "454/750 [=================>............] - ETA: 2s - loss: 0.1414 - accuracy: 0.9475\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "208/750 [=======>......................] - ETA: 4s - loss: 0.2316 - accuracy: 0.9160\n",
      "222/750 [=======>......................] - ETA: 4s - loss: 0.2309 - accuracy: 0.9158\n",
      "646/750 [========================>.....] - ETA: 0s - loss: 0.1436 - accuracy: 0.9466\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.1852 - accuracy: 0.9062\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "490/750 [==================>...........] - ETA: 1s - loss: 0.1420 - accuracy: 0.9471\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "252/750 [=========>....................] - ETA: 3s - loss: 0.2326 - accuracy: 0.9163\n",
      "668/750 [=========================>....] - ETA: 0s - loss: 0.1442 - accuracy: 0.9465\n",
      "572/750 [=====================>........] - ETA: 1s - loss: 0.1424 - accuracy: 0.9471\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "546/750 [====================>.........] - ETA: 1s - loss: 0.1425 - accuracy: 0.9469\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "306/750 [===========>..................] - ETA: 3s - loss: 0.2319 - accuracy: 0.9176\n",
      "660/750 [=========================>....] - ETA: 0s - loss: 0.1443 - accuracy: 0.9465\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "206/750 [=======>......................] - ETA: 4s - loss: 0.1743 - accuracy: 0.9377\n",
      "211/750 [=======>......................] - ETA: 4s - loss: 0.1742 - accuracy: 0.9374\n",
      "328/750 [============>.................] - ETA: 3s - loss: 0.2330 - accuracy: 0.9173\n",
      "333/750 [============>.................] - ETA: 3s - loss: 0.2334 - accuracy: 0.9172\n",
      "520/750 [===================>..........] - ETA: 1s - loss: 0.1417 - accuracy: 0.9473\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "345/750 [============>.................] - ETA: 3s - loss: 0.1424 - accuracy: 0.9470\n",
      "266/750 [=========>....................] - ETA: 3s - loss: 0.2329 - accuracy: 0.9164\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "607/750 [=======================>......] - ETA: 1s - loss: 0.1431 - accuracy: 0.9467\n",
      "344/750 [============>.................] - ETA: 3s - loss: 0.2331 - accuracy: 0.9172\n",
      "352/750 [=============>................] - ETA: 3s - loss: 0.2330 - accuracy: 0.9168\n",
      " 69/750 [=>............................] - ETA: 5s - loss: 0.1782 - accuracy: 0.9321\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "321/750 [===========>..................] - ETA: 3s - loss: 0.2323 - accuracy: 0.9174\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 47/750 [>.............................] - ETA: 5s - loss: 0.1866 - accuracy: 0.9295\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "430/750 [================>.............] - ETA: 2s - loss: 0.2310 - accuracy: 0.9176\n",
      "478/750 [==================>...........] - ETA: 2s - loss: 0.1414 - accuracy: 0.9471\n",
      "644/750 [========================>.....] - ETA: 0s - loss: 0.1807 - accuracy: 0.9356\n",
      "368/750 [=============>................] - ETA: 3s - loss: 0.2327 - accuracy: 0.9164\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "398/750 [==============>...............] - ETA: 2s - loss: 0.2314 - accuracy: 0.9171\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "475/750 [==================>...........] - ETA: 2s - loss: 0.2310 - accuracy: 0.9169\n",
      "459/750 [=================>............] - ETA: 2s - loss: 0.2306 - accuracy: 0.9173\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "694/750 [==========================>...] - ETA: 0s - loss: 0.1442 - accuracy: 0.9463\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "410/750 [===============>..............] - ETA: 2s - loss: 0.1786 - accuracy: 0.9363\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "275/750 [==========>...................] - ETA: 3s - loss: 0.2330 - accuracy: 0.9165\n",
      "114/750 [===>..........................] - ETA: 4s - loss: 0.1789 - accuracy: 0.9334\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "145/750 [====>.........................] - ETA: 4s - loss: 0.1751 - accuracy: 0.9350\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "154/750 [=====>........................] - ETA: 4s - loss: 0.1725 - accuracy: 0.9361\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 25/750 [>.............................] - ETA: 7s - loss: 0.1319 - accuracy: 0.9500\n",
      " 99/750 [==>...........................] - ETA: 5s - loss: 0.1756 - accuracy: 0.9336\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "171/750 [=====>........................] - ETA: 4s - loss: 0.1746 - accuracy: 0.9373\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.1446 - accuracy: 0.9464\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "578/750 [======================>.......] - ETA: 1s - loss: 0.2310 - accuracy: 0.9169\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.1449 - accuracy: 0.9464\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "382/750 [==============>...............] - ETA: 2s - loss: 0.1772 - accuracy: 0.9368\n",
      " 78/750 [==>...........................] - ETA: 5s - loss: 0.1336 - accuracy: 0.9495\n",
      "237/750 [========>.....................] - ETA: 4s - loss: 0.1745 - accuracy: 0.9376\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "105/750 [===>..........................] - ETA: 5s - loss: 0.1402 - accuracy: 0.9487\n",
      "287/750 [==========>...................] - ETA: 3s - loss: 0.1766 - accuracy: 0.9362\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 16/750 [..............................] - ETA: 5s - loss: 0.1175 - accuracy: 0.9570\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "633/750 [========================>.....] - ETA: 0s - loss: 0.2298 - accuracy: 0.9176\n",
      "449/750 [================>.............] - ETA: 2s - loss: 0.1790 - accuracy: 0.9362\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "647/750 [========================>.....] - ETA: 0s - loss: 0.2294 - accuracy: 0.9177\n",
      "197/750 [======>.......................] - ETA: 4s - loss: 0.1746 - accuracy: 0.9376\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "589/750 [======================>.......] - ETA: 1s - loss: 0.1820 - accuracy: 0.9360\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 0.1826 - accuracy: 0.9356\n",
      "330/750 [============>.................] - ETA: 3s - loss: 0.1758 - accuracy: 0.9364\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.2300 - accuracy: 0.9175\n",
      "502/750 [===================>..........] - ETA: 1s - loss: 0.1782 - accuracy: 0.9367\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "616/750 [=======================>......] - ETA: 1s - loss: 0.1836 - accuracy: 0.9353\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "629/750 [========================>.....] - ETA: 0s - loss: 0.1847 - accuracy: 0.9352\n",
      "750/750 [==============================] - 7s 10ms/step - loss: 0.1450 - accuracy: 0.9464 - val_loss: 0.4187 - val_accuracy: 0.8897\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 28/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "636/750 [========================>.....] - ETA: 0s - loss: 0.1846 - accuracy: 0.9353\n",
      "129/750 [====>.........................] - ETA: 5s - loss: 0.1373 - accuracy: 0.9500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2290 - accuracy: 0.9180\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "238/750 [========>.....................] - ETA: 4s - loss: 0.1350 - accuracy: 0.9499\n",
      "241/750 [========>.....................] - ETA: 4s - loss: 0.1351 - accuracy: 0.9497\n",
      "682/750 [==========================>...] - ETA: 0s - loss: 0.1836 - accuracy: 0.9354\n",
      "271/750 [=========>....................] - ETA: 4s - loss: 0.1357 - accuracy: 0.9494\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.1837 - accuracy: 0.9353\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.1834 - accuracy: 0.9354\n",
      "219/750 [=======>......................] - ETA: 4s - loss: 0.1332 - accuracy: 0.9511\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.1826 - accuracy: 0.9354\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.1878 - accuracy: 0.9375\n",
      "490/750 [==================>...........] - ETA: 2s - loss: 0.1792 - accuracy: 0.9364\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "252/750 [=========>....................] - ETA: 4s - loss: 0.1356 - accuracy: 0.9492\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "668/750 [=========================>....] - ETA: 0s - loss: 0.1837 - accuracy: 0.9354\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "574/750 [=====================>........] - ETA: 1s - loss: 0.1812 - accuracy: 0.9361\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "546/750 [====================>.........] - ETA: 1s - loss: 0.1799 - accuracy: 0.9362\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "303/750 [===========>..................] - ETA: 4s - loss: 0.1351 - accuracy: 0.9500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "658/750 [=========================>....] - ETA: 0s - loss: 0.1840 - accuracy: 0.9353\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:07:11,460 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7161860096; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/750 [===================>..........] - ETA: 1s - loss: 0.1780 - accuracy: 0.9366\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "266/750 [=========>....................] - ETA: 4s - loss: 0.1357 - accuracy: 0.9497\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "347/750 [============>.................] - ETA: 4s - loss: 0.1366 - accuracy: 0.9502\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "381/750 [==============>...............] - ETA: 3s - loss: 0.1371 - accuracy: 0.9501\n",
      "357/750 [=============>................] - ETA: 3s - loss: 0.1373 - accuracy: 0.9500\n",
      "  9/750 [..............................] - ETA: 4s - loss: 0.1988 - accuracy: 0.9323\n",
      " 63/750 [=>............................] - ETA: 6s - loss: 0.1347 - accuracy: 0.9494\n",
      "322/750 [===========>..................] - ETA: 4s - loss: 0.1367 - accuracy: 0.9497\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 56/750 [=>............................] - ETA: 6s - loss: 0.2350 - accuracy: 0.9132\n",
      "451/750 [=================>............] - ETA: 2s - loss: 0.1383 - accuracy: 0.9491\n",
      " 46/750 [>.............................] - ETA: 6s - loss: 0.2355 - accuracy: 0.9137\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "427/750 [================>.............] - ETA: 3s - loss: 0.1388 - accuracy: 0.9491\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 69/750 [=>............................] - ETA: 6s - loss: 0.2314 - accuracy: 0.9160\n",
      "464/750 [=================>............] - ETA: 2s - loss: 0.1390 - accuracy: 0.9489\n",
      "373/750 [=============>................] - ETA: 3s - loss: 0.1363 - accuracy: 0.9504\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 82/750 [==>...........................] - ETA: 6s - loss: 0.2309 - accuracy: 0.9173\n",
      "466/750 [=================>............] - ETA: 2s - loss: 0.1389 - accuracy: 0.9490\n",
      "397/750 [==============>...............] - ETA: 3s - loss: 0.1373 - accuracy: 0.9496\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "475/750 [==================>...........] - ETA: 2s - loss: 0.1386 - accuracy: 0.9489\n",
      "460/750 [=================>............] - ETA: 2s - loss: 0.1386 - accuracy: 0.9490\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 12s - loss: 0.1120 - accuracy: 0.9531\n",
      "691/750 [==========================>...] - ETA: 0s - loss: 0.1839 - accuracy: 0.9354\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "493/750 [==================>...........] - ETA: 2s - loss: 0.1381 - accuracy: 0.9493\n",
      " 12/750 [..............................] - ETA: 7s - loss: 0.1583 - accuracy: 0.9310\n",
      "416/750 [===============>..............] - ETA: 3s - loss: 0.1388 - accuracy: 0.9491\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "120/750 [===>..........................] - ETA: 6s - loss: 0.2300 - accuracy: 0.9185\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "143/750 [====>.........................] - ETA: 5s - loss: 0.1346 - accuracy: 0.9514\n",
      "130/750 [====>.........................] - ETA: 6s - loss: 0.2322 - accuracy: 0.9173\n",
      "155/750 [=====>........................] - ETA: 5s - loss: 0.1345 - accuracy: 0.9518\n",
      "526/750 [====================>.........] - ETA: 2s - loss: 0.1390 - accuracy: 0.9485\n",
      "141/750 [====>.........................] - ETA: 6s - loss: 0.2308 - accuracy: 0.9172\n",
      " 34/750 [>.............................] - ETA: 9s - loss: 0.1731 - accuracy: 0.9297\n",
      " 89/750 [==>...........................] - ETA: 7s - loss: 0.2293 - accuracy: 0.9178\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "169/750 [=====>........................] - ETA: 5s - loss: 0.1350 - accuracy: 0.9516\n",
      "530/750 [====================>.........] - ETA: 2s - loss: 0.1391 - accuracy: 0.9485\n",
      "148/750 [====>.........................] - ETA: 6s - loss: 0.2320 - accuracy: 0.9175\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.1829 - accuracy: 0.9354\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "158/750 [=====>........................] - ETA: 6s - loss: 0.2326 - accuracy: 0.9179\n",
      "168/750 [=====>........................] - ETA: 6s - loss: 0.2322 - accuracy: 0.9178\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2295 - accuracy: 0.9178\n",
      " 77/750 [==>...........................] - ETA: 6s - loss: 0.2276 - accuracy: 0.9176\n",
      "179/750 [======>.......................] - ETA: 6s - loss: 0.2309 - accuracy: 0.9186\n",
      " 79/750 [==>...........................] - ETA: 7s - loss: 0.1734 - accuracy: 0.9339\n",
      "576/750 [======================>.......] - ETA: 1s - loss: 0.1393 - accuracy: 0.9483\n",
      "233/750 [========>.....................] - ETA: 4s - loss: 0.1341 - accuracy: 0.9506\n",
      "101/750 [===>..........................] - ETA: 6s - loss: 0.2300 - accuracy: 0.9182\n",
      "582/750 [======================>.......] - ETA: 1s - loss: 0.1393 - accuracy: 0.9483\n",
      "206/750 [=======>......................] - ETA: 5s - loss: 0.2303 - accuracy: 0.9180\n",
      "292/750 [==========>...................] - ETA: 4s - loss: 0.1357 - accuracy: 0.9498\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 23/750 [..............................] - ETA: 7s - loss: 0.1769 - accuracy: 0.9239\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "648/750 [========================>.....] - ETA: 0s - loss: 0.1847 - accuracy: 0.9351\n",
      "438/750 [================>.............] - ETA: 3s - loss: 0.1383 - accuracy: 0.9492\n",
      "230/750 [========>.....................] - ETA: 5s - loss: 0.2315 - accuracy: 0.9176\n",
      "239/750 [========>.....................] - ETA: 5s - loss: 0.2302 - accuracy: 0.9179\n",
      "192/750 [======>.......................] - ETA: 6s - loss: 0.2317 - accuracy: 0.9178\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "595/750 [======================>.......] - ETA: 1s - loss: 0.1397 - accuracy: 0.9482\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.1408 - accuracy: 0.9478\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.1400 - accuracy: 0.9481\n",
      "649/750 [========================>.....] - ETA: 1s - loss: 0.1408 - accuracy: 0.9478\n",
      "275/750 [==========>...................] - ETA: 4s - loss: 0.2287 - accuracy: 0.9181\n",
      "503/750 [===================>..........] - ETA: 2s - loss: 0.1382 - accuracy: 0.9491\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.1406 - accuracy: 0.9480\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.1407 - accuracy: 0.9478\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.1828 - accuracy: 0.9354 - val_loss: 0.5551 - val_accuracy: 0.8890\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Epoch 30/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "195/750 [======>.......................] - ETA: 5s - loss: 0.1689 - accuracy: 0.9374\n",
      "131/750 [====>.........................] - ETA: 6s - loss: 0.1731 - accuracy: 0.9356\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.1828 - accuracy: 0.9355\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "310/750 [===========>..................] - ETA: 4s - loss: 0.2309 - accuracy: 0.9168\n",
      "327/750 [============>.................] - ETA: 4s - loss: 0.2302 - accuracy: 0.9171\n",
      "221/750 [=======>......................] - ETA: 5s - loss: 0.1710 - accuracy: 0.9374\n",
      "679/750 [==========================>...] - ETA: 0s - loss: 0.1405 - accuracy: 0.9479\n",
      "694/750 [==========================>...] - ETA: 0s - loss: 0.1408 - accuracy: 0.9480\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.1408 - accuracy: 0.9480\n",
      "216/750 [=======>......................] - ETA: 5s - loss: 0.1706 - accuracy: 0.9372\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "367/750 [=============>................] - ETA: 4s - loss: 0.2270 - accuracy: 0.9184\n",
      "375/750 [==============>...............] - ETA: 3s - loss: 0.2268 - accuracy: 0.9186\n",
      "486/750 [==================>...........] - ETA: 2s - loss: 0.1381 - accuracy: 0.9491\n",
      "258/750 [=========>....................] - ETA: 5s - loss: 0.1718 - accuracy: 0.9382\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "570/750 [=====================>........] - ETA: 1s - loss: 0.1391 - accuracy: 0.9485\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "439/750 [================>.............] - ETA: 3s - loss: 0.2261 - accuracy: 0.9190\n",
      "355/750 [=============>................] - ETA: 3s - loss: 0.1724 - accuracy: 0.9374\n",
      "547/750 [====================>.........] - ETA: 2s - loss: 0.1388 - accuracy: 0.9486\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "300/750 [===========>..................] - ETA: 4s - loss: 0.1723 - accuracy: 0.9380\n",
      "664/750 [=========================>....] - ETA: 0s - loss: 0.1406 - accuracy: 0.9479\n",
      "476/750 [==================>...........] - ETA: 2s - loss: 0.2260 - accuracy: 0.9184\n",
      "493/750 [==================>...........] - ETA: 2s - loss: 0.2259 - accuracy: 0.9185\n",
      "513/750 [===================>..........] - ETA: 2s - loss: 0.1388 - accuracy: 0.9487\n",
      "272/750 [=========>....................] - ETA: 4s - loss: 0.1717 - accuracy: 0.9384\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "337/750 [============>.................] - ETA: 4s - loss: 0.1726 - accuracy: 0.9376\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "501/750 [===================>..........] - ETA: 2s - loss: 0.2256 - accuracy: 0.9187\n",
      "507/750 [===================>..........] - ETA: 2s - loss: 0.2260 - accuracy: 0.9185\n",
      "519/750 [===================>..........] - ETA: 2s - loss: 0.2263 - accuracy: 0.9182\n",
      "437/750 [================>.............] - ETA: 2s - loss: 0.1708 - accuracy: 0.9386\n",
      "310/750 [===========>..................] - ETA: 4s - loss: 0.1719 - accuracy: 0.9383\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 30/750 [>.............................] - ETA: 5s - loss: 0.1240 - accuracy: 0.9500\n",
      " 68/750 [=>............................] - ETA: 8s - loss: 0.1737 - accuracy: 0.9338\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "450/750 [=================>............] - ETA: 2s - loss: 0.1722 - accuracy: 0.9382\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 43/750 [>.............................] - ETA: 5s - loss: 0.1358 - accuracy: 0.9469\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "425/750 [================>.............] - ETA: 3s - loss: 0.1707 - accuracy: 0.9385\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "588/750 [======================>.......] - ETA: 1s - loss: 0.2262 - accuracy: 0.9188\n",
      "601/750 [=======================>......] - ETA: 1s - loss: 0.2264 - accuracy: 0.9190\n",
      "367/750 [=============>................] - ETA: 3s - loss: 0.1723 - accuracy: 0.9376\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "612/750 [=======================>......] - ETA: 1s - loss: 0.2264 - accuracy: 0.9191\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.2263 - accuracy: 0.9192\n",
      "397/750 [==============>...............] - ETA: 3s - loss: 0.1709 - accuracy: 0.9380\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "465/750 [=================>............] - ETA: 2s - loss: 0.1727 - accuracy: 0.9382\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "552/750 [=====================>........] - ETA: 1s - loss: 0.1758 - accuracy: 0.9374\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.0650 - accuracy: 0.9844\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.1407 - accuracy: 0.9479\n",
      "498/750 [==================>...........] - ETA: 2s - loss: 0.1740 - accuracy: 0.9382\n",
      "131/750 [====>.........................] - ETA: 5s - loss: 0.1331 - accuracy: 0.9488\n",
      "663/750 [=========================>....] - ETA: 0s - loss: 0.2270 - accuracy: 0.9187\n",
      "410/750 [===============>..............] - ETA: 3s - loss: 0.1706 - accuracy: 0.9383\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "675/750 [==========================>...] - ETA: 0s - loss: 0.2271 - accuracy: 0.9187\n",
      "119/750 [===>..........................] - ETA: 5s - loss: 0.1334 - accuracy: 0.9483\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "145/750 [====>.........................] - ETA: 5s - loss: 0.1349 - accuracy: 0.9482\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.2271 - accuracy: 0.9189\n",
      "525/750 [====================>.........] - ETA: 2s - loss: 0.1738 - accuracy: 0.9385\n",
      "699/750 [==========================>...] - ETA: 0s - loss: 0.2269 - accuracy: 0.9189\n",
      " 93/750 [==>...........................] - ETA: 5s - loss: 0.1344 - accuracy: 0.9483\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.1408 - accuracy: 0.9481\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "170/750 [=====>........................] - ETA: 4s - loss: 0.1344 - accuracy: 0.9487\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2271 - accuracy: 0.9191\n",
      "178/750 [======>.......................] - ETA: 5s - loss: 0.1668 - accuracy: 0.9382\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2266 - accuracy: 0.9193\n",
      "203/750 [=======>......................] - ETA: 5s - loss: 0.1698 - accuracy: 0.9371\n",
      "287/750 [==========>...................] - ETA: 4s - loss: 0.1725 - accuracy: 0.9383\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 16/750 [..............................] - ETA: 5s - loss: 0.1223 - accuracy: 0.9463\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.1767 - accuracy: 0.9375\n",
      "225/750 [========>.....................] - ETA: 4s - loss: 0.1346 - accuracy: 0.9483\n",
      "249/750 [========>.....................] - ETA: 4s - loss: 0.1351 - accuracy: 0.9483\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "303/750 [===========>..................] - ETA: 3s - loss: 0.1355 - accuracy: 0.9489\n",
      "198/750 [======>.......................] - ETA: 4s - loss: 0.1360 - accuracy: 0.9479\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "646/750 [========================>.....] - ETA: 0s - loss: 0.1766 - accuracy: 0.9372\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9372\n",
      "335/750 [============>.................] - ETA: 3s - loss: 0.1360 - accuracy: 0.9488\n",
      "344/750 [============>.................] - ETA: 3s - loss: 0.1367 - accuracy: 0.9486\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.1409 - accuracy: 0.9480 - val_loss: 0.4364 - val_accuracy: 0.8924\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 29/30\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.1768 - accuracy: 0.9373\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "405/750 [===============>..............] - ETA: 2s - loss: 0.1376 - accuracy: 0.9488\n",
      "327/750 [============>.................] - ETA: 3s - loss: 0.1362 - accuracy: 0.9486\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 9s 11ms/step - loss: 0.2266 - accuracy: 0.9193 - val_loss: 0.3117 - val_accuracy: 0.8913\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Epoch 30/30\n",
      "411/750 [===============>..............] - ETA: 2s - loss: 0.1378 - accuracy: 0.9488\n",
      " 11/750 [..............................] - ETA: 4s - loss: 0.2613 - accuracy: 0.9020\n",
      " 48/750 [>.............................] - ETA: 4s - loss: 0.2288 - accuracy: 0.9173\n",
      "210/750 [=======>......................] - ETA: 4s - loss: 0.1332 - accuracy: 0.9490\n",
      "376/750 [==============>...............] - ETA: 3s - loss: 0.1382 - accuracy: 0.9485\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 79/750 [==>...........................] - ETA: 4s - loss: 0.2142 - accuracy: 0.9233\n",
      " 98/750 [==>...........................] - ETA: 4s - loss: 0.2105 - accuracy: 0.9235\n",
      "505/750 [===================>..........] - ETA: 2s - loss: 0.1381 - accuracy: 0.9491\n",
      "117/750 [===>..........................] - ETA: 4s - loss: 0.2164 - accuracy: 0.9207\n",
      "573/750 [=====================>........] - ETA: 1s - loss: 0.1767 - accuracy: 0.9375\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "526/750 [====================>.........] - ETA: 1s - loss: 0.1386 - accuracy: 0.9490\n",
      "537/750 [====================>.........] - ETA: 1s - loss: 0.1382 - accuracy: 0.9491\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "152/750 [=====>........................] - ETA: 4s - loss: 0.2179 - accuracy: 0.9216\n",
      "477/750 [==================>...........] - ETA: 2s - loss: 0.1719 - accuracy: 0.9385\n",
      "158/750 [=====>........................] - ETA: 4s - loss: 0.2180 - accuracy: 0.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:07:21,559 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 7161786368; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494/750 [==================>...........] - ETA: 2s - loss: 0.1379 - accuracy: 0.9491\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "176/750 [======>.......................] - ETA: 4s - loss: 0.2165 - accuracy: 0.9217\n",
      "579/750 [======================>.......] - ETA: 1s - loss: 0.1384 - accuracy: 0.9489\n",
      "272/750 [=========>....................] - ETA: 4s - loss: 0.1356 - accuracy: 0.9486\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "517/750 [===================>..........] - ETA: 1s - loss: 0.1390 - accuracy: 0.9488\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "205/750 [=======>......................] - ETA: 4s - loss: 0.2183 - accuracy: 0.9213\n",
      "210/750 [=======>......................] - ETA: 4s - loss: 0.2194 - accuracy: 0.9214\n",
      "448/750 [================>.............] - ETA: 2s - loss: 0.1372 - accuracy: 0.9491\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "222/750 [=======>......................] - ETA: 4s - loss: 0.2180 - accuracy: 0.9219\n",
      "316/750 [===========>..................] - ETA: 3s - loss: 0.1352 - accuracy: 0.9487\n",
      " 25/750 [>.............................] - ETA: 4s - loss: 0.2398 - accuracy: 0.9106\n",
      " 64/750 [=>............................] - ETA: 4s - loss: 0.2229 - accuracy: 0.9182\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "652/750 [=========================>....] - ETA: 0s - loss: 0.1377 - accuracy: 0.9491\n",
      "255/750 [=========>....................] - ETA: 4s - loss: 0.2207 - accuracy: 0.9215\n",
      "592/750 [======================>.......] - ETA: 1s - loss: 0.1382 - accuracy: 0.9490\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "672/750 [=========================>....] - ETA: 0s - loss: 0.1386 - accuracy: 0.9488\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 0.1382 - accuracy: 0.9490\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "679/750 [==========================>...] - ETA: 0s - loss: 0.1387 - accuracy: 0.9488\n",
      "360/750 [=============>................] - ETA: 3s - loss: 0.1371 - accuracy: 0.9487\n",
      "618/750 [=======================>......] - ETA: 1s - loss: 0.1380 - accuracy: 0.9491\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "288/750 [==========>...................] - ETA: 3s - loss: 0.2219 - accuracy: 0.9216\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.1774 - accuracy: 0.9370\n",
      "309/750 [===========>..................] - ETA: 3s - loss: 0.2222 - accuracy: 0.9212\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.1386 - accuracy: 0.9490\n",
      "389/750 [==============>...............] - ETA: 2s - loss: 0.1386 - accuracy: 0.9483\n",
      "315/750 [===========>..................] - ETA: 3s - loss: 0.2219 - accuracy: 0.9212\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.1387 - accuracy: 0.9490\n",
      "466/750 [=================>............] - ETA: 2s - loss: 0.1373 - accuracy: 0.9492\n",
      "126/750 [====>.........................] - ETA: 4s - loss: 0.2173 - accuracy: 0.9214\n",
      "665/750 [=========================>....] - ETA: 0s - loss: 0.1382 - accuracy: 0.9489\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "346/750 [============>.................] - ETA: 3s - loss: 0.2220 - accuracy: 0.9212\n",
      "419/750 [===============>..............] - ETA: 2s - loss: 0.1377 - accuracy: 0.9490\n",
      "353/750 [=============>................] - ETA: 3s - loss: 0.2214 - accuracy: 0.9214\n",
      "363/750 [=============>................] - ETA: 3s - loss: 0.2213 - accuracy: 0.9212\n",
      "138/750 [====>.........................] - ETA: 4s - loss: 0.2180 - accuracy: 0.9205\n",
      "692/750 [==========================>...] - ETA: 0s - loss: 0.1380 - accuracy: 0.9492\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">    loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_d00f2_00000</td><td style=\"text-align: right;\">    0.8871</td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">0.624277</td></tr>\n",
       "<tr><td>train_model_d00f2_00001</td><td style=\"text-align: right;\">    0.8872</td><td style=\"text-align: right;\">         0.0005</td><td style=\"text-align: right;\">0.487521</td></tr>\n",
       "<tr><td>train_model_d00f2_00002</td><td style=\"text-align: right;\">    0.8805</td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">0.339811</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=78153)\u001b[0m 313/313 - 2s - loss: 0.6243 - accuracy: 0.8871 - 2s/epoch - 7ms/step\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m \n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Training accuracy : 0.9372291564941406\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Validation accuracy : 0.8865000009536743\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Loss : 0.624276876449585\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m Accuracy : 0.8870999813079834\n",
      "\u001b[36m(train_model pid=78153)\u001b[0m \n",
      "386/750 [==============>...............] - ETA: 3s - loss: 0.2221 - accuracy: 0.9205\n",
      "395/750 [==============>...............] - ETA: 2s - loss: 0.2230 - accuracy: 0.9202\n",
      " 93/750 [==>...........................] - ETA: 4s - loss: 0.2121 - accuracy: 0.9229\n",
      "408/750 [===============>..............] - ETA: 2s - loss: 0.2221 - accuracy: 0.9205\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.1387 - accuracy: 0.9490\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.1381 - accuracy: 0.9491\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "420/750 [===============>..............] - ETA: 2s - loss: 0.2221 - accuracy: 0.9206\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.1389 - accuracy: 0.9490\n",
      "461/750 [=================>............] - ETA: 2s - loss: 0.2244 - accuracy: 0.9198\n",
      "471/750 [=================>............] - ETA: 2s - loss: 0.2242 - accuracy: 0.9199\n",
      "281/750 [==========>...................] - ETA: 3s - loss: 0.2224 - accuracy: 0.9211\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.1384 - accuracy: 0.9491\n",
      "247/750 [========>.....................] - ETA: 4s - loss: 0.2204 - accuracy: 0.9212\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 5s - loss: 0.2345 - accuracy: 0.9375\n",
      "301/750 [===========>..................] - ETA: 3s - loss: 0.2221 - accuracy: 0.9212\n",
      " 16/750 [..............................] - ETA: 5s - loss: 0.1299 - accuracy: 0.9551\n",
      "189/750 [======>.......................] - ETA: 4s - loss: 0.2177 - accuracy: 0.9209\n",
      "646/750 [========================>.....] - ETA: 0s - loss: 0.1378 - accuracy: 0.9491\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 33/750 [>.............................] - ETA: 4s - loss: 0.1183 - accuracy: 0.9588\n",
      " 47/750 [>.............................] - ETA: 4s - loss: 0.1233 - accuracy: 0.9578\n",
      "554/750 [=====================>........] - ETA: 1s - loss: 0.2235 - accuracy: 0.9208\n",
      "572/750 [=====================>........] - ETA: 1s - loss: 0.2235 - accuracy: 0.9205\n",
      " 82/750 [==>...........................] - ETA: 5s - loss: 0.1218 - accuracy: 0.9567\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.2229 - accuracy: 0.9206\n",
      " 94/750 [==>...........................] - ETA: 5s - loss: 0.1228 - accuracy: 0.9556\n",
      "331/750 [============>.................] - ETA: 3s - loss: 0.2232 - accuracy: 0.9208\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 0.1390 - accuracy: 0.9490 - val_loss: 0.4855 - val_accuracy: 0.8906\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=78156)\u001b[0m Epoch 30/30\n",
      "109/750 [===>..........................] - ETA: 5s - loss: 0.1270 - accuracy: 0.9540\n",
      "122/750 [===>..........................] - ETA: 4s - loss: 0.1264 - accuracy: 0.9540\n",
      "624/750 [=======================>......] - ETA: 1s - loss: 0.2230 - accuracy: 0.9210\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.2226 - accuracy: 0.9212\n",
      "136/750 [====>.........................] - ETA: 4s - loss: 0.1239 - accuracy: 0.9546\n",
      "167/750 [=====>........................] - ETA: 4s - loss: 0.1261 - accuracy: 0.9538\n",
      "379/750 [==============>...............] - ETA: 3s - loss: 0.2223 - accuracy: 0.9205\n",
      "182/750 [======>.......................] - ETA: 4s - loss: 0.1284 - accuracy: 0.9531\n",
      "197/750 [======>.......................] - ETA: 4s - loss: 0.1297 - accuracy: 0.9529\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2216 - accuracy: 0.9215\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.2222 - accuracy: 0.9214\n",
      "226/750 [========>.....................] - ETA: 3s - loss: 0.1308 - accuracy: 0.9527\n",
      "567/750 [=====================>........] - ETA: 1s - loss: 0.2234 - accuracy: 0.9206\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "526/750 [====================>.........] - ETA: 1s - loss: 0.2234 - accuracy: 0.9206\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2222 - accuracy: 0.9212\n",
      "255/750 [=========>....................] - ETA: 3s - loss: 0.1342 - accuracy: 0.9507\n",
      "542/750 [====================>.........] - ETA: 1s - loss: 0.2232 - accuracy: 0.9209\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "152/750 [=====>........................] - ETA: 4s - loss: 0.1250 - accuracy: 0.9541\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2221 - accuracy: 0.9213\n",
      "498/750 [==================>...........] - ETA: 2s - loss: 0.2236 - accuracy: 0.9207\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "304/750 [===========>..................] - ETA: 3s - loss: 0.1321 - accuracy: 0.9510\n",
      "270/750 [=========>....................] - ETA: 3s - loss: 0.1325 - accuracy: 0.9514\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "512/750 [===================>..........] - ETA: 1s - loss: 0.2238 - accuracy: 0.9205\n",
      "356/750 [=============>................] - ETA: 2s - loss: 0.1316 - accuracy: 0.9511\n",
      "448/750 [================>.............] - ETA: 2s - loss: 0.2237 - accuracy: 0.9200\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "214/750 [=======>......................] - ETA: 4s - loss: 0.1318 - accuracy: 0.9525\n",
      "387/750 [==============>...............] - ETA: 2s - loss: 0.1320 - accuracy: 0.9510\n",
      " 72/750 [=>............................] - ETA: 5s - loss: 0.1215 - accuracy: 0.9566\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.2232 - accuracy: 0.9206\n",
      "618/750 [=======================>......] - ETA: 1s - loss: 0.2232 - accuracy: 0.9209\n",
      "291/750 [==========>...................] - ETA: 3s - loss: 0.1324 - accuracy: 0.9513\n",
      "466/750 [=================>............] - ETA: 2s - loss: 0.1333 - accuracy: 0.9509\n",
      "320/750 [===========>..................] - ETA: 3s - loss: 0.1316 - accuracy: 0.9509\n",
      "501/750 [===================>..........] - ETA: 1s - loss: 0.1331 - accuracy: 0.9510\n",
      "673/750 [=========================>....] - ETA: 0s - loss: 0.2223 - accuracy: 0.9213\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "337/750 [============>.................] - ETA: 3s - loss: 0.1315 - accuracy: 0.9509\n",
      "517/750 [===================>..........] - ETA: 1s - loss: 0.1330 - accuracy: 0.9510\n",
      "370/750 [=============>................] - ETA: 2s - loss: 0.1317 - accuracy: 0.9511\n",
      "690/750 [==========================>...] - ETA: 0s - loss: 0.2217 - accuracy: 0.9215\n",
      "395/750 [==============>...............] - ETA: 2s - loss: 0.1313 - accuracy: 0.9513\n",
      "576/750 [======================>.......] - ETA: 1s - loss: 0.1340 - accuracy: 0.9508\n",
      "424/750 [===============>..............] - ETA: 2s - loss: 0.1323 - accuracy: 0.9514\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.2224 - accuracy: 0.9212\n",
      "593/750 [======================>.......] - ETA: 1s - loss: 0.1343 - accuracy: 0.9508\n",
      "608/750 [=======================>......] - ETA: 1s - loss: 0.1342 - accuracy: 0.9508\n",
      "626/750 [========================>.....] - ETA: 0s - loss: 0.1347 - accuracy: 0.9507\n",
      "283/750 [==========>...................] - ETA: 3s - loss: 0.1324 - accuracy: 0.9511\n",
      "665/750 [=========================>....] - ETA: 0s - loss: 0.1346 - accuracy: 0.9509\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.1345 - accuracy: 0.9510\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m 313/313 - 2s - loss: 0.3398 - accuracy: 0.8805 - 2s/epoch - 5ms/step\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m \n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Training accuracy : 0.9212499856948853\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Validation accuracy : 0.8882499933242798\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Loss : 0.3398114740848541\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m Accuracy : 0.8805000185966492\n",
      "\u001b[36m(train_model pid=78157)\u001b[0m \n",
      "694/750 [==========================>...] - ETA: 0s - loss: 0.1348 - accuracy: 0.9510\n",
      "238/750 [========>.....................] - ETA: 3s - loss: 0.1326 - accuracy: 0.9517\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.1342 - accuracy: 0.9509\n",
      "643/750 [========================>.....] - ETA: 0s - loss: 0.1351 - accuracy: 0.9507\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.1342 - accuracy: 0.9508\n",
      "550/750 [=====================>........] - ETA: 1s - loss: 0.1332 - accuracy: 0.9508\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.1341 - accuracy: 0.9509 - val_loss: 0.4803 - val_accuracy: 0.8894\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:07:31,658 E 78016 534070] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-01-02_661666_66854 is over 95% full, available space: 8236990464; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "2024-02-22 22:07:32,684\tINFO tune.py:1042 -- Total run time: 375.44 seconds (365.70 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/750 [===========================>..] - ETA: 0s - loss: 0.1339 - accuracy: 0.9512\n",
      "562/750 [=====================>........] - ETA: 1s - loss: 0.1333 - accuracy: 0.9508\n",
      "531/750 [====================>.........] - ETA: 1s - loss: 0.1333 - accuracy: 0.9508\n",
      "484/750 [==================>...........] - ETA: 1s - loss: 0.1333 - accuracy: 0.9510\n",
      "440/750 [================>.............] - ETA: 2s - loss: 0.1334 - accuracy: 0.9510\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter tuning\n",
    "analysis = tune.run(\n",
    "    train_model,\n",
    "    config=search_space,\n",
    "    metric=\"accuracy\",\n",
    "    mode=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FMM.plot_analysis_results(analysis, x_axis=\"learning_rate\", y_axis=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.0005}\n",
      "Best accuracy: 0.8871999979019165\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters and results\n",
    "best_config = analysis.best_config\n",
    "print(\"Best hyperparameters:\", best_config)\n",
    "print(\"Best accuracy:\", analysis.best_result[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with RMSprop optimizer...\n",
      "Epoch 1/30\n",
      "750/750 [==============================] - 9s 10ms/step - loss: 0.5536 - accuracy: 0.8064 - val_loss: 0.4810 - val_accuracy: 0.8152\n",
      "Epoch 2/30\n",
      "750/750 [==============================] - 6s 9ms/step - loss: 0.3898 - accuracy: 0.8606 - val_loss: 0.3743 - val_accuracy: 0.8659\n",
      "Epoch 3/30\n",
      "750/750 [==============================] - 6s 9ms/step - loss: 0.3466 - accuracy: 0.8729 - val_loss: 0.3406 - val_accuracy: 0.8787\n",
      "Epoch 4/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.3202 - accuracy: 0.8817 - val_loss: 0.3398 - val_accuracy: 0.8782\n",
      "Epoch 5/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2998 - accuracy: 0.8891 - val_loss: 0.3355 - val_accuracy: 0.8793\n",
      "Epoch 6/30\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.2864 - accuracy: 0.8945 - val_loss: 0.3200 - val_accuracy: 0.8864\n",
      "Epoch 7/30\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.2742 - accuracy: 0.8978 - val_loss: 0.3296 - val_accuracy: 0.8859\n",
      "Epoch 8/30\n",
      "750/750 [==============================] - 6s 9ms/step - loss: 0.2605 - accuracy: 0.9047 - val_loss: 0.3427 - val_accuracy: 0.8831\n",
      "Epoch 9/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2510 - accuracy: 0.9069 - val_loss: 0.3179 - val_accuracy: 0.8867\n",
      "Epoch 10/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2424 - accuracy: 0.9110 - val_loss: 0.3295 - val_accuracy: 0.8875\n",
      "Epoch 11/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2334 - accuracy: 0.9123 - val_loss: 0.3397 - val_accuracy: 0.8833\n",
      "Epoch 12/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2261 - accuracy: 0.9163 - val_loss: 0.3271 - val_accuracy: 0.8895\n",
      "Epoch 13/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2199 - accuracy: 0.9187 - val_loss: 0.3359 - val_accuracy: 0.8877\n",
      "Epoch 14/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2117 - accuracy: 0.9222 - val_loss: 0.3454 - val_accuracy: 0.8850\n",
      "Epoch 15/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2063 - accuracy: 0.9229 - val_loss: 0.3689 - val_accuracy: 0.8876\n",
      "Epoch 16/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2003 - accuracy: 0.9263 - val_loss: 0.3185 - val_accuracy: 0.8941\n",
      "Epoch 17/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.1926 - accuracy: 0.9275 - val_loss: 0.3534 - val_accuracy: 0.8893\n",
      "Epoch 18/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.1871 - accuracy: 0.9300 - val_loss: 0.3595 - val_accuracy: 0.8899\n",
      "Epoch 19/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.1825 - accuracy: 0.9315 - val_loss: 0.3531 - val_accuracy: 0.8841\n",
      "Epoch 20/30\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.1775 - accuracy: 0.9335 - val_loss: 0.3670 - val_accuracy: 0.8891\n",
      "Epoch 21/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.1735 - accuracy: 0.9366 - val_loss: 0.3779 - val_accuracy: 0.8881\n",
      "Epoch 22/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.1704 - accuracy: 0.9378 - val_loss: 0.3695 - val_accuracy: 0.8896\n",
      "Epoch 23/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.1647 - accuracy: 0.9392 - val_loss: 0.4083 - val_accuracy: 0.8905\n",
      "Epoch 24/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.1600 - accuracy: 0.9405 - val_loss: 0.4073 - val_accuracy: 0.8853\n",
      "Epoch 25/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.1569 - accuracy: 0.9425 - val_loss: 0.3698 - val_accuracy: 0.8934\n",
      "Epoch 26/30\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.1525 - accuracy: 0.9442 - val_loss: 0.4337 - val_accuracy: 0.8890\n",
      "Epoch 27/30\n",
      "750/750 [==============================] - 6s 9ms/step - loss: 0.1498 - accuracy: 0.9440 - val_loss: 0.4428 - val_accuracy: 0.8859\n",
      "Epoch 28/30\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.1463 - accuracy: 0.9451 - val_loss: 0.4341 - val_accuracy: 0.8898\n",
      "Epoch 29/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.1427 - accuracy: 0.9472 - val_loss: 0.4305 - val_accuracy: 0.8897\n",
      "Epoch 30/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.1387 - accuracy: 0.9486 - val_loss: 0.4333 - val_accuracy: 0.8903\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(**best_config)\n",
    "model = FMM.create_model_v1()\n",
    "print(f\"Training with {optimizer.__class__.__name__} optimizer...\")\n",
    "history = FMM.compile_and_train(\n",
    "    model, X_train, y_train, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.4621 - accuracy: 0.8855 - 1s/epoch - 3ms/step\n",
      "\n",
      "Training accuracy : 0.948645830154419\n",
      "Validation accuracy : 0.890250027179718\n",
      "Loss : 0.4620819687843323\n",
      "Accuracy : 0.8855000138282776\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FMM.evaluate(model, X_test, y_test, history)\n",
    "FMM.plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
