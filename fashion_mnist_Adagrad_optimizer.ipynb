{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Adagrad optimizer\n",
    "\n",
    "Adagrad (Adaptive Gradient Algorithm) is an optimization algorithm commonly used in training artificial neural networks (ANNs). It dynamically adjusts the learning rates of each parameter based on the historical gradients. \n",
    "\n",
    "## Details of Adagrad Algorithm\n",
    "\n",
    "Adagrad is designed to adaptively adjust the learning rates for each parameter during training. It achieves this by scaling the learning rates based on the historical gradients of each parameter. Here's how Adagrad works:\n",
    "\n",
    "1. Compute Squared Gradients: Adagrad maintains a sum of the squared gradients for each parameter.\n",
    "\n",
    "2. Adapt Learning Rates: It divides the learning rate by the square root of the sum of squared gradients for each parameter. This effectively reduces the learning rate for parameters that have large gradients and increases it for parameters that have small gradients.\n",
    "\n",
    "3. Accumulation of Gradients: Adagrad accumulates the squared gradients over time, so the learning rates decrease monotonically during training.\n",
    "\n",
    "## Pros of Adagrad optimizer\n",
    "\n",
    "1. Adaptive Learning Rates: Adagrad adapts the learning rates for each parameter individually based on the historical gradients. This can help converge faster and more efficiently, especially for sparse data or when dealing with features that occur infrequently.\n",
    "\n",
    "2. No Manual Tuning of Learning Rate: Adagrad automatically adjusts the learning rates based on the gradients, reducing the need for manual tuning of learning rate hyperparameters.\n",
    "\n",
    "## Cons of Adagrad optimizer\n",
    "\n",
    "1. Decreasing Learning Rates: Adagrad's accumulation of squared gradients can lead to learning rates that decrease too aggressively over time. This can cause the learning process to slow down prematurely, especially for deep neural networks.\n",
    "\n",
    "2. Memory Usage: Adagrad needs to store and update the sum of squared gradients for each parameter, which can lead to increased memory usage, especially for models with many parameters.\n",
    "\n",
    "3. RMSprop and AdaDelta: While Adagrad was one of the early adaptive learning rate algorithms, more recent algorithms like RMSprop and AdaDelta have been developed to address some of its shortcomings, such as the aggressive decrease in learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fashionmnist_model import FMM\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X_train, y_train, X_test, y_test = FMM.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "X_train, X_test = FMM.reshape_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adagrad` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adagrad`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adagrad`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Adagrad optimizer...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 21:57:09.065724: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 5s 6ms/step - loss: 1.4012 - accuracy: 0.6113 - val_loss: 0.9585 - val_accuracy: 0.7139\n",
      "Epoch 2/30\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.8427 - accuracy: 0.7339 - val_loss: 0.7513 - val_accuracy: 0.7558\n",
      "Epoch 3/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.7126 - accuracy: 0.7694 - val_loss: 0.6698 - val_accuracy: 0.7853\n",
      "Epoch 4/30\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.6474 - accuracy: 0.7932 - val_loss: 0.6222 - val_accuracy: 0.7992\n",
      "Epoch 5/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.6068 - accuracy: 0.8043 - val_loss: 0.5916 - val_accuracy: 0.8082\n",
      "Epoch 6/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5781 - accuracy: 0.8118 - val_loss: 0.5677 - val_accuracy: 0.8151\n",
      "Epoch 7/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5571 - accuracy: 0.8175 - val_loss: 0.5503 - val_accuracy: 0.8196\n",
      "Epoch 8/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5405 - accuracy: 0.8212 - val_loss: 0.5364 - val_accuracy: 0.8220\n",
      "Epoch 9/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5269 - accuracy: 0.8259 - val_loss: 0.5243 - val_accuracy: 0.8229\n",
      "Epoch 10/30\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.5155 - accuracy: 0.8284 - val_loss: 0.5157 - val_accuracy: 0.8257\n",
      "Epoch 11/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.5056 - accuracy: 0.8316 - val_loss: 0.5065 - val_accuracy: 0.8296\n",
      "Epoch 12/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4970 - accuracy: 0.8334 - val_loss: 0.4994 - val_accuracy: 0.8287\n",
      "Epoch 13/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.4894 - accuracy: 0.8354 - val_loss: 0.4918 - val_accuracy: 0.8320\n",
      "Epoch 14/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4823 - accuracy: 0.8369 - val_loss: 0.4862 - val_accuracy: 0.8334\n",
      "Epoch 15/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.4761 - accuracy: 0.8398 - val_loss: 0.4840 - val_accuracy: 0.8325\n",
      "Epoch 16/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4706 - accuracy: 0.8410 - val_loss: 0.4763 - val_accuracy: 0.8347\n",
      "Epoch 17/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.4655 - accuracy: 0.8417 - val_loss: 0.4728 - val_accuracy: 0.8372\n",
      "Epoch 18/30\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.4607 - accuracy: 0.8438 - val_loss: 0.4672 - val_accuracy: 0.8388\n",
      "Epoch 19/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4562 - accuracy: 0.8454 - val_loss: 0.4632 - val_accuracy: 0.8393\n",
      "Epoch 20/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4521 - accuracy: 0.8465 - val_loss: 0.4595 - val_accuracy: 0.8394\n",
      "Epoch 21/30\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.4485 - accuracy: 0.8478 - val_loss: 0.4561 - val_accuracy: 0.8421\n",
      "Epoch 22/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4448 - accuracy: 0.8492 - val_loss: 0.4540 - val_accuracy: 0.8415\n",
      "Epoch 23/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.4417 - accuracy: 0.8506 - val_loss: 0.4507 - val_accuracy: 0.8438\n",
      "Epoch 24/30\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.4388 - accuracy: 0.8511 - val_loss: 0.4477 - val_accuracy: 0.8433\n",
      "Epoch 25/30\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.4356 - accuracy: 0.8518 - val_loss: 0.4464 - val_accuracy: 0.8440\n",
      "Epoch 26/30\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.4329 - accuracy: 0.8523 - val_loss: 0.4429 - val_accuracy: 0.8460\n",
      "Epoch 27/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4305 - accuracy: 0.8539 - val_loss: 0.4411 - val_accuracy: 0.8463\n",
      "Epoch 28/30\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.4279 - accuracy: 0.8545 - val_loss: 0.4387 - val_accuracy: 0.8470\n",
      "Epoch 29/30\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 0.4256 - accuracy: 0.8551 - val_loss: 0.4373 - val_accuracy: 0.8478\n",
      "Epoch 30/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.4231 - accuracy: 0.8560 - val_loss: 0.4347 - val_accuracy: 0.8475\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adagrad()\n",
    "model = FMM.get_model()\n",
    "print(f\"Training with {optimizer.__class__.__name__} optimizer...\")\n",
    "history = FMM.compile_and_train(\n",
    "    model, X_train, y_train, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.4545 - accuracy: 0.8422 - 1s/epoch - 4ms/step\n",
      "\n",
      "Training accuracy : 0.8559583425521851\n",
      "Validation accuracy : 0.8475000262260437\n",
      "Loss : 0.45453017950057983\n",
      "Accuracy : 0.842199981212616\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FMM.evaluate(model, X_test, y_test, history)\n",
    "FMM.plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 22:00:07,537\tINFO worker.py:1715 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e402dc07a7241d7bef50c1f7a5da186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.11.5</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.9.2</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.11.5', ray_version='2.9.2', ray_commit='fce7a361807580953364e2da964f9498f3123bf9', protocol_version=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train the model\n",
    "def train_model(config):\n",
    "    from fashionmnist_model import FMM\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = FMM.load_data()\n",
    "    X_train, X_test = FMM.reshape_data(X_train, X_test)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adagrad(\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        # epsilon=config[\"epsilon\"],\n",
    "    )\n",
    "\n",
    "    model = FMM.get_model()\n",
    "    history = FMM.compile_and_train(\n",
    "        model, X_train, y_train, optimizer\n",
    "    )\n",
    "    \n",
    "    loss, accuracy, _, _ = FMM.evaluate(model, X_test, y_test, history)\n",
    "\n",
    "    train.report({\"accuracy\": accuracy, \"loss\": loss, **config})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"learning_rate\": tune.grid_search([0.01, 0.001, 0.0001]),\n",
    "    # \"epsilon\": tune.grid_search([1e-8, 1e-9, 1e-10]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 22:00:11,743\tINFO tune.py:583 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:00:16,446 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 8933634048; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-02-22 22:06:04</td></tr>\n",
       "<tr><td>Running for: </td><td>00:05:46.84        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.5/8.0 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  learning_rate</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_a904e_00000</td><td>TERMINATED</td><td>127.0.0.1:77688</td><td style=\"text-align: right;\">         0.01  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         330.493</td><td style=\"text-align: right;\">    0.8796</td><td style=\"text-align: right;\">0.340252</td><td style=\"text-align: right;\">         0.01  </td></tr>\n",
       "<tr><td>train_model_a904e_00001</td><td>TERMINATED</td><td>127.0.0.1:77689</td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         337.099</td><td style=\"text-align: right;\">    0.8387</td><td style=\"text-align: right;\">0.462487</td><td style=\"text-align: right;\">         0.001 </td></tr>\n",
       "<tr><td>train_model_a904e_00002</td><td>TERMINATED</td><td>127.0.0.1:77690</td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         333.425</td><td style=\"text-align: right;\">    0.7353</td><td style=\"text-align: right;\">0.81565 </td><td style=\"text-align: right;\">         0.0001</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:00:26,457 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 8930394112; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:00:36,500 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 8929583104; capacity: 245107195904. Object creation will fail if spilling is required.\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adagrad` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adagrad`.\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adagrad`.\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m 2024-02-22 22:00:43.451119: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 1/30\n",
      "  5/750 [..............................] - ETA: 9s - loss: 2.1579 - accuracy: 0.2313   \n",
      " 10/750 [..............................] - ETA: 13s - loss: 2.0294 - accuracy: 0.3141\n",
      " 20/750 [..............................] - ETA: 10s - loss: 1.8361 - accuracy: 0.4156\n",
      " 29/750 [>.............................] - ETA: 10s - loss: 1.7152 - accuracy: 0.4650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:00:46,518 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 8928317440; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30/750 [>.............................] - ETA: 12s - loss: 1.7002 - accuracy: 0.4724\n",
      " 42/750 [>.............................] - ETA: 10s - loss: 1.5604 - accuracy: 0.5264\n",
      " 55/750 [=>............................] - ETA: 9s - loss: 1.4509 - accuracy: 0.5611\n",
      " 63/750 [=>............................] - ETA: 9s - loss: 1.3917 - accuracy: 0.5799\n",
      " 70/750 [=>............................] - ETA: 9s - loss: 1.3531 - accuracy: 0.5915\n",
      " 86/750 [==>...........................] - ETA: 8s - loss: 1.2758 - accuracy: 0.6086\n",
      " 91/750 [==>...........................] - ETA: 8s - loss: 1.2558 - accuracy: 0.6123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=77689)\u001b[0m WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adagrad` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adagrad`.\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adagrad`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95/750 [==>...........................] - ETA: 8s - loss: 1.2404 - accuracy: 0.6155\n",
      "109/750 [===>..........................] - ETA: 11s - loss: 1.1870 - accuracy: 0.6293\n",
      "133/750 [====>.........................] - ETA: 9s - loss: 1.1150 - accuracy: 0.6492 \n",
      "144/750 [====>.........................] - ETA: 9s - loss: 1.0879 - accuracy: 0.6574\n",
      "162/750 [=====>........................] - ETA: 8s - loss: 1.0589 - accuracy: 0.6641\n",
      "180/750 [======>.......................] - ETA: 7s - loss: 1.0327 - accuracy: 0.6691\n",
      "194/750 [======>.......................] - ETA: 7s - loss: 1.0119 - accuracy: 0.6721\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 1/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "199/750 [======>.......................] - ETA: 6s - loss: 1.0033 - accuracy: 0.6749\n",
      "211/750 [=======>......................] - ETA: 6s - loss: 0.9835 - accuracy: 0.6816\n",
      "227/750 [========>.....................] - ETA: 6s - loss: 0.9609 - accuracy: 0.6878\n",
      "239/750 [========>.....................] - ETA: 5s - loss: 0.9484 - accuracy: 0.6915\n",
      "  1/750 [..............................] - ETA: 25:51 - loss: 2.6301 - accuracy: 0.0938\n",
      "255/750 [=========>....................] - ETA: 5s - loss: 0.9310 - accuracy: 0.6963\n",
      "  9/750 [..............................] - ETA: 11s - loss: 2.5135 - accuracy: 0.1076\n",
      "273/750 [=========>....................] - ETA: 5s - loss: 0.9129 - accuracy: 0.7018\n",
      " 12/750 [..............................] - ETA: 12s - loss: 2.4910 - accuracy: 0.1146\n",
      "286/750 [==========>...................] - ETA: 5s - loss: 0.9008 - accuracy: 0.7057\n",
      "295/750 [==========>...................] - ETA: 4s - loss: 0.8927 - accuracy: 0.7076\n",
      " 45/750 [>.............................] - ETA: 6s - loss: 2.4733 - accuracy: 0.1031\n",
      "304/750 [===========>..................] - ETA: 4s - loss: 0.8839 - accuracy: 0.7109\n",
      "312/750 [===========>..................] - ETA: 4s - loss: 0.8759 - accuracy: 0.7133\n",
      "328/750 [============>.................] - ETA: 4s - loss: 0.8643 - accuracy: 0.7172\n",
      "336/750 [============>.................] - ETA: 4s - loss: 0.8582 - accuracy: 0.7191\n",
      " 84/750 [==>...........................] - ETA: 5s - loss: 2.4460 - accuracy: 0.1012\n",
      "348/750 [============>.................] - ETA: 4s - loss: 0.8481 - accuracy: 0.7219\n",
      "363/750 [=============>................] - ETA: 3s - loss: 0.8377 - accuracy: 0.7251\n",
      "116/750 [===>..........................] - ETA: 5s - loss: 2.4307 - accuracy: 0.1001\n",
      "380/750 [==============>...............] - ETA: 3s - loss: 0.8269 - accuracy: 0.7280\n",
      "  3/750 [..............................] - ETA: 24s - loss: 2.3283 - accuracy: 0.1094  \n",
      "136/750 [====>.........................] - ETA: 4s - loss: 2.4148 - accuracy: 0.1002\n",
      "391/750 [==============>...............] - ETA: 3s - loss: 0.8193 - accuracy: 0.7303\n",
      "403/750 [===============>..............] - ETA: 3s - loss: 0.8129 - accuracy: 0.7320\n",
      " 25/750 [>.............................] - ETA: 9s - loss: 2.2560 - accuracy: 0.1338\n",
      "419/750 [===============>..............] - ETA: 3s - loss: 0.8040 - accuracy: 0.7346\n",
      "427/750 [================>.............] - ETA: 3s - loss: 0.8007 - accuracy: 0.7356\n",
      " 39/750 [>.............................] - ETA: 7s - loss: 2.2029 - accuracy: 0.1747\n",
      "436/750 [================>.............] - ETA: 3s - loss: 0.7970 - accuracy: 0.7371\n",
      " 47/750 [>.............................] - ETA: 7s - loss: 2.1778 - accuracy: 0.1938\n",
      "450/750 [=================>............] - ETA: 2s - loss: 0.7896 - accuracy: 0.7393\n",
      "458/750 [=================>............] - ETA: 2s - loss: 0.7860 - accuracy: 0.7404\n",
      "203/750 [=======>......................] - ETA: 4s - loss: 2.3785 - accuracy: 0.1028\n",
      "466/750 [=================>............] - ETA: 2s - loss: 0.7815 - accuracy: 0.7420\n",
      "220/750 [=======>......................] - ETA: 4s - loss: 2.3692 - accuracy: 0.1051\n",
      "482/750 [==================>...........] - ETA: 2s - loss: 0.7739 - accuracy: 0.7442\n",
      "497/750 [==================>...........] - ETA: 2s - loss: 0.7680 - accuracy: 0.7462\n",
      "511/750 [===================>..........] - ETA: 2s - loss: 0.7617 - accuracy: 0.7480\n",
      "518/750 [===================>..........] - ETA: 2s - loss: 0.7590 - accuracy: 0.7488\n",
      "528/750 [====================>.........] - ETA: 2s - loss: 0.7548 - accuracy: 0.7497\n",
      "155/750 [=====>........................] - ETA: 5s - loss: 1.9254 - accuracy: 0.3839\n",
      "277/750 [==========>...................] - ETA: 3s - loss: 2.3424 - accuracy: 0.1101\n",
      "540/750 [====================>.........] - ETA: 2s - loss: 0.7509 - accuracy: 0.7507\n",
      "550/750 [=====================>........] - ETA: 1s - loss: 0.7464 - accuracy: 0.7523\n",
      "172/750 [=====>........................] - ETA: 5s - loss: 1.8962 - accuracy: 0.4020\n",
      " 13/750 [..............................] - ETA: 11s - loss: 2.3050 - accuracy: 0.1214\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "565/750 [=====================>........] - ETA: 1s - loss: 0.7401 - accuracy: 0.7544\n",
      "578/750 [======================>.......] - ETA: 1s - loss: 0.7347 - accuracy: 0.7561\n",
      "590/750 [======================>.......] - ETA: 1s - loss: 0.7296 - accuracy: 0.7578\n",
      "609/750 [=======================>......] - ETA: 1s - loss: 0.7233 - accuracy: 0.7598\n",
      "358/750 [=============>................] - ETA: 3s - loss: 2.3098 - accuracy: 0.1203\n",
      "616/750 [=======================>......] - ETA: 1s - loss: 0.7210 - accuracy: 0.7605\n",
      " 63/750 [=>............................] - ETA: 7s - loss: 2.1375 - accuracy: 0.2207\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "642/750 [========================>.....] - ETA: 0s - loss: 0.7131 - accuracy: 0.7629\n",
      " 54/750 [=>............................] - ETA: 7s - loss: 2.1586 - accuracy: 0.2069\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "651/750 [=========================>....] - ETA: 0s - loss: 0.7100 - accuracy: 0.7641\n",
      "266/750 [=========>....................] - ETA: 4s - loss: 1.7499 - accuracy: 0.4764\n",
      "274/750 [=========>....................] - ETA: 4s - loss: 1.7393 - accuracy: 0.4807\n",
      " 98/750 [==>...........................] - ETA: 5s - loss: 2.0469 - accuracy: 0.2938\n",
      "669/750 [=========================>....] - ETA: 0s - loss: 0.7046 - accuracy: 0.7659\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.6997 - accuracy: 0.7674\n",
      "306/750 [===========>..................] - ETA: 3s - loss: 1.6959 - accuracy: 0.4999\n",
      "692/750 [==========================>...] - ETA: 0s - loss: 0.6981 - accuracy: 0.7678\n",
      "314/750 [===========>..................] - ETA: 3s - loss: 1.6852 - accuracy: 0.5037\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.6949 - accuracy: 0.7688\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.6912 - accuracy: 0.7698\n",
      "479/750 [==================>...........] - ETA: 2s - loss: 2.2678 - accuracy: 0.1374\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.6882 - accuracy: 0.7703\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.6854 - accuracy: 0.7710\n",
      "103/750 [===>..........................] - ETA: 5s - loss: 2.4388 - accuracy: 0.0991\n",
      "410/750 [===============>..............] - ETA: 2s - loss: 1.5755 - accuracy: 0.5404\n",
      "415/750 [===============>..............] - ETA: 2s - loss: 1.5705 - accuracy: 0.5420\n",
      "138/750 [====>.........................] - ETA: 5s - loss: 1.9575 - accuracy: 0.3639\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "168/750 [=====>........................] - ETA: 5s - loss: 1.9030 - accuracy: 0.3969\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "562/750 [=====================>........] - ETA: 1s - loss: 2.2419 - accuracy: 0.1545\n",
      "193/750 [======>.......................] - ETA: 4s - loss: 1.8607 - accuracy: 0.4225\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "178/750 [======>.......................] - ETA: 5s - loss: 1.8852 - accuracy: 0.4089\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 2.2298 - accuracy: 0.1638\n",
      "613/750 [=======================>......] - ETA: 1s - loss: 2.2270 - accuracy: 0.1658\n",
      "500/750 [===================>..........] - ETA: 1s - loss: 1.4925 - accuracy: 0.5634\n",
      "213/750 [=======>......................] - ETA: 4s - loss: 1.8286 - accuracy: 0.4391\n",
      "633/750 [========================>.....] - ETA: 0s - loss: 2.2212 - accuracy: 0.1700\n",
      "639/750 [========================>.....] - ETA: 0s - loss: 2.2196 - accuracy: 0.1716\n",
      "238/750 [========>.....................] - ETA: 4s - loss: 1.7870 - accuracy: 0.4600\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 24:08 - loss: 2.3231 - accuracy: 0.1250\n",
      "257/750 [=========>....................] - ETA: 4s - loss: 1.7627 - accuracy: 0.4705\n",
      "264/750 [=========>....................] - ETA: 3s - loss: 2.3479 - accuracy: 0.1094\n",
      "677/750 [==========================>...] - ETA: 0s - loss: 2.2088 - accuracy: 0.1813\n",
      "554/750 [=====================>........] - ETA: 1s - loss: 1.4496 - accuracy: 0.5751\n",
      "292/750 [==========>...................] - ETA: 3s - loss: 1.7147 - accuracy: 0.4918\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "313/750 [===========>..................] - ETA: 3s - loss: 2.3269 - accuracy: 0.1150\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "331/750 [============>.................] - ETA: 3s - loss: 1.6649 - accuracy: 0.5109\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "343/750 [============>.................] - ETA: 3s - loss: 2.3154 - accuracy: 0.1180\n",
      " 80/750 [==>...........................] - ETA: 6s - loss: 2.0920 - accuracy: 0.2559\n",
      "346/750 [============>.................] - ETA: 3s - loss: 1.6460 - accuracy: 0.5177\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "370/750 [=============>................] - ETA: 3s - loss: 1.6187 - accuracy: 0.5274\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "124/750 [===>..........................] - ETA: 5s - loss: 1.9883 - accuracy: 0.3416\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "376/750 [==============>...............] - ETA: 3s - loss: 2.3035 - accuracy: 0.1223\n",
      "388/750 [==============>...............] - ETA: 2s - loss: 1.5992 - accuracy: 0.5330\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "407/750 [===============>..............] - ETA: 2s - loss: 1.5786 - accuracy: 0.5395\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "425/750 [================>.............] - ETA: 2s - loss: 1.5604 - accuracy: 0.5450\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "445/750 [================>.............] - ETA: 2s - loss: 1.5408 - accuracy: 0.5504\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "451/750 [=================>............] - ETA: 2s - loss: 2.2770 - accuracy: 0.1326\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 1.3398 - accuracy: 0.6046\n",
      "466/750 [=================>............] - ETA: 2s - loss: 1.5229 - accuracy: 0.5550\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "742/750 [============================>.] - ETA: 0s - loss: 1.3289 - accuracy: 0.6076\n",
      "222/750 [=======>......................] - ETA: 4s - loss: 1.8145 - accuracy: 0.4456\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "485/750 [==================>...........] - ETA: 2s - loss: 1.5062 - accuracy: 0.5599\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "749/750 [============================>.] - ETA: 0s - loss: 1.3250 - accuracy: 0.6085\n",
      "750/750 [==============================] - 13s 13ms/step - loss: 0.6852 - accuracy: 0.7711 - val_loss: 0.5219 - val_accuracy: 0.8186\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 2/30\n",
      "  1/750 [..............................] - ETA: 9s - loss: 0.5548 - accuracy: 0.8594\n",
      "517/750 [===================>..........] - ETA: 1s - loss: 1.4789 - accuracy: 0.5669\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "501/750 [===================>..........] - ETA: 1s - loss: 2.2607 - accuracy: 0.1420\n",
      "527/750 [====================>.........] - ETA: 1s - loss: 1.4706 - accuracy: 0.5691\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  8/750 [..............................] - ETA: 5s - loss: 0.5104 - accuracy: 0.8359\n",
      "546/750 [====================>.........] - ETA: 1s - loss: 1.4557 - accuracy: 0.5736\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 24/750 [..............................] - ETA: 5s - loss: 0.5036 - accuracy: 0.8275\n",
      " 43/750 [>.............................] - ETA: 4s - loss: 0.4874 - accuracy: 0.8336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=77689)\u001b[0m 2024-02-22 22:00:47.484176: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:00:56,520 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 7853334528; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60/750 [=>............................] - ETA: 4s - loss: 0.4944 - accuracy: 0.8359\n",
      "582/750 [======================>.......] - ETA: 1s - loss: 1.4285 - accuracy: 0.5812\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "624/750 [=======================>......] - ETA: 1s - loss: 1.3985 - accuracy: 0.5892\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 85/750 [==>...........................] - ETA: 5s - loss: 0.5005 - accuracy: 0.8340\n",
      "106/750 [===>..........................] - ETA: 5s - loss: 0.5054 - accuracy: 0.8311\n",
      " 68/750 [=>............................] - ETA: 5s - loss: 0.4943 - accuracy: 0.8355\n",
      "636/750 [========================>.....] - ETA: 0s - loss: 1.3908 - accuracy: 0.5914\n",
      " 69/750 [=>............................] - ETA: 6s - loss: 0.4918 - accuracy: 0.8370\n",
      "652/750 [=========================>....] - ETA: 0s - loss: 1.3805 - accuracy: 0.5944\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "661/750 [=========================>....] - ETA: 0s - loss: 1.3752 - accuracy: 0.5957\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "156/750 [=====>........................] - ETA: 4s - loss: 0.4999 - accuracy: 0.8325\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 1.3583 - accuracy: 0.6002\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "176/750 [======>.......................] - ETA: 4s - loss: 0.4995 - accuracy: 0.8306\n",
      "206/750 [=======>......................] - ETA: 3s - loss: 0.4973 - accuracy: 0.8298\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 2.2024 - accuracy: 0.1871\n",
      "227/750 [========>.....................] - ETA: 3s - loss: 0.4959 - accuracy: 0.8302\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 1.3456 - accuracy: 0.6031\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "748/750 [============================>.] - ETA: 0s - loss: 2.1907 - accuracy: 0.1975\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  9/750 [..............................] - ETA: 5s - loss: 2.0019 - accuracy: 0.3646\n",
      "258/750 [=========>....................] - ETA: 3s - loss: 0.4915 - accuracy: 0.8315\n",
      "273/750 [=========>....................] - ETA: 3s - loss: 0.4943 - accuracy: 0.8301\n",
      " 33/750 [>.............................] - ETA: 5s - loss: 2.0002 - accuracy: 0.3679\n",
      "297/750 [==========>...................] - ETA: 3s - loss: 0.4918 - accuracy: 0.8312\n",
      " 59/750 [=>............................] - ETA: 5s - loss: 1.9931 - accuracy: 0.3779\n",
      "136/750 [====>.........................] - ETA: 4s - loss: 0.4991 - accuracy: 0.8333\n",
      "313/750 [===========>..................] - ETA: 3s - loss: 0.4899 - accuracy: 0.8314\n",
      " 71/750 [=>............................] - ETA: 5s - loss: 1.9926 - accuracy: 0.3765\n",
      "567/750 [=====================>........] - ETA: 1s - loss: 1.4399 - accuracy: 0.5778\n",
      " 92/750 [==>...........................] - ETA: 5s - loss: 1.9892 - accuracy: 0.3787\n",
      "100/750 [===>..........................] - ETA: 5s - loss: 1.9855 - accuracy: 0.3850\n",
      "185/750 [======>.......................] - ETA: 4s - loss: 0.4976 - accuracy: 0.8304\n",
      "600/750 [=======================>......] - ETA: 1s - loss: 1.4151 - accuracy: 0.5850\n",
      "355/750 [=============>................] - ETA: 2s - loss: 0.4877 - accuracy: 0.8323\n",
      "127/750 [====>.........................] - ETA: 5s - loss: 1.9815 - accuracy: 0.3866\n",
      "378/750 [==============>...............] - ETA: 2s - loss: 0.4869 - accuracy: 0.8321\n",
      "245/750 [========>.....................] - ETA: 3s - loss: 0.4929 - accuracy: 0.8309\n",
      "136/750 [====>.........................] - ETA: 5s - loss: 1.9804 - accuracy: 0.3881\n",
      "405/750 [===============>..............] - ETA: 2s - loss: 0.4870 - accuracy: 0.8320\n",
      " 46/750 [>.............................] - ETA: 5s - loss: 0.9217 - accuracy: 0.7058\n",
      "677/750 [==========================>...] - ETA: 0s - loss: 1.3651 - accuracy: 0.5984\n",
      "169/750 [=====>........................] - ETA: 4s - loss: 1.9742 - accuracy: 0.3964\n",
      "293/750 [==========>...................] - ETA: 3s - loss: 0.4928 - accuracy: 0.8306\n",
      "188/750 [======>.......................] - ETA: 4s - loss: 1.9714 - accuracy: 0.3971\n",
      "435/750 [================>.............] - ETA: 2s - loss: 0.4882 - accuracy: 0.8316\n",
      "199/750 [======>.......................] - ETA: 4s - loss: 1.9696 - accuracy: 0.3996\n",
      "450/750 [=================>............] - ETA: 2s - loss: 0.4879 - accuracy: 0.8312\n",
      "325/750 [============>.................] - ETA: 3s - loss: 0.4910 - accuracy: 0.8312\n",
      "475/750 [==================>...........] - ETA: 2s - loss: 0.4847 - accuracy: 0.8324\n",
      "339/750 [============>.................] - ETA: 2s - loss: 0.4899 - accuracy: 0.8317\n",
      "242/750 [========>.....................] - ETA: 4s - loss: 1.9622 - accuracy: 0.4069\n",
      "125/750 [====>.........................] - ETA: 4s - loss: 0.8952 - accuracy: 0.7172\n",
      "370/750 [=============>................] - ETA: 2s - loss: 0.4869 - accuracy: 0.8323\n",
      "247/750 [========>.....................] - ETA: 4s - loss: 1.9614 - accuracy: 0.4080\n",
      "500/750 [===================>..........] - ETA: 1s - loss: 0.4841 - accuracy: 0.8326\n",
      "119/750 [===>..........................] - ETA: 4s - loss: 0.8964 - accuracy: 0.7178\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "392/750 [==============>...............] - ETA: 2s - loss: 0.4870 - accuracy: 0.8319\n",
      "273/750 [=========>....................] - ETA: 4s - loss: 1.9572 - accuracy: 0.4119\n",
      "521/750 [===================>..........] - ETA: 1s - loss: 0.4822 - accuracy: 0.8330\n",
      "420/750 [===============>..............] - ETA: 2s - loss: 0.4856 - accuracy: 0.8322\n",
      "285/750 [==========>...................] - ETA: 3s - loss: 1.9556 - accuracy: 0.4132\n",
      "543/750 [====================>.........] - ETA: 1s - loss: 0.4815 - accuracy: 0.8330\n",
      "304/750 [===========>..................] - ETA: 3s - loss: 1.9533 - accuracy: 0.4159\n",
      "553/750 [=====================>........] - ETA: 1s - loss: 0.4817 - accuracy: 0.8331\n",
      "562/750 [=====================>........] - ETA: 1s - loss: 0.4801 - accuracy: 0.8337\n",
      "574/750 [=====================>........] - ETA: 1s - loss: 0.4798 - accuracy: 0.8339\n",
      "462/750 [=================>............] - ETA: 2s - loss: 0.4863 - accuracy: 0.8318\n",
      "328/750 [============>.................] - ETA: 3s - loss: 1.9496 - accuracy: 0.4188\n",
      "581/750 [======================>.......] - ETA: 1s - loss: 0.4790 - accuracy: 0.8343\n",
      "217/750 [=======>......................] - ETA: 4s - loss: 0.8841 - accuracy: 0.7221\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "492/750 [==================>...........] - ETA: 1s - loss: 0.4845 - accuracy: 0.8328\n",
      "338/750 [============>.................] - ETA: 3s - loss: 1.9485 - accuracy: 0.4194\n",
      "590/750 [======================>.......] - ETA: 1s - loss: 0.4787 - accuracy: 0.8343\n",
      "343/750 [============>.................] - ETA: 3s - loss: 1.9476 - accuracy: 0.4205\n",
      "351/750 [=============>................] - ETA: 3s - loss: 1.9462 - accuracy: 0.4213\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.4792 - accuracy: 0.8344\n",
      "360/750 [=============>................] - ETA: 3s - loss: 1.9450 - accuracy: 0.4223\n",
      "250/750 [=========>....................] - ETA: 4s - loss: 0.8763 - accuracy: 0.7253\n",
      "750/750 [==============================] - 11s 12ms/step - loss: 1.3243 - accuracy: 0.6087 - val_loss: 0.9095 - val_accuracy: 0.7158\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 2/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 4s - loss: 1.0339 - accuracy: 0.5781\n",
      "517/750 [===================>..........] - ETA: 1s - loss: 0.4825 - accuracy: 0.8330\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "379/750 [==============>...............] - ETA: 3s - loss: 1.9419 - accuracy: 0.4249\n",
      "629/750 [========================>.....] - ETA: 0s - loss: 0.4770 - accuracy: 0.8353\n",
      " 14/750 [..............................] - ETA: 7s - loss: 2.0016 - accuracy: 0.3627\n",
      "535/750 [====================>.........] - ETA: 1s - loss: 0.4822 - accuracy: 0.8328\n",
      "380/750 [==============>...............] - ETA: 3s - loss: 1.9417 - accuracy: 0.4247\n",
      "632/750 [========================>.....] - ETA: 0s - loss: 0.4768 - accuracy: 0.8355\n",
      " 18/750 [..............................] - ETA: 4s - loss: 0.9425 - accuracy: 0.7031\n",
      "387/750 [==============>...............] - ETA: 3s - loss: 1.9408 - accuracy: 0.4260\n",
      "638/750 [========================>.....] - ETA: 0s - loss: 0.4771 - accuracy: 0.8355\n",
      " 41/750 [>.............................] - ETA: 3s - loss: 0.9278 - accuracy: 0.7050\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "397/750 [==============>...............] - ETA: 3s - loss: 1.9392 - accuracy: 0.4270\n",
      "643/750 [========================>.....] - ETA: 0s - loss: 0.4775 - accuracy: 0.8354\n",
      "399/750 [==============>...............] - ETA: 3s - loss: 1.9388 - accuracy: 0.4272\n",
      "407/750 [===============>..............] - ETA: 3s - loss: 1.9374 - accuracy: 0.4277\n",
      "411/750 [===============>..............] - ETA: 3s - loss: 1.9367 - accuracy: 0.4281\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.4787 - accuracy: 0.8345\n",
      "670/750 [=========================>....] - ETA: 0s - loss: 0.4759 - accuracy: 0.8359\n",
      " 85/750 [==>...........................] - ETA: 5s - loss: 0.9087 - accuracy: 0.7153\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "423/750 [===============>..............] - ETA: 3s - loss: 1.9344 - accuracy: 0.4307\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.4761 - accuracy: 0.8358\n",
      "300/750 [===========>..................] - ETA: 4s - loss: 0.8696 - accuracy: 0.7271\n",
      "100/750 [===>..........................] - ETA: 4s - loss: 0.9032 - accuracy: 0.7173\n",
      "428/750 [================>.............] - ETA: 3s - loss: 1.9335 - accuracy: 0.4317\n",
      "657/750 [=========================>....] - ETA: 0s - loss: 0.4768 - accuracy: 0.8356\n",
      "437/750 [================>.............] - ETA: 3s - loss: 1.9321 - accuracy: 0.4325\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.4743 - accuracy: 0.8362\n",
      "326/750 [============>.................] - ETA: 4s - loss: 0.8646 - accuracy: 0.7283\n",
      "448/750 [================>.............] - ETA: 2s - loss: 1.9306 - accuracy: 0.4342\n",
      "153/750 [=====>........................] - ETA: 5s - loss: 0.8910 - accuracy: 0.7200\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.4755 - accuracy: 0.8361\n",
      "460/750 [=================>............] - ETA: 2s - loss: 1.9283 - accuracy: 0.4358\n",
      "183/750 [======>.......................] - ETA: 4s - loss: 0.8899 - accuracy: 0.7197\n",
      "203/750 [=======>......................] - ETA: 4s - loss: 0.8861 - accuracy: 0.7219\n",
      "485/750 [==================>...........] - ETA: 2s - loss: 1.9239 - accuracy: 0.4391\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.4739 - accuracy: 0.8357\n",
      "231/750 [========>.....................] - ETA: 4s - loss: 0.8827 - accuracy: 0.7225\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.4736 - accuracy: 0.8361\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "494/750 [==================>...........] - ETA: 2s - loss: 1.9224 - accuracy: 0.4406\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.4742 - accuracy: 0.8356\n",
      "271/750 [=========>....................] - ETA: 4s - loss: 0.8740 - accuracy: 0.7255\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "535/750 [====================>.........] - ETA: 2s - loss: 1.9168 - accuracy: 0.4450\n",
      "286/750 [==========>...................] - ETA: 4s - loss: 0.8719 - accuracy: 0.7255\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "549/750 [====================>.........] - ETA: 1s - loss: 1.9149 - accuracy: 0.4456\n",
      " 72/750 [=>............................] - ETA: 5s - loss: 0.9142 - accuracy: 0.7122\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "314/750 [===========>..................] - ETA: 4s - loss: 0.8675 - accuracy: 0.7271\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "578/750 [======================>.......] - ETA: 1s - loss: 1.9111 - accuracy: 0.4482\n",
      "612/750 [=======================>......] - ETA: 1s - loss: 1.9058 - accuracy: 0.4511\n",
      "525/750 [====================>.........] - ETA: 2s - loss: 0.8409 - accuracy: 0.7345\n",
      "144/750 [====>.........................] - ETA: 4s - loss: 0.8922 - accuracy: 0.7183\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "652/750 [=========================>....] - ETA: 0s - loss: 1.9001 - accuracy: 0.4537\n",
      "  9/750 [..............................] - ETA: 4s - loss: 0.4388 - accuracy: 0.8455\n",
      "671/750 [=========================>....] - ETA: 0s - loss: 1.8973 - accuracy: 0.4553\n",
      " 25/750 [>.............................] - ETA: 4s - loss: 0.4353 - accuracy: 0.8500\n",
      "166/750 [=====>........................] - ETA: 4s - loss: 0.8882 - accuracy: 0.7217\n",
      "688/750 [==========================>...] - ETA: 0s - loss: 1.8949 - accuracy: 0.4563\n",
      "196/750 [======>.......................] - ETA: 4s - loss: 0.8888 - accuracy: 0.7209\n",
      "460/750 [=================>............] - ETA: 2s - loss: 0.8477 - accuracy: 0.7330\n",
      "477/750 [==================>...........] - ETA: 2s - loss: 1.9253 - accuracy: 0.4382\n",
      "741/750 [============================>.] - ETA: 0s - loss: 1.8868 - accuracy: 0.4613\n",
      "236/750 [========>.....................] - ETA: 4s - loss: 0.8804 - accuracy: 0.7234\n",
      "503/750 [===================>..........] - ETA: 2s - loss: 1.9210 - accuracy: 0.4417\n",
      "126/750 [====>.........................] - ETA: 4s - loss: 0.4357 - accuracy: 0.8483\n",
      "112/750 [===>..........................] - ETA: 4s - loss: 0.4358 - accuracy: 0.8481\n",
      "155/750 [=====>........................] - ETA: 4s - loss: 0.4382 - accuracy: 0.8480\n",
      "685/750 [==========================>...] - ETA: 0s - loss: 0.8227 - accuracy: 0.7394\n",
      "257/750 [=========>....................] - ETA: 4s - loss: 0.8752 - accuracy: 0.7254\n",
      "175/750 [======>.......................] - ETA: 4s - loss: 0.4418 - accuracy: 0.8462\n",
      "294/750 [==========>...................] - ETA: 4s - loss: 0.8706 - accuracy: 0.7264\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "182/750 [======>.......................] - ETA: 4s - loss: 0.4405 - accuracy: 0.8472\n",
      "196/750 [======>.......................] - ETA: 4s - loss: 0.4379 - accuracy: 0.8476\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.8178 - accuracy: 0.7410\n",
      "560/750 [=====================>........] - ETA: 1s - loss: 0.8374 - accuracy: 0.7352\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "222/750 [=======>......................] - ETA: 3s - loss: 0.4434 - accuracy: 0.8457\n",
      "233/750 [========>.....................] - ETA: 3s - loss: 0.4441 - accuracy: 0.8453\n",
      "242/750 [========>.....................] - ETA: 3s - loss: 0.4450 - accuracy: 0.8443\n",
      "343/750 [============>.................] - ETA: 4s - loss: 0.8651 - accuracy: 0.7272\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "214/750 [=======>......................] - ETA: 4s - loss: 0.4429 - accuracy: 0.8451\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.8338 - accuracy: 0.7362\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "367/750 [=============>................] - ETA: 3s - loss: 0.8615 - accuracy: 0.7289\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "361/750 [=============>................] - ETA: 4s - loss: 0.8622 - accuracy: 0.7285\n",
      "282/750 [==========>...................] - ETA: 3s - loss: 0.4409 - accuracy: 0.8458\n",
      " 18/750 [..............................] - ETA: 5s - loss: 1.7802 - accuracy: 0.5061\n",
      "253/750 [=========>....................] - ETA: 3s - loss: 0.4442 - accuracy: 0.8446\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 1.8854 - accuracy: 0.4622 - val_loss: 1.7715 - val_accuracy: 0.5211\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 3/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "505/750 [===================>..........] - ETA: 2s - loss: 0.8416 - accuracy: 0.7349\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.8301 - accuracy: 0.7375\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 51/750 [=>............................] - ETA: 4s - loss: 1.7729 - accuracy: 0.5196\n",
      "332/750 [============>.................] - ETA: 3s - loss: 0.4433 - accuracy: 0.8454\n",
      "396/750 [==============>...............] - ETA: 3s - loss: 0.8577 - accuracy: 0.7301\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "641/750 [========================>.....] - ETA: 1s - loss: 0.8278 - accuracy: 0.7382\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 35/750 [>.............................] - ETA: 4s - loss: 1.7772 - accuracy: 0.5121\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "350/750 [=============>................] - ETA: 2s - loss: 0.4432 - accuracy: 0.8454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:01:06,520 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 7852171264; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/750 [=============>................] - ETA: 2s - loss: 0.4423 - accuracy: 0.8458\n",
      "103/750 [===>..........................] - ETA: 4s - loss: 1.7637 - accuracy: 0.5246\n",
      "411/750 [===============>..............] - ETA: 3s - loss: 0.8543 - accuracy: 0.7316\n",
      "113/750 [===>..........................] - ETA: 4s - loss: 1.7623 - accuracy: 0.5259\n",
      "419/750 [===============>..............] - ETA: 3s - loss: 0.8535 - accuracy: 0.7321\n",
      "664/750 [=========================>....] - ETA: 0s - loss: 0.8252 - accuracy: 0.7391\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "402/750 [===============>..............] - ETA: 2s - loss: 0.4414 - accuracy: 0.8460\n",
      " 22/750 [..............................] - ETA: 5s - loss: 0.7361 - accuracy: 0.7777\n",
      " 87/750 [==>...........................] - ETA: 4s - loss: 1.7654 - accuracy: 0.5219\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.8232 - accuracy: 0.7395\n",
      "416/750 [===============>..............] - ETA: 2s - loss: 0.4400 - accuracy: 0.8465\n",
      "421/750 [===============>..............] - ETA: 2s - loss: 0.4396 - accuracy: 0.8465\n",
      "300/750 [===========>..................] - ETA: 3s - loss: 0.4429 - accuracy: 0.8454\n",
      "427/750 [================>.............] - ETA: 3s - loss: 0.8522 - accuracy: 0.7324\n",
      "432/750 [================>.............] - ETA: 2s - loss: 0.4399 - accuracy: 0.8464\n",
      "439/750 [================>.............] - ETA: 3s - loss: 0.8500 - accuracy: 0.7326\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.8205 - accuracy: 0.7404\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "446/750 [================>.............] - ETA: 2s - loss: 0.4384 - accuracy: 0.8470\n",
      "176/750 [======>.......................] - ETA: 3s - loss: 1.7563 - accuracy: 0.5293\n",
      "456/750 [=================>............] - ETA: 2s - loss: 0.4389 - accuracy: 0.8469\n",
      " 78/750 [==>...........................] - ETA: 5s - loss: 0.7330 - accuracy: 0.7694\n",
      "152/750 [=====>........................] - ETA: 4s - loss: 1.7587 - accuracy: 0.5288\n",
      "473/750 [=================>............] - ETA: 2s - loss: 0.8458 - accuracy: 0.7337\n",
      "470/750 [=================>............] - ETA: 2s - loss: 0.4377 - accuracy: 0.8470\n",
      "197/750 [======>.......................] - ETA: 3s - loss: 1.7553 - accuracy: 0.5288\n",
      "482/750 [==================>...........] - ETA: 1s - loss: 0.4369 - accuracy: 0.8473\n",
      "496/750 [==================>...........] - ETA: 2s - loss: 0.8434 - accuracy: 0.7343\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "748/750 [============================>.] - ETA: 0s - loss: 1.8858 - accuracy: 0.4619\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "224/750 [=======>......................] - ETA: 3s - loss: 1.7502 - accuracy: 0.5323\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.8194 - accuracy: 0.7407\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "121/750 [===>..........................] - ETA: 4s - loss: 0.7347 - accuracy: 0.7660\n",
      "241/750 [========>.....................] - ETA: 3s - loss: 1.7475 - accuracy: 0.5349\n",
      "250/750 [=========>....................] - ETA: 3s - loss: 1.7467 - accuracy: 0.5346\n",
      "154/750 [=====>........................] - ETA: 4s - loss: 0.7329 - accuracy: 0.7679\n",
      "268/750 [=========>....................] - ETA: 3s - loss: 0.4424 - accuracy: 0.8453\n",
      "266/750 [=========>....................] - ETA: 3s - loss: 1.7452 - accuracy: 0.5354\n",
      "543/750 [====================>.........] - ETA: 1s - loss: 0.4347 - accuracy: 0.8488\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "303/750 [===========>..................] - ETA: 3s - loss: 1.7405 - accuracy: 0.5371\n",
      "207/750 [=======>......................] - ETA: 3s - loss: 0.7305 - accuracy: 0.7675\n",
      "329/750 [============>.................] - ETA: 2s - loss: 1.7365 - accuracy: 0.5385\n",
      " 63/750 [=>............................] - ETA: 5s - loss: 0.7277 - accuracy: 0.7713\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "316/750 [===========>..................] - ETA: 3s - loss: 0.4434 - accuracy: 0.8455\n",
      "624/750 [=======================>......] - ETA: 0s - loss: 0.4345 - accuracy: 0.8483\n",
      "575/750 [======================>.......] - ETA: 1s - loss: 0.4346 - accuracy: 0.8483\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "252/750 [=========>....................] - ETA: 3s - loss: 0.7299 - accuracy: 0.7673\n",
      "616/750 [=======================>......] - ETA: 1s - loss: 0.8312 - accuracy: 0.7372\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "382/750 [==============>...............] - ETA: 2s - loss: 1.7281 - accuracy: 0.5414\n",
      "529/750 [====================>.........] - ETA: 1s - loss: 0.4355 - accuracy: 0.8486\n",
      "137/750 [====>.........................] - ETA: 4s - loss: 0.7327 - accuracy: 0.7684\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "651/750 [=========================>....] - ETA: 0s - loss: 0.4340 - accuracy: 0.8484\n",
      " 10/750 [..............................] - ETA: 4s - loss: 0.7460 - accuracy: 0.7812\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "321/750 [===========>..................] - ETA: 3s - loss: 0.7252 - accuracy: 0.7688\n",
      "671/750 [=========================>....] - ETA: 0s - loss: 0.4331 - accuracy: 0.8488\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 0.4326 - accuracy: 0.8490\n",
      "451/750 [=================>............] - ETA: 2s - loss: 1.7201 - accuracy: 0.5443\n",
      "500/750 [===================>..........] - ETA: 1s - loss: 1.7141 - accuracy: 0.5477\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.8500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "130/750 [====>.........................] - ETA: 3s - loss: 1.7610 - accuracy: 0.5280\n",
      "552/750 [=====================>........] - ETA: 1s - loss: 1.7066 - accuracy: 0.5508\n",
      "431/750 [================>.............] - ETA: 2s - loss: 0.7185 - accuracy: 0.7702\n",
      "173/750 [=====>........................] - ETA: 4s - loss: 0.7322 - accuracy: 0.7674\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "480/750 [==================>...........] - ETA: 2s - loss: 0.7148 - accuracy: 0.7715\n",
      "291/750 [==========>...................] - ETA: 3s - loss: 0.7256 - accuracy: 0.7690\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "189/750 [======>.......................] - ETA: 4s - loss: 0.7288 - accuracy: 0.7688\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "566/750 [=====================>........] - ETA: 1s - loss: 1.7047 - accuracy: 0.5519\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "512/750 [===================>..........] - ETA: 1s - loss: 0.7128 - accuracy: 0.7722\n",
      "212/750 [=======>......................] - ETA: 3s - loss: 1.7533 - accuracy: 0.5297\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "630/750 [========================>.....] - ETA: 0s - loss: 1.6976 - accuracy: 0.5549\n",
      "516/750 [===================>..........] - ETA: 1s - loss: 0.7123 - accuracy: 0.7725\n",
      "349/750 [============>.................] - ETA: 2s - loss: 1.7343 - accuracy: 0.5392\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "525/750 [====================>.........] - ETA: 1s - loss: 0.7115 - accuracy: 0.7729\n",
      "592/750 [======================>.......] - ETA: 1s - loss: 1.7024 - accuracy: 0.5524\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "649/750 [========================>.....] - ETA: 0s - loss: 1.6953 - accuracy: 0.5553\n",
      "365/750 [=============>................] - ETA: 2s - loss: 0.7215 - accuracy: 0.7698\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "539/750 [====================>.........] - ETA: 1s - loss: 0.7119 - accuracy: 0.7723\n",
      "276/750 [==========>...................] - ETA: 3s - loss: 0.7272 - accuracy: 0.7685\n",
      " 17/750 [..............................] - ETA: 12s - loss: 0.4212 - accuracy: 0.8575\n",
      " 12/750 [..............................] - ETA: 13s - loss: 0.4400 - accuracy: 0.8555\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.4308 - accuracy: 0.8497 - val_loss: 0.4248 - val_accuracy: 0.8522\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 4/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "508/750 [===================>..........] - ETA: 1s - loss: 0.7128 - accuracy: 0.7723\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 29/750 [>.............................] - ETA: 10s - loss: 0.4078 - accuracy: 0.8658\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 1.6919 - accuracy: 0.5560\n",
      " 45/750 [>.............................] - ETA: 8s - loss: 0.4095 - accuracy: 0.8618\n",
      "576/750 [======================>.......] - ETA: 1s - loss: 0.7104 - accuracy: 0.7726\n",
      " 52/750 [=>............................] - ETA: 5s - loss: 0.7318 - accuracy: 0.7734\n",
      "336/750 [============>.................] - ETA: 3s - loss: 0.7230 - accuracy: 0.7702\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 1.6911 - accuracy: 0.5565\n",
      "398/750 [==============>...............] - ETA: 2s - loss: 0.7211 - accuracy: 0.7692\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "642/750 [========================>.....] - ETA: 0s - loss: 1.6959 - accuracy: 0.5554\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 33/750 [>.............................] - ETA: 6s - loss: 0.7258 - accuracy: 0.7789\n",
      "354/750 [=============>................] - ETA: 2s - loss: 0.7215 - accuracy: 0.7702\n",
      "364/750 [=============>................] - ETA: 2s - loss: 1.7311 - accuracy: 0.5411\n",
      " 67/750 [=>............................] - ETA: 7s - loss: 0.4145 - accuracy: 0.8563\n",
      "601/750 [=======================>......] - ETA: 1s - loss: 0.7091 - accuracy: 0.7729\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 1.6888 - accuracy: 0.5566\n",
      "103/750 [===>..........................] - ETA: 5s - loss: 0.7368 - accuracy: 0.7658\n",
      "651/750 [=========================>....] - ETA: 0s - loss: 1.6951 - accuracy: 0.5554\n",
      " 96/750 [==>...........................] - ETA: 6s - loss: 0.4150 - accuracy: 0.8527\n",
      "632/750 [========================>.....] - ETA: 0s - loss: 0.7076 - accuracy: 0.7733\n",
      "405/750 [===============>..............] - ETA: 2s - loss: 1.7252 - accuracy: 0.5429\n",
      " 83/750 [==>...........................] - ETA: 7s - loss: 0.4163 - accuracy: 0.8552\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "414/750 [===============>..............] - ETA: 2s - loss: 0.7197 - accuracy: 0.7696\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "423/750 [===============>..............] - ETA: 2s - loss: 0.7191 - accuracy: 0.7699\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "125/750 [====>.........................] - ETA: 5s - loss: 0.4136 - accuracy: 0.8533\n",
      "676/750 [==========================>...] - ETA: 0s - loss: 0.7040 - accuracy: 0.7746\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.4320 - accuracy: 0.8492\n",
      "434/750 [================>.............] - ETA: 2s - loss: 1.7226 - accuracy: 0.5432\n",
      "455/750 [=================>............] - ETA: 2s - loss: 0.7156 - accuracy: 0.7713\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.7023 - accuracy: 0.7755\n",
      "468/750 [=================>............] - ETA: 2s - loss: 1.7177 - accuracy: 0.5463\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.7018 - accuracy: 0.7754\n",
      "494/750 [==================>...........] - ETA: 1s - loss: 0.7146 - accuracy: 0.7716\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "745/750 [============================>.] - ETA: 0s - loss: 1.6854 - accuracy: 0.5576\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "224/750 [=======>......................] - ETA: 3s - loss: 0.7311 - accuracy: 0.7686\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 1.6899 - accuracy: 0.5565\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "208/750 [=======>......................] - ETA: 4s - loss: 0.4048 - accuracy: 0.8567\n",
      "104/750 [===>..........................] - ETA: 6s - loss: 0.4156 - accuracy: 0.8522\n",
      "242/750 [========>.....................] - ETA: 3s - loss: 0.7305 - accuracy: 0.7683\n",
      "228/750 [========>.....................] - ETA: 4s - loss: 0.4038 - accuracy: 0.8574\n",
      "233/750 [========>.....................] - ETA: 4s - loss: 0.4033 - accuracy: 0.8576\n",
      "244/750 [========>.....................] - ETA: 4s - loss: 0.4052 - accuracy: 0.8575\n",
      "152/750 [=====>........................] - ETA: 5s - loss: 0.4071 - accuracy: 0.8551\n",
      "270/750 [=========>....................] - ETA: 3s - loss: 0.7289 - accuracy: 0.7677\n",
      "261/750 [=========>....................] - ETA: 4s - loss: 0.4068 - accuracy: 0.8576\n",
      "536/750 [====================>.........] - ETA: 1s - loss: 0.7118 - accuracy: 0.7723\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "304/750 [===========>..................] - ETA: 3s - loss: 0.7263 - accuracy: 0.7682\n",
      "284/750 [==========>...................] - ETA: 3s - loss: 0.4056 - accuracy: 0.8584\n",
      "288/750 [==========>...................] - ETA: 4s - loss: 0.4060 - accuracy: 0.8585\n",
      " 62/750 [=>............................] - ETA: 7s - loss: 0.4107 - accuracy: 0.8586\n",
      "  1/750 [..............................] - ETA: 3s - loss: 1.5748 - accuracy: 0.6250\n",
      "305/750 [===========>..................] - ETA: 3s - loss: 0.4043 - accuracy: 0.8594\n",
      " 17/750 [..............................] - ETA: 5s - loss: 1.5978 - accuracy: 0.5855\n",
      "312/750 [===========>..................] - ETA: 3s - loss: 0.4040 - accuracy: 0.8593\n",
      " 28/750 [>.............................] - ETA: 5s - loss: 1.5919 - accuracy: 0.5882\n",
      "616/750 [=======================>......] - ETA: 1s - loss: 0.7078 - accuracy: 0.7731\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "378/750 [==============>...............] - ETA: 2s - loss: 0.7200 - accuracy: 0.7707\n",
      "327/750 [============>.................] - ETA: 3s - loss: 0.4044 - accuracy: 0.8592\n",
      " 41/750 [>.............................] - ETA: 5s - loss: 1.5874 - accuracy: 0.5918\n",
      "340/750 [============>.................] - ETA: 3s - loss: 0.4060 - accuracy: 0.8588\n",
      " 48/750 [>.............................] - ETA: 6s - loss: 1.5880 - accuracy: 0.5898\n",
      "349/750 [============>.................] - ETA: 3s - loss: 0.4075 - accuracy: 0.8589\n",
      " 59/750 [=>............................] - ETA: 6s - loss: 1.5908 - accuracy: 0.5829\n",
      "139/750 [====>.........................] - ETA: 5s - loss: 0.4100 - accuracy: 0.8544\n",
      "  9/750 [..............................] - ETA: 5s - loss: 0.4086 - accuracy: 0.8733\n",
      "364/750 [=============>................] - ETA: 3s - loss: 0.4082 - accuracy: 0.8584\n",
      " 69/750 [=>............................] - ETA: 6s - loss: 1.5888 - accuracy: 0.5863\n",
      "666/750 [=========================>....] - ETA: 0s - loss: 0.7052 - accuracy: 0.7743\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "372/750 [=============>................] - ETA: 3s - loss: 0.4084 - accuracy: 0.8581\n",
      "450/750 [=================>............] - ETA: 2s - loss: 0.7158 - accuracy: 0.7712\n",
      "104/750 [===>..........................] - ETA: 6s - loss: 1.5862 - accuracy: 0.5897\n",
      " 10/750 [..............................] - ETA: 4s - loss: 0.6449 - accuracy: 0.7969\n",
      "114/750 [===>..........................] - ETA: 6s - loss: 1.5842 - accuracy: 0.5896\n",
      " 21/750 [..............................] - ETA: 5s - loss: 0.6427 - accuracy: 0.7954\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.7004 - accuracy: 0.7761\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 22/750 [..............................] - ETA: 7s - loss: 0.6394 - accuracy: 0.7962\n",
      " 25/750 [>.............................] - ETA: 9s - loss: 0.6301 - accuracy: 0.8037\n",
      "129/750 [====>.........................] - ETA: 6s - loss: 1.5865 - accuracy: 0.5893\n",
      "436/750 [================>.............] - ETA: 2s - loss: 0.4093 - accuracy: 0.8574\n",
      "135/750 [====>.........................] - ETA: 6s - loss: 1.5875 - accuracy: 0.5882\n",
      "139/750 [====>.........................] - ETA: 6s - loss: 1.5878 - accuracy: 0.5882\n",
      " 47/750 [>.............................] - ETA: 7s - loss: 0.6451 - accuracy: 0.7916\n",
      "556/750 [=====================>........] - ETA: 1s - loss: 0.7115 - accuracy: 0.7721\n",
      "449/750 [================>.............] - ETA: 2s - loss: 0.4095 - accuracy: 0.8573\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "151/750 [=====>........................] - ETA: 6s - loss: 1.5863 - accuracy: 0.5888\n",
      "457/750 [=================>............] - ETA: 2s - loss: 0.4096 - accuracy: 0.8572\n",
      "460/750 [=================>............] - ETA: 2s - loss: 0.4090 - accuracy: 0.8573\n",
      "167/750 [=====>........................] - ETA: 5s - loss: 0.4054 - accuracy: 0.8562\n",
      "165/750 [=====>........................] - ETA: 6s - loss: 1.5866 - accuracy: 0.5867\n",
      "472/750 [=================>............] - ETA: 2s - loss: 0.4089 - accuracy: 0.8569\n",
      "180/750 [======>.......................] - ETA: 5s - loss: 1.5857 - accuracy: 0.5878\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "503/750 [===================>..........] - ETA: 2s - loss: 0.4083 - accuracy: 0.8570\n",
      "203/750 [=======>......................] - ETA: 5s - loss: 1.5825 - accuracy: 0.5901\n",
      "569/750 [=====================>........] - ETA: 1s - loss: 0.7102 - accuracy: 0.7725\n",
      "534/750 [====================>.........] - ETA: 1s - loss: 0.4077 - accuracy: 0.8574\n",
      "133/750 [====>.........................] - ETA: 5s - loss: 0.6561 - accuracy: 0.7932\n",
      "645/750 [========================>.....] - ETA: 0s - loss: 0.7071 - accuracy: 0.7735\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "550/750 [=====================>........] - ETA: 1s - loss: 0.4071 - accuracy: 0.8578\n",
      "145/750 [====>.........................] - ETA: 5s - loss: 0.6557 - accuracy: 0.7928\n",
      "251/750 [=========>....................] - ETA: 4s - loss: 1.5763 - accuracy: 0.5947\n",
      "557/750 [=====================>........] - ETA: 1s - loss: 0.4069 - accuracy: 0.8580\n",
      "590/750 [======================>.......] - ETA: 1s - loss: 0.7096 - accuracy: 0.7729\n",
      "570/750 [=====================>........] - ETA: 1s - loss: 0.4070 - accuracy: 0.8579\n",
      "582/750 [======================>.......] - ETA: 1s - loss: 0.4069 - accuracy: 0.8578\n",
      "182/750 [======>.......................] - ETA: 5s - loss: 0.6548 - accuracy: 0.7935\n",
      "288/750 [==========>...................] - ETA: 4s - loss: 1.5711 - accuracy: 0.5967\n",
      "595/750 [======================>.......] - ETA: 1s - loss: 0.4084 - accuracy: 0.8572\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 0.7006 - accuracy: 0.7762 - val_loss: 0.6597 - val_accuracy: 0.7839\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 4/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "514/750 [===================>..........] - ETA: 2s - loss: 0.4079 - accuracy: 0.8571\n",
      "298/750 [==========>...................] - ETA: 4s - loss: 1.5702 - accuracy: 0.5976\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 0.4080 - accuracy: 0.8574\n",
      "314/750 [===========>..................] - ETA: 4s - loss: 1.5686 - accuracy: 0.5984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:01:16,528 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 7851450368; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/750 [==========================>...] - ETA: 0s - loss: 0.7037 - accuracy: 0.7747\n",
      "398/750 [==============>...............] - ETA: 3s - loss: 0.4084 - accuracy: 0.8576\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.4077 - accuracy: 0.8578\n",
      " 50/750 [=>............................] - ETA: 7s - loss: 0.6484 - accuracy: 0.7909\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.7026 - accuracy: 0.7752\n",
      "338/750 [============>.................] - ETA: 3s - loss: 1.5668 - accuracy: 0.5986\n",
      "644/750 [========================>.....] - ETA: 0s - loss: 0.4068 - accuracy: 0.8582\n",
      "350/750 [=============>................] - ETA: 3s - loss: 1.5662 - accuracy: 0.5986\n",
      "656/750 [=========================>....] - ETA: 0s - loss: 0.4057 - accuracy: 0.8587\n",
      "664/750 [=========================>....] - ETA: 0s - loss: 0.4053 - accuracy: 0.8589\n",
      " 88/750 [==>...........................] - ETA: 6s - loss: 0.6508 - accuracy: 0.7931\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "377/750 [==============>...............] - ETA: 3s - loss: 1.5627 - accuracy: 0.6013\n",
      "690/750 [==========================>...] - ETA: 0s - loss: 0.4057 - accuracy: 0.8584\n",
      " 99/750 [==>...........................] - ETA: 6s - loss: 0.6554 - accuracy: 0.7909\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "422/750 [===============>..............] - ETA: 2s - loss: 0.4090 - accuracy: 0.8574\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "125/750 [====>.........................] - ETA: 6s - loss: 1.5868 - accuracy: 0.5879\n",
      "386/750 [==============>...............] - ETA: 3s - loss: 1.5617 - accuracy: 0.6020\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.4053 - accuracy: 0.8585\n",
      "405/750 [===============>..............] - ETA: 3s - loss: 1.5594 - accuracy: 0.6030\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.4063 - accuracy: 0.8579\n",
      "676/750 [==========================>...] - ETA: 0s - loss: 0.4054 - accuracy: 0.8587\n",
      "410/750 [===============>..............] - ETA: 3s - loss: 1.5581 - accuracy: 0.6038\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.4065 - accuracy: 0.8577\n",
      "354/750 [=============>................] - ETA: 3s - loss: 0.6516 - accuracy: 0.7915\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.4062 - accuracy: 0.8580\n",
      "489/750 [==================>...........] - ETA: 2s - loss: 0.4083 - accuracy: 0.8571\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.4057 - accuracy: 0.8582\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "214/750 [=======>......................] - ETA: 5s - loss: 0.6526 - accuracy: 0.7937\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "228/750 [========>.....................] - ETA: 4s - loss: 0.6527 - accuracy: 0.7934\n",
      "238/750 [========>.....................] - ETA: 4s - loss: 0.6525 - accuracy: 0.7937\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "484/750 [==================>...........] - ETA: 2s - loss: 1.5513 - accuracy: 0.6060\n",
      "499/750 [==================>...........] - ETA: 2s - loss: 1.5498 - accuracy: 0.6067\n",
      "268/750 [=========>....................] - ETA: 4s - loss: 0.6502 - accuracy: 0.7929\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "513/750 [===================>..........] - ETA: 2s - loss: 1.5487 - accuracy: 0.6071\n",
      "430/750 [================>.............] - ETA: 2s - loss: 0.6495 - accuracy: 0.7908\n",
      "542/750 [====================>.........] - ETA: 1s - loss: 1.5469 - accuracy: 0.6065\n",
      "302/750 [===========>..................] - ETA: 4s - loss: 0.6511 - accuracy: 0.7925\n",
      "475/750 [==================>...........] - ETA: 2s - loss: 0.6481 - accuracy: 0.7909\n",
      "620/750 [=======================>......] - ETA: 1s - loss: 0.4085 - accuracy: 0.8573\n",
      "328/750 [============>.................] - ETA: 3s - loss: 0.6509 - accuracy: 0.7921\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "481/750 [==================>...........] - ETA: 2s - loss: 0.6476 - accuracy: 0.7909\n",
      " 36/750 [>.............................] - ETA: 8s - loss: 0.6438 - accuracy: 0.7930\n",
      "340/750 [============>.................] - ETA: 3s - loss: 0.6521 - accuracy: 0.7915\n",
      "506/750 [===================>..........] - ETA: 2s - loss: 0.6479 - accuracy: 0.7907\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 1.5410 - accuracy: 0.6065\n",
      " 74/750 [=>............................] - ETA: 7s - loss: 0.6442 - accuracy: 0.7960\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "362/750 [=============>................] - ETA: 3s - loss: 0.6501 - accuracy: 0.7920\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 32/750 [>.............................] - ETA: 4s - loss: 0.3641 - accuracy: 0.8691\n",
      " 36/750 [>.............................] - ETA: 6s - loss: 0.3681 - accuracy: 0.8668\n",
      " 52/750 [=>............................] - ETA: 5s - loss: 0.3706 - accuracy: 0.8669\n",
      "670/750 [=========================>....] - ETA: 0s - loss: 1.5385 - accuracy: 0.6052\n",
      " 83/750 [==>...........................] - ETA: 5s - loss: 0.3799 - accuracy: 0.8646\n",
      " 13/750 [..............................] - ETA: 3s - loss: 0.3820 - accuracy: 0.8630\n",
      "118/750 [===>..........................] - ETA: 6s - loss: 0.6560 - accuracy: 0.7917\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.4055 - accuracy: 0.8582\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 1.5356 - accuracy: 0.6056\n",
      "109/750 [===>..........................] - ETA: 5s - loss: 0.3866 - accuracy: 0.8640\n",
      "444/750 [================>.............] - ETA: 2s - loss: 0.6484 - accuracy: 0.7910\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "725/750 [============================>.] - ETA: 0s - loss: 1.5348 - accuracy: 0.6059\n",
      "123/750 [===>..........................] - ETA: 4s - loss: 0.3889 - accuracy: 0.8626\n",
      "739/750 [============================>.] - ETA: 0s - loss: 1.5335 - accuracy: 0.6063\n",
      "143/750 [====>.........................] - ETA: 4s - loss: 0.3888 - accuracy: 0.8620\n",
      "468/750 [=================>............] - ETA: 2s - loss: 0.6478 - accuracy: 0.7912\n",
      "159/750 [=====>........................] - ETA: 4s - loss: 0.3842 - accuracy: 0.8641\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "461/750 [=================>............] - ETA: 2s - loss: 0.6489 - accuracy: 0.7908\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "170/750 [=====>........................] - ETA: 4s - loss: 0.3831 - accuracy: 0.8652\n",
      "683/750 [==========================>...] - ETA: 0s - loss: 0.6440 - accuracy: 0.7926\n",
      "187/750 [======>.......................] - ETA: 4s - loss: 0.3809 - accuracy: 0.8666\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.6427 - accuracy: 0.7937\n",
      "204/750 [=======>......................] - ETA: 5s - loss: 0.6521 - accuracy: 0.7943\n",
      "526/750 [====================>.........] - ETA: 2s - loss: 1.5479 - accuracy: 0.6067\n",
      "137/750 [====>.........................] - ETA: 4s - loss: 0.3886 - accuracy: 0.8625\n",
      "554/750 [=====================>........] - ETA: 1s - loss: 1.5462 - accuracy: 0.6065\n",
      "255/750 [=========>....................] - ETA: 4s - loss: 0.6505 - accuracy: 0.7937\n",
      "573/750 [=====================>........] - ETA: 1s - loss: 0.6468 - accuracy: 0.7917\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 4s - loss: 1.4064 - accuracy: 0.6406\n",
      "306/750 [===========>..................] - ETA: 3s - loss: 0.3839 - accuracy: 0.8660\n",
      " 11/750 [..............................] - ETA: 8s - loss: 1.4555 - accuracy: 0.6250\n",
      "291/750 [==========>...................] - ETA: 3s - loss: 0.3857 - accuracy: 0.8655\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "585/750 [======================>.......] - ETA: 1s - loss: 0.6467 - accuracy: 0.7917\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "325/750 [============>.................] - ETA: 3s - loss: 0.3829 - accuracy: 0.8667\n",
      " 25/750 [>.............................] - ETA: 7s - loss: 1.4712 - accuracy: 0.6119\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 1.5327 - accuracy: 0.6063 - val_loss: 1.4625 - val_accuracy: 0.6226\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 5/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "606/750 [=======================>......] - ETA: 1s - loss: 0.6465 - accuracy: 0.7915\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "316/750 [===========>..................] - ETA: 3s - loss: 0.6508 - accuracy: 0.7925\n",
      "393/750 [==============>...............] - ETA: 3s - loss: 0.6499 - accuracy: 0.7913\n",
      "347/750 [============>.................] - ETA: 3s - loss: 0.3852 - accuracy: 0.8658\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "648/750 [========================>.....] - ETA: 0s - loss: 0.6446 - accuracy: 0.7926\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "653/750 [=========================>....] - ETA: 0s - loss: 1.5396 - accuracy: 0.6059\n",
      "392/750 [==============>...............] - ETA: 2s - loss: 0.3841 - accuracy: 0.8656\n",
      "375/750 [==============>...............] - ETA: 2s - loss: 0.3853 - accuracy: 0.8654\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.6435 - accuracy: 0.7930\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "108/750 [===>..........................] - ETA: 5s - loss: 1.4555 - accuracy: 0.6306\n",
      "116/750 [===>..........................] - ETA: 5s - loss: 1.4555 - accuracy: 0.6294\n",
      " 97/750 [==>...........................] - ETA: 6s - loss: 1.4610 - accuracy: 0.6266\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "414/750 [===============>..............] - ETA: 3s - loss: 0.6495 - accuracy: 0.7908\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "382/750 [==============>...............] - ETA: 2s - loss: 0.3851 - accuracy: 0.8653\n",
      "408/750 [===============>..............] - ETA: 2s - loss: 0.3844 - accuracy: 0.8658\n",
      "400/750 [===============>..............] - ETA: 3s - loss: 0.6490 - accuracy: 0.7916\n",
      "133/750 [====>.........................] - ETA: 5s - loss: 1.4524 - accuracy: 0.6286\n",
      "145/750 [====>.........................] - ETA: 5s - loss: 1.4530 - accuracy: 0.6265\n",
      "446/750 [================>.............] - ETA: 2s - loss: 0.3849 - accuracy: 0.8656\n",
      "153/750 [=====>........................] - ETA: 5s - loss: 1.4522 - accuracy: 0.6277\n",
      " 69/750 [=>............................] - ETA: 6s - loss: 0.6280 - accuracy: 0.7976\n",
      "746/750 [============================>.] - ETA: 0s - loss: 1.5328 - accuracy: 0.6065\n",
      "217/750 [=======>......................] - ETA: 3s - loss: 0.3817 - accuracy: 0.8669\n",
      "182/750 [======>.......................] - ETA: 5s - loss: 1.4500 - accuracy: 0.6277\n",
      "246/750 [========>.....................] - ETA: 3s - loss: 0.3834 - accuracy: 0.8670\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "498/750 [==================>...........] - ETA: 2s - loss: 0.3850 - accuracy: 0.8652\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "101/750 [===>..........................] - ETA: 6s - loss: 0.6169 - accuracy: 0.8007\n",
      "211/750 [=======>......................] - ETA: 4s - loss: 1.4488 - accuracy: 0.6271\n",
      "220/750 [=======>......................] - ETA: 4s - loss: 1.4481 - accuracy: 0.6267\n",
      "273/750 [=========>....................] - ETA: 3s - loss: 0.3858 - accuracy: 0.8658\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "521/750 [===================>..........] - ETA: 1s - loss: 0.6475 - accuracy: 0.7913\n",
      "529/750 [====================>.........] - ETA: 1s - loss: 0.3860 - accuracy: 0.8649\n",
      "246/750 [========>.....................] - ETA: 4s - loss: 1.4474 - accuracy: 0.6257\n",
      "547/750 [====================>.........] - ETA: 1s - loss: 0.3857 - accuracy: 0.8650\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "306/750 [===========>..................] - ETA: 3s - loss: 1.4440 - accuracy: 0.6249\n",
      "314/750 [===========>..................] - ETA: 3s - loss: 1.4441 - accuracy: 0.6240\n",
      "512/750 [===================>..........] - ETA: 1s - loss: 0.3851 - accuracy: 0.8651\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "618/750 [=======================>......] - ETA: 1s - loss: 0.6464 - accuracy: 0.7919\n",
      "323/750 [===========>..................] - ETA: 3s - loss: 1.4435 - accuracy: 0.6236\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.3862 - accuracy: 0.8645\n",
      " 59/750 [=>............................] - ETA: 7s - loss: 0.6248 - accuracy: 0.7977\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "361/750 [=============>................] - ETA: 2s - loss: 0.3850 - accuracy: 0.8657\n",
      " 48/750 [>.............................] - ETA: 8s - loss: 0.6230 - accuracy: 0.7995\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "254/750 [=========>....................] - ETA: 4s - loss: 0.6178 - accuracy: 0.8006\n",
      "352/750 [=============>................] - ETA: 3s - loss: 1.4416 - accuracy: 0.6242\n",
      "651/750 [=========================>....] - ETA: 0s - loss: 0.3865 - accuracy: 0.8643\n",
      " 51/750 [=>............................] - ETA: 6s - loss: 1.4545 - accuracy: 0.6305\n",
      "371/750 [=============>................] - ETA: 3s - loss: 1.4399 - accuracy: 0.6247\n",
      "668/750 [=========================>....] - ETA: 0s - loss: 0.3853 - accuracy: 0.8647\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 79/750 [==>...........................] - ETA: 5s - loss: 1.4580 - accuracy: 0.6295\n",
      "404/750 [===============>..............] - ETA: 2s - loss: 1.4380 - accuracy: 0.6250\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.3855 - accuracy: 0.8648\n",
      "312/750 [===========>..................] - ETA: 3s - loss: 0.6164 - accuracy: 0.8014\n",
      "322/750 [===========>..................] - ETA: 3s - loss: 0.6167 - accuracy: 0.8011\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.3871 - accuracy: 0.8644\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "117/750 [===>..........................] - ETA: 5s - loss: 0.6157 - accuracy: 0.8011\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "331/750 [============>.................] - ETA: 3s - loss: 0.6171 - accuracy: 0.8003\n",
      "432/750 [================>.............] - ETA: 2s - loss: 1.4371 - accuracy: 0.6248\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8644\n",
      "343/750 [============>.................] - ETA: 3s - loss: 0.6164 - accuracy: 0.8007\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8644\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "162/750 [=====>........................] - ETA: 5s - loss: 0.6197 - accuracy: 0.7992\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "463/750 [=================>............] - ETA: 2s - loss: 1.4351 - accuracy: 0.6245\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "479/750 [==================>...........] - ETA: 2s - loss: 1.4338 - accuracy: 0.6244\n",
      "199/750 [======>.......................] - ETA: 4s - loss: 0.6200 - accuracy: 0.7989\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "508/750 [===================>..........] - ETA: 2s - loss: 1.4311 - accuracy: 0.6256\n",
      "517/750 [===================>..........] - ETA: 1s - loss: 1.4305 - accuracy: 0.6253\n",
      "429/750 [================>.............] - ETA: 2s - loss: 0.6128 - accuracy: 0.8013\n",
      "554/750 [=====================>........] - ETA: 1s - loss: 1.4269 - accuracy: 0.6269\n",
      "576/750 [======================>.......] - ETA: 1s - loss: 1.4261 - accuracy: 0.6266\n",
      "568/750 [=====================>........] - ETA: 1s - loss: 1.4263 - accuracy: 0.6271\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.4137 - accuracy: 0.8906\n",
      "303/750 [===========>..................] - ETA: 3s - loss: 1.4446 - accuracy: 0.6248\n",
      " 15/750 [..............................] - ETA: 9s - loss: 0.6414 - accuracy: 0.7833\n",
      "298/750 [==========>...................] - ETA: 3s - loss: 0.6167 - accuracy: 0.8011\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 1.4247 - accuracy: 0.6273\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "623/750 [=======================>......] - ETA: 1s - loss: 1.4226 - accuracy: 0.6279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:01:26,628 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 7851028480; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25/750 [>.............................] - ETA: 9s - loss: 0.6203 - accuracy: 0.7894\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 0.6435 - accuracy: 0.7933 - val_loss: 0.6191 - val_accuracy: 0.7956\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 5/30\n",
      "608/750 [=======================>......] - ETA: 1s - loss: 1.4232 - accuracy: 0.6277\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 0.3867 - accuracy: 0.8644 - val_loss: 0.3978 - val_accuracy: 0.8617\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 6/30\n",
      "  6/750 [..............................] - ETA: 7s - loss: 0.3981 - accuracy: 0.8672\n",
      " 16/750 [..............................] - ETA: 8s - loss: 0.4042 - accuracy: 0.8535\n",
      " 32/750 [>.............................] - ETA: 6s - loss: 0.3940 - accuracy: 0.8589\n",
      "339/750 [============>.................] - ETA: 3s - loss: 1.4426 - accuracy: 0.6243\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "646/750 [========================>.....] - ETA: 0s - loss: 1.4210 - accuracy: 0.6279\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "676/750 [==========================>...] - ETA: 0s - loss: 1.4194 - accuracy: 0.6280\n",
      "398/750 [==============>...............] - ETA: 2s - loss: 0.6137 - accuracy: 0.8009\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "381/750 [==============>...............] - ETA: 3s - loss: 0.6153 - accuracy: 0.8012\n",
      "694/750 [==========================>...] - ETA: 0s - loss: 1.4185 - accuracy: 0.6275\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 87/750 [==>...........................] - ETA: 6s - loss: 0.6172 - accuracy: 0.8006\n",
      "420/750 [===============>..............] - ETA: 2s - loss: 0.6136 - accuracy: 0.8010\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "728/750 [============================>.] - ETA: 0s - loss: 1.4170 - accuracy: 0.6278\n",
      " 83/750 [==>...........................] - ETA: 6s - loss: 0.3659 - accuracy: 0.8710\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.6097 - accuracy: 0.8028\n",
      "730/750 [============================>.] - ETA: 0s - loss: 1.4168 - accuracy: 0.6278\n",
      " 95/750 [==>...........................] - ETA: 6s - loss: 0.3669 - accuracy: 0.8709\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.6089 - accuracy: 0.8031\n",
      "136/750 [====>.........................] - ETA: 5s - loss: 0.6192 - accuracy: 0.8003\n",
      "647/750 [========================>.....] - ETA: 0s - loss: 0.6083 - accuracy: 0.8032\n",
      "154/750 [=====>........................] - ETA: 5s - loss: 0.6212 - accuracy: 0.7995\n",
      "138/750 [====>.........................] - ETA: 5s - loss: 0.3637 - accuracy: 0.8732\n",
      "155/750 [=====>........................] - ETA: 5s - loss: 0.3657 - accuracy: 0.8721\n",
      " 69/750 [=>............................] - ETA: 6s - loss: 0.3676 - accuracy: 0.8698\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "179/750 [======>.......................] - ETA: 5s - loss: 0.6219 - accuracy: 0.7985\n",
      "237/750 [========>.....................] - ETA: 4s - loss: 0.6176 - accuracy: 0.8010\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "493/750 [==================>...........] - ETA: 2s - loss: 0.6113 - accuracy: 0.8019\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "177/750 [======>.......................] - ETA: 5s - loss: 0.3695 - accuracy: 0.8713\n",
      "100/750 [===>..........................] - ETA: 6s - loss: 0.3645 - accuracy: 0.8727\n",
      "222/750 [=======>......................] - ETA: 4s - loss: 0.6204 - accuracy: 0.8000\n",
      "268/750 [=========>....................] - ETA: 4s - loss: 0.6184 - accuracy: 0.8003\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "531/750 [====================>.........] - ETA: 1s - loss: 1.4292 - accuracy: 0.6257\n",
      "204/750 [=======>......................] - ETA: 4s - loss: 0.3720 - accuracy: 0.8709\n",
      "223/750 [=======>......................] - ETA: 4s - loss: 0.3738 - accuracy: 0.8693\n",
      "547/750 [====================>.........] - ETA: 1s - loss: 0.6092 - accuracy: 0.8034\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "277/750 [==========>...................] - ETA: 4s - loss: 0.3736 - accuracy: 0.8690\n",
      "300/750 [===========>..................] - ETA: 3s - loss: 0.3729 - accuracy: 0.8687\n",
      "310/750 [===========>..................] - ETA: 3s - loss: 0.3725 - accuracy: 0.8689\n",
      " 57/750 [=>............................] - ETA: 7s - loss: 0.3709 - accuracy: 0.8692\n",
      " 39/750 [>.............................] - ETA: 5s - loss: 1.3552 - accuracy: 0.6430\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "317/750 [===========>..................] - ETA: 3s - loss: 0.3715 - accuracy: 0.8691\n",
      " 53/750 [=>............................] - ETA: 5s - loss: 1.3542 - accuracy: 0.6418\n",
      "251/750 [=========>....................] - ETA: 4s - loss: 0.3709 - accuracy: 0.8703\n",
      "659/750 [=========================>....] - ETA: 0s - loss: 1.4200 - accuracy: 0.6283\n",
      "332/750 [============>.................] - ETA: 3s - loss: 0.3732 - accuracy: 0.8690\n",
      " 61/750 [=>............................] - ETA: 5s - loss: 1.3541 - accuracy: 0.6396\n",
      "368/750 [=============>................] - ETA: 3s - loss: 0.6147 - accuracy: 0.8007\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 71/750 [=>............................] - ETA: 5s - loss: 1.3548 - accuracy: 0.6386\n",
      "669/750 [=========================>....] - ETA: 0s - loss: 0.6081 - accuracy: 0.8035\n",
      "353/750 [=============>................] - ETA: 3s - loss: 0.3728 - accuracy: 0.8691\n",
      "363/750 [=============>................] - ETA: 3s - loss: 0.3743 - accuracy: 0.8688\n",
      " 85/750 [==>...........................] - ETA: 6s - loss: 1.3500 - accuracy: 0.6406\n",
      "378/750 [==============>...............] - ETA: 3s - loss: 0.3754 - accuracy: 0.8683\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.6076 - accuracy: 0.8036\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "116/750 [===>..........................] - ETA: 6s - loss: 0.3574 - accuracy: 0.8747\n",
      "111/750 [===>..........................] - ETA: 5s - loss: 1.3466 - accuracy: 0.6398\n",
      "344/750 [============>.................] - ETA: 3s - loss: 0.3728 - accuracy: 0.8692\n",
      "448/750 [================>.............] - ETA: 2s - loss: 0.6123 - accuracy: 0.8011\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "119/750 [===>..........................] - ETA: 5s - loss: 1.3453 - accuracy: 0.6400\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.6077 - accuracy: 0.8038\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "122/750 [===>..........................] - ETA: 5s - loss: 1.3467 - accuracy: 0.6391\n",
      "168/750 [=====>........................] - ETA: 5s - loss: 0.3660 - accuracy: 0.8722\n",
      "464/750 [=================>............] - ETA: 2s - loss: 0.6122 - accuracy: 0.8014\n",
      "477/750 [==================>...........] - ETA: 2s - loss: 0.6121 - accuracy: 0.8015\n",
      "163/750 [=====>........................] - ETA: 4s - loss: 1.3479 - accuracy: 0.6377\n",
      "455/750 [=================>............] - ETA: 2s - loss: 0.3751 - accuracy: 0.8684\n",
      "473/750 [=================>............] - ETA: 2s - loss: 0.3755 - accuracy: 0.8683\n",
      "184/750 [======>.......................] - ETA: 4s - loss: 1.3490 - accuracy: 0.6377\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "520/750 [===================>..........] - ETA: 1s - loss: 0.6102 - accuracy: 0.8026\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "482/750 [==================>...........] - ETA: 2s - loss: 0.3756 - accuracy: 0.8685\n",
      " 78/750 [==>...........................] - ETA: 6s - loss: 0.5951 - accuracy: 0.8017\n",
      "506/750 [===================>..........] - ETA: 2s - loss: 0.3759 - accuracy: 0.8680\n",
      "216/750 [=======>......................] - ETA: 4s - loss: 1.3503 - accuracy: 0.6351\n",
      "222/750 [=======>......................] - ETA: 4s - loss: 1.3497 - accuracy: 0.6344\n",
      "535/750 [====================>.........] - ETA: 1s - loss: 0.3759 - accuracy: 0.8676\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.6096 - accuracy: 0.8028\n",
      "569/750 [=====================>........] - ETA: 1s - loss: 0.3745 - accuracy: 0.8683\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "300/750 [===========>..................] - ETA: 3s - loss: 1.3462 - accuracy: 0.6356\n",
      "287/750 [==========>...................] - ETA: 3s - loss: 0.3733 - accuracy: 0.8690\n",
      "582/750 [======================>.......] - ETA: 1s - loss: 0.3748 - accuracy: 0.8682\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "607/750 [=======================>......] - ETA: 1s - loss: 0.6100 - accuracy: 0.8027\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.3741 - accuracy: 0.8684\n",
      "610/750 [=======================>......] - ETA: 1s - loss: 0.3757 - accuracy: 0.8678\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 0.6067 - accuracy: 0.8043 - val_loss: 0.5896 - val_accuracy: 0.8056\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 6/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  7/750 [..............................] - ETA: 7s - loss: 0.5892 - accuracy: 0.7991 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "316/750 [===========>..................] - ETA: 3s - loss: 1.3455 - accuracy: 0.6357\n",
      "624/750 [=======================>......] - ETA: 1s - loss: 0.3757 - accuracy: 0.8678\n",
      " 17/750 [..............................] - ETA: 8s - loss: 0.6005 - accuracy: 0.7978\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "334/750 [============>.................] - ETA: 3s - loss: 1.3442 - accuracy: 0.6370\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "642/750 [========================>.....] - ETA: 0s - loss: 0.3747 - accuracy: 0.8684\n",
      "357/750 [=============>................] - ETA: 3s - loss: 1.3440 - accuracy: 0.6362\n",
      "659/750 [=========================>....] - ETA: 0s - loss: 0.3749 - accuracy: 0.8682\n",
      "256/750 [=========>....................] - ETA: 3s - loss: 0.5926 - accuracy: 0.8065\n",
      "673/750 [=========================>....] - ETA: 0s - loss: 0.3741 - accuracy: 0.8685\n",
      "394/750 [==============>...............] - ETA: 3s - loss: 0.3756 - accuracy: 0.8679\n",
      "384/750 [==============>...............] - ETA: 3s - loss: 1.3412 - accuracy: 0.6385\n",
      "283/750 [==========>...................] - ETA: 3s - loss: 0.5892 - accuracy: 0.8078\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.3733 - accuracy: 0.8687\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "397/750 [==============>...............] - ETA: 2s - loss: 1.3399 - accuracy: 0.6389\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.3726 - accuracy: 0.8688\n",
      "299/750 [==========>...................] - ETA: 3s - loss: 0.5881 - accuracy: 0.8086\n",
      "420/750 [===============>..............] - ETA: 2s - loss: 0.3756 - accuracy: 0.8683\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 93/750 [==>...........................] - ETA: 5s - loss: 0.5935 - accuracy: 0.8036\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.6067 - accuracy: 0.8044\n",
      "431/750 [================>.............] - ETA: 2s - loss: 1.3384 - accuracy: 0.6392\n",
      "346/750 [============>.................] - ETA: 3s - loss: 0.5856 - accuracy: 0.8111\n",
      "135/750 [====>.........................] - ETA: 5s - loss: 0.6007 - accuracy: 0.8029\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "379/750 [==============>...............] - ETA: 2s - loss: 0.5848 - accuracy: 0.8111\n",
      "152/750 [=====>........................] - ETA: 5s - loss: 0.5974 - accuracy: 0.8051\n",
      "238/750 [========>.....................] - ETA: 4s - loss: 0.5918 - accuracy: 0.8069\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "492/750 [==================>...........] - ETA: 2s - loss: 1.3342 - accuracy: 0.6404\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "182/750 [======>.......................] - ETA: 4s - loss: 0.5951 - accuracy: 0.8074\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "527/750 [====================>.........] - ETA: 1s - loss: 1.3331 - accuracy: 0.6401\n",
      "421/750 [===============>..............] - ETA: 2s - loss: 0.5836 - accuracy: 0.8117\n",
      "271/750 [=========>....................] - ETA: 3s - loss: 0.5892 - accuracy: 0.8081\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "207/750 [=======>......................] - ETA: 4s - loss: 0.5943 - accuracy: 0.8075\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "223/750 [=======>......................] - ETA: 4s - loss: 0.5929 - accuracy: 0.8066\n",
      "547/750 [====================>.........] - ETA: 1s - loss: 1.3325 - accuracy: 0.6401\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 1.3305 - accuracy: 0.6401\n",
      "  1/750 [..............................] - ETA: 2s - loss: 0.4340 - accuracy: 0.8906\n",
      "629/750 [========================>.....] - ETA: 0s - loss: 1.3290 - accuracy: 0.6401\n",
      "277/750 [==========>...................] - ETA: 4s - loss: 1.3468 - accuracy: 0.6355\n",
      "645/750 [========================>.....] - ETA: 0s - loss: 1.3284 - accuracy: 0.6402\n",
      "650/750 [=========================>....] - ETA: 0s - loss: 1.3283 - accuracy: 0.6402\n",
      "658/750 [=========================>....] - ETA: 0s - loss: 1.3282 - accuracy: 0.6399\n",
      "668/750 [=========================>....] - ETA: 0s - loss: 1.3280 - accuracy: 0.6399\n",
      " 61/750 [=>............................] - ETA: 6s - loss: 0.3683 - accuracy: 0.8681\n",
      "305/750 [===========>..................] - ETA: 3s - loss: 1.3453 - accuracy: 0.6360\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 1.3268 - accuracy: 0.6406\n",
      " 46/750 [>.............................] - ETA: 5s - loss: 0.3638 - accuracy: 0.8679\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "332/750 [============>.................] - ETA: 3s - loss: 0.5851 - accuracy: 0.8106\n",
      " 59/750 [=>............................] - ETA: 5s - loss: 0.3626 - accuracy: 0.8692\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "359/750 [=============>................] - ETA: 3s - loss: 0.5853 - accuracy: 0.8111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "611/750 [=======================>......] - ETA: 1s - loss: 0.5802 - accuracy: 0.8124\n",
      "127/750 [====>.........................] - ETA: 4s - loss: 0.3558 - accuracy: 0.8719\n",
      " 96/750 [==>...........................] - ETA: 5s - loss: 0.5944 - accuracy: 0.8044\n",
      "746/750 [============================>.] - ETA: 0s - loss: 1.3240 - accuracy: 0.6411\n",
      "151/750 [=====>........................] - ETA: 4s - loss: 0.3586 - accuracy: 0.8719\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 1.3256 - accuracy: 0.6404\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "436/750 [================>.............] - ETA: 2s - loss: 0.5842 - accuracy: 0.8114\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "184/750 [======>.......................] - ETA: 4s - loss: 0.3646 - accuracy: 0.8686\n",
      "681/750 [==========================>...] - ETA: 0s - loss: 0.5814 - accuracy: 0.8117\n",
      "741/750 [============================>.] - ETA: 0s - loss: 1.3244 - accuracy: 0.6409\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "114/750 [===>..........................] - ETA: 4s - loss: 0.3572 - accuracy: 0.8729\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "163/750 [=====>........................] - ETA: 4s - loss: 0.3593 - accuracy: 0.8705\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "454/750 [=================>............] - ETA: 2s - loss: 0.5834 - accuracy: 0.8116\n",
      "225/750 [========>.....................] - ETA: 4s - loss: 0.3640 - accuracy: 0.8688\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.5817 - accuracy: 0.8113\n",
      "473/750 [=================>............] - ETA: 2s - loss: 0.5826 - accuracy: 0.8117\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "192/750 [======>.......................] - ETA: 4s - loss: 0.5929 - accuracy: 0.8083\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "514/750 [===================>..........] - ETA: 1s - loss: 0.5803 - accuracy: 0.8124\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 80/750 [==>...........................] - ETA: 5s - loss: 0.3664 - accuracy: 0.8705\n",
      "505/750 [===================>..........] - ETA: 1s - loss: 0.5807 - accuracy: 0.8121\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "210/750 [=======>......................] - ETA: 4s - loss: 0.3637 - accuracy: 0.8689\n",
      "306/750 [===========>..................] - ETA: 3s - loss: 0.3672 - accuracy: 0.8692\n",
      " 30/750 [>.............................] - ETA: 4s - loss: 1.2807 - accuracy: 0.6500\n",
      " 34/750 [>.............................] - ETA: 4s - loss: 1.2805 - accuracy: 0.6480\n",
      " 51/750 [=>............................] - ETA: 4s - loss: 1.2802 - accuracy: 0.6458\n",
      "565/750 [=====================>........] - ETA: 1s - loss: 0.5790 - accuracy: 0.8126\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "584/750 [======================>.......] - ETA: 1s - loss: 0.5788 - accuracy: 0.8127\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:01:36,632 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 7850778624; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90/750 [==>...........................] - ETA: 4s - loss: 1.2817 - accuracy: 0.6453\n",
      "623/750 [=======================>......] - ETA: 0s - loss: 0.5809 - accuracy: 0.8123\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 99/750 [==>...........................] - ETA: 4s - loss: 1.2822 - accuracy: 0.6458\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 1.3241 - accuracy: 0.6411 - val_loss: 1.2771 - val_accuracy: 0.6508\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 7/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 12/750 [..............................] - ETA: 3s - loss: 1.2581 - accuracy: 0.6628\n",
      "319/750 [===========>..................] - ETA: 3s - loss: 0.3664 - accuracy: 0.8700\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 23/750 [..............................] - ETA: 7s - loss: 0.3665 - accuracy: 0.8662\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "107/750 [===>..........................] - ETA: 4s - loss: 1.2822 - accuracy: 0.6437\n",
      " 13/750 [..............................] - ETA: 3s - loss: 0.5426 - accuracy: 0.8257\n",
      "343/750 [============>.................] - ETA: 3s - loss: 0.3638 - accuracy: 0.8711\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "661/750 [=========================>....] - ETA: 0s - loss: 0.5807 - accuracy: 0.8121\n",
      "126/750 [====>.........................] - ETA: 4s - loss: 1.2812 - accuracy: 0.6440\n",
      "132/750 [====>.........................] - ETA: 4s - loss: 1.2813 - accuracy: 0.6454\n",
      "452/750 [=================>............] - ETA: 2s - loss: 0.3611 - accuracy: 0.8721\n",
      "290/750 [==========>...................] - ETA: 3s - loss: 0.3668 - accuracy: 0.8691\n",
      "699/750 [==========================>...] - ETA: 0s - loss: 0.5809 - accuracy: 0.8117\n",
      "394/750 [==============>...............] - ETA: 2s - loss: 0.3620 - accuracy: 0.8718\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 1.3262 - accuracy: 0.6405\n",
      "166/750 [=====>........................] - ETA: 4s - loss: 1.2784 - accuracy: 0.6468\n",
      "174/750 [=====>........................] - ETA: 4s - loss: 1.2781 - accuracy: 0.6465\n",
      "424/750 [===============>..............] - ETA: 2s - loss: 0.3616 - accuracy: 0.8724\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 84/750 [==>...........................] - ETA: 4s - loss: 1.2811 - accuracy: 0.6466\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 77/750 [==>...........................] - ETA: 5s - loss: 0.5714 - accuracy: 0.8174\n",
      "207/750 [=======>......................] - ETA: 4s - loss: 1.2756 - accuracy: 0.6464\n",
      "222/750 [=======>......................] - ETA: 4s - loss: 1.2730 - accuracy: 0.6470\n",
      "144/750 [====>.........................] - ETA: 4s - loss: 1.2814 - accuracy: 0.6445\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "254/750 [=========>....................] - ETA: 3s - loss: 1.2724 - accuracy: 0.6484\n",
      "576/750 [======================>.......] - ETA: 1s - loss: 0.3597 - accuracy: 0.8727\n",
      "277/750 [==========>...................] - ETA: 3s - loss: 1.2710 - accuracy: 0.6493\n",
      "239/750 [========>.....................] - ETA: 3s - loss: 1.2727 - accuracy: 0.6481\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "487/750 [==================>...........] - ETA: 2s - loss: 0.3598 - accuracy: 0.8729\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "176/750 [======>.......................] - ETA: 4s - loss: 0.5684 - accuracy: 0.8165\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "527/750 [====================>.........] - ETA: 1s - loss: 0.5796 - accuracy: 0.8124\n",
      "287/750 [==========>...................] - ETA: 3s - loss: 1.2694 - accuracy: 0.6506\n",
      "262/750 [=========>....................] - ETA: 3s - loss: 1.2721 - accuracy: 0.6492\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "201/750 [=======>......................] - ETA: 4s - loss: 1.2766 - accuracy: 0.6458\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "298/750 [==========>...................] - ETA: 3s - loss: 1.2700 - accuracy: 0.6496\n",
      "549/750 [====================>.........] - ETA: 1s - loss: 0.3600 - accuracy: 0.8728\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 0.5800 - accuracy: 0.8123\n",
      "627/750 [========================>.....] - ETA: 0s - loss: 0.3600 - accuracy: 0.8728\n",
      "325/750 [============>.................] - ETA: 3s - loss: 1.2680 - accuracy: 0.6498\n",
      "634/750 [========================>.....] - ETA: 0s - loss: 0.3601 - accuracy: 0.8731\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "338/750 [============>.................] - ETA: 3s - loss: 1.2666 - accuracy: 0.6507\n",
      "234/750 [========>.....................] - ETA: 4s - loss: 0.5676 - accuracy: 0.8152\n",
      "354/750 [=============>................] - ETA: 3s - loss: 1.2674 - accuracy: 0.6500\n",
      "660/750 [=========================>....] - ETA: 0s - loss: 0.3600 - accuracy: 0.8730\n",
      "240/750 [========>.....................] - ETA: 4s - loss: 0.5681 - accuracy: 0.8145\n",
      "673/750 [=========================>....] - ETA: 0s - loss: 0.3596 - accuracy: 0.8733\n",
      "376/750 [==============>...............] - ETA: 3s - loss: 1.2681 - accuracy: 0.6488\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 0.3584 - accuracy: 0.8739\n",
      " 45/750 [>.............................] - ETA: 6s - loss: 0.5592 - accuracy: 0.8198\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.3587 - accuracy: 0.8737\n",
      "400/750 [===============>..............] - ETA: 3s - loss: 1.2665 - accuracy: 0.6496\n",
      " 63/750 [=>............................] - ETA: 5s - loss: 0.5711 - accuracy: 0.8194\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "364/750 [=============>................] - ETA: 3s - loss: 1.2679 - accuracy: 0.6495\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "132/750 [====>.........................] - ETA: 4s - loss: 0.5733 - accuracy: 0.8164\n",
      "425/750 [================>.............] - ETA: 2s - loss: 1.2647 - accuracy: 0.6506\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.3593 - accuracy: 0.8737\n",
      "160/750 [=====>........................] - ETA: 4s - loss: 1.2782 - accuracy: 0.6463\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.3581 - accuracy: 0.8740\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "441/750 [================>.............] - ETA: 2s - loss: 1.2642 - accuracy: 0.6507\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.3593 - accuracy: 0.8738\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "115/750 [===>..........................] - ETA: 5s - loss: 0.5721 - accuracy: 0.8179\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "492/750 [==================>...........] - ETA: 2s - loss: 1.2632 - accuracy: 0.6508\n",
      "510/750 [===================>..........] - ETA: 2s - loss: 1.2630 - accuracy: 0.6506\n",
      "163/750 [=====>........................] - ETA: 4s - loss: 0.5689 - accuracy: 0.8167\n",
      "227/750 [========>.....................] - ETA: 4s - loss: 0.5678 - accuracy: 0.8151\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.3584 - accuracy: 0.8740\n",
      "472/750 [=================>............] - ETA: 2s - loss: 1.2641 - accuracy: 0.6511\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "192/750 [======>.......................] - ETA: 4s - loss: 0.5702 - accuracy: 0.8148\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "524/750 [===================>..........] - ETA: 1s - loss: 1.2618 - accuracy: 0.6509\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "554/750 [=====================>........] - ETA: 1s - loss: 1.2606 - accuracy: 0.6512\n",
      "503/750 [===================>..........] - ETA: 2s - loss: 1.2628 - accuracy: 0.6508\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "575/750 [======================>.......] - ETA: 1s - loss: 1.2599 - accuracy: 0.6505\n",
      "582/750 [======================>.......] - ETA: 1s - loss: 1.2599 - accuracy: 0.6505\n",
      "483/750 [==================>...........] - ETA: 2s - loss: 0.5656 - accuracy: 0.8159\n",
      "300/750 [===========>..................] - ETA: 3s - loss: 0.5674 - accuracy: 0.8143\n",
      "600/750 [=======================>......] - ETA: 1s - loss: 1.2586 - accuracy: 0.6509\n",
      " 26/750 [>.............................] - ETA: 4s - loss: 0.3353 - accuracy: 0.8864\n",
      "569/750 [=====================>........] - ETA: 1s - loss: 1.2603 - accuracy: 0.6507\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "653/750 [=========================>....] - ETA: 0s - loss: 1.2565 - accuracy: 0.6514\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.3603 - accuracy: 0.8727\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "623/750 [=======================>......] - ETA: 1s - loss: 1.2576 - accuracy: 0.6519\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 0.3593 - accuracy: 0.8737 - val_loss: 0.3809 - val_accuracy: 0.8666\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 8/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "316/750 [===========>..................] - ETA: 3s - loss: 0.5652 - accuracy: 0.8149\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 24/750 [..............................] - ETA: 5s - loss: 0.5631 - accuracy: 0.8210\n",
      "101/750 [===>..........................] - ETA: 5s - loss: 0.5729 - accuracy: 0.8176\n",
      "688/750 [==========================>...] - ETA: 0s - loss: 1.2543 - accuracy: 0.6520\n",
      " 12/750 [..............................] - ETA: 3s - loss: 0.3214 - accuracy: 0.8828\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 1.2528 - accuracy: 0.6519\n",
      "106/750 [===>..........................] - ETA: 5s - loss: 0.3596 - accuracy: 0.8710\n",
      "450/750 [=================>............] - ETA: 2s - loss: 0.5658 - accuracy: 0.8151\n",
      "125/750 [====>.........................] - ETA: 5s - loss: 0.3546 - accuracy: 0.8725\n",
      "739/750 [============================>.] - ETA: 0s - loss: 1.2520 - accuracy: 0.6520\n",
      "128/750 [====>.........................] - ETA: 5s - loss: 0.3539 - accuracy: 0.8726\n",
      "748/750 [============================>.] - ETA: 0s - loss: 1.2513 - accuracy: 0.6524\n",
      "134/750 [====>.........................] - ETA: 5s - loss: 0.3545 - accuracy: 0.8728\n",
      "391/750 [==============>...............] - ETA: 3s - loss: 0.5644 - accuracy: 0.8153\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "143/750 [====>.........................] - ETA: 5s - loss: 0.3537 - accuracy: 0.8725\n",
      "152/750 [=====>........................] - ETA: 4s - loss: 0.3511 - accuracy: 0.8733\n",
      "651/750 [=========================>....] - ETA: 0s - loss: 0.5621 - accuracy: 0.8163\n",
      "656/750 [=========================>....] - ETA: 0s - loss: 0.5618 - accuracy: 0.8164\n",
      "421/750 [===============>..............] - ETA: 2s - loss: 0.5637 - accuracy: 0.8156\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 90/750 [==>...........................] - ETA: 5s - loss: 0.3563 - accuracy: 0.8733\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "156/750 [=====>........................] - ETA: 4s - loss: 0.3511 - accuracy: 0.8728\n",
      " 76/750 [==>...........................] - ETA: 5s - loss: 0.3546 - accuracy: 0.8748\n",
      "166/750 [=====>........................] - ETA: 5s - loss: 0.3503 - accuracy: 0.8727\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.5619 - accuracy: 0.8164\n",
      "215/750 [=======>......................] - ETA: 4s - loss: 0.5701 - accuracy: 0.8145\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "140/750 [====>.........................] - ETA: 4s - loss: 0.5712 - accuracy: 0.8166\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.5607 - accuracy: 0.8172\n",
      "226/750 [========>.....................] - ETA: 4s - loss: 0.3494 - accuracy: 0.8754\n",
      "579/750 [======================>.......] - ETA: 1s - loss: 0.5629 - accuracy: 0.8161\n",
      "279/750 [==========>...................] - ETA: 4s - loss: 0.5697 - accuracy: 0.8138\n",
      "251/750 [=========>....................] - ETA: 4s - loss: 0.3502 - accuracy: 0.8750\n",
      "243/750 [========>.....................] - ETA: 4s - loss: 0.3505 - accuracy: 0.8745\n",
      "498/750 [==================>...........] - ETA: 2s - loss: 0.5647 - accuracy: 0.8159\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "177/750 [======>.......................] - ETA: 4s - loss: 0.3513 - accuracy: 0.8730\n",
      "289/750 [==========>...................] - ETA: 4s - loss: 0.5683 - accuracy: 0.8137\n",
      "279/750 [==========>...................] - ETA: 3s - loss: 0.3507 - accuracy: 0.8756\n",
      "264/750 [=========>....................] - ETA: 4s - loss: 0.3507 - accuracy: 0.8751\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "293/750 [==========>...................] - ETA: 3s - loss: 0.3503 - accuracy: 0.8757\n",
      "541/750 [====================>.........] - ETA: 1s - loss: 0.5648 - accuracy: 0.8156\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.5626 - accuracy: 0.8159\n",
      " 11/750 [..............................] - ETA: 5s - loss: 1.1886 - accuracy: 0.6761\n",
      "328/750 [============>.................] - ETA: 3s - loss: 0.5641 - accuracy: 0.8149\n",
      " 19/750 [..............................] - ETA: 7s - loss: 1.2174 - accuracy: 0.6480\n",
      "644/750 [========================>.....] - ETA: 0s - loss: 0.5629 - accuracy: 0.8157\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "344/750 [============>.................] - ETA: 3s - loss: 0.5636 - accuracy: 0.8148\n",
      "334/750 [============>.................] - ETA: 3s - loss: 0.3486 - accuracy: 0.8762\n",
      "665/750 [=========================>....] - ETA: 0s - loss: 0.5622 - accuracy: 0.8162\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "349/750 [============>.................] - ETA: 3s - loss: 0.3487 - accuracy: 0.8760\n",
      " 52/750 [=>............................] - ETA: 5s - loss: 1.2188 - accuracy: 0.6572\n",
      "356/750 [=============>................] - ETA: 3s - loss: 0.3499 - accuracy: 0.8756\n",
      " 77/750 [==>...........................] - ETA: 5s - loss: 1.2208 - accuracy: 0.6528\n",
      " 34/750 [>.............................] - ETA: 6s - loss: 1.2221 - accuracy: 0.6530\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 1.2539 - accuracy: 0.6520\n",
      "405/750 [===============>..............] - ETA: 3s - loss: 0.5633 - accuracy: 0.8157\n",
      " 66/750 [=>............................] - ETA: 5s - loss: 1.2171 - accuracy: 0.6574\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "372/750 [=============>................] - ETA: 3s - loss: 0.3499 - accuracy: 0.8753\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.6435 - accuracy: 0.7500\n",
      "426/750 [================>.............] - ETA: 2s - loss: 0.3492 - accuracy: 0.8755\n",
      "129/750 [====>.........................] - ETA: 5s - loss: 1.2181 - accuracy: 0.6504\n",
      "147/750 [====>.........................] - ETA: 4s - loss: 1.2204 - accuracy: 0.6493\n",
      " 32/750 [>.............................] - ETA: 6s - loss: 0.5695 - accuracy: 0.8076\n",
      " 41/750 [>.............................] - ETA: 5s - loss: 0.5750 - accuracy: 0.8049\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.5612 - accuracy: 0.8167\n",
      " 45/750 [>.............................] - ETA: 7s - loss: 0.5727 - accuracy: 0.8080\n",
      "441/750 [================>.............] - ETA: 2s - loss: 0.3489 - accuracy: 0.8755\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "176/750 [======>.......................] - ETA: 4s - loss: 1.2192 - accuracy: 0.6508\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.5601 - accuracy: 0.8173\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "112/750 [===>..........................] - ETA: 5s - loss: 1.2169 - accuracy: 0.6508\n",
      "200/750 [=======>......................] - ETA: 4s - loss: 1.2161 - accuracy: 0.6533\n",
      "467/750 [=================>............] - ETA: 2s - loss: 0.3505 - accuracy: 0.8751\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "239/750 [========>.....................] - ETA: 4s - loss: 1.2136 - accuracy: 0.6547\n",
      "117/750 [===>..........................] - ETA: 5s - loss: 0.5645 - accuracy: 0.8149\n",
      "193/750 [======>.......................] - ETA: 4s - loss: 1.2156 - accuracy: 0.6530\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "518/750 [===================>..........] - ETA: 1s - loss: 0.3492 - accuracy: 0.8753\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "550/750 [=====================>........] - ETA: 1s - loss: 0.5655 - accuracy: 0.8151\n",
      "247/750 [========>.....................] - ETA: 3s - loss: 1.2127 - accuracy: 0.6551\n",
      "260/750 [=========>....................] - ETA: 3s - loss: 1.2120 - accuracy: 0.6552\n",
      "267/750 [=========>....................] - ETA: 3s - loss: 1.2114 - accuracy: 0.6560\n",
      "568/750 [=====================>........] - ETA: 1s - loss: 0.3486 - accuracy: 0.8752\n",
      "276/750 [==========>...................] - ETA: 3s - loss: 1.2112 - accuracy: 0.6558\n",
      "480/750 [==================>...........] - ETA: 2s - loss: 0.3497 - accuracy: 0.8754\n",
      "608/750 [=======================>......] - ETA: 1s - loss: 0.5623 - accuracy: 0.8159\n",
      "305/750 [===========>..................] - ETA: 3s - loss: 1.2079 - accuracy: 0.6573\n",
      "634/750 [========================>.....] - ETA: 0s - loss: 0.3487 - accuracy: 0.8754\n",
      "560/750 [=====================>........] - ETA: 1s - loss: 0.3488 - accuracy: 0.8751\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "353/750 [=============>................] - ETA: 3s - loss: 1.2057 - accuracy: 0.6573\n",
      "650/750 [=========================>....] - ETA: 0s - loss: 0.3484 - accuracy: 0.8757\n",
      "234/750 [========>.....................] - ETA: 4s - loss: 0.5539 - accuracy: 0.8191\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.3488 - accuracy: 0.8752\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "248/750 [========>.....................] - ETA: 4s - loss: 0.5543 - accuracy: 0.8183\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.3492 - accuracy: 0.8751\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:01:46,726 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 7850262528; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 8s 10ms/step - loss: 0.5605 - accuracy: 0.8171 - val_loss: 0.5508 - val_accuracy: 0.8151\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 8/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "320/750 [===========>..................] - ETA: 3s - loss: 1.2068 - accuracy: 0.6576\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "682/750 [==========================>...] - ETA: 0s - loss: 0.3495 - accuracy: 0.8754\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "400/750 [===============>..............] - ETA: 2s - loss: 1.2034 - accuracy: 0.6584\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.3489 - accuracy: 0.8757\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.3492 - accuracy: 0.8754\n",
      "106/750 [===>..........................] - ETA: 5s - loss: 0.5670 - accuracy: 0.8134\n",
      "327/750 [============>.................] - ETA: 3s - loss: 0.5512 - accuracy: 0.8201\n",
      "453/750 [=================>............] - ETA: 2s - loss: 1.2008 - accuracy: 0.6582\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.8751\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.5602 - accuracy: 0.8172\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "347/750 [============>.................] - ETA: 3s - loss: 0.5528 - accuracy: 0.8191\n",
      "382/750 [==============>...............] - ETA: 2s - loss: 1.2043 - accuracy: 0.6583\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "415/750 [===============>..............] - ETA: 2s - loss: 1.2016 - accuracy: 0.6587\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 86/750 [==>...........................] - ETA: 6s - loss: 0.5715 - accuracy: 0.8116\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "172/750 [=====>........................] - ETA: 4s - loss: 0.5580 - accuracy: 0.8171\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "501/750 [===================>..........] - ETA: 1s - loss: 1.1973 - accuracy: 0.6598\n",
      "380/750 [==============>...............] - ETA: 2s - loss: 0.5495 - accuracy: 0.8209\n",
      "390/750 [==============>...............] - ETA: 2s - loss: 0.5480 - accuracy: 0.8212\n",
      "221/750 [=======>......................] - ETA: 4s - loss: 0.5556 - accuracy: 0.8186\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "529/750 [====================>.........] - ETA: 1s - loss: 1.1983 - accuracy: 0.6583\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.3487 - accuracy: 0.8753\n",
      "554/750 [=====================>........] - ETA: 1s - loss: 1.1976 - accuracy: 0.6583\n",
      "484/750 [==================>...........] - ETA: 2s - loss: 1.1993 - accuracy: 0.6584\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "472/750 [=================>............] - ETA: 2s - loss: 0.5466 - accuracy: 0.8210\n",
      "475/750 [==================>...........] - ETA: 2s - loss: 0.5462 - accuracy: 0.8210\n",
      "265/750 [=========>....................] - ETA: 3s - loss: 0.5542 - accuracy: 0.8185\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "287/750 [==========>...................] - ETA: 3s - loss: 0.5528 - accuracy: 0.8190\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "540/750 [====================>.........] - ETA: 1s - loss: 1.1981 - accuracy: 0.6582\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "641/750 [========================>.....] - ETA: 0s - loss: 1.1954 - accuracy: 0.6584\n",
      "515/750 [===================>..........] - ETA: 1s - loss: 0.5451 - accuracy: 0.8213\n",
      " 22/750 [..............................] - ETA: 7s - loss: 0.5894 - accuracy: 0.8033\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "634/750 [========================>.....] - ETA: 0s - loss: 1.1950 - accuracy: 0.6586\n",
      "339/750 [============>.................] - ETA: 3s - loss: 0.5523 - accuracy: 0.8194\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "645/750 [========================>.....] - ETA: 0s - loss: 1.1950 - accuracy: 0.6585\n",
      "667/750 [=========================>....] - ETA: 0s - loss: 0.3488 - accuracy: 0.8757\n",
      "662/750 [=========================>....] - ETA: 0s - loss: 1.1938 - accuracy: 0.6590\n",
      "  3/750 [..............................] - ETA: 1:15 - loss: 0.4095 - accuracy: 0.8854\n",
      "525/750 [====================>.........] - ETA: 1s - loss: 0.5449 - accuracy: 0.8212\n",
      "672/750 [=========================>....] - ETA: 0s - loss: 1.1936 - accuracy: 0.6594\n",
      "  8/750 [..............................] - ETA: 35s - loss: 0.4024 - accuracy: 0.8770\n",
      "675/750 [==========================>...] - ETA: 0s - loss: 1.1931 - accuracy: 0.6596\n",
      " 17/750 [..............................] - ETA: 20s - loss: 0.3633 - accuracy: 0.8787\n",
      " 29/750 [>.............................] - ETA: 14s - loss: 0.3414 - accuracy: 0.8836\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 1.1930 - accuracy: 0.6598\n",
      " 51/750 [=>............................] - ETA: 9s - loss: 0.3397 - accuracy: 0.8836 \n",
      "703/750 [===========================>..] - ETA: 0s - loss: 1.1928 - accuracy: 0.6597\n",
      " 71/750 [=>............................] - ETA: 6s - loss: 0.5661 - accuracy: 0.8143\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "368/750 [=============>................] - ETA: 3s - loss: 0.5497 - accuracy: 0.8209\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 7s - loss: 0.4317 - accuracy: 0.8750\n",
      "430/750 [================>.............] - ETA: 2s - loss: 0.5479 - accuracy: 0.8205\n",
      "578/750 [======================>.......] - ETA: 1s - loss: 0.5463 - accuracy: 0.8203\n",
      "125/750 [====>.........................] - ETA: 5s - loss: 0.5595 - accuracy: 0.8169\n",
      "142/750 [====>.........................] - ETA: 5s - loss: 0.5611 - accuracy: 0.8168\n",
      "730/750 [============================>.] - ETA: 0s - loss: 1.1927 - accuracy: 0.6598\n",
      " 72/750 [=>............................] - ETA: 10s - loss: 0.3422 - accuracy: 0.8804\n",
      "594/750 [======================>.......] - ETA: 1s - loss: 0.5465 - accuracy: 0.8204\n",
      " 86/750 [==>...........................] - ETA: 9s - loss: 0.3377 - accuracy: 0.8821\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 0.5461 - accuracy: 0.8208\n",
      "445/750 [================>.............] - ETA: 2s - loss: 0.5474 - accuracy: 0.8205\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "743/750 [============================>.] - ETA: 0s - loss: 1.1930 - accuracy: 0.6593\n",
      "113/750 [===>..........................] - ETA: 7s - loss: 0.3375 - accuracy: 0.8823\n",
      "204/750 [=======>......................] - ETA: 4s - loss: 0.5588 - accuracy: 0.8171\n",
      "128/750 [====>.........................] - ETA: 7s - loss: 0.3330 - accuracy: 0.8839\n",
      "139/750 [====>.........................] - ETA: 7s - loss: 0.3359 - accuracy: 0.8822\n",
      "462/750 [=================>............] - ETA: 2s - loss: 0.5476 - accuracy: 0.8203\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "150/750 [=====>........................] - ETA: 6s - loss: 0.3339 - accuracy: 0.8828\n",
      "186/750 [======>.......................] - ETA: 4s - loss: 0.5544 - accuracy: 0.8182\n",
      "521/750 [===================>..........] - ETA: 1s - loss: 0.5451 - accuracy: 0.8213\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "274/750 [=========>....................] - ETA: 3s - loss: 0.5531 - accuracy: 0.8182\n",
      "181/750 [======>.......................] - ETA: 6s - loss: 0.3352 - accuracy: 0.8819\n",
      "195/750 [======>.......................] - ETA: 5s - loss: 0.3324 - accuracy: 0.8829\n",
      "567/750 [=====================>........] - ETA: 1s - loss: 0.5460 - accuracy: 0.8204\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.5445 - accuracy: 0.8218\n",
      "230/750 [========>.....................] - ETA: 5s - loss: 0.3340 - accuracy: 0.8823\n",
      "305/750 [===========>..................] - ETA: 3s - loss: 0.5507 - accuracy: 0.8199\n",
      "257/750 [=========>....................] - ETA: 4s - loss: 0.3361 - accuracy: 0.8819\n",
      "  1/750 [..............................] - ETA: 13s - loss: 1.3263 - accuracy: 0.6250\n",
      "275/750 [==========>...................] - ETA: 4s - loss: 0.3358 - accuracy: 0.8823\n",
      " 10/750 [..............................] - ETA: 4s - loss: 1.1630 - accuracy: 0.6891 \n",
      "564/750 [=====================>........] - ETA: 1s - loss: 0.5456 - accuracy: 0.8205\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "651/750 [=========================>....] - ETA: 0s - loss: 0.5449 - accuracy: 0.8215\n",
      " 31/750 [>.............................] - ETA: 5s - loss: 1.1665 - accuracy: 0.6694\n",
      "242/750 [========>.....................] - ETA: 5s - loss: 0.3350 - accuracy: 0.8820\n",
      "590/750 [======================>.......] - ETA: 1s - loss: 0.5463 - accuracy: 0.8204\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "305/750 [===========>..................] - ETA: 4s - loss: 0.3338 - accuracy: 0.8825\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.5452 - accuracy: 0.8213\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 41/750 [>.............................] - ETA: 6s - loss: 1.1623 - accuracy: 0.6658\n",
      " 48/750 [>.............................] - ETA: 6s - loss: 1.1603 - accuracy: 0.6693\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 1.1929 - accuracy: 0.6594 - val_loss: 1.1593 - val_accuracy: 0.6665\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 9/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "312/750 [===========>..................] - ETA: 4s - loss: 0.3334 - accuracy: 0.8827\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.5461 - accuracy: 0.8215\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 54/750 [=>............................] - ETA: 7s - loss: 1.1644 - accuracy: 0.6646\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.5447 - accuracy: 0.8217\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "331/750 [============>.................] - ETA: 3s - loss: 0.3333 - accuracy: 0.8826\n",
      " 75/750 [==>...........................] - ETA: 7s - loss: 1.1644 - accuracy: 0.6631\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.5445 - accuracy: 0.8216\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 94/750 [==>...........................] - ETA: 7s - loss: 1.1644 - accuracy: 0.6587\n",
      "345/750 [============>.................] - ETA: 3s - loss: 0.3325 - accuracy: 0.8827\n",
      "104/750 [===>..........................] - ETA: 7s - loss: 1.1666 - accuracy: 0.6575\n",
      "418/750 [===============>..............] - ETA: 2s - loss: 0.5472 - accuracy: 0.8211\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 89/750 [==>...........................] - ETA: 7s - loss: 1.1640 - accuracy: 0.6601\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "380/750 [==============>...............] - ETA: 3s - loss: 0.3331 - accuracy: 0.8826\n",
      "165/750 [=====>........................] - ETA: 6s - loss: 0.3338 - accuracy: 0.8827\n",
      "391/750 [==============>...............] - ETA: 3s - loss: 0.3340 - accuracy: 0.8823\n",
      "133/750 [====>.........................] - ETA: 6s - loss: 1.1666 - accuracy: 0.6598\n",
      "211/750 [=======>......................] - ETA: 5s - loss: 0.3315 - accuracy: 0.8832\n",
      "419/750 [===============>..............] - ETA: 3s - loss: 0.3345 - accuracy: 0.8821\n",
      "499/750 [==================>...........] - ETA: 2s - loss: 0.5465 - accuracy: 0.8206\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "163/750 [=====>........................] - ETA: 7s - loss: 1.1658 - accuracy: 0.6596\n",
      " 49/750 [>.............................] - ETA: 8s - loss: 0.5205 - accuracy: 0.8316\n",
      "289/750 [==========>...................] - ETA: 4s - loss: 0.3352 - accuracy: 0.8820\n",
      "186/750 [======>.......................] - ETA: 6s - loss: 1.1645 - accuracy: 0.6602\n",
      "476/750 [==================>...........] - ETA: 2s - loss: 0.3358 - accuracy: 0.8809\n",
      "547/750 [====================>.........] - ETA: 1s - loss: 0.5448 - accuracy: 0.8209\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "200/750 [=======>......................] - ETA: 6s - loss: 1.1631 - accuracy: 0.6616\n",
      "642/750 [========================>.....] - ETA: 0s - loss: 0.5456 - accuracy: 0.8212\n",
      "215/750 [=======>......................] - ETA: 5s - loss: 1.1633 - accuracy: 0.6616\n",
      "504/750 [===================>..........] - ETA: 2s - loss: 0.3375 - accuracy: 0.8801\n",
      "217/750 [=======>......................] - ETA: 5s - loss: 1.1624 - accuracy: 0.6623\n",
      "223/750 [=======>......................] - ETA: 5s - loss: 1.1624 - accuracy: 0.6625\n",
      "515/750 [===================>..........] - ETA: 2s - loss: 0.3381 - accuracy: 0.8801\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 17/750 [..............................] - ETA: 9s - loss: 0.5194 - accuracy: 0.8318\n",
      "342/750 [============>.................] - ETA: 3s - loss: 0.3327 - accuracy: 0.8826\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.5454 - accuracy: 0.8215\n",
      "234/750 [========>.....................] - ETA: 5s - loss: 1.1628 - accuracy: 0.6618\n",
      "525/750 [====================>.........] - ETA: 2s - loss: 0.3384 - accuracy: 0.8801\n",
      "241/750 [========>.....................] - ETA: 5s - loss: 1.1629 - accuracy: 0.6618\n",
      "664/750 [=========================>....] - ETA: 0s - loss: 0.5455 - accuracy: 0.8214\n",
      " 19/750 [..............................] - ETA: 11s - loss: 0.5202 - accuracy: 0.8289\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "246/750 [========>.....................] - ETA: 5s - loss: 1.1622 - accuracy: 0.6622\n",
      "532/750 [====================>.........] - ETA: 2s - loss: 0.3381 - accuracy: 0.8802\n",
      "259/750 [=========>....................] - ETA: 5s - loss: 1.1635 - accuracy: 0.6609\n",
      "551/750 [=====================>........] - ETA: 1s - loss: 0.3374 - accuracy: 0.8800\n",
      "121/750 [===>..........................] - ETA: 6s - loss: 0.5223 - accuracy: 0.8294\n",
      "682/750 [==========================>...] - ETA: 0s - loss: 0.5457 - accuracy: 0.8215\n",
      "268/750 [=========>....................] - ETA: 5s - loss: 1.1642 - accuracy: 0.6603\n",
      "274/750 [=========>....................] - ETA: 5s - loss: 1.1638 - accuracy: 0.6604\n",
      " 31/750 [>.............................] - ETA: 9s - loss: 0.5024 - accuracy: 0.8382 \n",
      "287/750 [==========>...................] - ETA: 5s - loss: 1.1640 - accuracy: 0.6596\n",
      " 64/750 [=>............................] - ETA: 7s - loss: 0.5135 - accuracy: 0.8354\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "369/750 [=============>................] - ETA: 3s - loss: 0.3334 - accuracy: 0.8825\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "298/750 [==========>...................] - ETA: 4s - loss: 1.1627 - accuracy: 0.6612\n",
      "305/750 [===========>..................] - ETA: 4s - loss: 1.1631 - accuracy: 0.6607\n",
      "166/750 [=====>........................] - ETA: 5s - loss: 0.5210 - accuracy: 0.8308\n",
      "169/750 [=====>........................] - ETA: 6s - loss: 0.5209 - accuracy: 0.8311\n",
      "577/750 [======================>.......] - ETA: 1s - loss: 0.3364 - accuracy: 0.8803\n",
      "308/750 [===========>..................] - ETA: 4s - loss: 1.1630 - accuracy: 0.6609\n",
      "600/750 [=======================>......] - ETA: 1s - loss: 0.3374 - accuracy: 0.8803\n",
      "321/750 [===========>..................] - ETA: 4s - loss: 1.1608 - accuracy: 0.6617\n",
      "335/750 [============>.................] - ETA: 4s - loss: 1.1584 - accuracy: 0.6628\n",
      "449/750 [================>.............] - ETA: 2s - loss: 0.3344 - accuracy: 0.8817\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "347/750 [============>.................] - ETA: 4s - loss: 1.1581 - accuracy: 0.6629\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.3391 - accuracy: 0.8801\n",
      "111/750 [===>..........................] - ETA: 6s - loss: 0.5220 - accuracy: 0.8288\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "354/750 [=============>................] - ETA: 4s - loss: 1.1585 - accuracy: 0.6623\n",
      "636/750 [========================>.....] - ETA: 1s - loss: 0.3385 - accuracy: 0.8806\n",
      "125/750 [====>.........................] - ETA: 6s - loss: 1.1676 - accuracy: 0.6586\n",
      "644/750 [========================>.....] - ETA: 1s - loss: 0.3383 - accuracy: 0.8806\n",
      "149/750 [====>.........................] - ETA: 6s - loss: 0.5188 - accuracy: 0.8313\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 1.1568 - accuracy: 0.6631\n",
      "653/750 [=========================>....] - ETA: 0s - loss: 0.3384 - accuracy: 0.8805\n",
      "470/750 [=================>............] - ETA: 2s - loss: 0.3358 - accuracy: 0.8812\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "154/750 [=====>........................] - ETA: 7s - loss: 1.1655 - accuracy: 0.6603\n",
      "383/750 [==============>...............] - ETA: 4s - loss: 1.1563 - accuracy: 0.6634\n",
      "673/750 [=========================>....] - ETA: 0s - loss: 0.3386 - accuracy: 0.8805\n",
      "179/750 [======>.......................] - ETA: 6s - loss: 1.1653 - accuracy: 0.6605\n",
      "192/750 [======>.......................] - ETA: 5s - loss: 0.5218 - accuracy: 0.8301\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.3387 - accuracy: 0.8799\n",
      "229/750 [========>.....................] - ETA: 5s - loss: 0.5265 - accuracy: 0.8275\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.3385 - accuracy: 0.8800\n",
      "350/750 [=============>................] - ETA: 3s - loss: 0.5305 - accuracy: 0.8270\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.4972 - accuracy: 0.8281\n",
      "566/750 [=====================>........] - ETA: 1s - loss: 0.3373 - accuracy: 0.8801\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "587/750 [======================>.......] - ETA: 1s - loss: 0.3363 - accuracy: 0.8804\n",
      "613/750 [=======================>......] - ETA: 1s - loss: 0.3378 - accuracy: 0.8803\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "519/750 [===================>..........] - ETA: 2s - loss: 1.1506 - accuracy: 0.6644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:01:56,824 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 7849066496; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 8s 11ms/step - loss: 0.5445 - accuracy: 0.8217 - val_loss: 0.5373 - val_accuracy: 0.8195\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 9/30\n",
      "692/750 [==========================>...] - ETA: 0s - loss: 0.3391 - accuracy: 0.8800\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 70/750 [=>............................] - ETA: 7s - loss: 0.5141 - accuracy: 0.8339\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.3388 - accuracy: 0.8800\n",
      "542/750 [====================>.........] - ETA: 2s - loss: 1.1508 - accuracy: 0.6643\n",
      "550/750 [=====================>........] - ETA: 2s - loss: 1.1505 - accuracy: 0.6644\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.3397 - accuracy: 0.8797\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "580/750 [======================>.......] - ETA: 1s - loss: 1.1482 - accuracy: 0.6648\n",
      "455/750 [=================>............] - ETA: 2s - loss: 0.5302 - accuracy: 0.8268\n",
      "595/750 [======================>.......] - ETA: 1s - loss: 1.1477 - accuracy: 0.6653\n",
      "458/750 [=================>............] - ETA: 2s - loss: 0.5299 - accuracy: 0.8269\n",
      "467/750 [=================>............] - ETA: 2s - loss: 0.5298 - accuracy: 0.8270\n",
      "411/750 [===============>..............] - ETA: 3s - loss: 0.5306 - accuracy: 0.8267\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      " 99/750 [==>...........................] - ETA: 7s - loss: 0.5159 - accuracy: 0.8318\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "394/750 [==============>...............] - ETA: 3s - loss: 0.5305 - accuracy: 0.8268\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "482/750 [==================>...........] - ETA: 2s - loss: 0.5304 - accuracy: 0.8270\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.3398 - accuracy: 0.8797 - val_loss: 0.3660 - val_accuracy: 0.8711\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 10/30\n",
      "  7/750 [..............................] - ETA: 6s - loss: 0.3447 - accuracy: 0.8862 \n",
      "419/750 [===============>..............] - ETA: 3s - loss: 0.5296 - accuracy: 0.8269\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 16/750 [..............................] - ETA: 7s - loss: 0.3394 - accuracy: 0.8867 \n",
      "665/750 [=========================>....] - ETA: 0s - loss: 1.1472 - accuracy: 0.6650\n",
      " 28/750 [>.............................] - ETA: 9s - loss: 0.3340 - accuracy: 0.8895\n",
      "496/750 [==================>...........] - ETA: 2s - loss: 0.5295 - accuracy: 0.8270\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "159/750 [=====>........................] - ETA: 6s - loss: 0.5187 - accuracy: 0.8313\n",
      " 41/750 [>.............................] - ETA: 8s - loss: 0.3421 - accuracy: 0.8861\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 1.1474 - accuracy: 0.6647\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 1.1470 - accuracy: 0.6648\n",
      " 52/750 [=>............................] - ETA: 8s - loss: 0.3370 - accuracy: 0.8849\n",
      "181/750 [======>.......................] - ETA: 6s - loss: 0.5218 - accuracy: 0.8310\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 1.1469 - accuracy: 0.6650\n",
      "541/750 [====================>.........] - ETA: 2s - loss: 0.5331 - accuracy: 0.8254\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "203/750 [=======>......................] - ETA: 5s - loss: 0.5240 - accuracy: 0.8297\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 1.1469 - accuracy: 0.6651\n",
      " 72/750 [=>............................] - ETA: 7s - loss: 0.3377 - accuracy: 0.8832\n",
      "211/750 [=======>......................] - ETA: 5s - loss: 0.5240 - accuracy: 0.8291\n",
      "501/750 [===================>..........] - ETA: 2s - loss: 1.1517 - accuracy: 0.6640\n",
      "740/750 [============================>.] - ETA: 0s - loss: 1.1455 - accuracy: 0.6655\n",
      "509/750 [===================>..........] - ETA: 2s - loss: 0.5311 - accuracy: 0.8264\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "240/750 [========>.....................] - ETA: 5s - loss: 0.5253 - accuracy: 0.8281\n",
      "244/750 [========>.....................] - ETA: 5s - loss: 0.5245 - accuracy: 0.8285\n",
      "270/750 [=========>....................] - ETA: 5s - loss: 0.5241 - accuracy: 0.8278\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "141/750 [====>.........................] - ETA: 6s - loss: 0.3378 - accuracy: 0.8800\n",
      "155/750 [=====>........................] - ETA: 5s - loss: 0.3356 - accuracy: 0.8807\n",
      "295/750 [==========>...................] - ETA: 4s - loss: 0.5272 - accuracy: 0.8265\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "180/750 [======>.......................] - ETA: 5s - loss: 0.3362 - accuracy: 0.8809\n",
      " 64/750 [=>............................] - ETA: 8s - loss: 0.3378 - accuracy: 0.8843\n",
      "366/750 [=============>................] - ETA: 3s - loss: 0.5297 - accuracy: 0.8276\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "162/750 [=====>........................] - ETA: 5s - loss: 0.3370 - accuracy: 0.8805\n",
      "194/750 [======>.......................] - ETA: 5s - loss: 0.3339 - accuracy: 0.8818\n",
      "210/750 [=======>......................] - ETA: 4s - loss: 0.3324 - accuracy: 0.8831\n",
      "218/750 [=======>......................] - ETA: 4s - loss: 0.3342 - accuracy: 0.8821\n",
      "322/750 [===========>..................] - ETA: 4s - loss: 0.5286 - accuracy: 0.8270\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "222/750 [=======>......................] - ETA: 5s - loss: 0.3335 - accuracy: 0.8825\n",
      "224/750 [=======>......................] - ETA: 5s - loss: 0.3329 - accuracy: 0.8827\n",
      "229/750 [========>.....................] - ETA: 5s - loss: 0.3325 - accuracy: 0.8824\n",
      "241/750 [========>.....................] - ETA: 5s - loss: 0.3307 - accuracy: 0.8836\n",
      "448/750 [================>.............] - ETA: 2s - loss: 0.5297 - accuracy: 0.8270\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "336/750 [============>.................] - ETA: 4s - loss: 0.5290 - accuracy: 0.8267\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 1.1470 - accuracy: 0.6654\n",
      "121/750 [===>..........................] - ETA: 6s - loss: 0.3392 - accuracy: 0.8802\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "645/750 [========================>.....] - ETA: 1s - loss: 0.5324 - accuracy: 0.8248\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "254/750 [=========>....................] - ETA: 5s - loss: 0.3308 - accuracy: 0.8831\n",
      "646/750 [========================>.....] - ETA: 1s - loss: 1.1468 - accuracy: 0.6653\n",
      "  1/750 [..............................] - ETA: 5s - loss: 1.0542 - accuracy: 0.6875\n",
      "131/750 [====>.........................] - ETA: 6s - loss: 0.3398 - accuracy: 0.8800\n",
      "658/750 [=========================>....] - ETA: 0s - loss: 0.5322 - accuracy: 0.8249\n",
      "474/750 [=================>............] - ETA: 2s - loss: 1.1527 - accuracy: 0.6641\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "375/750 [==============>...............] - ETA: 3s - loss: 0.5301 - accuracy: 0.8272\n",
      "670/750 [=========================>....] - ETA: 0s - loss: 1.1472 - accuracy: 0.6652\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 25/750 [>.............................] - ETA: 6s - loss: 1.0965 - accuracy: 0.6888\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.5319 - accuracy: 0.8244\n",
      " 56/750 [=>............................] - ETA: 7s - loss: 1.1189 - accuracy: 0.6733\n",
      "328/750 [============>.................] - ETA: 4s - loss: 0.3292 - accuracy: 0.8841\n",
      "341/750 [============>.................] - ETA: 4s - loss: 0.3306 - accuracy: 0.8837\n",
      "568/750 [=====================>........] - ETA: 1s - loss: 0.5341 - accuracy: 0.8245\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "623/750 [=======================>......] - ETA: 1s - loss: 0.5335 - accuracy: 0.8244\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "520/750 [===================>..........] - ETA: 2s - loss: 0.5325 - accuracy: 0.8257\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.5311 - accuracy: 0.8250\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 65/750 [=>............................] - ETA: 17s - loss: 1.1220 - accuracy: 0.6721\n",
      "357/750 [=============>................] - ETA: 4s - loss: 0.3305 - accuracy: 0.8837\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.5327 - accuracy: 0.8244\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 81/750 [==>...........................] - ETA: 14s - loss: 1.1228 - accuracy: 0.6730\n",
      " 19/750 [..............................] - ETA: 4s - loss: 0.5144 - accuracy: 0.8388\n",
      " 93/750 [==>...........................] - ETA: 13s - loss: 1.1226 - accuracy: 0.6720\n",
      "595/750 [======================>.......] - ETA: 1s - loss: 0.5337 - accuracy: 0.8246\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "106/750 [===>..........................] - ETA: 11s - loss: 1.1261 - accuracy: 0.6682\n",
      " 94/750 [==>...........................] - ETA: 7s - loss: 0.3389 - accuracy: 0.8826\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "397/750 [==============>...............] - ETA: 4s - loss: 0.3335 - accuracy: 0.8825\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "116/750 [===>..........................] - ETA: 11s - loss: 1.1248 - accuracy: 0.6685\n",
      "407/750 [===============>..............] - ETA: 4s - loss: 0.3330 - accuracy: 0.8826\n",
      "126/750 [====>.........................] - ETA: 10s - loss: 1.1245 - accuracy: 0.6680\n",
      "415/750 [===============>..............] - ETA: 3s - loss: 0.3326 - accuracy: 0.8828\n",
      "138/750 [====>.........................] - ETA: 10s - loss: 1.1239 - accuracy: 0.6679\n",
      "428/750 [================>.............] - ETA: 3s - loss: 0.3330 - accuracy: 0.8827\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.5315 - accuracy: 0.8250 - val_loss: 0.5269 - val_accuracy: 0.8221\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 10/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 11/750 [..............................] - ETA: 3s - loss: 0.5055 - accuracy: 0.8438\n",
      "152/750 [=====>........................] - ETA: 9s - loss: 1.1213 - accuracy: 0.6689\n",
      "159/750 [=====>........................] - ETA: 9s - loss: 1.1215 - accuracy: 0.6691\n",
      " 18/750 [..............................] - ETA: 4s - loss: 1.0993 - accuracy: 0.6823\n",
      "668/750 [=========================>....] - ETA: 0s - loss: 0.5319 - accuracy: 0.8250\n",
      "167/750 [=====>........................] - ETA: 8s - loss: 1.1209 - accuracy: 0.6678\n",
      "460/750 [=================>............] - ETA: 3s - loss: 0.3323 - accuracy: 0.8834\n",
      "171/750 [=====>........................] - ETA: 8s - loss: 1.1199 - accuracy: 0.6679\n",
      " 99/750 [==>...........................] - ETA: 6s - loss: 0.5378 - accuracy: 0.8288\n",
      " 40/750 [>.............................] - ETA: 5s - loss: 0.5442 - accuracy: 0.8242\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "479/750 [==================>...........] - ETA: 3s - loss: 0.3327 - accuracy: 0.8834\n",
      "133/750 [====>.........................] - ETA: 5s - loss: 0.5325 - accuracy: 0.8291\n",
      " 53/750 [=>............................] - ETA: 5s - loss: 0.5474 - accuracy: 0.8228\n",
      "204/750 [=======>......................] - ETA: 7s - loss: 1.1135 - accuracy: 0.6710\n",
      "494/750 [==================>...........] - ETA: 2s - loss: 0.3346 - accuracy: 0.8827\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.5325 - accuracy: 0.8246\n",
      "505/750 [===================>..........] - ETA: 2s - loss: 0.3337 - accuracy: 0.8830\n",
      " 63/750 [=>............................] - ETA: 6s - loss: 1.1191 - accuracy: 0.6739\n",
      "227/750 [========>.....................] - ETA: 7s - loss: 1.1141 - accuracy: 0.6724\n",
      "520/750 [===================>..........] - ETA: 2s - loss: 0.3333 - accuracy: 0.8833\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.5317 - accuracy: 0.8249\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "532/750 [====================>.........] - ETA: 2s - loss: 0.3327 - accuracy: 0.8836\n",
      "524/750 [===================>..........] - ETA: 2s - loss: 0.3329 - accuracy: 0.8835\n",
      "547/750 [====================>.........] - ETA: 2s - loss: 0.3319 - accuracy: 0.8839\n",
      "269/750 [=========>....................] - ETA: 6s - loss: 1.1149 - accuracy: 0.6709\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "143/750 [====>.........................] - ETA: 5s - loss: 0.5367 - accuracy: 0.8273\n",
      "164/750 [=====>........................] - ETA: 5s - loss: 0.5322 - accuracy: 0.8274\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "580/750 [======================>.......] - ETA: 1s - loss: 0.3319 - accuracy: 0.8835\n",
      "304/750 [===========>..................] - ETA: 5s - loss: 1.1138 - accuracy: 0.6699\n",
      "253/750 [=========>....................] - ETA: 4s - loss: 0.5357 - accuracy: 0.8232\n",
      "289/750 [==========>...................] - ETA: 6s - loss: 1.1136 - accuracy: 0.6710\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "176/750 [======>.......................] - ETA: 5s - loss: 0.5337 - accuracy: 0.8249\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "372/750 [=============>................] - ETA: 4s - loss: 0.3316 - accuracy: 0.8835\n",
      "189/750 [======>.......................] - ETA: 5s - loss: 0.5372 - accuracy: 0.8225\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "214/750 [=======>......................] - ETA: 5s - loss: 0.5353 - accuracy: 0.8240\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.3304 - accuracy: 0.8837\n",
      "360/750 [=============>................] - ETA: 4s - loss: 1.1129 - accuracy: 0.6693\n",
      "294/750 [==========>...................] - ETA: 4s - loss: 0.5338 - accuracy: 0.8248\n",
      "300/750 [===========>..................] - ETA: 4s - loss: 0.5339 - accuracy: 0.8245\n",
      "322/750 [===========>..................] - ETA: 5s - loss: 1.1148 - accuracy: 0.6695\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "215/750 [=======>......................] - ETA: 7s - loss: 1.1144 - accuracy: 0.6714\n",
      "368/750 [=============>................] - ETA: 4s - loss: 1.1123 - accuracy: 0.6697\n",
      "653/750 [=========================>....] - ETA: 1s - loss: 0.3289 - accuracy: 0.8842\n",
      "241/750 [========>.....................] - ETA: 4s - loss: 0.5352 - accuracy: 0.8232\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "443/750 [================>.............] - ETA: 3s - loss: 0.3325 - accuracy: 0.8831\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.3298 - accuracy: 0.8838\n",
      "121/750 [===>..........................] - ETA: 6s - loss: 0.5347 - accuracy: 0.8292\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.3298 - accuracy: 0.8840\n",
      "270/750 [=========>....................] - ETA: 4s - loss: 0.5359 - accuracy: 0.8231\n",
      "348/750 [============>.................] - ETA: 3s - loss: 0.5318 - accuracy: 0.8248\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.3303 - accuracy: 0.8833\n",
      "466/750 [=================>............] - ETA: 3s - loss: 0.3328 - accuracy: 0.8830\n",
      "667/750 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.8839\n",
      "431/750 [================>.............] - ETA: 3s - loss: 1.1101 - accuracy: 0.6693\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.3307 - accuracy: 0.8833\n",
      "366/750 [=============>................] - ETA: 3s - loss: 0.5315 - accuracy: 0.8246\n",
      " 26/750 [>.............................] - ETA: 5s - loss: 0.5250 - accuracy: 0.8383\n",
      "455/750 [=================>............] - ETA: 3s - loss: 1.1099 - accuracy: 0.6695\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.3309 - accuracy: 0.8834\n",
      "462/750 [=================>............] - ETA: 3s - loss: 1.1103 - accuracy: 0.6692\n",
      " 74/750 [=>............................] - ETA: 6s - loss: 0.5452 - accuracy: 0.8250\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "479/750 [==================>...........] - ETA: 3s - loss: 1.1103 - accuracy: 0.6690\n",
      "344/750 [============>.................] - ETA: 3s - loss: 0.5319 - accuracy: 0.8245\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "508/750 [===================>..........] - ETA: 2s - loss: 1.1104 - accuracy: 0.6689\n",
      "450/750 [=================>............] - ETA: 2s - loss: 0.5278 - accuracy: 0.8252\n",
      "461/750 [=================>............] - ETA: 2s - loss: 0.5270 - accuracy: 0.8255\n",
      "469/750 [=================>............] - ETA: 2s - loss: 0.5256 - accuracy: 0.8260\n",
      "550/750 [=====================>........] - ETA: 2s - loss: 1.1093 - accuracy: 0.6694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:02:06,924 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6772379648; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567/750 [=====================>........] - ETA: 2s - loss: 1.1080 - accuracy: 0.6698\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.3309 - accuracy: 0.8837\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "696/750 [==========================>...] - ETA: 0s - loss: 0.3302 - accuracy: 0.8834\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "553/750 [=====================>........] - ETA: 1s - loss: 0.5265 - accuracy: 0.8261\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.3315 - accuracy: 0.8831\n",
      "632/750 [========================>.....] - ETA: 1s - loss: 1.1075 - accuracy: 0.6705\n",
      "  1/750 [..............................] - ETA: 5s - loss: 0.3206 - accuracy: 0.8594\n",
      "598/750 [======================>.......] - ETA: 1s - loss: 1.1076 - accuracy: 0.6706\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  5/750 [..............................] - ETA: 14s - loss: 0.3435 - accuracy: 0.8750\n",
      "578/750 [======================>.......] - ETA: 1s - loss: 0.5248 - accuracy: 0.8268\n",
      " 96/750 [==>...........................] - ETA: 6s - loss: 0.5415 - accuracy: 0.8273\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "392/750 [==============>...............] - ETA: 3s - loss: 0.5304 - accuracy: 0.8246\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "405/750 [===============>..............] - ETA: 3s - loss: 0.5301 - accuracy: 0.8247\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  8/750 [..............................] - ETA: 22s - loss: 0.3364 - accuracy: 0.8750\n",
      "419/750 [===============>..............] - ETA: 3s - loss: 0.5296 - accuracy: 0.8247\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "646/750 [========================>.....] - ETA: 1s - loss: 1.1074 - accuracy: 0.6707\n",
      "  9/750 [..............................] - ETA: 33s - loss: 0.3274 - accuracy: 0.8750\n",
      "658/750 [=========================>....] - ETA: 1s - loss: 1.1071 - accuracy: 0.6708\n",
      " 28/750 [>.............................] - ETA: 12s - loss: 0.3313 - accuracy: 0.8750\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3315 - accuracy: 0.8831 - val_loss: 0.3682 - val_accuracy: 0.8690\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 11/30\n",
      "664/750 [=========================>....] - ETA: 0s - loss: 1.1065 - accuracy: 0.6712\n",
      "607/750 [=======================>......] - ETA: 1s - loss: 0.5246 - accuracy: 0.8268\n",
      " 41/750 [>.............................] - ETA: 12s - loss: 0.3386 - accuracy: 0.8742\n",
      " 46/750 [>.............................] - ETA: 12s - loss: 0.3327 - accuracy: 0.8760\n",
      "475/750 [==================>...........] - ETA: 3s - loss: 1.1103 - accuracy: 0.6690\n",
      " 60/750 [=>............................] - ETA: 10s - loss: 0.3251 - accuracy: 0.8805\n",
      "201/750 [=======>......................] - ETA: 5s - loss: 0.5368 - accuracy: 0.8229\n",
      "492/750 [==================>...........] - ETA: 2s - loss: 0.5251 - accuracy: 0.8266\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 67/750 [=>............................] - ETA: 10s - loss: 0.3222 - accuracy: 0.8827\n",
      "523/750 [===================>..........] - ETA: 2s - loss: 0.5258 - accuracy: 0.8268\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 1.1057 - accuracy: 0.6710\n",
      " 82/750 [==>...........................] - ETA: 9s - loss: 0.3263 - accuracy: 0.8807 \n",
      "228/750 [========>.....................] - ETA: 4s - loss: 0.5366 - accuracy: 0.8228\n",
      " 87/750 [==>...........................] - ETA: 9s - loss: 0.3249 - accuracy: 0.8825\n",
      "669/750 [=========================>....] - ETA: 0s - loss: 0.5238 - accuracy: 0.8275\n",
      "732/750 [============================>.] - ETA: 0s - loss: 1.1054 - accuracy: 0.6709\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "537/750 [====================>.........] - ETA: 2s - loss: 0.5269 - accuracy: 0.8262\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "104/750 [===>..........................] - ETA: 9s - loss: 0.3256 - accuracy: 0.8846\n",
      "750/750 [==============================] - ETA: 0s - loss: 1.1053 - accuracy: 0.6707\n",
      "132/750 [====>.........................] - ETA: 7s - loss: 0.3257 - accuracy: 0.8848\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.5221 - accuracy: 0.8283\n",
      "265/750 [=========>....................] - ETA: 4s - loss: 0.5358 - accuracy: 0.8231\n",
      "141/750 [====>.........................] - ETA: 7s - loss: 0.3259 - accuracy: 0.8849\n",
      "583/750 [======================>.......] - ETA: 1s - loss: 1.1088 - accuracy: 0.6699\n",
      "153/750 [=====>........................] - ETA: 7s - loss: 0.3229 - accuracy: 0.8857\n",
      "159/750 [=====>........................] - ETA: 7s - loss: 0.3251 - accuracy: 0.8849\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.5215 - accuracy: 0.8284\n",
      "283/750 [==========>...................] - ETA: 4s - loss: 0.5333 - accuracy: 0.8251\n",
      "167/750 [=====>........................] - ETA: 7s - loss: 0.3240 - accuracy: 0.8851\n",
      "174/750 [=====>........................] - ETA: 7s - loss: 0.3235 - accuracy: 0.8852\n",
      "648/750 [========================>.....] - ETA: 1s - loss: 0.5236 - accuracy: 0.8274\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "183/750 [======>.......................] - ETA: 7s - loss: 0.3247 - accuracy: 0.8846\n",
      "188/750 [======>.......................] - ETA: 7s - loss: 0.3241 - accuracy: 0.8846\n",
      "357/750 [=============>................] - ETA: 3s - loss: 0.5315 - accuracy: 0.8246\n",
      "200/750 [=======>......................] - ETA: 7s - loss: 0.3252 - accuracy: 0.8841\n",
      "324/750 [===========>..................] - ETA: 4s - loss: 0.5327 - accuracy: 0.8244\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "207/750 [=======>......................] - ETA: 7s - loss: 0.3255 - accuracy: 0.8841\n",
      "683/750 [==========================>...] - ETA: 0s - loss: 0.5230 - accuracy: 0.8279\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "213/750 [=======>......................] - ETA: 7s - loss: 0.3249 - accuracy: 0.8845\n",
      "120/750 [===>..........................] - ETA: 8s - loss: 0.3218 - accuracy: 0.8871\n",
      "224/750 [=======>......................] - ETA: 7s - loss: 0.3236 - accuracy: 0.8843\n",
      "233/750 [========>.....................] - ETA: 6s - loss: 0.3220 - accuracy: 0.8849\n",
      "245/750 [========>.....................] - ETA: 6s - loss: 0.3241 - accuracy: 0.8840\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.5222 - accuracy: 0.8281\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "257/750 [=========>....................] - ETA: 6s - loss: 0.3259 - accuracy: 0.8834\n",
      "434/750 [================>.............] - ETA: 3s - loss: 0.5293 - accuracy: 0.8248\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.5221 - accuracy: 0.8281\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "267/750 [=========>....................] - ETA: 6s - loss: 0.3240 - accuracy: 0.8844\n",
      "272/750 [=========>....................] - ETA: 6s - loss: 0.3228 - accuracy: 0.8847\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 1.1053 - accuracy: 0.6707 - val_loss: 1.0787 - val_accuracy: 0.6759\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 11/30\n",
      "288/750 [==========>...................] - ETA: 5s - loss: 0.3226 - accuracy: 0.8843\n",
      "  9/750 [..............................] - ETA: 10s - loss: 1.0850 - accuracy: 0.6701\n",
      "300/750 [===========>..................] - ETA: 5s - loss: 0.3238 - accuracy: 0.8840\n",
      " 17/750 [..............................] - ETA: 10s - loss: 1.0861 - accuracy: 0.6746\n",
      "507/750 [===================>..........] - ETA: 2s - loss: 0.5270 - accuracy: 0.8264\n",
      "311/750 [===========>..................] - ETA: 5s - loss: 0.3256 - accuracy: 0.8832\n",
      "327/750 [============>.................] - ETA: 5s - loss: 0.3257 - accuracy: 0.8832\n",
      " 51/750 [=>............................] - ETA: 9s - loss: 1.0917 - accuracy: 0.6661 \n",
      "340/750 [============>.................] - ETA: 5s - loss: 0.3249 - accuracy: 0.8839\n",
      " 57/750 [=>............................] - ETA: 9s - loss: 1.0889 - accuracy: 0.6680\n",
      "348/750 [============>.................] - ETA: 5s - loss: 0.3256 - accuracy: 0.8832\n",
      " 65/750 [=>............................] - ETA: 9s - loss: 1.0916 - accuracy: 0.6687\n",
      "353/750 [=============>................] - ETA: 5s - loss: 0.3249 - accuracy: 0.8835\n",
      " 73/750 [=>............................] - ETA: 8s - loss: 1.0916 - accuracy: 0.6721\n",
      "363/750 [=============>................] - ETA: 4s - loss: 0.3247 - accuracy: 0.8835\n",
      " 11/750 [..............................] - ETA: 17s - loss: 0.4887 - accuracy: 0.8324\n",
      "373/750 [=============>................] - ETA: 4s - loss: 0.3244 - accuracy: 0.8837\n",
      "573/750 [=====================>........] - ETA: 1s - loss: 0.5250 - accuracy: 0.8268\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "619/750 [=======================>......] - ETA: 1s - loss: 0.5248 - accuracy: 0.8266\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.5228 - accuracy: 0.8281\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.4744 - accuracy: 0.8438\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "597/750 [======================>.......] - ETA: 1s - loss: 0.5251 - accuracy: 0.8266\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "391/750 [==============>...............] - ETA: 4s - loss: 0.3246 - accuracy: 0.8830\n",
      "105/750 [===>..........................] - ETA: 9s - loss: 1.0894 - accuracy: 0.6740\n",
      " 87/750 [==>...........................] - ETA: 9s - loss: 1.0870 - accuracy: 0.6753\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "395/750 [==============>...............] - ETA: 4s - loss: 0.3244 - accuracy: 0.8830\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 24/750 [..............................] - ETA: 13s - loss: 0.4890 - accuracy: 0.8392\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "119/750 [===>..........................] - ETA: 9s - loss: 1.0869 - accuracy: 0.6748\n",
      "406/750 [===============>..............] - ETA: 4s - loss: 0.3245 - accuracy: 0.8829\n",
      "642/750 [========================>.....] - ETA: 1s - loss: 0.5234 - accuracy: 0.8273\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "415/750 [===============>..............] - ETA: 4s - loss: 0.3247 - accuracy: 0.8830\n",
      "661/750 [=========================>....] - ETA: 0s - loss: 0.5233 - accuracy: 0.8276\n",
      "425/750 [================>.............] - ETA: 4s - loss: 0.3241 - accuracy: 0.8833\n",
      " 69/750 [=>............................] - ETA: 10s - loss: 0.5233 - accuracy: 0.8263\n",
      "432/750 [================>.............] - ETA: 4s - loss: 0.3239 - accuracy: 0.8834\n",
      " 78/750 [==>...........................] - ETA: 10s - loss: 0.5202 - accuracy: 0.8287\n",
      " 46/750 [>.............................] - ETA: 12s - loss: 0.5157 - accuracy: 0.8288\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "441/750 [================>.............] - ETA: 4s - loss: 0.3228 - accuracy: 0.8835\n",
      " 39/750 [>.............................] - ETA: 11s - loss: 0.5063 - accuracy: 0.8337\n",
      " 85/750 [==>...........................] - ETA: 10s - loss: 0.5205 - accuracy: 0.8281\n",
      "448/750 [================>.............] - ETA: 4s - loss: 0.3230 - accuracy: 0.8836\n",
      " 92/750 [==>...........................] - ETA: 10s - loss: 0.5227 - accuracy: 0.8257\n",
      " 63/750 [=>............................] - ETA: 11s - loss: 0.5171 - accuracy: 0.8289\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "173/750 [=====>........................] - ETA: 7s - loss: 1.0814 - accuracy: 0.6775\n",
      "455/750 [=================>............] - ETA: 3s - loss: 0.3218 - accuracy: 0.8844\n",
      "101/750 [===>..........................] - ETA: 10s - loss: 0.5174 - accuracy: 0.8275\n",
      "460/750 [=================>............] - ETA: 3s - loss: 0.3219 - accuracy: 0.8843\n",
      "114/750 [===>..........................] - ETA: 9s - loss: 0.5203 - accuracy: 0.8257\n",
      "474/750 [=================>............] - ETA: 3s - loss: 0.3218 - accuracy: 0.8846\n",
      "126/750 [====>.........................] - ETA: 8s - loss: 0.5174 - accuracy: 0.8263\n",
      " 98/750 [==>...........................] - ETA: 9s - loss: 1.0860 - accuracy: 0.6759\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "487/750 [==================>...........] - ETA: 3s - loss: 0.3219 - accuracy: 0.8845\n",
      "494/750 [==================>...........] - ETA: 3s - loss: 0.3222 - accuracy: 0.8840\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.5203 - accuracy: 0.8289\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "506/750 [===================>..........] - ETA: 3s - loss: 0.3220 - accuracy: 0.8843\n",
      "510/750 [===================>..........] - ETA: 3s - loss: 0.3215 - accuracy: 0.8844\n",
      "148/750 [====>.........................] - ETA: 8s - loss: 0.5136 - accuracy: 0.8279\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "235/750 [========>.....................] - ETA: 6s - loss: 1.0808 - accuracy: 0.6751\n",
      "519/750 [===================>..........] - ETA: 3s - loss: 0.3216 - accuracy: 0.8842\n",
      "522/750 [===================>..........] - ETA: 3s - loss: 0.3222 - accuracy: 0.8839\n",
      "243/750 [========>.....................] - ETA: 6s - loss: 1.0798 - accuracy: 0.6752\n",
      "165/750 [=====>........................] - ETA: 8s - loss: 0.5127 - accuracy: 0.8291\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "528/750 [====================>.........] - ETA: 2s - loss: 0.3221 - accuracy: 0.8838\n",
      "177/750 [======>.......................] - ETA: 8s - loss: 0.5120 - accuracy: 0.8299\n",
      "251/750 [=========>....................] - ETA: 7s - loss: 1.0784 - accuracy: 0.6757\n",
      "537/750 [====================>.........] - ETA: 2s - loss: 0.3216 - accuracy: 0.8840\n",
      "539/750 [====================>.........] - ETA: 2s - loss: 0.3214 - accuracy: 0.8842\n",
      "187/750 [======>.......................] - ETA: 8s - loss: 0.5109 - accuracy: 0.8303\n",
      "184/750 [======>.......................] - ETA: 8s - loss: 0.5117 - accuracy: 0.8301\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "554/750 [=====================>........] - ETA: 2s - loss: 0.3207 - accuracy: 0.8844\n",
      "280/750 [==========>...................] - ETA: 6s - loss: 1.0796 - accuracy: 0.6747\n",
      "563/750 [=====================>........] - ETA: 2s - loss: 0.3208 - accuracy: 0.8846\n",
      "199/750 [======>.......................] - ETA: 8s - loss: 0.5107 - accuracy: 0.8309\n",
      "281/750 [==========>...................] - ETA: 6s - loss: 1.0796 - accuracy: 0.6748\n",
      "202/750 [=======>......................] - ETA: 8s - loss: 0.5119 - accuracy: 0.8305\n",
      "315/750 [===========>..................] - ETA: 5s - loss: 0.3254 - accuracy: 0.8834\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "284/750 [==========>...................] - ETA: 6s - loss: 1.0794 - accuracy: 0.6752\n",
      "566/750 [=====================>........] - ETA: 2s - loss: 0.3203 - accuracy: 0.8849\n",
      "217/750 [=======>......................] - ETA: 7s - loss: 0.5126 - accuracy: 0.8308\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "577/750 [======================>.......] - ETA: 2s - loss: 0.3204 - accuracy: 0.8849\n",
      "222/750 [=======>......................] - ETA: 7s - loss: 0.5140 - accuracy: 0.8304\n",
      "224/750 [=======>......................] - ETA: 7s - loss: 0.5131 - accuracy: 0.8307\n",
      "595/750 [======================>.......] - ETA: 2s - loss: 0.3202 - accuracy: 0.8853\n",
      "238/750 [========>.....................] - ETA: 7s - loss: 1.0805 - accuracy: 0.6750\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 0.3201 - accuracy: 0.8855\n",
      "332/750 [============>.................] - ETA: 5s - loss: 1.0817 - accuracy: 0.6731\n",
      "256/750 [=========>....................] - ETA: 7s - loss: 0.5087 - accuracy: 0.8323\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.3214 - accuracy: 0.8851\n",
      "351/750 [=============>................] - ETA: 5s - loss: 1.0813 - accuracy: 0.6724\n",
      "633/750 [========================>.....] - ETA: 1s - loss: 0.3223 - accuracy: 0.8849\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.3223 - accuracy: 0.8849\n",
      "273/750 [=========>....................] - ETA: 7s - loss: 0.5085 - accuracy: 0.8326\n",
      "640/750 [========================>.....] - ETA: 1s - loss: 0.3221 - accuracy: 0.8851\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.5204 - accuracy: 0.8288 - val_loss: 0.5177 - val_accuracy: 0.8246\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 11/30\n",
      "285/750 [==========>...................] - ETA: 6s - loss: 0.5082 - accuracy: 0.8334\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "653/750 [=========================>....] - ETA: 1s - loss: 0.3223 - accuracy: 0.8849\n",
      "665/750 [=========================>....] - ETA: 1s - loss: 0.3222 - accuracy: 0.8848\n",
      " 19/750 [..............................] - ETA: 14s - loss: 0.4917 - accuracy: 0.8380\n",
      "666/750 [=========================>....] - ETA: 1s - loss: 0.3221 - accuracy: 0.8848\n",
      "671/750 [=========================>....] - ETA: 1s - loss: 0.3223 - accuracy: 0.8848\n",
      "313/750 [===========>..................] - ETA: 6s - loss: 0.5043 - accuracy: 0.8340\n",
      "313/750 [===========>..................] - ETA: 6s - loss: 1.0797 - accuracy: 0.6741\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "331/750 [============>.................] - ETA: 5s - loss: 1.0819 - accuracy: 0.6729\n",
      "339/750 [============>.................] - ETA: 5s - loss: 1.0820 - accuracy: 0.6724\n",
      "416/750 [===============>..............] - ETA: 4s - loss: 1.0790 - accuracy: 0.6739\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.3235 - accuracy: 0.8846\n",
      "417/750 [===============>..............] - ETA: 4s - loss: 1.0792 - accuracy: 0.6738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:02:16,925 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6771417088; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337/750 [============>.................] - ETA: 6s - loss: 0.5042 - accuracy: 0.8344\n",
      "366/750 [=============>................] - ETA: 5s - loss: 1.0813 - accuracy: 0.6728\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.3235 - accuracy: 0.8846\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.3243 - accuracy: 0.8845\n",
      "359/750 [=============>................] - ETA: 5s - loss: 0.5045 - accuracy: 0.8345\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "613/750 [=======================>......] - ETA: 1s - loss: 0.3211 - accuracy: 0.8852\n",
      "692/750 [==========================>...] - ETA: 0s - loss: 0.3230 - accuracy: 0.8847\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "451/750 [=================>............] - ETA: 4s - loss: 1.0801 - accuracy: 0.6728\n",
      "380/750 [==============>...............] - ETA: 5s - loss: 0.5084 - accuracy: 0.8328\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.3243 - accuracy: 0.8844\n",
      "590/750 [======================>.......] - ETA: 2s - loss: 0.3204 - accuracy: 0.8852\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "399/750 [==============>...............] - ETA: 4s - loss: 1.0791 - accuracy: 0.6740\n",
      "395/750 [==============>...............] - ETA: 5s - loss: 0.5093 - accuracy: 0.8324\n",
      "392/750 [==============>...............] - ETA: 5s - loss: 0.5092 - accuracy: 0.8326\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "477/750 [==================>...........] - ETA: 3s - loss: 1.0781 - accuracy: 0.6738\n",
      "419/750 [===============>..............] - ETA: 4s - loss: 0.5093 - accuracy: 0.8326\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "501/750 [===================>..........] - ETA: 3s - loss: 1.0783 - accuracy: 0.6733\n",
      "429/750 [================>.............] - ETA: 4s - loss: 1.0794 - accuracy: 0.6735\n",
      "430/750 [================>.............] - ETA: 4s - loss: 1.0795 - accuracy: 0.6735\n",
      "444/750 [================>.............] - ETA: 4s - loss: 0.5089 - accuracy: 0.8323\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "171/750 [=====>........................] - ETA: 8s - loss: 0.5139 - accuracy: 0.8288\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "470/750 [=================>............] - ETA: 3s - loss: 1.0791 - accuracy: 0.6730\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "484/750 [==================>...........] - ETA: 3s - loss: 0.5098 - accuracy: 0.8322\n",
      "468/750 [=================>............] - ETA: 3s - loss: 0.5094 - accuracy: 0.8320\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "564/750 [=====================>........] - ETA: 2s - loss: 1.0766 - accuracy: 0.6735\n",
      "494/750 [==================>...........] - ETA: 3s - loss: 0.5091 - accuracy: 0.8325\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 1.0751 - accuracy: 0.6742\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.3241 - accuracy: 0.8845\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "524/750 [===================>..........] - ETA: 3s - loss: 0.5098 - accuracy: 0.8332\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "623/750 [=======================>......] - ETA: 1s - loss: 1.0749 - accuracy: 0.6741\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.3244 - accuracy: 0.8843 - val_loss: 0.3586 - val_accuracy: 0.8761\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 12/30\n",
      "  1/750 [..............................] - ETA: 5s - loss: 0.4505 - accuracy: 0.8594\n",
      "236/750 [========>.....................] - ETA: 7s - loss: 0.5110 - accuracy: 0.8315\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "640/750 [========================>.....] - ETA: 1s - loss: 1.0745 - accuracy: 0.6740\n",
      " 16/750 [..............................] - ETA: 6s - loss: 0.3199 - accuracy: 0.8877\n",
      "503/750 [===================>..........] - ETA: 3s - loss: 0.5099 - accuracy: 0.8324\n",
      " 22/750 [..............................] - ETA: 8s - loss: 0.3158 - accuracy: 0.8878\n",
      " 28/750 [>.............................] - ETA: 7s - loss: 0.3221 - accuracy: 0.8873\n",
      "539/750 [====================>.........] - ETA: 2s - loss: 0.5095 - accuracy: 0.8330\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 40/750 [>.............................] - ETA: 8s - loss: 0.3177 - accuracy: 0.8867\n",
      " 53/750 [=>............................] - ETA: 7s - loss: 0.3136 - accuracy: 0.8856\n",
      "192/750 [======>.......................] - ETA: 8s - loss: 0.5112 - accuracy: 0.8306\n",
      "555/750 [=====================>........] - ETA: 2s - loss: 0.5100 - accuracy: 0.8329\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 65/750 [=>............................] - ETA: 7s - loss: 0.3148 - accuracy: 0.8856\n",
      "623/750 [=======================>......] - ETA: 1s - loss: 0.5092 - accuracy: 0.8325\n",
      "299/750 [==========>...................] - ETA: 6s - loss: 0.5071 - accuracy: 0.8337\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "561/750 [=====================>........] - ETA: 2s - loss: 0.5092 - accuracy: 0.8330\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 69/750 [=>............................] - ETA: 7s - loss: 0.3190 - accuracy: 0.8841\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 1.0720 - accuracy: 0.6752\n",
      " 73/750 [=>............................] - ETA: 7s - loss: 0.3178 - accuracy: 0.8844\n",
      "323/750 [===========>..................] - ETA: 6s - loss: 0.5037 - accuracy: 0.8345\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 1.0717 - accuracy: 0.6754\n",
      " 83/750 [==>...........................] - ETA: 7s - loss: 0.3188 - accuracy: 0.8846\n",
      " 90/750 [==>...........................] - ETA: 7s - loss: 0.3152 - accuracy: 0.8863\n",
      "726/750 [============================>.] - ETA: 0s - loss: 1.0716 - accuracy: 0.6749\n",
      " 92/750 [==>...........................] - ETA: 8s - loss: 0.3164 - accuracy: 0.8867\n",
      " 99/750 [==>...........................] - ETA: 8s - loss: 0.3144 - accuracy: 0.8876\n",
      "107/750 [===>..........................] - ETA: 8s - loss: 0.3127 - accuracy: 0.8881\n",
      "248/750 [========>.....................] - ETA: 7s - loss: 0.5097 - accuracy: 0.8322\n",
      "111/750 [===>..........................] - ETA: 8s - loss: 0.3122 - accuracy: 0.8884\n",
      "327/750 [============>.................] - ETA: 6s - loss: 0.5042 - accuracy: 0.8345\n",
      "266/750 [=========>....................] - ETA: 7s - loss: 0.5106 - accuracy: 0.8316\n",
      "123/750 [===>..........................] - ETA: 8s - loss: 0.3117 - accuracy: 0.8880\n",
      "127/750 [====>.........................] - ETA: 8s - loss: 0.3127 - accuracy: 0.8878\n",
      "350/750 [=============>................] - ETA: 5s - loss: 0.5039 - accuracy: 0.8344\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.5092 - accuracy: 0.8322\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "137/750 [====>.........................] - ETA: 8s - loss: 0.3177 - accuracy: 0.8864\n",
      "145/750 [====>.........................] - ETA: 8s - loss: 0.3163 - accuracy: 0.8865\n",
      "296/750 [==========>...................] - ETA: 6s - loss: 0.5074 - accuracy: 0.8338\n",
      "148/750 [====>.........................] - ETA: 8s - loss: 0.3187 - accuracy: 0.8857\n",
      "673/750 [=========================>....] - ETA: 0s - loss: 0.5108 - accuracy: 0.8318\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "653/750 [=========================>....] - ETA: 1s - loss: 0.5095 - accuracy: 0.8322\n",
      "157/750 [=====>........................] - ETA: 8s - loss: 0.3183 - accuracy: 0.8860\n",
      "168/750 [=====>........................] - ETA: 8s - loss: 0.3164 - accuracy: 0.8868\n",
      "319/750 [===========>..................] - ETA: 6s - loss: 0.5038 - accuracy: 0.8345\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "187/750 [======>.......................] - ETA: 7s - loss: 0.3159 - accuracy: 0.8883\n",
      "195/750 [======>.......................] - ETA: 7s - loss: 0.3179 - accuracy: 0.8877\n",
      "197/750 [======>.......................] - ETA: 7s - loss: 0.3193 - accuracy: 0.8874\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 1.0720 - accuracy: 0.6749\n",
      "206/750 [=======>......................] - ETA: 7s - loss: 0.3197 - accuracy: 0.8873\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.5107 - accuracy: 0.8317\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "210/750 [=======>......................] - ETA: 7s - loss: 0.3187 - accuracy: 0.8879\n",
      "216/750 [=======>......................] - ETA: 7s - loss: 0.3171 - accuracy: 0.8886\n",
      "225/750 [========>.....................] - ETA: 7s - loss: 0.3164 - accuracy: 0.8893\n",
      "366/750 [=============>................] - ETA: 5s - loss: 0.5056 - accuracy: 0.8339\n",
      "236/750 [========>.....................] - ETA: 6s - loss: 0.3184 - accuracy: 0.8878\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.5111 - accuracy: 0.8315\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "455/750 [=================>............] - ETA: 4s - loss: 0.5090 - accuracy: 0.8323\n",
      "240/750 [========>.....................] - ETA: 7s - loss: 0.3181 - accuracy: 0.8882\n",
      "747/750 [============================>.] - ETA: 0s - loss: 1.0714 - accuracy: 0.6752\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "249/750 [========>.....................] - ETA: 6s - loss: 0.3180 - accuracy: 0.8879\n",
      "595/750 [======================>.......] - ETA: 2s - loss: 0.5082 - accuracy: 0.8331\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "260/750 [=========>....................] - ETA: 6s - loss: 0.3195 - accuracy: 0.8874\n",
      "478/750 [==================>...........] - ETA: 3s - loss: 0.5101 - accuracy: 0.8319\n",
      "273/750 [=========>....................] - ETA: 6s - loss: 0.3178 - accuracy: 0.8876\n",
      "284/750 [==========>...................] - ETA: 6s - loss: 0.3181 - accuracy: 0.8877\n",
      "292/750 [==========>...................] - ETA: 6s - loss: 0.3172 - accuracy: 0.8877\n",
      "  9/750 [..............................] - ETA: 9s - loss: 1.0893 - accuracy: 0.6771\n",
      "302/750 [===========>..................] - ETA: 5s - loss: 0.3180 - accuracy: 0.8873\n",
      "310/750 [===========>..................] - ETA: 5s - loss: 0.3168 - accuracy: 0.8881\n",
      " 34/750 [>.............................] - ETA: 6s - loss: 1.0780 - accuracy: 0.6737\n",
      "325/750 [============>.................] - ETA: 5s - loss: 0.3164 - accuracy: 0.8876\n",
      "173/750 [=====>........................] - ETA: 7s - loss: 0.3163 - accuracy: 0.8876\n",
      "327/750 [============>.................] - ETA: 5s - loss: 0.3163 - accuracy: 0.8876\n",
      "336/750 [============>.................] - ETA: 5s - loss: 0.3154 - accuracy: 0.8880\n",
      "572/750 [=====================>........] - ETA: 2s - loss: 0.5099 - accuracy: 0.8329\n",
      "347/750 [============>.................] - ETA: 5s - loss: 0.3143 - accuracy: 0.8884\n",
      "352/750 [=============>................] - ETA: 5s - loss: 0.3144 - accuracy: 0.8884\n",
      "365/750 [=============>................] - ETA: 5s - loss: 0.3125 - accuracy: 0.8891\n",
      " 17/750 [..............................] - ETA: 11s - loss: 0.4810 - accuracy: 0.8392\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.5091 - accuracy: 0.8325\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.5107 - accuracy: 0.8313\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "374/750 [=============>................] - ETA: 4s - loss: 0.3140 - accuracy: 0.8883\n",
      " 25/750 [>.............................] - ETA: 9s - loss: 0.4818 - accuracy: 0.8363 \n",
      " 81/750 [==>...........................] - ETA: 9s - loss: 1.0514 - accuracy: 0.6865\n",
      "378/750 [==============>...............] - ETA: 4s - loss: 0.3143 - accuracy: 0.8881\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.5109 - accuracy: 0.8311 - val_loss: 0.5093 - val_accuracy: 0.8274\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 12/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.5345 - accuracy: 0.8125\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "642/750 [========================>.....] - ETA: 1s - loss: 0.5095 - accuracy: 0.8321\n",
      " 16/750 [..............................] - ETA: 10s - loss: 1.0682 - accuracy: 0.6895\n",
      "389/750 [==============>...............] - ETA: 4s - loss: 0.3141 - accuracy: 0.8883\n",
      " 42/750 [>.............................] - ETA: 9s - loss: 0.4951 - accuracy: 0.8296 \n",
      "401/750 [===============>..............] - ETA: 4s - loss: 0.3141 - accuracy: 0.8882\n",
      "100/750 [===>..........................] - ETA: 9s - loss: 1.0459 - accuracy: 0.6869\n",
      " 37/750 [>.............................] - ETA: 9s - loss: 1.0743 - accuracy: 0.6748\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "105/750 [===>..........................] - ETA: 9s - loss: 1.0453 - accuracy: 0.6868\n",
      "407/750 [===============>..............] - ETA: 4s - loss: 0.3141 - accuracy: 0.8884\n",
      " 60/750 [=>............................] - ETA: 9s - loss: 0.5011 - accuracy: 0.8323\n",
      " 49/750 [>.............................] - ETA: 10s - loss: 0.4905 - accuracy: 0.8313\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "416/750 [===============>..............] - ETA: 4s - loss: 0.3146 - accuracy: 0.8881\n",
      "422/750 [===============>..............] - ETA: 4s - loss: 0.3147 - accuracy: 0.8878\n",
      " 74/750 [=>............................] - ETA: 9s - loss: 0.4965 - accuracy: 0.8355\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "433/750 [================>.............] - ETA: 4s - loss: 0.3148 - accuracy: 0.8881\n",
      "439/750 [================>.............] - ETA: 4s - loss: 0.3135 - accuracy: 0.8887\n",
      " 64/750 [=>............................] - ETA: 9s - loss: 0.4945 - accuracy: 0.8347\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.5106 - accuracy: 0.8317\n",
      "449/750 [================>.............] - ETA: 3s - loss: 0.3148 - accuracy: 0.8877\n",
      "154/750 [=====>........................] - ETA: 8s - loss: 1.0469 - accuracy: 0.6853\n",
      "457/750 [=================>............] - ETA: 3s - loss: 0.3155 - accuracy: 0.8875\n",
      "106/750 [===>..........................] - ETA: 8s - loss: 0.4977 - accuracy: 0.8349\n",
      " 94/750 [==>...........................] - ETA: 8s - loss: 0.4974 - accuracy: 0.8348\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "466/750 [=================>............] - ETA: 3s - loss: 0.3162 - accuracy: 0.8871\n",
      " 95/750 [==>...........................] - ETA: 9s - loss: 1.0473 - accuracy: 0.6868\n",
      "178/750 [======>.......................] - ETA: 7s - loss: 1.0469 - accuracy: 0.6837\n",
      "477/750 [==================>...........] - ETA: 3s - loss: 0.3175 - accuracy: 0.8867\n",
      "127/750 [====>.........................] - ETA: 7s - loss: 0.5006 - accuracy: 0.8335\n",
      "488/750 [==================>...........] - ETA: 3s - loss: 0.3171 - accuracy: 0.8865\n",
      "200/750 [=======>......................] - ETA: 6s - loss: 1.0527 - accuracy: 0.6809\n",
      "502/750 [===================>..........] - ETA: 3s - loss: 0.3169 - accuracy: 0.8861\n",
      "150/750 [=====>........................] - ETA: 7s - loss: 0.4973 - accuracy: 0.8351\n",
      "119/750 [===>..........................] - ETA: 7s - loss: 0.5035 - accuracy: 0.8322\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "509/750 [===================>..........] - ETA: 3s - loss: 0.3169 - accuracy: 0.8861\n",
      "214/750 [=======>......................] - ETA: 6s - loss: 1.0522 - accuracy: 0.6813\n",
      "518/750 [===================>..........] - ETA: 2s - loss: 0.3164 - accuracy: 0.8863\n",
      "528/750 [====================>.........] - ETA: 2s - loss: 0.3164 - accuracy: 0.8865\n",
      "232/750 [========>.....................] - ETA: 6s - loss: 1.0518 - accuracy: 0.6815\n",
      "537/750 [====================>.........] - ETA: 2s - loss: 0.3169 - accuracy: 0.8867\n",
      "141/750 [====>.........................] - ETA: 7s - loss: 0.4983 - accuracy: 0.8347\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "238/750 [========>.....................] - ETA: 6s - loss: 1.0520 - accuracy: 0.6807\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.3170 - accuracy: 0.8867\n",
      "553/750 [=====================>........] - ETA: 2s - loss: 0.3173 - accuracy: 0.8865\n",
      "556/750 [=====================>........] - ETA: 2s - loss: 0.3172 - accuracy: 0.8865\n",
      "170/750 [=====>........................] - ETA: 7s - loss: 0.4991 - accuracy: 0.8338\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "569/750 [=====================>........] - ETA: 2s - loss: 0.3170 - accuracy: 0.8866\n",
      "275/750 [==========>...................] - ETA: 6s - loss: 1.0523 - accuracy: 0.6809\n",
      "292/750 [==========>...................] - ETA: 5s - loss: 1.0547 - accuracy: 0.6790\n",
      "196/750 [======>.......................] - ETA: 6s - loss: 0.5008 - accuracy: 0.8333\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "300/750 [===========>..................] - ETA: 5s - loss: 1.0543 - accuracy: 0.6792\n",
      "601/750 [=======================>......] - ETA: 1s - loss: 0.3164 - accuracy: 0.8871\n",
      "608/750 [=======================>......] - ETA: 1s - loss: 0.3166 - accuracy: 0.8869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:02:27,022 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6856269824; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/750 [======>.......................] - ETA: 6s - loss: 0.5013 - accuracy: 0.8339\n",
      "278/750 [==========>...................] - ETA: 5s - loss: 0.4993 - accuracy: 0.8348\n",
      "206/750 [=======>......................] - ETA: 6s - loss: 1.0532 - accuracy: 0.6814\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.3161 - accuracy: 0.8868\n",
      "637/750 [========================>.....] - ETA: 1s - loss: 0.3172 - accuracy: 0.8864\n",
      "227/750 [========>.....................] - ETA: 6s - loss: 0.4953 - accuracy: 0.8365\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "353/750 [=============>................] - ETA: 4s - loss: 1.0500 - accuracy: 0.6798\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.3166 - accuracy: 0.8865\n",
      "248/750 [========>.....................] - ETA: 5s - loss: 0.4959 - accuracy: 0.8364\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "658/750 [=========================>....] - ETA: 1s - loss: 0.3162 - accuracy: 0.8866\n",
      "669/750 [=========================>....] - ETA: 1s - loss: 0.3160 - accuracy: 0.8867\n",
      "586/750 [======================>.......] - ETA: 2s - loss: 0.3160 - accuracy: 0.8872\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "676/750 [==========================>...] - ETA: 0s - loss: 0.3159 - accuracy: 0.8867\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.3160 - accuracy: 0.8867\n",
      "269/750 [=========>....................] - ETA: 5s - loss: 0.4971 - accuracy: 0.8360\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "683/750 [==========================>...] - ETA: 0s - loss: 0.3163 - accuracy: 0.8867\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.3175 - accuracy: 0.8862\n",
      "299/750 [==========>...................] - ETA: 5s - loss: 0.4967 - accuracy: 0.8354\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.3176 - accuracy: 0.8863\n",
      "  8/750 [..............................] - ETA: 13s - loss: 0.4978 - accuracy: 0.8242\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.3179 - accuracy: 0.8863\n",
      "315/750 [===========>..................] - ETA: 5s - loss: 0.4969 - accuracy: 0.8356\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.3178 - accuracy: 0.8864\n",
      "377/750 [==============>...............] - ETA: 4s - loss: 0.4985 - accuracy: 0.8352\n",
      "326/750 [============>.................] - ETA: 4s - loss: 0.4964 - accuracy: 0.8354\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "427/750 [================>.............] - ETA: 4s - loss: 1.0498 - accuracy: 0.6794\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.3180 - accuracy: 0.8863\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.3178 - accuracy: 0.8864\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.8864\n",
      "343/750 [============>.................] - ETA: 4s - loss: 0.4976 - accuracy: 0.8349\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "450/750 [=================>............] - ETA: 3s - loss: 1.0493 - accuracy: 0.6786\n",
      "368/750 [=============>................] - ETA: 4s - loss: 0.4969 - accuracy: 0.8356\n",
      "467/750 [=================>............] - ETA: 3s - loss: 1.0480 - accuracy: 0.6790\n",
      "482/750 [==================>...........] - ETA: 3s - loss: 1.0469 - accuracy: 0.6795\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.3162 - accuracy: 0.8867\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.3182 - accuracy: 0.8865\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "358/750 [=============>................] - ETA: 4s - loss: 0.4970 - accuracy: 0.8353\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "487/750 [==================>...........] - ETA: 3s - loss: 1.0468 - accuracy: 0.6795\n",
      "390/750 [==============>...............] - ETA: 4s - loss: 1.0489 - accuracy: 0.6801\n",
      "397/750 [==============>...............] - ETA: 4s - loss: 0.4986 - accuracy: 0.8350\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "403/750 [===============>..............] - ETA: 4s - loss: 0.4988 - accuracy: 0.8349\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "420/750 [===============>..............] - ETA: 4s - loss: 0.4991 - accuracy: 0.8349\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "410/750 [===============>..............] - ETA: 4s - loss: 0.4998 - accuracy: 0.8348\n",
      "433/750 [================>.............] - ETA: 3s - loss: 0.4996 - accuracy: 0.8352\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "449/750 [================>.............] - ETA: 3s - loss: 0.5001 - accuracy: 0.8347\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "468/750 [=================>............] - ETA: 3s - loss: 0.4983 - accuracy: 0.8353\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "576/750 [======================>.......] - ETA: 2s - loss: 1.0450 - accuracy: 0.6798\n",
      "476/750 [==================>...........] - ETA: 3s - loss: 1.0475 - accuracy: 0.6795\n",
      "493/750 [==================>...........] - ETA: 3s - loss: 0.4973 - accuracy: 0.8354\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "503/750 [===================>..........] - ETA: 3s - loss: 0.4968 - accuracy: 0.8356\n",
      "510/750 [===================>..........] - ETA: 2s - loss: 0.4970 - accuracy: 0.8353\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "607/750 [=======================>......] - ETA: 1s - loss: 1.0446 - accuracy: 0.6794\n",
      "212/750 [=======>......................] - ETA: 6s - loss: 0.4983 - accuracy: 0.8353\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "521/750 [===================>..........] - ETA: 2s - loss: 0.4976 - accuracy: 0.8354\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "619/750 [=======================>......] - ETA: 1s - loss: 1.0444 - accuracy: 0.6793\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.3181 - accuracy: 0.8865 - val_loss: 0.3503 - val_accuracy: 0.8769\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 13/30\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.2640 - accuracy: 0.8906\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.4988 - accuracy: 0.8352\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "633/750 [========================>.....] - ETA: 1s - loss: 1.0443 - accuracy: 0.6794\n",
      "537/750 [====================>.........] - ETA: 2s - loss: 1.0451 - accuracy: 0.6802\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 23/750 [..............................] - ETA: 7s - loss: 0.3320 - accuracy: 0.8791\n",
      "551/750 [=====================>........] - ETA: 2s - loss: 1.0454 - accuracy: 0.6796\n",
      " 33/750 [>.............................] - ETA: 7s - loss: 0.3296 - accuracy: 0.8849\n",
      "554/750 [=====================>........] - ETA: 2s - loss: 0.4987 - accuracy: 0.8350\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 44/750 [>.............................] - ETA: 7s - loss: 0.3289 - accuracy: 0.8864\n",
      "561/750 [=====================>........] - ETA: 2s - loss: 0.4989 - accuracy: 0.8350\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 1.0424 - accuracy: 0.6802\n",
      " 61/750 [=>............................] - ETA: 6s - loss: 0.3247 - accuracy: 0.8873\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.5007 - accuracy: 0.8342\n",
      "284/750 [==========>...................] - ETA: 5s - loss: 0.4979 - accuracy: 0.8351\n",
      "691/750 [==========================>...] - ETA: 0s - loss: 1.0423 - accuracy: 0.6804\n",
      " 71/750 [=>............................] - ETA: 6s - loss: 0.3216 - accuracy: 0.8869\n",
      " 80/750 [==>...........................] - ETA: 6s - loss: 0.3164 - accuracy: 0.8889\n",
      "681/750 [==========================>...] - ETA: 0s - loss: 0.5011 - accuracy: 0.8338\n",
      "306/750 [===========>..................] - ETA: 5s - loss: 0.4966 - accuracy: 0.8354\n",
      "608/750 [=======================>......] - ETA: 1s - loss: 0.5004 - accuracy: 0.8351\n",
      " 91/750 [==>...........................] - ETA: 6s - loss: 0.3149 - accuracy: 0.8901\n",
      " 99/750 [==>...........................] - ETA: 6s - loss: 0.3128 - accuracy: 0.8903\n",
      "110/750 [===>..........................] - ETA: 6s - loss: 0.3153 - accuracy: 0.8891\n",
      "125/750 [====>.........................] - ETA: 6s - loss: 0.3176 - accuracy: 0.8886\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.5020 - accuracy: 0.8338\n",
      "643/750 [========================>.....] - ETA: 1s - loss: 0.4992 - accuracy: 0.8349\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "139/750 [====>.........................] - ETA: 5s - loss: 0.3187 - accuracy: 0.8887\n",
      "350/750 [=============>................] - ETA: 4s - loss: 0.4971 - accuracy: 0.8352\n",
      "149/750 [====>.........................] - ETA: 5s - loss: 0.3161 - accuracy: 0.8892\n",
      "665/750 [=========================>....] - ETA: 1s - loss: 0.5013 - accuracy: 0.8339\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "161/750 [=====>........................] - ETA: 5s - loss: 0.3163 - accuracy: 0.8898\n",
      "178/750 [======>.......................] - ETA: 5s - loss: 0.3184 - accuracy: 0.8887\n",
      "180/750 [======>.......................] - ETA: 5s - loss: 0.3176 - accuracy: 0.8888\n",
      "594/750 [======================>.......] - ETA: 1s - loss: 0.5004 - accuracy: 0.8348\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 1.0427 - accuracy: 0.6801\n",
      "186/750 [======>.......................] - ETA: 5s - loss: 0.3168 - accuracy: 0.8890\n",
      "193/750 [======>.......................] - ETA: 5s - loss: 0.3155 - accuracy: 0.8900\n",
      "204/750 [=======>......................] - ETA: 5s - loss: 0.3146 - accuracy: 0.8902\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.5011 - accuracy: 0.8341\n",
      "217/750 [=======>......................] - ETA: 5s - loss: 0.3143 - accuracy: 0.8898\n",
      " 15/750 [..............................] - ETA: 2s - loss: 0.3260 - accuracy: 0.8823\n",
      "230/750 [========>.....................] - ETA: 5s - loss: 0.3131 - accuracy: 0.8899\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.5015 - accuracy: 0.8341\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "242/750 [========>.....................] - ETA: 5s - loss: 0.3138 - accuracy: 0.8895\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 1.0433 - accuracy: 0.6798\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "253/750 [=========>....................] - ETA: 5s - loss: 0.3112 - accuracy: 0.8902\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.5026 - accuracy: 0.8335\n",
      "264/750 [=========>....................] - ETA: 4s - loss: 0.3096 - accuracy: 0.8911\n",
      "276/750 [==========>...................] - ETA: 4s - loss: 0.3114 - accuracy: 0.8905\n",
      "289/750 [==========>...................] - ETA: 4s - loss: 0.3107 - accuracy: 0.8905\n",
      "474/750 [=================>............] - ETA: 3s - loss: 0.4979 - accuracy: 0.8354\n",
      " 16/750 [..............................] - ETA: 2s - loss: 1.0326 - accuracy: 0.6572\n",
      "298/750 [==========>...................] - ETA: 4s - loss: 0.3115 - accuracy: 0.8903\n",
      " 26/750 [>.............................] - ETA: 3s - loss: 1.0338 - accuracy: 0.6659\n",
      "307/750 [===========>..................] - ETA: 4s - loss: 0.3125 - accuracy: 0.8900\n",
      " 15/750 [..............................] - ETA: 3s - loss: 0.4876 - accuracy: 0.8406\n",
      "313/750 [===========>..................] - ETA: 4s - loss: 0.3127 - accuracy: 0.8899\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.5024 - accuracy: 0.8336\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "325/750 [============>.................] - ETA: 4s - loss: 0.3127 - accuracy: 0.8900\n",
      " 32/750 [>.............................] - ETA: 7s - loss: 0.4994 - accuracy: 0.8369\n",
      "336/750 [============>.................] - ETA: 4s - loss: 0.3134 - accuracy: 0.8900\n",
      "342/750 [============>.................] - ETA: 4s - loss: 0.3143 - accuracy: 0.8897\n",
      "352/750 [=============>................] - ETA: 4s - loss: 0.3140 - accuracy: 0.8900\n",
      " 76/750 [==>...........................] - ETA: 7s - loss: 1.0216 - accuracy: 0.6815\n",
      "360/750 [=============>................] - ETA: 4s - loss: 0.3138 - accuracy: 0.8901\n",
      " 63/750 [=>............................] - ETA: 8s - loss: 0.4985 - accuracy: 0.8380\n",
      "364/750 [=============>................] - ETA: 4s - loss: 0.3135 - accuracy: 0.8903\n",
      " 69/750 [=>............................] - ETA: 8s - loss: 0.5025 - accuracy: 0.8358\n",
      "370/750 [=============>................] - ETA: 4s - loss: 0.3128 - accuracy: 0.8902\n",
      "100/750 [===>..........................] - ETA: 7s - loss: 1.0168 - accuracy: 0.6858\n",
      "380/750 [==============>...............] - ETA: 4s - loss: 0.3118 - accuracy: 0.8903\n",
      "390/750 [==============>...............] - ETA: 3s - loss: 0.3120 - accuracy: 0.8901\n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.5008 - accuracy: 0.8345\n",
      "395/750 [==============>...............] - ETA: 3s - loss: 0.3122 - accuracy: 0.8898\n",
      "406/750 [===============>..............] - ETA: 3s - loss: 0.3138 - accuracy: 0.8891\n",
      "418/750 [===============>..............] - ETA: 3s - loss: 0.3146 - accuracy: 0.8890\n",
      "122/750 [===>..........................] - ETA: 7s - loss: 0.4939 - accuracy: 0.8368\n",
      "135/750 [====>.........................] - ETA: 7s - loss: 1.0250 - accuracy: 0.6812\n",
      "423/750 [===============>..............] - ETA: 3s - loss: 0.3149 - accuracy: 0.8886\n",
      "621/750 [=======================>......] - ETA: 1s - loss: 0.5002 - accuracy: 0.8347\n",
      "433/750 [================>.............] - ETA: 3s - loss: 0.3156 - accuracy: 0.8882\n",
      "438/750 [================>.............] - ETA: 3s - loss: 0.3160 - accuracy: 0.8877\n",
      "211/750 [=======>......................] - ETA: 5s - loss: 0.3132 - accuracy: 0.8903\n",
      "449/750 [================>.............] - ETA: 3s - loss: 0.3150 - accuracy: 0.8880\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.5026 - accuracy: 0.8335 - val_loss: 0.5022 - val_accuracy: 0.8279\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 13/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 6s - loss: 0.4448 - accuracy: 0.8594\n",
      "458/750 [=================>............] - ETA: 3s - loss: 0.3141 - accuracy: 0.8882\n",
      "180/750 [======>.......................] - ETA: 7s - loss: 1.0262 - accuracy: 0.6811\n",
      "472/750 [=================>............] - ETA: 3s - loss: 0.3137 - accuracy: 0.8883\n",
      " 21/750 [..............................] - ETA: 7s - loss: 0.4875 - accuracy: 0.8438\n",
      "475/750 [==================>...........] - ETA: 3s - loss: 0.3131 - accuracy: 0.8885\n",
      " 49/750 [>.............................] - ETA: 8s - loss: 0.5039 - accuracy: 0.8345\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "485/750 [==================>...........] - ETA: 2s - loss: 0.3121 - accuracy: 0.8887\n",
      "496/750 [==================>...........] - ETA: 2s - loss: 0.3135 - accuracy: 0.8881\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 0.5016 - accuracy: 0.8335\n",
      "218/750 [=======>......................] - ETA: 6s - loss: 1.0258 - accuracy: 0.6838\n",
      "504/750 [===================>..........] - ETA: 2s - loss: 0.3129 - accuracy: 0.8883\n",
      " 57/750 [=>............................] - ETA: 8s - loss: 0.4992 - accuracy: 0.8369\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "231/750 [========>.....................] - ETA: 6s - loss: 1.0239 - accuracy: 0.6850\n",
      "515/750 [===================>..........] - ETA: 2s - loss: 0.3132 - accuracy: 0.8883\n",
      " 86/750 [==>...........................] - ETA: 8s - loss: 0.5017 - accuracy: 0.8330\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "240/750 [========>.....................] - ETA: 6s - loss: 1.0223 - accuracy: 0.6853\n",
      "532/750 [====================>.........] - ETA: 2s - loss: 0.3122 - accuracy: 0.8886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:02:37,023 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6857199616; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97/750 [==>...........................] - ETA: 8s - loss: 0.5029 - accuracy: 0.8330\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "538/750 [====================>.........] - ETA: 2s - loss: 0.3119 - accuracy: 0.8886\n",
      "254/750 [=========>....................] - ETA: 5s - loss: 1.0230 - accuracy: 0.6852\n",
      "262/750 [=========>....................] - ETA: 5s - loss: 1.0232 - accuracy: 0.6854\n",
      "551/750 [=====================>........] - ETA: 2s - loss: 0.3115 - accuracy: 0.8888\n",
      "269/750 [=========>....................] - ETA: 5s - loss: 1.0241 - accuracy: 0.6854\n",
      "118/750 [===>..........................] - ETA: 7s - loss: 0.4963 - accuracy: 0.8365\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "273/750 [=========>....................] - ETA: 5s - loss: 1.0240 - accuracy: 0.6850\n",
      "562/750 [=====================>........] - ETA: 2s - loss: 0.3107 - accuracy: 0.8890\n",
      "575/750 [======================>.......] - ETA: 1s - loss: 0.3114 - accuracy: 0.8885\n",
      "141/750 [====>.........................] - ETA: 7s - loss: 0.4956 - accuracy: 0.8358\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "592/750 [======================>.......] - ETA: 1s - loss: 0.3117 - accuracy: 0.8882\n",
      "165/750 [=====>........................] - ETA: 7s - loss: 0.4948 - accuracy: 0.8363\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "311/750 [===========>..................] - ETA: 5s - loss: 1.0244 - accuracy: 0.6837\n",
      "601/750 [=======================>......] - ETA: 1s - loss: 0.3125 - accuracy: 0.8880\n",
      "305/750 [===========>..................] - ETA: 5s - loss: 0.4939 - accuracy: 0.8348\n",
      "178/750 [======>.......................] - ETA: 6s - loss: 0.4923 - accuracy: 0.8373\n",
      "612/750 [=======================>......] - ETA: 1s - loss: 0.3120 - accuracy: 0.8883\n",
      "194/750 [======>.......................] - ETA: 6s - loss: 1.0275 - accuracy: 0.6810\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "586/750 [======================>.......] - ETA: 1s - loss: 0.3114 - accuracy: 0.8884\n",
      "624/750 [=======================>......] - ETA: 1s - loss: 0.3115 - accuracy: 0.8885\n",
      "191/750 [======>.......................] - ETA: 6s - loss: 0.4908 - accuracy: 0.8377\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "635/750 [========================>.....] - ETA: 1s - loss: 0.3122 - accuracy: 0.8882\n",
      "200/750 [=======>......................] - ETA: 6s - loss: 0.4896 - accuracy: 0.8388\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.3134 - accuracy: 0.8877\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.3135 - accuracy: 0.8875\n",
      "375/750 [==============>...............] - ETA: 4s - loss: 1.0225 - accuracy: 0.6840\n",
      "667/750 [=========================>....] - ETA: 0s - loss: 0.3131 - accuracy: 0.8880\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.3135 - accuracy: 0.8877\n",
      "246/750 [========>.....................] - ETA: 5s - loss: 0.4906 - accuracy: 0.8382\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "683/750 [==========================>...] - ETA: 0s - loss: 0.3134 - accuracy: 0.8878\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.3132 - accuracy: 0.8879\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.3130 - accuracy: 0.8880\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.3130 - accuracy: 0.8879\n",
      "269/750 [=========>....................] - ETA: 5s - loss: 0.4937 - accuracy: 0.8363\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.3128 - accuracy: 0.8879\n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.3130 - accuracy: 0.8878\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.3127 - accuracy: 0.8878\n",
      "297/750 [==========>...................] - ETA: 5s - loss: 0.4934 - accuracy: 0.8355\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.3125 - accuracy: 0.8879\n",
      "732/750 [============================>.] - ETA: 0s - loss: 0.3126 - accuracy: 0.8878\n",
      "285/750 [==========>...................] - ETA: 5s - loss: 0.4930 - accuracy: 0.8363\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.3125 - accuracy: 0.8878\n",
      "319/750 [===========>..................] - ETA: 5s - loss: 0.4945 - accuracy: 0.8357\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.3123 - accuracy: 0.8880\n",
      "341/750 [============>.................] - ETA: 4s - loss: 1.0241 - accuracy: 0.6836\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "508/750 [===================>..........] - ETA: 2s - loss: 1.0204 - accuracy: 0.6833\n",
      "340/750 [============>.................] - ETA: 4s - loss: 0.4949 - accuracy: 0.8357\n",
      "350/750 [=============>................] - ETA: 4s - loss: 0.4937 - accuracy: 0.8363\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 78/750 [==>...........................] - ETA: 8s - loss: 0.5016 - accuracy: 0.8339\n",
      "373/750 [=============>................] - ETA: 4s - loss: 0.4944 - accuracy: 0.8363\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "396/750 [==============>...............] - ETA: 4s - loss: 0.4919 - accuracy: 0.8371\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "555/750 [=====================>........] - ETA: 2s - loss: 0.4917 - accuracy: 0.8370\n",
      "406/750 [===============>..............] - ETA: 3s - loss: 0.4912 - accuracy: 0.8371\n",
      "584/750 [======================>.......] - ETA: 1s - loss: 1.0177 - accuracy: 0.6843\n",
      "424/750 [===============>..............] - ETA: 3s - loss: 0.4923 - accuracy: 0.8370\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "417/750 [===============>..............] - ETA: 3s - loss: 1.0223 - accuracy: 0.6835\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 1.0178 - accuracy: 0.6842\n",
      "608/750 [=======================>......] - ETA: 1s - loss: 1.0178 - accuracy: 0.6845\n",
      "447/750 [================>.............] - ETA: 3s - loss: 0.4919 - accuracy: 0.8373\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "439/750 [================>.............] - ETA: 3s - loss: 0.4913 - accuracy: 0.8375\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 1.0170 - accuracy: 0.6850\n",
      "  1/750 [..............................] - ETA: 2s - loss: 0.3409 - accuracy: 0.8750\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3121 - accuracy: 0.8880 - val_loss: 0.3436 - val_accuracy: 0.8788\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 14/30\n",
      " 13/750 [..............................] - ETA: 3s - loss: 0.3286 - accuracy: 0.8822\n",
      "472/750 [=================>............] - ETA: 3s - loss: 0.4915 - accuracy: 0.8370\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 19/750 [..............................] - ETA: 8s - loss: 0.3193 - accuracy: 0.8882\n",
      "496/750 [==================>...........] - ETA: 2s - loss: 0.4912 - accuracy: 0.8370\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "655/750 [=========================>....] - ETA: 1s - loss: 0.4932 - accuracy: 0.8359\n",
      " 34/750 [>.............................] - ETA: 6s - loss: 0.3066 - accuracy: 0.8925\n",
      "499/750 [==================>...........] - ETA: 2s - loss: 1.0206 - accuracy: 0.6830\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 40/750 [>.............................] - ETA: 7s - loss: 0.3047 - accuracy: 0.8918\n",
      " 57/750 [=>............................] - ETA: 6s - loss: 0.2945 - accuracy: 0.8972\n",
      "224/750 [=======>......................] - ETA: 6s - loss: 0.4928 - accuracy: 0.8378\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "691/750 [==========================>...] - ETA: 0s - loss: 1.0149 - accuracy: 0.6853\n",
      " 65/750 [=>............................] - ETA: 6s - loss: 0.2958 - accuracy: 0.8959\n",
      "521/750 [===================>..........] - ETA: 2s - loss: 0.4918 - accuracy: 0.8366\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 1.0156 - accuracy: 0.6850\n",
      " 76/750 [==>...........................] - ETA: 6s - loss: 0.2925 - accuracy: 0.8966\n",
      "529/750 [====================>.........] - ETA: 2s - loss: 0.4917 - accuracy: 0.8367\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 1.0158 - accuracy: 0.6846\n",
      " 87/750 [==>...........................] - ETA: 6s - loss: 0.2916 - accuracy: 0.8982\n",
      "539/750 [====================>.........] - ETA: 2s - loss: 0.4917 - accuracy: 0.8370\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "103/750 [===>..........................] - ETA: 6s - loss: 0.3019 - accuracy: 0.8978\n",
      "550/750 [=====================>........] - ETA: 2s - loss: 0.4915 - accuracy: 0.8370\n",
      "744/750 [============================>.] - ETA: 0s - loss: 1.0155 - accuracy: 0.6845\n",
      "110/750 [===>..........................] - ETA: 6s - loss: 0.3016 - accuracy: 0.8972\n",
      "748/750 [============================>.] - ETA: 0s - loss: 1.0156 - accuracy: 0.6845\n",
      "116/750 [===>..........................] - ETA: 6s - loss: 0.3033 - accuracy: 0.8960\n",
      "569/750 [=====================>........] - ETA: 2s - loss: 0.4912 - accuracy: 0.8369\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "124/750 [===>..........................] - ETA: 6s - loss: 0.3018 - accuracy: 0.8959\n",
      "131/750 [====>.........................] - ETA: 6s - loss: 0.3022 - accuracy: 0.8958\n",
      "143/750 [====>.........................] - ETA: 6s - loss: 0.2993 - accuracy: 0.8961\n",
      "598/750 [======================>.......] - ETA: 1s - loss: 1.0183 - accuracy: 0.6840\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "154/750 [=====>........................] - ETA: 6s - loss: 0.3019 - accuracy: 0.8953\n",
      "167/750 [=====>........................] - ETA: 5s - loss: 0.3036 - accuracy: 0.8944\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.4913 - accuracy: 0.8369\n",
      "182/750 [======>.......................] - ETA: 5s - loss: 0.3011 - accuracy: 0.8946\n",
      "619/750 [=======================>......] - ETA: 1s - loss: 0.4913 - accuracy: 0.8370\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "196/750 [======>.......................] - ETA: 5s - loss: 0.3005 - accuracy: 0.8949\n",
      "640/750 [========================>.....] - ETA: 1s - loss: 0.4933 - accuracy: 0.8360\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "231/750 [========>.....................] - ETA: 4s - loss: 0.3018 - accuracy: 0.8941\n",
      "204/750 [=======>......................] - ETA: 5s - loss: 0.3027 - accuracy: 0.8940\n",
      "665/750 [=========================>....] - ETA: 0s - loss: 0.4939 - accuracy: 0.8355\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "244/750 [========>.....................] - ETA: 4s - loss: 0.3031 - accuracy: 0.8929\n",
      "675/750 [==========================>...] - ETA: 0s - loss: 0.4943 - accuracy: 0.8353\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "263/750 [=========>....................] - ETA: 4s - loss: 0.3016 - accuracy: 0.8935\n",
      "241/750 [========>.....................] - ETA: 4s - loss: 0.3037 - accuracy: 0.8928\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.4946 - accuracy: 0.8353\n",
      "274/750 [=========>....................] - ETA: 4s - loss: 0.3032 - accuracy: 0.8925\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 1.0158 - accuracy: 0.6844 - val_loss: 0.9953 - val_accuracy: 0.6888\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 14/30\n",
      "297/750 [==========>...................] - ETA: 4s - loss: 0.3044 - accuracy: 0.8926\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.4945 - accuracy: 0.8355\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.8351\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "317/750 [===========>..................] - ETA: 4s - loss: 0.3029 - accuracy: 0.8931\n",
      "  4/750 [..............................] - ETA: 17s - loss: 0.3866 - accuracy: 0.8516\n",
      "320/750 [===========>..................] - ETA: 4s - loss: 0.3026 - accuracy: 0.8930\n",
      " 14/750 [..............................] - ETA: 10s - loss: 0.5025 - accuracy: 0.8304\n",
      " 26/750 [>.............................] - ETA: 8s - loss: 1.0121 - accuracy: 0.6683 \n",
      "327/750 [============>.................] - ETA: 4s - loss: 0.3025 - accuracy: 0.8930\n",
      " 30/750 [>.............................] - ETA: 7s - loss: 0.4798 - accuracy: 0.8495\n",
      " 38/750 [>.............................] - ETA: 8s - loss: 1.0132 - accuracy: 0.6674\n",
      "347/750 [============>.................] - ETA: 3s - loss: 0.3021 - accuracy: 0.8928\n",
      "354/750 [=============>................] - ETA: 3s - loss: 0.3036 - accuracy: 0.8923\n",
      "340/750 [============>.................] - ETA: 4s - loss: 0.3023 - accuracy: 0.8928\n",
      " 61/750 [=>............................] - ETA: 7s - loss: 0.9972 - accuracy: 0.6826\n",
      "508/750 [===================>..........] - ETA: 2s - loss: 0.4917 - accuracy: 0.8368\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "378/750 [==============>...............] - ETA: 3s - loss: 0.3053 - accuracy: 0.8917\n",
      "365/750 [=============>................] - ETA: 3s - loss: 0.3056 - accuracy: 0.8914\n",
      " 85/750 [==>...........................] - ETA: 7s - loss: 1.0000 - accuracy: 0.6794\n",
      "398/750 [==============>...............] - ETA: 3s - loss: 0.3063 - accuracy: 0.8909\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.4913 - accuracy: 0.8367\n",
      "453/750 [=================>............] - ETA: 3s - loss: 0.3060 - accuracy: 0.8913\n",
      "409/750 [===============>..............] - ETA: 3s - loss: 0.3064 - accuracy: 0.8909\n",
      "157/750 [=====>........................] - ETA: 6s - loss: 0.4922 - accuracy: 0.8417\n",
      "421/750 [===============>..............] - ETA: 3s - loss: 0.3061 - accuracy: 0.8911\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "475/750 [==================>...........] - ETA: 2s - loss: 0.3061 - accuracy: 0.8914\n",
      "161/750 [=====>........................] - ETA: 6s - loss: 0.4914 - accuracy: 0.8422\n",
      "441/750 [================>.............] - ETA: 3s - loss: 0.3056 - accuracy: 0.8916\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 6s - loss: 0.9969 - accuracy: 0.6406\n",
      "185/750 [======>.......................] - ETA: 6s - loss: 0.9956 - accuracy: 0.6848\n",
      "  7/750 [..............................] - ETA: 9s - loss: 1.0589 - accuracy: 0.6429\n",
      "463/750 [=================>............] - ETA: 2s - loss: 0.3064 - accuracy: 0.8911\n",
      " 16/750 [..............................] - ETA: 10s - loss: 1.0214 - accuracy: 0.6543\n",
      "515/750 [===================>..........] - ETA: 2s - loss: 0.3058 - accuracy: 0.8907\n",
      "477/750 [==================>...........] - ETA: 2s - loss: 0.3060 - accuracy: 0.8915\n",
      "491/750 [==================>...........] - ETA: 2s - loss: 0.3057 - accuracy: 0.8913\n",
      " 46/750 [>.............................] - ETA: 7s - loss: 0.4779 - accuracy: 0.8488\n",
      "532/750 [====================>.........] - ETA: 2s - loss: 0.3062 - accuracy: 0.8909\n",
      "224/750 [=======>......................] - ETA: 5s - loss: 0.4924 - accuracy: 0.8401\n",
      "242/750 [========>.....................] - ETA: 5s - loss: 1.0000 - accuracy: 0.6835\n",
      "221/750 [=======>......................] - ETA: 5s - loss: 0.4920 - accuracy: 0.8404\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.4941 - accuracy: 0.8353\n",
      "252/750 [=========>....................] - ETA: 5s - loss: 1.0006 - accuracy: 0.6828\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.4945 - accuracy: 0.8351\n",
      " 75/750 [==>...........................] - ETA: 7s - loss: 0.4848 - accuracy: 0.8515\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "525/750 [====================>.........] - ETA: 2s - loss: 0.3065 - accuracy: 0.8909\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.4947 - accuracy: 0.8353\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "583/750 [======================>.......] - ETA: 1s - loss: 0.3064 - accuracy: 0.8908\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.3064 - accuracy: 0.8907\n",
      "597/750 [======================>.......] - ETA: 1s - loss: 0.3067 - accuracy: 0.8908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:02:47,119 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6857039872; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741/750 [============================>.] - ETA: 0s - loss: 0.4950 - accuracy: 0.8355\n",
      "102/750 [===>..........................] - ETA: 7s - loss: 0.4884 - accuracy: 0.8465\n",
      "303/750 [===========>..................] - ETA: 4s - loss: 0.9984 - accuracy: 0.6840\n",
      "310/750 [===========>..................] - ETA: 4s - loss: 0.4902 - accuracy: 0.8387\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.3062 - accuracy: 0.8908\n",
      "319/750 [===========>..................] - ETA: 4s - loss: 0.4883 - accuracy: 0.8392\n",
      "566/750 [=====================>........] - ETA: 1s - loss: 0.3062 - accuracy: 0.8912\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "121/750 [===>..........................] - ETA: 7s - loss: 0.4896 - accuracy: 0.8443\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "138/750 [====>.........................] - ETA: 6s - loss: 0.4909 - accuracy: 0.8430\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "325/750 [============>.................] - ETA: 4s - loss: 0.9982 - accuracy: 0.6843\n",
      "628/750 [========================>.....] - ETA: 1s - loss: 0.3056 - accuracy: 0.8909\n",
      "143/750 [====>.........................] - ETA: 6s - loss: 0.4901 - accuracy: 0.8427\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "334/750 [============>.................] - ETA: 4s - loss: 0.4883 - accuracy: 0.8397\n",
      "155/750 [=====>........................] - ETA: 6s - loss: 0.9952 - accuracy: 0.6844\n",
      "650/750 [=========================>....] - ETA: 1s - loss: 0.3052 - accuracy: 0.8908\n",
      "351/750 [=============>................] - ETA: 4s - loss: 0.9990 - accuracy: 0.6838\n",
      "356/750 [=============>................] - ETA: 4s - loss: 0.4884 - accuracy: 0.8388\n",
      "610/750 [=======================>......] - ETA: 1s - loss: 0.3057 - accuracy: 0.8911\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 0.3046 - accuracy: 0.8909\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.3046 - accuracy: 0.8909\n",
      "634/750 [========================>.....] - ETA: 1s - loss: 0.3054 - accuracy: 0.8910\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.3047 - accuracy: 0.8909\n",
      "414/750 [===============>..............] - ETA: 3s - loss: 0.4892 - accuracy: 0.8385\n",
      "227/750 [========>.....................] - ETA: 5s - loss: 1.0001 - accuracy: 0.6830\n",
      "662/750 [=========================>....] - ETA: 0s - loss: 0.3050 - accuracy: 0.8906\n",
      "428/750 [================>.............] - ETA: 3s - loss: 0.9995 - accuracy: 0.6853\n",
      "240/750 [========>.....................] - ETA: 5s - loss: 0.4943 - accuracy: 0.8391\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "431/750 [================>.............] - ETA: 3s - loss: 0.9992 - accuracy: 0.6855\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.3055 - accuracy: 0.8907\n",
      "677/750 [==========================>...] - ETA: 0s - loss: 0.3046 - accuracy: 0.8908\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.8906\n",
      "460/750 [=================>............] - ETA: 2s - loss: 0.4887 - accuracy: 0.8386\n",
      "271/750 [=========>....................] - ETA: 5s - loss: 1.0010 - accuracy: 0.6832\n",
      "478/750 [==================>...........] - ETA: 2s - loss: 0.4892 - accuracy: 0.8384\n",
      "269/750 [=========>....................] - ETA: 5s - loss: 0.4922 - accuracy: 0.8396\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "486/750 [==================>...........] - ETA: 2s - loss: 0.9981 - accuracy: 0.6863\n",
      "485/750 [==================>...........] - ETA: 2s - loss: 0.4883 - accuracy: 0.8388\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.4951 - accuracy: 0.8352 - val_loss: 0.4953 - val_accuracy: 0.8311\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 14/30\n",
      "495/750 [==================>...........] - ETA: 2s - loss: 0.9977 - accuracy: 0.6864\n",
      "292/750 [==========>...................] - ETA: 4s - loss: 0.4902 - accuracy: 0.8389\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.3054 - accuracy: 0.8907\n",
      "503/750 [===================>..........] - ETA: 2s - loss: 0.9977 - accuracy: 0.6866\n",
      "507/750 [===================>..........] - ETA: 2s - loss: 0.4896 - accuracy: 0.8383\n",
      "322/750 [===========>..................] - ETA: 4s - loss: 0.4884 - accuracy: 0.8393\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "515/750 [===================>..........] - ETA: 2s - loss: 0.9969 - accuracy: 0.6871\n",
      "528/750 [====================>.........] - ETA: 2s - loss: 0.9962 - accuracy: 0.6876\n",
      " 48/750 [>.............................] - ETA: 8s - loss: 1.0039 - accuracy: 0.6761\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "329/750 [============>.................] - ETA: 4s - loss: 0.9988 - accuracy: 0.6839\n",
      "533/750 [====================>.........] - ETA: 2s - loss: 0.4891 - accuracy: 0.8385\n",
      "554/750 [=====================>........] - ETA: 1s - loss: 0.4874 - accuracy: 0.8385\n",
      " 68/750 [=>............................] - ETA: 7s - loss: 0.4869 - accuracy: 0.8495\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "560/750 [=====================>........] - ETA: 1s - loss: 0.4874 - accuracy: 0.8385\n",
      "503/750 [===================>..........] - ETA: 2s - loss: 0.3058 - accuracy: 0.8908\n",
      "567/750 [=====================>........] - ETA: 1s - loss: 0.4864 - accuracy: 0.8388\n",
      " 96/750 [==>...........................] - ETA: 7s - loss: 0.4867 - accuracy: 0.8477\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.9971 - accuracy: 0.6866\n",
      "594/750 [======================>.......] - ETA: 1s - loss: 0.4859 - accuracy: 0.8393\n",
      "606/750 [=======================>......] - ETA: 1s - loss: 0.4863 - accuracy: 0.8390\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.3056 - accuracy: 0.8906 - val_loss: 0.3498 - val_accuracy: 0.8744\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 15/30\n",
      "  8/750 [..............................] - ETA: 6s - loss: 0.2942 - accuracy: 0.8984 \n",
      "395/750 [==============>...............] - ETA: 3s - loss: 0.9988 - accuracy: 0.6849\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 19/750 [..............................] - ETA: 6s - loss: 0.2978 - accuracy: 0.8923\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.9961 - accuracy: 0.6875\n",
      " 28/750 [>.............................] - ETA: 7s - loss: 0.2990 - accuracy: 0.8956\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.4856 - accuracy: 0.8390\n",
      "632/750 [========================>.....] - ETA: 1s - loss: 0.4862 - accuracy: 0.8388\n",
      "648/750 [========================>.....] - ETA: 1s - loss: 0.9968 - accuracy: 0.6874\n",
      "640/750 [========================>.....] - ETA: 1s - loss: 0.4865 - accuracy: 0.8386\n",
      "450/750 [=================>............] - ETA: 3s - loss: 0.4883 - accuracy: 0.8390\n",
      "658/750 [=========================>....] - ETA: 0s - loss: 0.9958 - accuracy: 0.6877\n",
      " 48/750 [>.............................] - ETA: 6s - loss: 0.2993 - accuracy: 0.8942\n",
      "661/750 [=========================>....] - ETA: 0s - loss: 0.9953 - accuracy: 0.6879\n",
      "168/750 [=====>........................] - ETA: 6s - loss: 0.9969 - accuracy: 0.6830\n",
      "475/750 [==================>...........] - ETA: 2s - loss: 0.9991 - accuracy: 0.6858\n",
      " 64/750 [=>............................] - ETA: 8s - loss: 0.3014 - accuracy: 0.8931\n",
      "174/750 [=====>........................] - ETA: 6s - loss: 0.4898 - accuracy: 0.8417\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "443/750 [================>.............] - ETA: 3s - loss: 1.0004 - accuracy: 0.6851\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "198/750 [======>.......................] - ETA: 6s - loss: 0.4908 - accuracy: 0.8426\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 91/750 [==>...........................] - ETA: 6s - loss: 0.3041 - accuracy: 0.8961\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.4885 - accuracy: 0.8382\n",
      "530/750 [====================>.........] - ETA: 2s - loss: 0.9960 - accuracy: 0.6878\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.9936 - accuracy: 0.6885\n",
      "131/750 [====>.........................] - ETA: 6s - loss: 0.2983 - accuracy: 0.8978\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.9929 - accuracy: 0.6887\n",
      "159/750 [=====>........................] - ETA: 6s - loss: 0.3003 - accuracy: 0.8963\n",
      " 83/750 [==>...........................] - ETA: 7s - loss: 0.3038 - accuracy: 0.8959\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.4883 - accuracy: 0.8383\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "577/750 [======================>.......] - ETA: 1s - loss: 0.4866 - accuracy: 0.8389\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "176/750 [======>.......................] - ETA: 5s - loss: 0.3021 - accuracy: 0.8953\n",
      "587/750 [======================>.......] - ETA: 1s - loss: 0.4861 - accuracy: 0.8393\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "610/750 [=======================>......] - ETA: 1s - loss: 0.4861 - accuracy: 0.8391\n",
      "200/750 [=======>......................] - ETA: 5s - loss: 0.3006 - accuracy: 0.8957\n",
      "569/750 [=====================>........] - ETA: 1s - loss: 0.9970 - accuracy: 0.6871\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "118/750 [===>..........................] - ETA: 7s - loss: 0.3001 - accuracy: 0.8966\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.9961 - accuracy: 0.6874\n",
      "214/750 [=======>......................] - ETA: 5s - loss: 0.3026 - accuracy: 0.8946\n",
      "141/750 [====>.........................] - ETA: 6s - loss: 0.2999 - accuracy: 0.8966\n",
      "227/750 [========>.....................] - ETA: 5s - loss: 0.3027 - accuracy: 0.8952\n",
      "243/750 [========>.....................] - ETA: 5s - loss: 0.3026 - accuracy: 0.8944\n",
      "347/750 [============>.................] - ETA: 4s - loss: 0.4876 - accuracy: 0.8395\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "657/750 [=========================>....] - ETA: 0s - loss: 0.4869 - accuracy: 0.8386\n",
      "372/750 [=============>................] - ETA: 4s - loss: 0.9989 - accuracy: 0.6848\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "279/750 [==========>...................] - ETA: 4s - loss: 0.3016 - accuracy: 0.8945\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.9947 - accuracy: 0.6883\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "694/750 [==========================>...] - ETA: 0s - loss: 0.4887 - accuracy: 0.8383\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.5019 - accuracy: 0.8750\n",
      "422/750 [===============>..............] - ETA: 3s - loss: 0.4889 - accuracy: 0.8387\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "313/750 [===========>..................] - ETA: 4s - loss: 0.2999 - accuracy: 0.8943\n",
      "  8/750 [..............................] - ETA: 7s - loss: 0.5759 - accuracy: 0.8203\n",
      "330/750 [============>.................] - ETA: 4s - loss: 0.3008 - accuracy: 0.8942\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.4886 - accuracy: 0.8381\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 26/750 [>.............................] - ETA: 10s - loss: 0.5356 - accuracy: 0.8347\n",
      "344/750 [============>.................] - ETA: 4s - loss: 0.3003 - accuracy: 0.8944\n",
      " 40/750 [>.............................] - ETA: 8s - loss: 0.5198 - accuracy: 0.8352\n",
      "472/750 [=================>............] - ETA: 2s - loss: 0.4889 - accuracy: 0.8387\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 58/750 [=>............................] - ETA: 8s - loss: 0.5102 - accuracy: 0.8394\n",
      "270/750 [=========>....................] - ETA: 4s - loss: 0.3008 - accuracy: 0.8946\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "490/750 [==================>...........] - ETA: 2s - loss: 0.4874 - accuracy: 0.8391\n",
      "378/750 [==============>...............] - ETA: 3s - loss: 0.2987 - accuracy: 0.8948\n",
      "299/750 [==========>...................] - ETA: 4s - loss: 0.3027 - accuracy: 0.8936\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "522/750 [===================>..........] - ETA: 2s - loss: 0.4897 - accuracy: 0.8381\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 47/750 [>.............................] - ETA: 8s - loss: 0.9897 - accuracy: 0.6862\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.9959 - accuracy: 0.6877\n",
      "108/750 [===>..........................] - ETA: 7s - loss: 0.9809 - accuracy: 0.6946\n",
      "125/750 [====>.........................] - ETA: 7s - loss: 0.4847 - accuracy: 0.8440\n",
      " 71/750 [=>............................] - ETA: 8s - loss: 0.9891 - accuracy: 0.6932\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "134/750 [====>.........................] - ETA: 7s - loss: 0.4848 - accuracy: 0.8435\n",
      "146/750 [====>.........................] - ETA: 6s - loss: 0.4798 - accuracy: 0.8450\n",
      "463/750 [=================>............] - ETA: 2s - loss: 0.2992 - accuracy: 0.8935\n",
      "469/750 [=================>............] - ETA: 2s - loss: 0.2997 - accuracy: 0.8933\n",
      "157/750 [=====>........................] - ETA: 6s - loss: 0.4789 - accuracy: 0.8447\n",
      " 95/750 [==>...........................] - ETA: 7s - loss: 0.9802 - accuracy: 0.6964\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "480/750 [==================>...........] - ETA: 2s - loss: 0.2999 - accuracy: 0.8936\n",
      "167/750 [=====>........................] - ETA: 6s - loss: 0.4818 - accuracy: 0.8438\n",
      "493/750 [==================>...........] - ETA: 2s - loss: 0.3001 - accuracy: 0.8935\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.4854 - accuracy: 0.8392\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 9s 13ms/step - loss: 0.9929 - accuracy: 0.6887 - val_loss: 0.9738 - val_accuracy: 0.6945\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 15/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "495/750 [==================>...........] - ETA: 2s - loss: 0.3001 - accuracy: 0.8936\n",
      "397/750 [==============>...............] - ETA: 3s - loss: 0.2972 - accuracy: 0.8951\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 24/750 [..............................] - ETA: 10s - loss: 0.9703 - accuracy: 0.7012\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "516/750 [===================>..........] - ETA: 2s - loss: 0.2994 - accuracy: 0.8938\n",
      "208/750 [=======>......................] - ETA: 6s - loss: 0.9785 - accuracy: 0.6937\n",
      "673/750 [=========================>....] - ETA: 0s - loss: 0.9946 - accuracy: 0.6881\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "537/750 [====================>.........] - ETA: 2s - loss: 0.2992 - accuracy: 0.8941\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.3006 - accuracy: 0.8936\n",
      "241/750 [========>.....................] - ETA: 5s - loss: 0.4822 - accuracy: 0.8411\n",
      " 68/750 [=>............................] - ETA: 7s - loss: 0.4996 - accuracy: 0.8421\n",
      "250/750 [=========>....................] - ETA: 5s - loss: 0.4801 - accuracy: 0.8418\n",
      "164/750 [=====>........................] - ETA: 6s - loss: 0.9825 - accuracy: 0.6932\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "448/750 [================>.............] - ETA: 3s - loss: 0.2992 - accuracy: 0.8936\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "571/750 [=====================>........] - ETA: 1s - loss: 0.3018 - accuracy: 0.8933\n",
      "192/750 [======>.......................] - ETA: 6s - loss: 0.9810 - accuracy: 0.6924\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      " 77/750 [==>...........................] - ETA: 7s - loss: 0.4971 - accuracy: 0.8411\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "267/750 [=========>....................] - ETA: 5s - loss: 0.4830 - accuracy: 0.8406\n",
      "585/750 [======================>.......] - ETA: 1s - loss: 0.3007 - accuracy: 0.8937\n",
      "278/750 [==========>...................] - ETA: 5s - loss: 0.4844 - accuracy: 0.8402\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.3014 - accuracy: 0.8933\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.3022 - accuracy: 0.8928\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.3022 - accuracy: 0.8927\n",
      "300/750 [===========>..................] - ETA: 5s - loss: 0.4827 - accuracy: 0.8406\n",
      "130/750 [====>.........................] - ETA: 7s - loss: 0.9804 - accuracy: 0.6941\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.3022 - accuracy: 0.8925\n",
      "157/750 [=====>........................] - ETA: 6s - loss: 0.9820 - accuracy: 0.6927\n",
      "636/750 [========================>.....] - ETA: 1s - loss: 0.3019 - accuracy: 0.8928\n",
      "645/750 [========================>.....] - ETA: 1s - loss: 0.3030 - accuracy: 0.8923\n",
      "178/750 [======>.......................] - ETA: 6s - loss: 0.4809 - accuracy: 0.8434\n",
      "580/750 [======================>.......] - ETA: 1s - loss: 0.3013 - accuracy: 0.8934\n",
      "654/750 [=========================>....] - ETA: 1s - loss: 0.3025 - accuracy: 0.8925\n",
      "356/750 [=============>................] - ETA: 4s - loss: 0.4855 - accuracy: 0.8402\n",
      "660/750 [=========================>....] - ETA: 0s - loss: 0.3022 - accuracy: 0.8927\n",
      "663/750 [=========================>....] - ETA: 0s - loss: 0.3018 - accuracy: 0.8929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:02:57,214 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 7090450432; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355/750 [=============>................] - ETA: 4s - loss: 0.9778 - accuracy: 0.6945\n",
      "670/750 [=========================>....] - ETA: 0s - loss: 0.3019 - accuracy: 0.8929\n",
      "221/750 [=======>......................] - ETA: 6s - loss: 0.9763 - accuracy: 0.6941\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "562/750 [=====================>........] - ETA: 1s - loss: 0.3019 - accuracy: 0.8932\n",
      "121/750 [===>..........................] - ETA: 7s - loss: 0.9804 - accuracy: 0.6950\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "222/750 [=======>......................] - ETA: 5s - loss: 0.4850 - accuracy: 0.8405\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "379/750 [==============>...............] - ETA: 4s - loss: 0.9779 - accuracy: 0.6929\n",
      "244/750 [========>.....................] - ETA: 5s - loss: 0.9791 - accuracy: 0.6928\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "338/750 [============>.................] - ETA: 4s - loss: 0.9769 - accuracy: 0.6952\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.3007 - accuracy: 0.8934\n",
      "402/750 [===============>..............] - ETA: 3s - loss: 0.9770 - accuracy: 0.6932\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.3003 - accuracy: 0.8935\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.8936\n",
      "366/750 [=============>................] - ETA: 4s - loss: 0.9775 - accuracy: 0.6945\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.8935\n",
      "425/750 [================>.............] - ETA: 3s - loss: 0.4836 - accuracy: 0.8403\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.3012 - accuracy: 0.8933\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.3018 - accuracy: 0.8932\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.8931\n",
      "  1/750 [..............................] - ETA: 6s - loss: 0.9099 - accuracy: 0.7188\n",
      "423/750 [===============>..............] - ETA: 3s - loss: 0.9759 - accuracy: 0.6933\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "320/750 [===========>..................] - ETA: 4s - loss: 0.9777 - accuracy: 0.6952\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "326/750 [============>.................] - ETA: 4s - loss: 0.4854 - accuracy: 0.8393\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.3009 - accuracy: 0.8931\n",
      "332/750 [============>.................] - ETA: 4s - loss: 0.9770 - accuracy: 0.6951\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 36/750 [>.............................] - ETA: 8s - loss: 0.9781 - accuracy: 0.6923\n",
      "469/750 [=================>............] - ETA: 3s - loss: 0.9751 - accuracy: 0.6931\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 56/750 [=>............................] - ETA: 8s - loss: 0.9944 - accuracy: 0.6875\n",
      "273/750 [=========>....................] - ETA: 5s - loss: 0.9781 - accuracy: 0.6936\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "375/750 [==============>...............] - ETA: 4s - loss: 0.4849 - accuracy: 0.8398\n",
      "531/750 [====================>.........] - ETA: 2s - loss: 0.4832 - accuracy: 0.8404\n",
      "296/750 [==========>...................] - ETA: 5s - loss: 0.9778 - accuracy: 0.6945\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "517/750 [===================>..........] - ETA: 2s - loss: 0.9732 - accuracy: 0.6941\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "551/750 [=====================>........] - ETA: 2s - loss: 0.4833 - accuracy: 0.8401\n",
      "572/750 [=====================>........] - ETA: 1s - loss: 0.4841 - accuracy: 0.8400\n",
      "583/750 [======================>.......] - ETA: 1s - loss: 0.4844 - accuracy: 0.8399\n",
      "139/750 [====>.........................] - ETA: 7s - loss: 0.9825 - accuracy: 0.6922\n",
      "464/750 [=================>............] - ETA: 3s - loss: 0.4834 - accuracy: 0.8402\n",
      "172/750 [=====>........................] - ETA: 6s - loss: 0.9806 - accuracy: 0.6944\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.3424 - accuracy: 0.8750\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.4839 - accuracy: 0.8398\n",
      "493/750 [==================>...........] - ETA: 2s - loss: 0.9741 - accuracy: 0.6938\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  3/750 [..............................] - ETA: 53s - loss: 0.2575 - accuracy: 0.9062\n",
      "  7/750 [..............................] - ETA: 24s - loss: 0.2723 - accuracy: 0.8973\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.9742 - accuracy: 0.6921\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3007 - accuracy: 0.8931 - val_loss: 0.3397 - val_accuracy: 0.8788\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 16/30\n",
      "497/750 [==================>...........] - ETA: 2s - loss: 0.9738 - accuracy: 0.6939\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      " 12/750 [..............................] - ETA: 18s - loss: 0.2662 - accuracy: 0.8984\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.4838 - accuracy: 0.8398\n",
      "398/750 [==============>...............] - ETA: 3s - loss: 0.9770 - accuracy: 0.6933\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 26/750 [>.............................] - ETA: 11s - loss: 0.3038 - accuracy: 0.8870\n",
      "649/750 [========================>.....] - ETA: 1s - loss: 0.4835 - accuracy: 0.8398\n",
      "521/750 [===================>..........] - ETA: 2s - loss: 0.9733 - accuracy: 0.6941\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 31/750 [>.............................] - ETA: 12s - loss: 0.2955 - accuracy: 0.8916\n",
      " 43/750 [>.............................] - ETA: 10s - loss: 0.3014 - accuracy: 0.8895\n",
      "671/750 [=========================>....] - ETA: 0s - loss: 0.4824 - accuracy: 0.8403\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.9729 - accuracy: 0.6938\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 48/750 [>.............................] - ETA: 11s - loss: 0.2956 - accuracy: 0.8936\n",
      "682/750 [==========================>...] - ETA: 0s - loss: 0.4829 - accuracy: 0.8399\n",
      " 62/750 [=>............................] - ETA: 9s - loss: 0.2940 - accuracy: 0.8959 \n",
      " 66/750 [=>............................] - ETA: 9s - loss: 0.2929 - accuracy: 0.8977\n",
      "449/750 [================>.............] - ETA: 3s - loss: 0.9748 - accuracy: 0.6936\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "561/750 [=====================>........] - ETA: 2s - loss: 0.9731 - accuracy: 0.6931\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 75/750 [==>...........................] - ETA: 9s - loss: 0.2922 - accuracy: 0.8983\n",
      " 82/750 [==>...........................] - ETA: 9s - loss: 0.2949 - accuracy: 0.8982\n",
      "263/750 [=========>....................] - ETA: 5s - loss: 0.9789 - accuracy: 0.6928\n",
      "588/750 [======================>.......] - ETA: 1s - loss: 0.4840 - accuracy: 0.8398\n",
      " 90/750 [==>...........................] - ETA: 9s - loss: 0.2948 - accuracy: 0.8976\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.9727 - accuracy: 0.6928\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.4830 - accuracy: 0.8392\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.9725 - accuracy: 0.6929\n",
      "107/750 [===>..........................] - ETA: 8s - loss: 0.2936 - accuracy: 0.8962\n",
      "607/750 [=======================>......] - ETA: 1s - loss: 0.9728 - accuracy: 0.6930\n",
      "108/750 [===>..........................] - ETA: 9s - loss: 0.2933 - accuracy: 0.8963\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.4826 - accuracy: 0.8393\n",
      "304/750 [===========>..................] - ETA: 5s - loss: 0.9775 - accuracy: 0.6953\n",
      "139/750 [====>.........................] - ETA: 7s - loss: 0.2933 - accuracy: 0.8960\n",
      "148/750 [====>.........................] - ETA: 7s - loss: 0.2966 - accuracy: 0.8953\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.9726 - accuracy: 0.6932\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "161/750 [=====>........................] - ETA: 7s - loss: 0.2930 - accuracy: 0.8966\n",
      "174/750 [=====>........................] - ETA: 6s - loss: 0.2895 - accuracy: 0.8974\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.9726 - accuracy: 0.6931\n",
      "186/750 [======>.......................] - ETA: 6s - loss: 0.2910 - accuracy: 0.8963\n",
      "373/750 [=============>................] - ETA: 4s - loss: 0.9782 - accuracy: 0.6935\n",
      "198/750 [======>.......................] - ETA: 6s - loss: 0.2926 - accuracy: 0.8955\n",
      "121/750 [===>..........................] - ETA: 8s - loss: 0.2900 - accuracy: 0.8976\n",
      "218/750 [=======>......................] - ETA: 6s - loss: 0.2951 - accuracy: 0.8945\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "232/750 [========>.....................] - ETA: 5s - loss: 0.2959 - accuracy: 0.8943\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.9729 - accuracy: 0.6928\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "250/750 [=========>....................] - ETA: 5s - loss: 0.2965 - accuracy: 0.8936\n",
      "413/750 [===============>..............] - ETA: 3s - loss: 0.4846 - accuracy: 0.8398\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.9724 - accuracy: 0.6928\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "277/750 [==========>...................] - ETA: 5s - loss: 0.2944 - accuracy: 0.8942\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.9725 - accuracy: 0.6929\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.4828 - accuracy: 0.8392 - val_loss: 0.4851 - val_accuracy: 0.8347\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 16/30\n",
      "295/750 [==========>...................] - ETA: 4s - loss: 0.2940 - accuracy: 0.8952\n",
      " 21/750 [..............................] - ETA: 3s - loss: 0.5160 - accuracy: 0.8363\n",
      "302/750 [===========>..................] - ETA: 4s - loss: 0.2945 - accuracy: 0.8952\n",
      "320/750 [===========>..................] - ETA: 4s - loss: 0.2941 - accuracy: 0.8954\n",
      " 29/750 [>.............................] - ETA: 6s - loss: 0.5003 - accuracy: 0.8394\n",
      "330/750 [============>.................] - ETA: 4s - loss: 0.2946 - accuracy: 0.8955\n",
      " 42/750 [>.............................] - ETA: 6s - loss: 0.4895 - accuracy: 0.8441\n",
      " 29/750 [>.............................] - ETA: 9s - loss: 0.9376 - accuracy: 0.7037\n",
      "340/750 [============>.................] - ETA: 4s - loss: 0.2944 - accuracy: 0.8953\n",
      " 49/750 [>.............................] - ETA: 6s - loss: 0.4802 - accuracy: 0.8466\n",
      "349/750 [============>.................] - ETA: 4s - loss: 0.2941 - accuracy: 0.8951\n",
      " 47/750 [>.............................] - ETA: 8s - loss: 0.9467 - accuracy: 0.6981\n",
      " 56/750 [=>............................] - ETA: 7s - loss: 0.4857 - accuracy: 0.8418\n",
      "362/750 [=============>................] - ETA: 4s - loss: 0.2941 - accuracy: 0.8954\n",
      " 66/750 [=>............................] - ETA: 7s - loss: 0.4846 - accuracy: 0.8419\n",
      "264/750 [=========>....................] - ETA: 5s - loss: 0.2969 - accuracy: 0.8933\n",
      "367/750 [=============>................] - ETA: 4s - loss: 0.2941 - accuracy: 0.8954\n",
      "531/750 [====================>.........] - ETA: 2s - loss: 0.9735 - accuracy: 0.6938\n",
      "377/750 [==============>...............] - ETA: 4s - loss: 0.2940 - accuracy: 0.8953\n",
      "288/750 [==========>...................] - ETA: 4s - loss: 0.2937 - accuracy: 0.8950\n",
      "554/750 [=====================>........] - ETA: 2s - loss: 0.9733 - accuracy: 0.6934\n",
      "394/750 [==============>...............] - ETA: 3s - loss: 0.2937 - accuracy: 0.8955\n",
      "404/750 [===============>..............] - ETA: 3s - loss: 0.2953 - accuracy: 0.8951\n",
      "570/750 [=====================>........] - ETA: 1s - loss: 0.9729 - accuracy: 0.6931\n",
      "117/750 [===>..........................] - ETA: 7s - loss: 0.9611 - accuracy: 0.6922\n",
      "423/750 [===============>..............] - ETA: 3s - loss: 0.2943 - accuracy: 0.8954\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.4849 - accuracy: 0.8394\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "125/750 [====>.........................] - ETA: 7s - loss: 0.9571 - accuracy: 0.6940\n",
      "426/750 [================>.............] - ETA: 3s - loss: 0.2949 - accuracy: 0.8952\n",
      "153/750 [=====>........................] - ETA: 6s - loss: 0.9579 - accuracy: 0.6967\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.8787 - accuracy: 0.7344\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "155/750 [=====>........................] - ETA: 7s - loss: 0.9576 - accuracy: 0.6976\n",
      "455/750 [=================>............] - ETA: 3s - loss: 0.2948 - accuracy: 0.8947\n",
      "  7/750 [..............................] - ETA: 17s - loss: 0.9323 - accuracy: 0.7210\n",
      " 18/750 [..............................] - ETA: 10s - loss: 0.9291 - accuracy: 0.7109\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "467/750 [=================>............] - ETA: 3s - loss: 0.2946 - accuracy: 0.8949\n",
      "179/750 [======>.......................] - ETA: 6s - loss: 0.4794 - accuracy: 0.8401\n",
      "475/750 [==================>...........] - ETA: 3s - loss: 0.2948 - accuracy: 0.8947\n",
      "181/750 [======>.......................] - ETA: 6s - loss: 0.9564 - accuracy: 0.6987\n",
      "479/750 [==================>...........] - ETA: 3s - loss: 0.2948 - accuracy: 0.8945\n",
      "389/750 [==============>...............] - ETA: 3s - loss: 0.2940 - accuracy: 0.8954\n",
      "185/750 [======>.......................] - ETA: 6s - loss: 0.9564 - accuracy: 0.6984\n",
      "485/750 [==================>...........] - ETA: 2s - loss: 0.2947 - accuracy: 0.8945\n",
      "204/750 [=======>......................] - ETA: 6s - loss: 0.4810 - accuracy: 0.8403\n",
      "496/750 [==================>...........] - ETA: 2s - loss: 0.2948 - accuracy: 0.8945\n",
      "211/750 [=======>......................] - ETA: 6s - loss: 0.4815 - accuracy: 0.8400\n",
      "505/750 [===================>..........] - ETA: 2s - loss: 0.2947 - accuracy: 0.8944\n",
      "511/750 [===================>..........] - ETA: 2s - loss: 0.2947 - accuracy: 0.8945\n",
      "674/750 [=========================>....] - ETA: 0s - loss: 0.9722 - accuracy: 0.6933\n",
      "517/750 [===================>..........] - ETA: 2s - loss: 0.2950 - accuracy: 0.8944\n",
      "523/750 [===================>..........] - ETA: 2s - loss: 0.2951 - accuracy: 0.8943\n",
      "240/750 [========>.....................] - ETA: 5s - loss: 0.4764 - accuracy: 0.8421\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.9722 - accuracy: 0.6933\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "225/750 [========>.....................] - ETA: 6s - loss: 0.9560 - accuracy: 0.6977\n",
      "532/750 [====================>.........] - ETA: 2s - loss: 0.2952 - accuracy: 0.8944\n",
      "249/750 [========>.....................] - ETA: 5s - loss: 0.4778 - accuracy: 0.8416\n",
      " 72/750 [=>............................] - ETA: 8s - loss: 0.9520 - accuracy: 0.7001\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.2951 - accuracy: 0.8944\n",
      "264/750 [=========>....................] - ETA: 5s - loss: 0.4784 - accuracy: 0.8416\n",
      "445/750 [================>.............] - ETA: 3s - loss: 0.2947 - accuracy: 0.8949\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 82/750 [==>...........................] - ETA: 7s - loss: 0.9562 - accuracy: 0.6955\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "250/750 [=========>....................] - ETA: 5s - loss: 0.9552 - accuracy: 0.6983\n",
      "551/750 [=====================>........] - ETA: 2s - loss: 0.2958 - accuracy: 0.8943\n",
      " 96/750 [==>...........................] - ETA: 7s - loss: 0.9557 - accuracy: 0.6935\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "565/750 [=====================>........] - ETA: 2s - loss: 0.2952 - accuracy: 0.8944\n",
      "290/750 [==========>...................] - ETA: 4s - loss: 0.4777 - accuracy: 0.8422\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.4842 - accuracy: 0.8389\n",
      "276/750 [==========>...................] - ETA: 5s - loss: 0.9528 - accuracy: 0.6988\n",
      "575/750 [======================>.......] - ETA: 1s - loss: 0.2952 - accuracy: 0.8945\n",
      "301/750 [===========>..................] - ETA: 4s - loss: 0.4779 - accuracy: 0.8420\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.9724 - accuracy: 0.6930\n",
      "294/750 [==========>...................] - ETA: 5s - loss: 0.9543 - accuracy: 0.6982\n",
      "306/750 [===========>..................] - ETA: 4s - loss: 0.4784 - accuracy: 0.8415\n",
      "114/750 [===>..........................] - ETA: 7s - loss: 0.4807 - accuracy: 0.8422\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "598/750 [======================>.......] - ETA: 1s - loss: 0.2945 - accuracy: 0.8946\n",
      "608/750 [=======================>......] - ETA: 1s - loss: 0.2949 - accuracy: 0.8947\n",
      "325/750 [============>.................] - ETA: 4s - loss: 0.4772 - accuracy: 0.8412\n",
      "142/750 [====>.........................] - ETA: 7s - loss: 0.9537 - accuracy: 0.6981\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "616/750 [=======================>......] - ETA: 1s - loss: 0.2945 - accuracy: 0.8947\n",
      "620/750 [=======================>......] - ETA: 1s - loss: 0.2950 - accuracy: 0.8945\n",
      "350/750 [=============>................] - ETA: 4s - loss: 0.4750 - accuracy: 0.8419\n",
      "163/750 [=====>........................] - ETA: 7s - loss: 0.9560 - accuracy: 0.6994\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.2948 - accuracy: 0.8946\n",
      "353/750 [=============>................] - ETA: 4s - loss: 0.4746 - accuracy: 0.8422\n",
      "654/750 [=========================>....] - ETA: 1s - loss: 0.2948 - accuracy: 0.8946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:03:07,216 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 7115935744; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/750 [======>.......................] - ETA: 6s - loss: 0.9568 - accuracy: 0.6981\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "658/750 [=========================>....] - ETA: 1s - loss: 0.2951 - accuracy: 0.8944\n",
      "373/750 [=============>................] - ETA: 4s - loss: 0.4765 - accuracy: 0.8412\n",
      "669/750 [=========================>....] - ETA: 0s - loss: 0.2949 - accuracy: 0.8945\n",
      "386/750 [==============>...............] - ETA: 3s - loss: 0.4768 - accuracy: 0.8412\n",
      "223/750 [=======>......................] - ETA: 5s - loss: 0.4805 - accuracy: 0.8408\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2950 - accuracy: 0.8950\n",
      "431/750 [================>.............] - ETA: 3s - loss: 0.4779 - accuracy: 0.8407\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2954 - accuracy: 0.8948\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2955 - accuracy: 0.8948\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2955 - accuracy: 0.8948\n",
      "457/750 [=================>............] - ETA: 3s - loss: 0.4770 - accuracy: 0.8412\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2953 - accuracy: 0.8948\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.9724 - accuracy: 0.6929 - val_loss: 0.9544 - val_accuracy: 0.6977\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 16/30\n",
      "464/750 [=================>............] - ETA: 3s - loss: 0.9546 - accuracy: 0.6965\n",
      "499/750 [==================>...........] - ETA: 2s - loss: 0.4779 - accuracy: 0.8409\n",
      "318/750 [===========>..................] - ETA: 4s - loss: 0.9542 - accuracy: 0.6975\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 43/750 [>.............................] - ETA: 8s - loss: 0.9479 - accuracy: 0.6969\n",
      "335/750 [============>.................] - ETA: 4s - loss: 0.9549 - accuracy: 0.6969\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "502/750 [===================>..........] - ETA: 2s - loss: 0.9548 - accuracy: 0.6965\n",
      "526/750 [====================>.........] - ETA: 2s - loss: 0.4782 - accuracy: 0.8403\n",
      " 69/750 [=>............................] - ETA: 7s - loss: 0.9537 - accuracy: 0.6979\n",
      "370/750 [=============>................] - ETA: 4s - loss: 0.9526 - accuracy: 0.6981\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "398/750 [==============>...............] - ETA: 3s - loss: 0.4778 - accuracy: 0.8411\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "600/750 [=======================>......] - ETA: 1s - loss: 0.4785 - accuracy: 0.8398\n",
      "122/750 [===>..........................] - ETA: 7s - loss: 0.4833 - accuracy: 0.8402\n",
      "418/750 [===============>..............] - ETA: 3s - loss: 0.9538 - accuracy: 0.6965\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.9547 - accuracy: 0.6961\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "140/750 [====>.........................] - ETA: 7s - loss: 0.4866 - accuracy: 0.8388\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.4783 - accuracy: 0.8399\n",
      "636/750 [========================>.....] - ETA: 1s - loss: 0.4787 - accuracy: 0.8396\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2953 - accuracy: 0.8947 - val_loss: 0.3380 - val_accuracy: 0.8789\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 17/30\n",
      "640/750 [========================>.....] - ETA: 1s - loss: 0.4782 - accuracy: 0.8398\n",
      "  7/750 [..............................] - ETA: 21s - loss: 0.2842 - accuracy: 0.8996\n",
      "643/750 [========================>.....] - ETA: 1s - loss: 0.4781 - accuracy: 0.8399\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.2721 - accuracy: 0.8594\n",
      "168/750 [=====>........................] - ETA: 6s - loss: 0.4822 - accuracy: 0.8396\n",
      "454/750 [=================>............] - ETA: 3s - loss: 0.4773 - accuracy: 0.8412\n",
      " 16/750 [..............................] - ETA: 16s - loss: 0.2993 - accuracy: 0.8906\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "675/750 [==========================>...] - ETA: 0s - loss: 0.4784 - accuracy: 0.8394\n",
      "176/750 [======>.......................] - ETA: 6s - loss: 0.9560 - accuracy: 0.6988\n",
      "477/750 [==================>...........] - ETA: 2s - loss: 0.9556 - accuracy: 0.6960\n",
      " 30/750 [>.............................] - ETA: 13s - loss: 0.2869 - accuracy: 0.8969\n",
      "677/750 [==========================>...] - ETA: 0s - loss: 0.4782 - accuracy: 0.8395\n",
      " 40/750 [>.............................] - ETA: 11s - loss: 0.2738 - accuracy: 0.8988\n",
      "204/750 [=======>......................] - ETA: 6s - loss: 0.9564 - accuracy: 0.6985\n",
      "493/750 [==================>...........] - ETA: 2s - loss: 0.9549 - accuracy: 0.6965\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 52/750 [=>............................] - ETA: 10s - loss: 0.2836 - accuracy: 0.8960\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.4774 - accuracy: 0.8402\n",
      "221/750 [=======>......................] - ETA: 6s - loss: 0.9557 - accuracy: 0.6978\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "517/750 [===================>..........] - ETA: 2s - loss: 0.9555 - accuracy: 0.6959\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "507/750 [===================>..........] - ETA: 2s - loss: 0.4789 - accuracy: 0.8405\n",
      " 62/750 [=>............................] - ETA: 9s - loss: 0.2808 - accuracy: 0.8992\n",
      "246/750 [========>.....................] - ETA: 5s - loss: 0.9563 - accuracy: 0.6973\n",
      "692/750 [==========================>...] - ETA: 0s - loss: 0.9545 - accuracy: 0.6968\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 82/750 [==>...........................] - ETA: 8s - loss: 0.2833 - accuracy: 0.8998\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.9551 - accuracy: 0.6961\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "102/750 [===>..........................] - ETA: 7s - loss: 0.2805 - accuracy: 0.9007\n",
      "260/750 [=========>....................] - ETA: 5s - loss: 0.9537 - accuracy: 0.6987\n",
      "445/750 [================>.............] - ETA: 3s - loss: 0.9541 - accuracy: 0.6965\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 79/750 [==>...........................] - ETA: 8s - loss: 0.2836 - accuracy: 0.8987\n",
      "271/750 [=========>....................] - ETA: 5s - loss: 0.4786 - accuracy: 0.8418\n",
      "557/750 [=====================>........] - ETA: 2s - loss: 0.9554 - accuracy: 0.6960\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "573/750 [=====================>........] - ETA: 1s - loss: 0.9552 - accuracy: 0.6960\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "130/750 [====>.........................] - ETA: 7s - loss: 0.2803 - accuracy: 0.8999\n",
      "136/750 [====>.........................] - ETA: 7s - loss: 0.2792 - accuracy: 0.8998\n",
      "117/750 [===>..........................] - ETA: 7s - loss: 0.2833 - accuracy: 0.9002\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "151/750 [=====>........................] - ETA: 7s - loss: 0.2773 - accuracy: 0.9001\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.9543 - accuracy: 0.6963\n",
      "330/750 [============>.................] - ETA: 4s - loss: 0.9544 - accuracy: 0.6972\n",
      "145/750 [====>.........................] - ETA: 7s - loss: 0.2778 - accuracy: 0.8999\n",
      "612/750 [=======================>......] - ETA: 1s - loss: 0.9547 - accuracy: 0.6961\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "350/750 [=============>................] - ETA: 4s - loss: 0.9539 - accuracy: 0.6974\n",
      "172/750 [=====>........................] - ETA: 7s - loss: 0.2798 - accuracy: 0.8992\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "207/750 [=======>......................] - ETA: 6s - loss: 0.2849 - accuracy: 0.8970\n",
      "195/750 [======>.......................] - ETA: 6s - loss: 0.2853 - accuracy: 0.8968\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "664/750 [=========================>....] - ETA: 0s - loss: 0.9541 - accuracy: 0.6967\n",
      "216/750 [=======>......................] - ETA: 6s - loss: 0.2845 - accuracy: 0.8971\n",
      "674/750 [=========================>....] - ETA: 0s - loss: 0.9535 - accuracy: 0.6972\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "222/750 [=======>......................] - ETA: 6s - loss: 0.2839 - accuracy: 0.8972\n",
      "397/750 [==============>...............] - ETA: 3s - loss: 0.9529 - accuracy: 0.6977\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "236/750 [========>.....................] - ETA: 6s - loss: 0.2854 - accuracy: 0.8960\n",
      "246/750 [========>.....................] - ETA: 5s - loss: 0.2829 - accuracy: 0.8973\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.9554 - accuracy: 0.6965\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "262/750 [=========>....................] - ETA: 5s - loss: 0.2882 - accuracy: 0.8950\n",
      "426/750 [================>.............] - ETA: 3s - loss: 0.9535 - accuracy: 0.6966\n",
      "278/750 [==========>...................] - ETA: 5s - loss: 0.2864 - accuracy: 0.8961\n",
      " 10/750 [..............................] - ETA: 4s - loss: 0.5225 - accuracy: 0.8313\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.9545 - accuracy: 0.6971\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "284/750 [==========>...................] - ETA: 5s - loss: 0.2872 - accuracy: 0.8956\n",
      "466/750 [=================>............] - ETA: 3s - loss: 0.9547 - accuracy: 0.6963\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.9543 - accuracy: 0.6973\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 2s - loss: 0.8895 - accuracy: 0.6719\n",
      "293/750 [==========>...................] - ETA: 5s - loss: 0.2875 - accuracy: 0.8957\n",
      " 20/750 [..............................] - ETA: 10s - loss: 0.4876 - accuracy: 0.8367\n",
      "303/750 [===========>..................] - ETA: 5s - loss: 0.2882 - accuracy: 0.8953\n",
      " 28/750 [>.............................] - ETA: 10s - loss: 0.4663 - accuracy: 0.8432\n",
      " 34/750 [>.............................] - ETA: 9s - loss: 0.4777 - accuracy: 0.8359 \n",
      "309/750 [===========>..................] - ETA: 5s - loss: 0.2882 - accuracy: 0.8955\n",
      " 34/750 [>.............................] - ETA: 7s - loss: 0.9244 - accuracy: 0.7096\n",
      "321/750 [===========>..................] - ETA: 4s - loss: 0.2880 - accuracy: 0.8957\n",
      " 46/750 [>.............................] - ETA: 8s - loss: 0.4846 - accuracy: 0.8336\n",
      " 36/750 [>.............................] - ETA: 8s - loss: 0.9238 - accuracy: 0.7127\n",
      "332/750 [============>.................] - ETA: 4s - loss: 0.2885 - accuracy: 0.8956\n",
      " 53/750 [=>............................] - ETA: 9s - loss: 0.4794 - accuracy: 0.8376\n",
      "340/750 [============>.................] - ETA: 4s - loss: 0.2890 - accuracy: 0.8955\n",
      " 63/750 [=>............................] - ETA: 8s - loss: 0.4815 - accuracy: 0.8383\n",
      "528/750 [====================>.........] - ETA: 2s - loss: 0.9547 - accuracy: 0.6962\n",
      "346/750 [============>.................] - ETA: 4s - loss: 0.2890 - accuracy: 0.8955\n",
      " 70/750 [=>............................] - ETA: 8s - loss: 0.4799 - accuracy: 0.8400\n",
      " 80/750 [==>...........................] - ETA: 8s - loss: 0.4830 - accuracy: 0.8377\n",
      "359/750 [=============>................] - ETA: 4s - loss: 0.2884 - accuracy: 0.8956\n",
      " 91/750 [==>...........................] - ETA: 7s - loss: 0.4838 - accuracy: 0.8355\n",
      " 80/750 [==>...........................] - ETA: 7s - loss: 0.9525 - accuracy: 0.6977\n",
      "370/750 [=============>................] - ETA: 4s - loss: 0.2882 - accuracy: 0.8955\n",
      "101/750 [===>..........................] - ETA: 7s - loss: 0.4844 - accuracy: 0.8357\n",
      "109/750 [===>..........................] - ETA: 7s - loss: 0.4861 - accuracy: 0.8353\n",
      "389/750 [==============>...............] - ETA: 4s - loss: 0.2885 - accuracy: 0.8957\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "138/750 [====>.........................] - ETA: 7s - loss: 0.4825 - accuracy: 0.8359\n",
      "412/750 [===============>..............] - ETA: 3s - loss: 0.2874 - accuracy: 0.8964\n",
      "422/750 [===============>..............] - ETA: 3s - loss: 0.2868 - accuracy: 0.8970\n",
      "641/750 [========================>.....] - ETA: 1s - loss: 0.9544 - accuracy: 0.6964\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.9540 - accuracy: 0.6966\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.9541 - accuracy: 0.6973 - val_loss: 0.9371 - val_accuracy: 0.7007\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 17/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "454/750 [=================>............] - ETA: 3s - loss: 0.2871 - accuracy: 0.8971\n",
      "176/750 [======>.......................] - ETA: 6s - loss: 0.4787 - accuracy: 0.8373\n",
      " 13/750 [..............................] - ETA: 3s - loss: 0.9123 - accuracy: 0.7163\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "461/750 [=================>............] - ETA: 3s - loss: 0.2868 - accuracy: 0.8974\n",
      "179/750 [======>.......................] - ETA: 6s - loss: 0.4772 - accuracy: 0.8377\n",
      "473/750 [=================>............] - ETA: 3s - loss: 0.2868 - accuracy: 0.8973\n",
      " 19/750 [..............................] - ETA: 15s - loss: 0.3007 - accuracy: 0.8873\n",
      "480/750 [==================>...........] - ETA: 3s - loss: 0.2866 - accuracy: 0.8974\n",
      "677/750 [==========================>...] - ETA: 0s - loss: 0.9536 - accuracy: 0.6972\n",
      "500/750 [===================>..........] - ETA: 2s - loss: 0.2864 - accuracy: 0.8975\n",
      "487/750 [==================>...........] - ETA: 3s - loss: 0.2867 - accuracy: 0.8975\n",
      "232/750 [========>.....................] - ETA: 6s - loss: 0.4776 - accuracy: 0.8398\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.9549 - accuracy: 0.6968\n",
      "200/750 [=======>......................] - ETA: 6s - loss: 0.9438 - accuracy: 0.6988\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "516/750 [===================>..........] - ETA: 2s - loss: 0.2870 - accuracy: 0.8971\n",
      "522/750 [===================>..........] - ETA: 2s - loss: 0.2868 - accuracy: 0.8972\n",
      "228/750 [========>.....................] - ETA: 6s - loss: 0.9434 - accuracy: 0.6992\n",
      "527/750 [====================>.........] - ETA: 2s - loss: 0.2875 - accuracy: 0.8970\n",
      "536/750 [====================>.........] - ETA: 2s - loss: 0.2871 - accuracy: 0.8973\n",
      "541/750 [====================>.........] - ETA: 2s - loss: 0.2866 - accuracy: 0.8975\n",
      "444/750 [================>.............] - ETA: 3s - loss: 0.2867 - accuracy: 0.8971\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "545/750 [====================>.........] - ETA: 2s - loss: 0.2870 - accuracy: 0.8973\n",
      "255/750 [=========>....................] - ETA: 6s - loss: 0.9433 - accuracy: 0.7001\n",
      "553/750 [=====================>........] - ETA: 2s - loss: 0.2878 - accuracy: 0.8970\n",
      "259/750 [=========>....................] - ETA: 6s - loss: 0.9446 - accuracy: 0.6993\n",
      "125/750 [====>.........................] - ETA: 6s - loss: 0.9494 - accuracy: 0.6964\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "562/750 [=====================>........] - ETA: 2s - loss: 0.2893 - accuracy: 0.8967\n",
      "114/750 [===>..........................] - ETA: 7s - loss: 0.4856 - accuracy: 0.8346\n",
      "572/750 [=====================>........] - ETA: 2s - loss: 0.2897 - accuracy: 0.8965\n",
      "266/750 [=========>....................] - ETA: 6s - loss: 0.9432 - accuracy: 0.7002\n",
      "270/750 [=========>....................] - ETA: 6s - loss: 0.9439 - accuracy: 0.6994\n",
      "576/750 [======================>.......] - ETA: 2s - loss: 0.2899 - accuracy: 0.8964\n",
      "580/750 [======================>.......] - ETA: 2s - loss: 0.2903 - accuracy: 0.8963\n",
      "583/750 [======================>.......] - ETA: 2s - loss: 0.2905 - accuracy: 0.8962\n",
      "586/750 [======================>.......] - ETA: 1s - loss: 0.2907 - accuracy: 0.8961\n",
      "594/750 [======================>.......] - ETA: 1s - loss: 0.2894 - accuracy: 0.8966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:03:17,217 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 7115431936; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/750 [===========>..................] - ETA: 5s - loss: 0.4746 - accuracy: 0.8417\n",
      "172/750 [=====>........................] - ETA: 6s - loss: 0.9451 - accuracy: 0.6993\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.2897 - accuracy: 0.8964\n",
      "606/750 [=======================>......] - ETA: 1s - loss: 0.2900 - accuracy: 0.8963\n",
      "199/750 [======>.......................] - ETA: 6s - loss: 0.4767 - accuracy: 0.8385\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "616/750 [=======================>......] - ETA: 1s - loss: 0.2901 - accuracy: 0.8960\n",
      "331/750 [============>.................] - ETA: 5s - loss: 0.4762 - accuracy: 0.8413\n",
      "214/750 [=======>......................] - ETA: 6s - loss: 0.9438 - accuracy: 0.6989\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.2904 - accuracy: 0.8958\n",
      "399/750 [==============>...............] - ETA: 3s - loss: 0.2888 - accuracy: 0.8957\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "631/750 [========================>.....] - ETA: 1s - loss: 0.2906 - accuracy: 0.8956\n",
      "246/750 [========>.....................] - ETA: 6s - loss: 0.9430 - accuracy: 0.7005\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "354/750 [=============>................] - ETA: 5s - loss: 0.9425 - accuracy: 0.6994\n",
      "650/750 [=========================>....] - ETA: 1s - loss: 0.2903 - accuracy: 0.8956\n",
      "264/750 [=========>....................] - ETA: 6s - loss: 0.9433 - accuracy: 0.7001\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "355/750 [=============>................] - ETA: 5s - loss: 0.9423 - accuracy: 0.6995\n",
      "657/750 [=========================>....] - ETA: 1s - loss: 0.2900 - accuracy: 0.8958\n",
      "660/750 [=========================>....] - ETA: 1s - loss: 0.2900 - accuracy: 0.8958\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 0.4745 - accuracy: 0.8420\n",
      "662/750 [=========================>....] - ETA: 1s - loss: 0.2899 - accuracy: 0.8957\n",
      "666/750 [=========================>....] - ETA: 1s - loss: 0.2899 - accuracy: 0.8958\n",
      "298/750 [==========>...................] - ETA: 5s - loss: 0.9422 - accuracy: 0.6998\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "369/750 [=============>................] - ETA: 5s - loss: 0.9414 - accuracy: 0.6998\n",
      "670/750 [=========================>....] - ETA: 0s - loss: 0.2902 - accuracy: 0.8958\n",
      "290/750 [==========>...................] - ETA: 6s - loss: 0.9415 - accuracy: 0.7002\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.2904 - accuracy: 0.8956\n",
      " 19/750 [..............................] - ETA: 10s - loss: 0.9113 - accuracy: 0.7138\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.2902 - accuracy: 0.8957\n",
      "402/750 [===============>..............] - ETA: 4s - loss: 0.4744 - accuracy: 0.8418\n",
      "406/750 [===============>..............] - ETA: 4s - loss: 0.4742 - accuracy: 0.8418\n",
      "402/750 [===============>..............] - ETA: 4s - loss: 0.9416 - accuracy: 0.6997\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.2904 - accuracy: 0.8959\n",
      "324/750 [===========>..................] - ETA: 5s - loss: 0.9432 - accuracy: 0.6997\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.2902 - accuracy: 0.8958\n",
      " 45/750 [>.............................] - ETA: 8s - loss: 0.9387 - accuracy: 0.7059\n",
      "349/750 [============>.................] - ETA: 5s - loss: 0.4764 - accuracy: 0.8413\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2911 - accuracy: 0.8955\n",
      " 67/750 [=>............................] - ETA: 8s - loss: 0.9525 - accuracy: 0.6980\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2912 - accuracy: 0.8955\n",
      "338/750 [============>.................] - ETA: 5s - loss: 0.9432 - accuracy: 0.6997\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "435/750 [================>.............] - ETA: 4s - loss: 0.9396 - accuracy: 0.7005\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.2908 - accuracy: 0.8957\n",
      "450/750 [=================>............] - ETA: 3s - loss: 0.4751 - accuracy: 0.8411\n",
      " 96/750 [==>...........................] - ETA: 6s - loss: 0.9506 - accuracy: 0.6965\n",
      "366/750 [=============>................] - ETA: 5s - loss: 0.9415 - accuracy: 0.6998\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2908 - accuracy: 0.8957\n",
      "453/750 [=================>............] - ETA: 3s - loss: 0.4749 - accuracy: 0.8414\n",
      "456/750 [=================>............] - ETA: 3s - loss: 0.4755 - accuracy: 0.8412\n",
      "449/750 [================>.............] - ETA: 3s - loss: 0.9383 - accuracy: 0.7016\n",
      "104/750 [===>..........................] - ETA: 7s - loss: 0.9480 - accuracy: 0.6977\n",
      "114/750 [===>..........................] - ETA: 7s - loss: 0.9498 - accuracy: 0.6965\n",
      "480/750 [==================>...........] - ETA: 3s - loss: 0.4746 - accuracy: 0.8419\n",
      "386/750 [==============>...............] - ETA: 4s - loss: 0.4752 - accuracy: 0.8418\n",
      "482/750 [==================>...........] - ETA: 3s - loss: 0.9375 - accuracy: 0.7013\n",
      "496/750 [==================>...........] - ETA: 3s - loss: 0.4753 - accuracy: 0.8419\n",
      "147/750 [====>.........................] - ETA: 6s - loss: 0.9455 - accuracy: 0.6990\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "422/750 [===============>..............] - ETA: 4s - loss: 0.9406 - accuracy: 0.7000\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.2907 - accuracy: 0.8956\n",
      "473/750 [=================>............] - ETA: 3s - loss: 0.4751 - accuracy: 0.8415\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "528/750 [====================>.........] - ETA: 2s - loss: 0.9382 - accuracy: 0.7007\n",
      "198/750 [======>.......................] - ETA: 6s - loss: 0.9436 - accuracy: 0.6986\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "486/750 [==================>...........] - ETA: 3s - loss: 0.9373 - accuracy: 0.7014\n",
      "587/750 [======================>.......] - ETA: 2s - loss: 0.4719 - accuracy: 0.8428\n",
      "582/750 [======================>.......] - ETA: 2s - loss: 0.9364 - accuracy: 0.7017\n",
      "596/750 [======================>.......] - ETA: 1s - loss: 0.4713 - accuracy: 0.8430\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.4709 - accuracy: 0.8433\n",
      "225/750 [========>.....................] - ETA: 6s - loss: 0.9435 - accuracy: 0.6995\n",
      "515/750 [===================>..........] - ETA: 3s - loss: 0.9386 - accuracy: 0.7007\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "247/750 [========>.....................] - ETA: 6s - loss: 0.9424 - accuracy: 0.7007\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "544/750 [====================>.........] - ETA: 2s - loss: 0.4746 - accuracy: 0.8420\n",
      "635/750 [========================>.....] - ETA: 1s - loss: 0.4728 - accuracy: 0.8424\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.2908 - accuracy: 0.8959 - val_loss: 0.3384 - val_accuracy: 0.8807\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 18/30\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.3419 - accuracy: 0.8906\n",
      "442/750 [================>.............] - ETA: 4s - loss: 0.9387 - accuracy: 0.7011\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "538/750 [====================>.........] - ETA: 2s - loss: 0.9382 - accuracy: 0.7008\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  2/750 [..............................] - ETA: 1:34 - loss: 0.2810 - accuracy: 0.8984\n",
      "662/750 [=========================>....] - ETA: 1s - loss: 0.4719 - accuracy: 0.8423\n",
      "558/750 [=====================>........] - ETA: 2s - loss: 0.9380 - accuracy: 0.7011\n",
      "650/750 [=========================>....] - ETA: 1s - loss: 0.9369 - accuracy: 0.7017\n",
      " 19/750 [..............................] - ETA: 10s - loss: 0.3190 - accuracy: 0.8808\n",
      "669/750 [=========================>....] - ETA: 1s - loss: 0.4720 - accuracy: 0.8422\n",
      " 21/750 [..............................] - ETA: 11s - loss: 0.3135 - accuracy: 0.8810\n",
      "565/750 [=====================>........] - ETA: 2s - loss: 0.9382 - accuracy: 0.7011\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "668/750 [=========================>....] - ETA: 1s - loss: 0.9369 - accuracy: 0.7016\n",
      " 45/750 [>.............................] - ETA: 7s - loss: 0.3034 - accuracy: 0.8934\n",
      " 49/750 [>.............................] - ETA: 8s - loss: 0.3004 - accuracy: 0.8925\n",
      "685/750 [==========================>...] - ETA: 0s - loss: 0.9365 - accuracy: 0.7020\n",
      "690/750 [==========================>...] - ETA: 0s - loss: 0.9364 - accuracy: 0.7022\n",
      "312/750 [===========>..................] - ETA: 5s - loss: 0.9423 - accuracy: 0.7004\n",
      "624/750 [=======================>......] - ETA: 1s - loss: 0.9358 - accuracy: 0.7023\n",
      " 77/750 [==>...........................] - ETA: 8s - loss: 0.3047 - accuracy: 0.8890\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.4714 - accuracy: 0.8423\n",
      "621/750 [=======================>......] - ETA: 1s - loss: 0.9356 - accuracy: 0.7024\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 88/750 [==>...........................] - ETA: 8s - loss: 0.3022 - accuracy: 0.8887\n",
      " 92/750 [==>...........................] - ETA: 9s - loss: 0.3023 - accuracy: 0.8896\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.4728 - accuracy: 0.8424\n",
      "106/750 [===>..........................] - ETA: 8s - loss: 0.3015 - accuracy: 0.8899\n",
      "393/750 [==============>...............] - ETA: 4s - loss: 0.9414 - accuracy: 0.7001\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "113/750 [===>..........................] - ETA: 8s - loss: 0.3002 - accuracy: 0.8903\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.4725 - accuracy: 0.8418\n",
      "129/750 [====>.........................] - ETA: 7s - loss: 0.3030 - accuracy: 0.8894\n",
      "154/750 [=====>........................] - ETA: 7s - loss: 0.2964 - accuracy: 0.8931\n",
      "671/750 [=========================>....] - ETA: 1s - loss: 0.9368 - accuracy: 0.7017\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "162/750 [=====>........................] - ETA: 7s - loss: 0.2969 - accuracy: 0.8927\n",
      "383/750 [==============>...............] - ETA: 4s - loss: 0.9420 - accuracy: 0.6997\n",
      "174/750 [=====>........................] - ETA: 6s - loss: 0.2951 - accuracy: 0.8927\n",
      "191/750 [======>.......................] - ETA: 6s - loss: 0.2966 - accuracy: 0.8929\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.9364 - accuracy: 0.7021\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "208/750 [=======>......................] - ETA: 5s - loss: 0.2944 - accuracy: 0.8936\n",
      "220/750 [=======>......................] - ETA: 5s - loss: 0.2920 - accuracy: 0.8945\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.9365 - accuracy: 0.7018\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.9367 - accuracy: 0.7013\n",
      "227/750 [========>.....................] - ETA: 5s - loss: 0.2928 - accuracy: 0.8941\n",
      "235/750 [========>.....................] - ETA: 5s - loss: 0.2941 - accuracy: 0.8942\n",
      " 71/750 [=>............................] - ETA: 8s - loss: 0.3059 - accuracy: 0.8893\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.9372 - accuracy: 0.7012\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "248/750 [========>.....................] - ETA: 5s - loss: 0.2921 - accuracy: 0.8951\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.9373 - accuracy: 0.7012\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "257/750 [=========>....................] - ETA: 5s - loss: 0.2907 - accuracy: 0.8957\n",
      "465/750 [=================>............] - ETA: 3s - loss: 0.9374 - accuracy: 0.7013\n",
      "272/750 [=========>....................] - ETA: 5s - loss: 0.2916 - accuracy: 0.8950\n",
      "286/750 [==========>...................] - ETA: 5s - loss: 0.2910 - accuracy: 0.8959\n",
      "297/750 [==========>...................] - ETA: 4s - loss: 0.2899 - accuracy: 0.8962\n",
      "309/750 [===========>..................] - ETA: 4s - loss: 0.2919 - accuracy: 0.8954\n",
      " 32/750 [>.............................] - ETA: 5s - loss: 0.4201 - accuracy: 0.8652\n",
      "495/750 [==================>...........] - ETA: 3s - loss: 0.9376 - accuracy: 0.7011\n",
      "  5/750 [..............................] - ETA: 12s - loss: 0.8995 - accuracy: 0.7437\n",
      "322/750 [===========>..................] - ETA: 4s - loss: 0.2910 - accuracy: 0.8957\n",
      " 42/750 [>.............................] - ETA: 6s - loss: 0.4348 - accuracy: 0.8590\n",
      " 15/750 [..............................] - ETA: 10s - loss: 0.9392 - accuracy: 0.7188\n",
      "333/750 [============>.................] - ETA: 4s - loss: 0.2897 - accuracy: 0.8961\n",
      "141/750 [====>.........................] - ETA: 7s - loss: 0.2974 - accuracy: 0.8922\n",
      " 49/750 [>.............................] - ETA: 6s - loss: 0.4383 - accuracy: 0.8584\n",
      "340/750 [============>.................] - ETA: 4s - loss: 0.2889 - accuracy: 0.8964\n",
      " 39/750 [>.............................] - ETA: 8s - loss: 0.9398 - accuracy: 0.7051\n",
      "350/750 [=============>................] - ETA: 4s - loss: 0.2882 - accuracy: 0.8965\n",
      " 51/750 [=>............................] - ETA: 7s - loss: 0.9257 - accuracy: 0.7068\n",
      "358/750 [=============>................] - ETA: 4s - loss: 0.2887 - accuracy: 0.8965\n",
      "366/750 [=============>................] - ETA: 4s - loss: 0.2891 - accuracy: 0.8960\n",
      "199/750 [======>.......................] - ETA: 6s - loss: 0.2953 - accuracy: 0.8933\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 0.2898 - accuracy: 0.8957\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.9354 - accuracy: 0.7024\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "401/750 [===============>..............] - ETA: 3s - loss: 0.2896 - accuracy: 0.8957\n",
      "411/750 [===============>..............] - ETA: 3s - loss: 0.2906 - accuracy: 0.8953\n",
      "134/750 [====>.........................] - ETA: 7s - loss: 0.4685 - accuracy: 0.8420\n",
      "426/750 [================>.............] - ETA: 3s - loss: 0.2898 - accuracy: 0.8956\n",
      "143/750 [====>.........................] - ETA: 7s - loss: 0.4662 - accuracy: 0.8436\n",
      "164/750 [=====>........................] - ETA: 6s - loss: 0.4669 - accuracy: 0.8438\n",
      "641/750 [========================>.....] - ETA: 1s - loss: 0.9364 - accuracy: 0.7017\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.9375 - accuracy: 0.7011 - val_loss: 0.9213 - val_accuracy: 0.7053\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 18/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 39s - loss: 0.4239 - accuracy: 0.8750\n",
      "138/750 [====>.........................] - ETA: 7s - loss: 0.9288 - accuracy: 0.7079\n",
      "458/750 [=================>............] - ETA: 3s - loss: 0.2882 - accuracy: 0.8968\n",
      "447/750 [================>.............] - ETA: 3s - loss: 0.2897 - accuracy: 0.8963\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 16/750 [..............................] - ETA: 6s - loss: 0.4332 - accuracy: 0.8604\n",
      "469/750 [=================>............] - ETA: 3s - loss: 0.2876 - accuracy: 0.8974\n",
      "477/750 [==================>...........] - ETA: 2s - loss: 0.2882 - accuracy: 0.8971\n",
      "175/750 [======>.......................] - ETA: 6s - loss: 0.9267 - accuracy: 0.7097\n",
      "481/750 [==================>...........] - ETA: 2s - loss: 0.2878 - accuracy: 0.8971\n",
      "195/750 [======>.......................] - ETA: 6s - loss: 0.4696 - accuracy: 0.8419\n",
      " 22/750 [..............................] - ETA: 9s - loss: 0.9391 - accuracy: 0.7116 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "492/750 [==================>...........] - ETA: 2s - loss: 0.2867 - accuracy: 0.8975\n",
      "199/750 [======>.......................] - ETA: 6s - loss: 0.4701 - accuracy: 0.8416\n",
      "502/750 [===================>..........] - ETA: 2s - loss: 0.2862 - accuracy: 0.8978\n",
      "505/750 [===================>..........] - ETA: 2s - loss: 0.2860 - accuracy: 0.8979\n",
      "204/750 [=======>......................] - ETA: 6s - loss: 0.9275 - accuracy: 0.7076\n",
      "515/750 [===================>..........] - ETA: 2s - loss: 0.2869 - accuracy: 0.8978\n",
      "530/750 [====================>.........] - ETA: 2s - loss: 0.2874 - accuracy: 0.8976\n",
      "238/750 [========>.....................] - ETA: 5s - loss: 0.4708 - accuracy: 0.8410\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.2871 - accuracy: 0.8979\n",
      "250/750 [=========>....................] - ETA: 5s - loss: 0.4703 - accuracy: 0.8418\n",
      " 81/750 [==>...........................] - ETA: 8s - loss: 0.9281 - accuracy: 0.7064\n",
      "551/750 [=====================>........] - ETA: 2s - loss: 0.2870 - accuracy: 0.8979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:03:27,309 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 7115153408; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726/750 [============================>.] - ETA: 0s - loss: 0.9371 - accuracy: 0.7012\n",
      " 91/750 [==>...........................] - ETA: 7s - loss: 0.9327 - accuracy: 0.7055\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "555/750 [=====================>........] - ETA: 2s - loss: 0.2874 - accuracy: 0.8977\n",
      "564/750 [=====================>........] - ETA: 2s - loss: 0.2874 - accuracy: 0.8978\n",
      "275/750 [==========>...................] - ETA: 5s - loss: 0.4707 - accuracy: 0.8404\n",
      "103/750 [===>..........................] - ETA: 7s - loss: 0.9352 - accuracy: 0.7036\n",
      "572/750 [=====================>........] - ETA: 2s - loss: 0.2874 - accuracy: 0.8979\n",
      "397/750 [==============>...............] - ETA: 3s - loss: 0.2896 - accuracy: 0.8956\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "114/750 [===>..........................] - ETA: 7s - loss: 0.9337 - accuracy: 0.7033\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.9375 - accuracy: 0.7011\n",
      "125/750 [====>.........................] - ETA: 7s - loss: 0.9330 - accuracy: 0.7051\n",
      "586/750 [======================>.......] - ETA: 1s - loss: 0.2867 - accuracy: 0.8982\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.2871 - accuracy: 0.8981\n",
      "296/750 [==========>...................] - ETA: 5s - loss: 0.4687 - accuracy: 0.8412\n",
      "601/750 [=======================>......] - ETA: 1s - loss: 0.2868 - accuracy: 0.8981\n",
      "158/750 [=====>........................] - ETA: 6s - loss: 0.9293 - accuracy: 0.7077\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "615/750 [=======================>......] - ETA: 1s - loss: 0.2863 - accuracy: 0.8985\n",
      "162/750 [=====>........................] - ETA: 6s - loss: 0.9297 - accuracy: 0.7076\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "301/750 [===========>..................] - ETA: 5s - loss: 0.9278 - accuracy: 0.7049\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.2862 - accuracy: 0.8985\n",
      "329/750 [============>.................] - ETA: 4s - loss: 0.4679 - accuracy: 0.8418\n",
      "189/750 [======>.......................] - ETA: 6s - loss: 0.9263 - accuracy: 0.7089\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "349/750 [============>.................] - ETA: 4s - loss: 0.4694 - accuracy: 0.8413\n",
      "214/750 [=======>......................] - ETA: 6s - loss: 0.9257 - accuracy: 0.7082\n",
      "651/750 [=========================>....] - ETA: 1s - loss: 0.2871 - accuracy: 0.8982\n",
      "665/750 [=========================>....] - ETA: 0s - loss: 0.2871 - accuracy: 0.8981\n",
      "222/750 [=======>......................] - ETA: 6s - loss: 0.9265 - accuracy: 0.7074\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "667/750 [=========================>....] - ETA: 0s - loss: 0.2873 - accuracy: 0.8980\n",
      "354/750 [=============>................] - ETA: 4s - loss: 0.9270 - accuracy: 0.7038\n",
      "229/750 [========>.....................] - ETA: 6s - loss: 0.4699 - accuracy: 0.8416\n",
      "669/750 [=========================>....] - ETA: 0s - loss: 0.2876 - accuracy: 0.8979\n",
      "247/750 [========>.....................] - ETA: 6s - loss: 0.9256 - accuracy: 0.7079\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 74/750 [=>............................] - ETA: 8s - loss: 0.9267 - accuracy: 0.7054\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.2873 - accuracy: 0.8982\n",
      "388/750 [==============>...............] - ETA: 4s - loss: 0.9257 - accuracy: 0.7033\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.2870 - accuracy: 0.8983\n",
      "267/750 [=========>....................] - ETA: 5s - loss: 0.9251 - accuracy: 0.7076\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2868 - accuracy: 0.8983\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2866 - accuracy: 0.8984\n",
      "295/750 [==========>...................] - ETA: 5s - loss: 0.9272 - accuracy: 0.7056\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2869 - accuracy: 0.8981\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2866 - accuracy: 0.8982\n",
      "452/750 [=================>............] - ETA: 3s - loss: 0.4689 - accuracy: 0.8413\n",
      "313/750 [===========>..................] - ETA: 5s - loss: 0.9297 - accuracy: 0.7035\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2867 - accuracy: 0.8982\n",
      "457/750 [=================>............] - ETA: 3s - loss: 0.4683 - accuracy: 0.8416\n",
      "447/750 [================>.............] - ETA: 3s - loss: 0.9250 - accuracy: 0.7032\n",
      "462/750 [=================>............] - ETA: 3s - loss: 0.4681 - accuracy: 0.8420\n",
      "346/750 [============>.................] - ETA: 4s - loss: 0.9277 - accuracy: 0.7034\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "478/750 [==================>...........] - ETA: 3s - loss: 0.9238 - accuracy: 0.7044\n",
      " 56/750 [=>............................] - ETA: 9s - loss: 0.9279 - accuracy: 0.7042\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "366/750 [=============>................] - ETA: 4s - loss: 0.9257 - accuracy: 0.7038\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "382/750 [==============>...............] - ETA: 4s - loss: 0.9252 - accuracy: 0.7038\n",
      "580/750 [======================>.......] - ETA: 1s - loss: 0.2870 - accuracy: 0.8980\n",
      "550/750 [=====================>........] - ETA: 2s - loss: 0.4698 - accuracy: 0.8421\n",
      "414/750 [===============>..............] - ETA: 3s - loss: 0.9255 - accuracy: 0.7033\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "135/750 [====>.........................] - ETA: 7s - loss: 0.9302 - accuracy: 0.7071\n",
      "430/750 [================>.............] - ETA: 3s - loss: 0.9254 - accuracy: 0.7028\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "581/750 [======================>.......] - ETA: 1s - loss: 0.9237 - accuracy: 0.7051\n",
      "590/750 [======================>.......] - ETA: 1s - loss: 0.9233 - accuracy: 0.7053\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.2861 - accuracy: 0.8986\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "463/750 [=================>............] - ETA: 3s - loss: 0.9234 - accuracy: 0.7042\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "441/750 [================>.............] - ETA: 3s - loss: 0.9247 - accuracy: 0.7035\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.4698 - accuracy: 0.8420\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.4701 - accuracy: 0.8418\n",
      "498/750 [==================>...........] - ETA: 2s - loss: 0.9245 - accuracy: 0.7043\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.2866 - accuracy: 0.8983 - val_loss: 0.3413 - val_accuracy: 0.8777\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 19/30\n",
      " 13/750 [..............................] - ETA: 3s - loss: 0.2952 - accuracy: 0.8990\n",
      " 22/750 [..............................] - ETA: 3s - loss: 0.2982 - accuracy: 0.8999\n",
      " 26/750 [>.............................] - ETA: 7s - loss: 0.2938 - accuracy: 0.9026\n",
      "517/750 [===================>..........] - ETA: 2s - loss: 0.9236 - accuracy: 0.7050\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 33/750 [>.............................] - ETA: 8s - loss: 0.2788 - accuracy: 0.9077\n",
      " 51/750 [=>............................] - ETA: 6s - loss: 0.2777 - accuracy: 0.9056\n",
      "240/750 [========>.....................] - ETA: 5s - loss: 0.9272 - accuracy: 0.7070\n",
      "679/750 [==========================>...] - ETA: 0s - loss: 0.4693 - accuracy: 0.8426\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.9230 - accuracy: 0.7053\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 76/750 [==>...........................] - ETA: 7s - loss: 0.2757 - accuracy: 0.9040\n",
      "568/750 [=====================>........] - ETA: 2s - loss: 0.9241 - accuracy: 0.7050\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 83/750 [==>...........................] - ETA: 7s - loss: 0.2810 - accuracy: 0.9019\n",
      "275/750 [==========>...................] - ETA: 5s - loss: 0.9251 - accuracy: 0.7069\n",
      " 95/750 [==>...........................] - ETA: 7s - loss: 0.2803 - accuracy: 0.9018\n",
      "394/750 [==============>...............] - ETA: 4s - loss: 0.9255 - accuracy: 0.7032\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "102/750 [===>..........................] - ETA: 7s - loss: 0.2783 - accuracy: 0.9026\n",
      "595/750 [======================>.......] - ETA: 1s - loss: 0.9236 - accuracy: 0.7051\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "111/750 [===>..........................] - ETA: 7s - loss: 0.2792 - accuracy: 0.9037\n",
      "125/750 [====>.........................] - ETA: 6s - loss: 0.2826 - accuracy: 0.9000\n",
      "136/750 [====>.........................] - ETA: 6s - loss: 0.2814 - accuracy: 0.9004\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.9220 - accuracy: 0.7058\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "150/750 [=====>........................] - ETA: 6s - loss: 0.2818 - accuracy: 0.9001\n",
      "624/750 [=======================>......] - ETA: 1s - loss: 0.9221 - accuracy: 0.7057\n",
      "161/750 [=====>........................] - ETA: 6s - loss: 0.2809 - accuracy: 0.8998\n",
      "325/750 [============>.................] - ETA: 5s - loss: 0.9284 - accuracy: 0.7039\n",
      "167/750 [=====>........................] - ETA: 6s - loss: 0.2807 - accuracy: 0.8999\n",
      "173/750 [=====>........................] - ETA: 6s - loss: 0.2800 - accuracy: 0.8996\n",
      "349/750 [============>.................] - ETA: 4s - loss: 0.9273 - accuracy: 0.7038\n",
      "188/750 [======>.......................] - ETA: 6s - loss: 0.2808 - accuracy: 0.8996\n",
      "666/750 [=========================>....] - ETA: 0s - loss: 0.9223 - accuracy: 0.7055\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "199/750 [======>.......................] - ETA: 5s - loss: 0.2810 - accuracy: 0.8989\n",
      "214/750 [=======>......................] - ETA: 5s - loss: 0.2813 - accuracy: 0.8992\n",
      "670/750 [=========================>....] - ETA: 0s - loss: 0.4698 - accuracy: 0.8424\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "219/750 [=======>......................] - ETA: 5s - loss: 0.2813 - accuracy: 0.8995\n",
      "230/750 [========>.....................] - ETA: 5s - loss: 0.2801 - accuracy: 0.9001\n",
      " 68/750 [=>............................] - ETA: 7s - loss: 0.2773 - accuracy: 0.9040\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "699/750 [==========================>...] - ETA: 0s - loss: 0.9215 - accuracy: 0.7061\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "245/750 [========>.....................] - ETA: 5s - loss: 0.2780 - accuracy: 0.9006\n",
      "256/750 [=========>....................] - ETA: 5s - loss: 0.2813 - accuracy: 0.8994\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.4685 - accuracy: 0.8427\n",
      "264/750 [=========>....................] - ETA: 4s - loss: 0.2823 - accuracy: 0.8991\n",
      "722/750 [===========================>..] - ETA: 0s - loss: 0.9213 - accuracy: 0.7061\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "278/750 [==========>...................] - ETA: 4s - loss: 0.2821 - accuracy: 0.8994\n",
      "292/750 [==========>...................] - ETA: 4s - loss: 0.2825 - accuracy: 0.8992\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.9225 - accuracy: 0.7057\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 3s - loss: 1.0827 - accuracy: 0.6406\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.4684 - accuracy: 0.8431\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "307/750 [===========>..................] - ETA: 4s - loss: 0.2844 - accuracy: 0.8984\n",
      "313/750 [===========>..................] - ETA: 4s - loss: 0.2845 - accuracy: 0.8986\n",
      "315/750 [===========>..................] - ETA: 4s - loss: 0.2848 - accuracy: 0.8985\n",
      " 13/750 [..............................] - ETA: 11s - loss: 0.9281 - accuracy: 0.7103\n",
      "329/750 [============>.................] - ETA: 4s - loss: 0.2837 - accuracy: 0.8986\n",
      " 34/750 [>.............................] - ETA: 7s - loss: 0.9324 - accuracy: 0.7073\n",
      "342/750 [============>.................] - ETA: 4s - loss: 0.2833 - accuracy: 0.8988\n",
      " 40/750 [>.............................] - ETA: 7s - loss: 0.9339 - accuracy: 0.7063\n",
      "353/750 [=============>................] - ETA: 3s - loss: 0.2837 - accuracy: 0.8986\n",
      "364/750 [=============>................] - ETA: 3s - loss: 0.2837 - accuracy: 0.8990\n",
      " 66/750 [=>............................] - ETA: 5s - loss: 0.4592 - accuracy: 0.8492\n",
      "369/750 [=============>................] - ETA: 3s - loss: 0.2834 - accuracy: 0.8990\n",
      "381/750 [==============>...............] - ETA: 3s - loss: 0.2851 - accuracy: 0.8986\n",
      "394/750 [==============>...............] - ETA: 3s - loss: 0.2848 - accuracy: 0.8986\n",
      "109/750 [===>..........................] - ETA: 5s - loss: 0.4695 - accuracy: 0.8423\n",
      "553/750 [=====================>........] - ETA: 2s - loss: 0.9226 - accuracy: 0.7058\n",
      "407/750 [===============>..............] - ETA: 3s - loss: 0.2846 - accuracy: 0.8982\n",
      "413/750 [===============>..............] - ETA: 3s - loss: 0.2852 - accuracy: 0.8980\n",
      "417/750 [===============>..............] - ETA: 3s - loss: 0.2849 - accuracy: 0.8980\n",
      "430/750 [================>.............] - ETA: 3s - loss: 0.2849 - accuracy: 0.8979\n",
      "597/750 [======================>.......] - ETA: 1s - loss: 0.4691 - accuracy: 0.8422\n",
      "438/750 [================>.............] - ETA: 3s - loss: 0.2844 - accuracy: 0.8979\n",
      "451/750 [=================>............] - ETA: 2s - loss: 0.2836 - accuracy: 0.8979\n",
      "472/750 [=================>............] - ETA: 2s - loss: 0.2844 - accuracy: 0.8977\n",
      "182/750 [======>.......................] - ETA: 5s - loss: 0.4730 - accuracy: 0.8410\n",
      "643/750 [========================>.....] - ETA: 1s - loss: 0.9220 - accuracy: 0.7057\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "463/750 [=================>............] - ETA: 2s - loss: 0.2836 - accuracy: 0.8978\n",
      "481/750 [==================>...........] - ETA: 2s - loss: 0.2844 - accuracy: 0.8975\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.9216 - accuracy: 0.7060\n",
      "494/750 [==================>...........] - ETA: 2s - loss: 0.2835 - accuracy: 0.8981\n",
      "212/750 [=======>......................] - ETA: 5s - loss: 0.4733 - accuracy: 0.8416\n",
      "488/750 [==================>...........] - ETA: 2s - loss: 0.2841 - accuracy: 0.8977\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.4682 - accuracy: 0.8432 - val_loss: 0.4716 - val_accuracy: 0.8374\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 19/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 11/750 [..............................] - ETA: 3s - loss: 0.4164 - accuracy: 0.8665\n",
      "503/750 [===================>..........] - ETA: 2s - loss: 0.2832 - accuracy: 0.8983\n",
      "221/750 [=======>......................] - ETA: 5s - loss: 0.4733 - accuracy: 0.8413\n",
      " 23/750 [..............................] - ETA: 3s - loss: 0.4282 - accuracy: 0.8607\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "205/750 [=======>......................] - ETA: 5s - loss: 0.9128 - accuracy: 0.7071\n",
      "227/750 [========>.....................] - ETA: 4s - loss: 0.4729 - accuracy: 0.8415\n",
      "529/750 [====================>.........] - ETA: 2s - loss: 0.2822 - accuracy: 0.8986\n",
      "516/750 [===================>..........] - ETA: 2s - loss: 0.2823 - accuracy: 0.8985\n",
      " 44/750 [>.............................] - ETA: 5s - loss: 0.4447 - accuracy: 0.8512\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "536/750 [====================>.........] - ETA: 2s - loss: 0.2832 - accuracy: 0.8983\n",
      " 51/750 [=>............................] - ETA: 7s - loss: 0.9338 - accuracy: 0.7028\n",
      "264/750 [=========>....................] - ETA: 4s - loss: 0.4687 - accuracy: 0.8426\n",
      "675/750 [==========================>...] - ETA: 0s - loss: 0.9230 - accuracy: 0.7052\n",
      "542/750 [====================>.........] - ETA: 2s - loss: 0.2830 - accuracy: 0.8984\n",
      "554/750 [=====================>........] - ETA: 1s - loss: 0.2819 - accuracy: 0.8991\n",
      "569/750 [=====================>........] - ETA: 1s - loss: 0.2820 - accuracy: 0.8990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:03:37,401 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 7114874880; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/750 [==========>...................] - ETA: 4s - loss: 0.4673 - accuracy: 0.8429\n",
      " 76/750 [==>...........................] - ETA: 6s - loss: 0.9270 - accuracy: 0.7042\n",
      "572/750 [=====================>........] - ETA: 1s - loss: 0.2822 - accuracy: 0.8990\n",
      " 84/750 [==>...........................] - ETA: 7s - loss: 0.9225 - accuracy: 0.7063\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "578/750 [======================>.......] - ETA: 1s - loss: 0.2829 - accuracy: 0.8987\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.2828 - accuracy: 0.8990\n",
      "601/750 [=======================>......] - ETA: 1s - loss: 0.2828 - accuracy: 0.8989\n",
      "104/750 [===>..........................] - ETA: 6s - loss: 0.9260 - accuracy: 0.7070\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "120/750 [===>..........................] - ETA: 6s - loss: 0.9185 - accuracy: 0.7095\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.2826 - accuracy: 0.8989\n",
      "144/750 [====>.........................] - ETA: 6s - loss: 0.9173 - accuracy: 0.7080\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "621/750 [=======================>......] - ETA: 1s - loss: 0.2829 - accuracy: 0.8989\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "632/750 [========================>.....] - ETA: 1s - loss: 0.2828 - accuracy: 0.8989\n",
      "326/750 [============>.................] - ETA: 4s - loss: 0.9166 - accuracy: 0.7046\n",
      "156/750 [=====>........................] - ETA: 5s - loss: 0.9170 - accuracy: 0.7068\n",
      "330/750 [============>.................] - ETA: 4s - loss: 0.9169 - accuracy: 0.7048\n",
      "644/750 [========================>.....] - ETA: 1s - loss: 0.2829 - accuracy: 0.8987\n",
      "158/750 [=====>........................] - ETA: 5s - loss: 0.9170 - accuracy: 0.7069\n",
      "392/750 [==============>...............] - ETA: 3s - loss: 0.4654 - accuracy: 0.8447\n",
      "171/750 [=====>........................] - ETA: 5s - loss: 0.9170 - accuracy: 0.7063\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "675/750 [==========================>...] - ETA: 0s - loss: 0.2820 - accuracy: 0.8989\n",
      "401/750 [===============>..............] - ETA: 3s - loss: 0.4647 - accuracy: 0.8452\n",
      "193/750 [======>.......................] - ETA: 5s - loss: 0.9123 - accuracy: 0.7084\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "665/750 [=========================>....] - ETA: 0s - loss: 0.2825 - accuracy: 0.8987\n",
      "179/750 [======>.......................] - ETA: 5s - loss: 0.9144 - accuracy: 0.7075\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "407/750 [===============>..............] - ETA: 3s - loss: 0.4644 - accuracy: 0.8452\n",
      "653/750 [=========================>....] - ETA: 0s - loss: 0.2824 - accuracy: 0.8989\n",
      "381/750 [==============>...............] - ETA: 4s - loss: 0.9169 - accuracy: 0.7049\n",
      "417/750 [===============>..............] - ETA: 3s - loss: 0.4643 - accuracy: 0.8455\n",
      "220/750 [=======>......................] - ETA: 5s - loss: 0.9162 - accuracy: 0.7059\n",
      " 64/750 [=>............................] - ETA: 6s - loss: 0.9280 - accuracy: 0.7034\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.2814 - accuracy: 0.8991\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "398/750 [==============>...............] - ETA: 3s - loss: 0.9152 - accuracy: 0.7058\n",
      "243/750 [========>.....................] - ETA: 5s - loss: 0.9197 - accuracy: 0.7030\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2821 - accuracy: 0.8988\n",
      "444/750 [================>.............] - ETA: 3s - loss: 0.4627 - accuracy: 0.8456\n",
      "251/750 [=========>....................] - ETA: 5s - loss: 0.9188 - accuracy: 0.7039\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2824 - accuracy: 0.8987\n",
      "264/750 [=========>....................] - ETA: 5s - loss: 0.9179 - accuracy: 0.7040\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2816 - accuracy: 0.8990\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "464/750 [=================>............] - ETA: 2s - loss: 0.4631 - accuracy: 0.8453\n",
      "277/750 [==========>...................] - ETA: 5s - loss: 0.9180 - accuracy: 0.7043\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.8987\n",
      "479/750 [==================>...........] - ETA: 2s - loss: 0.4633 - accuracy: 0.8450\n",
      "296/750 [==========>...................] - ETA: 4s - loss: 0.9156 - accuracy: 0.7053\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "492/750 [==================>...........] - ETA: 2s - loss: 0.4636 - accuracy: 0.8448\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2823 - accuracy: 0.8988\n",
      "505/750 [===================>..........] - ETA: 2s - loss: 0.4635 - accuracy: 0.8447\n",
      "319/750 [===========>..................] - ETA: 4s - loss: 0.9170 - accuracy: 0.7047\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "519/750 [===================>..........] - ETA: 2s - loss: 0.4634 - accuracy: 0.8448\n",
      "325/750 [============>.................] - ETA: 4s - loss: 0.4660 - accuracy: 0.8437\n",
      "528/750 [====================>.........] - ETA: 2s - loss: 0.4642 - accuracy: 0.8442\n",
      "336/750 [============>.................] - ETA: 4s - loss: 0.9170 - accuracy: 0.7053\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "541/750 [====================>.........] - ETA: 2s - loss: 0.4648 - accuracy: 0.8441\n",
      "358/750 [=============>................] - ETA: 4s - loss: 0.9159 - accuracy: 0.7057\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "363/750 [=============>................] - ETA: 4s - loss: 0.9162 - accuracy: 0.7052\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "562/750 [=====================>........] - ETA: 1s - loss: 0.4649 - accuracy: 0.8441\n",
      "570/750 [=====================>........] - ETA: 1s - loss: 0.4651 - accuracy: 0.8442\n",
      "375/750 [==============>...............] - ETA: 4s - loss: 0.9166 - accuracy: 0.7050\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "578/750 [======================>.......] - ETA: 1s - loss: 0.4648 - accuracy: 0.8444\n",
      "587/750 [======================>.......] - ETA: 1s - loss: 0.4649 - accuracy: 0.8442\n",
      "110/750 [===>..........................] - ETA: 6s - loss: 0.9217 - accuracy: 0.7098\n",
      "428/750 [================>.............] - ETA: 3s - loss: 0.9134 - accuracy: 0.7069\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.4644 - accuracy: 0.8440\n",
      "436/750 [================>.............] - ETA: 3s - loss: 0.4632 - accuracy: 0.8456\n",
      "459/750 [=================>............] - ETA: 3s - loss: 0.9105 - accuracy: 0.7085\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 6s - loss: 0.1825 - accuracy: 0.9219\n",
      "653/750 [=========================>....] - ETA: 0s - loss: 0.4648 - accuracy: 0.8440\n",
      "666/750 [=========================>....] - ETA: 0s - loss: 0.4639 - accuracy: 0.8442\n",
      "641/750 [========================>.....] - ETA: 1s - loss: 0.4648 - accuracy: 0.8438\n",
      "636/750 [========================>.....] - ETA: 1s - loss: 0.9079 - accuracy: 0.7094\n",
      " 14/750 [..............................] - ETA: 10s - loss: 0.2724 - accuracy: 0.8984\n",
      "646/750 [========================>.....] - ETA: 1s - loss: 0.9081 - accuracy: 0.7095\n",
      " 26/750 [>.............................] - ETA: 9s - loss: 0.2700 - accuracy: 0.9032 \n",
      "682/750 [==========================>...] - ETA: 0s - loss: 0.4646 - accuracy: 0.8440\n",
      "215/750 [=======>......................] - ETA: 5s - loss: 0.9152 - accuracy: 0.7067\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2821 - accuracy: 0.8987 - val_loss: 0.3319 - val_accuracy: 0.8808\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 20/30\n",
      "523/750 [===================>..........] - ETA: 2s - loss: 0.9099 - accuracy: 0.7088\n",
      "666/750 [=========================>....] - ETA: 0s - loss: 0.9080 - accuracy: 0.7097\n",
      "  6/750 [..............................] - ETA: 7s - loss: 0.2799 - accuracy: 0.8828\n",
      " 51/750 [=>............................] - ETA: 8s - loss: 0.2665 - accuracy: 0.9001\n",
      " 44/750 [>.............................] - ETA: 7s - loss: 0.2668 - accuracy: 0.8995\n",
      "536/750 [====================>.........] - ETA: 2s - loss: 0.9091 - accuracy: 0.7086\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.9078 - accuracy: 0.7098\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.4640 - accuracy: 0.8441\n",
      "259/750 [=========>....................] - ETA: 5s - loss: 0.9178 - accuracy: 0.7040\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.9083 - accuracy: 0.7097\n",
      "569/750 [=====================>........] - ETA: 1s - loss: 0.9088 - accuracy: 0.7091\n",
      "106/750 [===>..........................] - ETA: 7s - loss: 0.2698 - accuracy: 0.8999\n",
      " 89/750 [==>...........................] - ETA: 8s - loss: 0.2688 - accuracy: 0.9001\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "596/750 [======================>.......] - ETA: 1s - loss: 0.9077 - accuracy: 0.7091\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "126/750 [====>.........................] - ETA: 7s - loss: 0.2685 - accuracy: 0.9005\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.4650 - accuracy: 0.8439\n",
      "152/750 [=====>........................] - ETA: 6s - loss: 0.2738 - accuracy: 0.8988\n",
      "101/750 [===>..........................] - ETA: 7s - loss: 0.2692 - accuracy: 0.9005\n",
      "115/750 [===>..........................] - ETA: 7s - loss: 0.2704 - accuracy: 0.8997\n",
      "177/750 [======>.......................] - ETA: 6s - loss: 0.2741 - accuracy: 0.8992\n",
      "139/750 [====>.........................] - ETA: 7s - loss: 0.2728 - accuracy: 0.8996\n",
      "621/750 [=======================>......] - ETA: 1s - loss: 0.9076 - accuracy: 0.7098\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "205/750 [=======>......................] - ETA: 5s - loss: 0.2748 - accuracy: 0.9001\n",
      "208/750 [=======>......................] - ETA: 5s - loss: 0.2749 - accuracy: 0.8999\n",
      "216/750 [=======>......................] - ETA: 5s - loss: 0.2752 - accuracy: 0.9002\n",
      "226/750 [========>.....................] - ETA: 5s - loss: 0.2756 - accuracy: 0.8998\n",
      "385/750 [==============>...............] - ETA: 3s - loss: 0.9167 - accuracy: 0.7052\n",
      "166/750 [=====>........................] - ETA: 6s - loss: 0.2744 - accuracy: 0.8986\n",
      "677/750 [==========================>...] - ETA: 0s - loss: 0.4644 - accuracy: 0.8442\n",
      "190/750 [======>.......................] - ETA: 6s - loss: 0.2731 - accuracy: 0.8999\n",
      "197/750 [======>.......................] - ETA: 6s - loss: 0.2738 - accuracy: 0.9004\n",
      "259/750 [=========>....................] - ETA: 5s - loss: 0.2734 - accuracy: 0.9008\n",
      "419/750 [===============>..............] - ETA: 3s - loss: 0.9143 - accuracy: 0.7064\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "271/750 [=========>....................] - ETA: 5s - loss: 0.2726 - accuracy: 0.9013\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.4640 - accuracy: 0.8441 - val_loss: 0.4679 - val_accuracy: 0.8380\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 20/30\n",
      " 70/750 [=>............................] - ETA: 8s - loss: 0.2686 - accuracy: 0.9002\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.9074 - accuracy: 0.7100\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "280/750 [==========>...................] - ETA: 4s - loss: 0.2712 - accuracy: 0.9021\n",
      "236/750 [========>.....................] - ETA: 5s - loss: 0.2752 - accuracy: 0.8994\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.4642 - accuracy: 0.8444\n",
      "297/750 [==========>...................] - ETA: 4s - loss: 0.2706 - accuracy: 0.9020\n",
      " 19/750 [..............................] - ETA: 7s - loss: 0.4680 - accuracy: 0.8347 \n",
      "439/750 [================>.............] - ETA: 3s - loss: 0.9113 - accuracy: 0.7081\n",
      "251/750 [=========>....................] - ETA: 5s - loss: 0.2753 - accuracy: 0.8998\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.9076 - accuracy: 0.7098\n",
      " 15/750 [..............................] - ETA: 2s - loss: 0.8942 - accuracy: 0.7135\n",
      " 29/750 [>.............................] - ETA: 9s - loss: 0.4409 - accuracy: 0.8481\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.9078 - accuracy: 0.7096\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "316/750 [===========>..................] - ETA: 4s - loss: 0.2727 - accuracy: 0.9013\n",
      " 45/750 [>.............................] - ETA: 7s - loss: 0.4290 - accuracy: 0.8542\n",
      "470/750 [=================>............] - ETA: 2s - loss: 0.9105 - accuracy: 0.7085\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.4640 - accuracy: 0.8441\n",
      "324/750 [===========>..................] - ETA: 4s - loss: 0.2732 - accuracy: 0.9012\n",
      "291/750 [==========>...................] - ETA: 4s - loss: 0.2697 - accuracy: 0.9027\n",
      "496/750 [==================>...........] - ETA: 2s - loss: 0.9112 - accuracy: 0.7079\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 80/750 [==>...........................] - ETA: 6s - loss: 0.4477 - accuracy: 0.8480\n",
      "305/750 [===========>..................] - ETA: 4s - loss: 0.2723 - accuracy: 0.9012\n",
      " 66/750 [=>............................] - ETA: 6s - loss: 0.9072 - accuracy: 0.7029\n",
      "357/750 [=============>................] - ETA: 4s - loss: 0.2730 - accuracy: 0.9020\n",
      "517/750 [===================>..........] - ETA: 2s - loss: 0.9098 - accuracy: 0.7089\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "364/750 [=============>................] - ETA: 3s - loss: 0.2731 - accuracy: 0.9020\n",
      "371/750 [=============>................] - ETA: 3s - loss: 0.2720 - accuracy: 0.9023\n",
      "102/750 [===>..........................] - ETA: 6s - loss: 0.4522 - accuracy: 0.8482\n",
      "542/750 [====================>.........] - ETA: 2s - loss: 0.9088 - accuracy: 0.7091\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "340/750 [============>.................] - ETA: 4s - loss: 0.2731 - accuracy: 0.9020\n",
      "112/750 [===>..........................] - ETA: 6s - loss: 0.4516 - accuracy: 0.8492\n",
      "352/750 [=============>................] - ETA: 4s - loss: 0.2727 - accuracy: 0.9018\n",
      "398/750 [==============>...............] - ETA: 3s - loss: 0.2731 - accuracy: 0.9017\n",
      "137/750 [====>.........................] - ETA: 6s - loss: 0.4500 - accuracy: 0.8503\n",
      "562/750 [=====================>........] - ETA: 2s - loss: 0.9096 - accuracy: 0.7087\n",
      "141/750 [====>.........................] - ETA: 6s - loss: 0.4513 - accuracy: 0.8492\n",
      "380/750 [==============>...............] - ETA: 3s - loss: 0.2721 - accuracy: 0.9023\n",
      "426/750 [================>.............] - ETA: 3s - loss: 0.2741 - accuracy: 0.9016\n",
      "144/750 [====>.........................] - ETA: 6s - loss: 0.4527 - accuracy: 0.8488\n",
      "161/750 [=====>........................] - ETA: 5s - loss: 0.4499 - accuracy: 0.8498\n",
      "437/750 [================>.............] - ETA: 3s - loss: 0.2762 - accuracy: 0.9009\n",
      "166/750 [=====>........................] - ETA: 5s - loss: 0.4501 - accuracy: 0.8487\n",
      "448/750 [================>.............] - ETA: 3s - loss: 0.2772 - accuracy: 0.9001\n",
      "459/750 [=================>............] - ETA: 2s - loss: 0.2767 - accuracy: 0.9003\n",
      "188/750 [======>.......................] - ETA: 5s - loss: 0.4558 - accuracy: 0.8464\n",
      "472/750 [=================>............] - ETA: 2s - loss: 0.2765 - accuracy: 0.9005\n",
      "198/750 [======>.......................] - ETA: 5s - loss: 0.4562 - accuracy: 0.8463\n",
      "206/750 [=======>......................] - ETA: 5s - loss: 0.4567 - accuracy: 0.8459\n",
      "  1/750 [..............................] - ETA: 3s - loss: 0.3273 - accuracy: 0.8750\n",
      "494/750 [==================>...........] - ETA: 2s - loss: 0.2759 - accuracy: 0.9009\n",
      "224/750 [=======>......................] - ETA: 5s - loss: 0.4581 - accuracy: 0.8458\n",
      "208/750 [=======>......................] - ETA: 5s - loss: 0.9046 - accuracy: 0.7117\n",
      "232/750 [========>.....................] - ETA: 5s - loss: 0.4586 - accuracy: 0.8455\n",
      "671/750 [=========================>....] - ETA: 0s - loss: 0.9079 - accuracy: 0.7097\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 19/750 [..............................] - ETA: 8s - loss: 0.8879 - accuracy: 0.7179\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "245/750 [========>.....................] - ETA: 5s - loss: 0.4567 - accuracy: 0.8457\n",
      "250/750 [=========>....................] - ETA: 5s - loss: 0.4559 - accuracy: 0.8462\n",
      "279/750 [==========>...................] - ETA: 4s - loss: 0.4557 - accuracy: 0.8460\n",
      " 56/750 [=>............................] - ETA: 6s - loss: 0.9108 - accuracy: 0.7012\n",
      "559/750 [=====================>........] - ETA: 1s - loss: 0.2736 - accuracy: 0.9021\n",
      "564/750 [=====================>........] - ETA: 1s - loss: 0.2734 - accuracy: 0.9022\n",
      "286/750 [==========>...................] - ETA: 4s - loss: 0.4553 - accuracy: 0.8463\n",
      "571/750 [=====================>........] - ETA: 1s - loss: 0.2742 - accuracy: 0.9018\n",
      "300/750 [===========>..................] - ETA: 4s - loss: 0.4575 - accuracy: 0.8460\n",
      "315/750 [===========>..................] - ETA: 4s - loss: 0.4575 - accuracy: 0.8453\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.9084 - accuracy: 0.7096\n",
      "596/750 [======================>.......] - ETA: 1s - loss: 0.2747 - accuracy: 0.9016\n",
      "322/750 [===========>..................] - ETA: 4s - loss: 0.4586 - accuracy: 0.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:03:47,488 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 7114448896; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/750 [===>..........................] - ETA: 6s - loss: 0.9021 - accuracy: 0.7104\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.2745 - accuracy: 0.9016\n",
      "336/750 [============>.................] - ETA: 4s - loss: 0.4571 - accuracy: 0.8459\n",
      " 98/750 [==>...........................] - ETA: 6s - loss: 0.9014 - accuracy: 0.7098\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "594/750 [======================>.......] - ETA: 1s - loss: 0.2744 - accuracy: 0.9018\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "340/750 [============>.................] - ETA: 4s - loss: 0.4570 - accuracy: 0.8460\n",
      "129/750 [====>.........................] - ETA: 6s - loss: 0.9054 - accuracy: 0.7065\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "326/750 [============>.................] - ETA: 4s - loss: 0.8999 - accuracy: 0.7111\n",
      "341/750 [============>.................] - ETA: 4s - loss: 0.4569 - accuracy: 0.8460\n",
      "151/750 [=====>........................] - ETA: 5s - loss: 0.9052 - accuracy: 0.7100\n",
      "342/750 [============>.................] - ETA: 4s - loss: 0.4570 - accuracy: 0.8460\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.2746 - accuracy: 0.9017\n",
      "344/750 [============>.................] - ETA: 4s - loss: 0.4569 - accuracy: 0.8460\n",
      "176/750 [======>.......................] - ETA: 5s - loss: 0.4519 - accuracy: 0.8483\n",
      "625/750 [========================>.....] - ETA: 1s - loss: 0.2748 - accuracy: 0.9018\n",
      "346/750 [============>.................] - ETA: 4s - loss: 0.4568 - accuracy: 0.8457\n",
      "621/750 [=======================>......] - ETA: 1s - loss: 0.2745 - accuracy: 0.9017\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "633/750 [========================>.....] - ETA: 1s - loss: 0.2758 - accuracy: 0.9015\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.2760 - accuracy: 0.9014\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.2763 - accuracy: 0.9014\n",
      "362/750 [=============>................] - ETA: 4s - loss: 0.4554 - accuracy: 0.8463\n",
      "243/750 [========>.....................] - ETA: 5s - loss: 0.9041 - accuracy: 0.7102\n",
      "352/750 [=============>................] - ETA: 5s - loss: 0.9008 - accuracy: 0.7106\n",
      "640/750 [========================>.....] - ETA: 1s - loss: 0.2761 - accuracy: 0.9015\n",
      "374/750 [=============>................] - ETA: 4s - loss: 0.4568 - accuracy: 0.8460\n",
      "257/750 [=========>....................] - ETA: 4s - loss: 0.9033 - accuracy: 0.7096\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "417/750 [===============>..............] - ETA: 3s - loss: 0.2745 - accuracy: 0.9016\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.9085 - accuracy: 0.7096 - val_loss: 0.8936 - val_accuracy: 0.7138\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 20/30\n",
      " 73/750 [=>............................] - ETA: 6s - loss: 0.9071 - accuracy: 0.7061\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "283/750 [==========>...................] - ETA: 4s - loss: 0.9010 - accuracy: 0.7102\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "644/750 [========================>.....] - ETA: 1s - loss: 0.2763 - accuracy: 0.9014\n",
      "375/750 [==============>...............] - ETA: 5s - loss: 0.4570 - accuracy: 0.8460\n",
      " 40/750 [>.............................] - ETA: 7s - loss: 0.9057 - accuracy: 0.7090\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "307/750 [===========>..................] - ETA: 4s - loss: 0.4579 - accuracy: 0.8452\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.2764 - accuracy: 0.9013\n",
      "662/750 [=========================>....] - ETA: 1s - loss: 0.2770 - accuracy: 0.9011\n",
      "407/750 [===============>..............] - ETA: 4s - loss: 0.4561 - accuracy: 0.8468\n",
      "488/750 [==================>...........] - ETA: 2s - loss: 0.2761 - accuracy: 0.9008\n",
      "410/750 [===============>..............] - ETA: 4s - loss: 0.4556 - accuracy: 0.8471\n",
      "354/750 [=============>................] - ETA: 5s - loss: 0.8999 - accuracy: 0.7111\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "674/750 [=========================>....] - ETA: 0s - loss: 0.2768 - accuracy: 0.9012\n",
      "519/750 [===================>..........] - ETA: 2s - loss: 0.2750 - accuracy: 0.9016\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 0.2770 - accuracy: 0.9013\n",
      "548/750 [====================>.........] - ETA: 2s - loss: 0.2740 - accuracy: 0.9019\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "109/750 [===>..........................] - ETA: 6s - loss: 0.9019 - accuracy: 0.7097\n",
      "398/750 [==============>...............] - ETA: 5s - loss: 0.8967 - accuracy: 0.7124\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.2767 - accuracy: 0.9013\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.2768 - accuracy: 0.9013\n",
      "141/750 [====>.........................] - ETA: 6s - loss: 0.9049 - accuracy: 0.7089\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2774 - accuracy: 0.9012\n",
      "448/750 [================>.............] - ETA: 4s - loss: 0.4569 - accuracy: 0.8466\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2769 - accuracy: 0.9014\n",
      "453/750 [=================>............] - ETA: 4s - loss: 0.4565 - accuracy: 0.8465\n",
      "173/750 [=====>........................] - ETA: 5s - loss: 0.9050 - accuracy: 0.7104\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "442/750 [================>.............] - ETA: 4s - loss: 0.4566 - accuracy: 0.8467\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2771 - accuracy: 0.9013\n",
      "461/750 [=================>............] - ETA: 4s - loss: 0.4559 - accuracy: 0.8466\n",
      "441/750 [================>.............] - ETA: 4s - loss: 0.8959 - accuracy: 0.7130\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2770 - accuracy: 0.9014\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2771 - accuracy: 0.9013\n",
      "469/750 [=================>............] - ETA: 4s - loss: 0.4569 - accuracy: 0.8462\n",
      "196/750 [======>.......................] - ETA: 5s - loss: 0.9054 - accuracy: 0.7111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.2772 - accuracy: 0.9011\n",
      "478/750 [==================>...........] - ETA: 4s - loss: 0.4565 - accuracy: 0.8459\n",
      "454/750 [=================>............] - ETA: 4s - loss: 0.8959 - accuracy: 0.7132\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2778 - accuracy: 0.9008\n",
      "490/750 [==================>...........] - ETA: 3s - loss: 0.4564 - accuracy: 0.8460\n",
      "223/750 [=======>......................] - ETA: 5s - loss: 0.9041 - accuracy: 0.7106\n",
      "462/750 [=================>............] - ETA: 4s - loss: 0.8955 - accuracy: 0.7133\n",
      "498/750 [==================>...........] - ETA: 3s - loss: 0.4561 - accuracy: 0.8463\n",
      "502/750 [===================>..........] - ETA: 3s - loss: 0.4567 - accuracy: 0.8463\n",
      "237/750 [========>.....................] - ETA: 5s - loss: 0.9036 - accuracy: 0.7101\n",
      "669/750 [=========================>....] - ETA: 1s - loss: 0.2767 - accuracy: 0.9012\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "471/750 [=================>............] - ETA: 4s - loss: 0.8959 - accuracy: 0.7130\n",
      "274/750 [=========>....................] - ETA: 4s - loss: 0.9010 - accuracy: 0.7107\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "295/750 [==========>...................] - ETA: 4s - loss: 0.9018 - accuracy: 0.7095\n",
      "525/750 [====================>.........] - ETA: 3s - loss: 0.8954 - accuracy: 0.7134\n",
      "559/750 [=====================>........] - ETA: 2s - loss: 0.4557 - accuracy: 0.8468\n",
      "531/750 [====================>.........] - ETA: 3s - loss: 0.8951 - accuracy: 0.7134\n",
      "539/750 [====================>.........] - ETA: 3s - loss: 0.8949 - accuracy: 0.7136\n",
      "564/750 [=====================>........] - ETA: 2s - loss: 0.4554 - accuracy: 0.8467\n",
      "304/750 [===========>..................] - ETA: 4s - loss: 0.9015 - accuracy: 0.7098\n",
      "541/750 [====================>.........] - ETA: 3s - loss: 0.8951 - accuracy: 0.7135\n",
      "568/750 [=====================>........] - ETA: 2s - loss: 0.4550 - accuracy: 0.8469\n",
      "580/750 [======================>.......] - ETA: 2s - loss: 0.4554 - accuracy: 0.8467\n",
      "317/750 [===========>..................] - ETA: 4s - loss: 0.8998 - accuracy: 0.7113\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "557/750 [=====================>........] - ETA: 2s - loss: 0.8958 - accuracy: 0.7136\n",
      "595/750 [======================>.......] - ETA: 2s - loss: 0.4560 - accuracy: 0.8465\n",
      "337/750 [============>.................] - ETA: 4s - loss: 0.9003 - accuracy: 0.7107\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "594/750 [======================>.......] - ETA: 2s - loss: 0.4561 - accuracy: 0.8464\n",
      "588/750 [======================>.......] - ETA: 2s - loss: 0.8946 - accuracy: 0.7146\n",
      "348/750 [============>.................] - ETA: 4s - loss: 0.9016 - accuracy: 0.7101\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "599/750 [======================>.......] - ETA: 2s - loss: 0.8951 - accuracy: 0.7141\n",
      "604/750 [=======================>......] - ETA: 2s - loss: 0.8955 - accuracy: 0.7140\n",
      "619/750 [=======================>......] - ETA: 1s - loss: 0.8949 - accuracy: 0.7141\n",
      "654/750 [=========================>....] - ETA: 1s - loss: 0.4583 - accuracy: 0.8452\n",
      "618/750 [=======================>......] - ETA: 1s - loss: 0.8947 - accuracy: 0.7142\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.4582 - accuracy: 0.8451\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2778 - accuracy: 0.9008 - val_loss: 0.3273 - val_accuracy: 0.8817\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 21/30\n",
      "  1/750 [..............................] - ETA: 8s - loss: 0.2519 - accuracy: 0.8906\n",
      "  6/750 [..............................] - ETA: 20s - loss: 0.2670 - accuracy: 0.9115\n",
      "628/750 [========================>.....] - ETA: 1s - loss: 0.4575 - accuracy: 0.8455\n",
      " 12/750 [..............................] - ETA: 17s - loss: 0.2712 - accuracy: 0.9115\n",
      "681/750 [==========================>...] - ETA: 0s - loss: 0.4582 - accuracy: 0.8450\n",
      "374/750 [=============>................] - ETA: 5s - loss: 0.8969 - accuracy: 0.7125\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 18/750 [..............................] - ETA: 16s - loss: 0.2867 - accuracy: 0.9019\n",
      " 28/750 [>.............................] - ETA: 13s - loss: 0.2749 - accuracy: 0.9046\n",
      " 44/750 [>.............................] - ETA: 9s - loss: 0.2746 - accuracy: 0.9041 \n",
      " 51/750 [=>............................] - ETA: 11s - loss: 0.2776 - accuracy: 0.9047\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.4600 - accuracy: 0.8444\n",
      "689/750 [==========================>...] - ETA: 0s - loss: 0.8950 - accuracy: 0.7140\n",
      " 58/750 [=>............................] - ETA: 11s - loss: 0.2764 - accuracy: 0.9044\n",
      "418/750 [===============>..............] - ETA: 5s - loss: 0.8960 - accuracy: 0.7129\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 71/750 [=>............................] - ETA: 10s - loss: 0.2748 - accuracy: 0.9045\n",
      " 79/750 [==>...........................] - ETA: 10s - loss: 0.2720 - accuracy: 0.9055\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.4593 - accuracy: 0.8447\n",
      " 84/750 [==>...........................] - ETA: 10s - loss: 0.2708 - accuracy: 0.9048\n",
      "669/750 [=========================>....] - ETA: 1s - loss: 0.8944 - accuracy: 0.7141\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 90/750 [==>...........................] - ETA: 10s - loss: 0.2756 - accuracy: 0.9033\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.4594 - accuracy: 0.8449\n",
      "102/750 [===>..........................] - ETA: 9s - loss: 0.2733 - accuracy: 0.9033 \n",
      "104/750 [===>..........................] - ETA: 9s - loss: 0.2718 - accuracy: 0.9041\n",
      "110/750 [===>..........................] - ETA: 9s - loss: 0.2719 - accuracy: 0.9044\n",
      "424/750 [===============>..............] - ETA: 4s - loss: 0.8963 - accuracy: 0.7129\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "116/750 [===>..........................] - ETA: 9s - loss: 0.2728 - accuracy: 0.9046\n",
      "511/750 [===================>..........] - ETA: 3s - loss: 0.8960 - accuracy: 0.7133\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "696/750 [==========================>...] - ETA: 0s - loss: 0.8951 - accuracy: 0.7140\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "123/750 [===>..........................] - ETA: 9s - loss: 0.2738 - accuracy: 0.9043\n",
      "128/750 [====>.........................] - ETA: 9s - loss: 0.2726 - accuracy: 0.9047\n",
      "548/750 [====================>.........] - ETA: 2s - loss: 0.8961 - accuracy: 0.7132\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "133/750 [====>.........................] - ETA: 9s - loss: 0.2720 - accuracy: 0.9054\n",
      "146/750 [====>.........................] - ETA: 8s - loss: 0.2741 - accuracy: 0.9040\n",
      "147/750 [====>.........................] - ETA: 9s - loss: 0.2744 - accuracy: 0.9040\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.8946 - accuracy: 0.7143\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "150/750 [=====>........................] - ETA: 8s - loss: 0.2749 - accuracy: 0.9035\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.4594 - accuracy: 0.8447\n",
      "167/750 [=====>........................] - ETA: 8s - loss: 0.2750 - accuracy: 0.9041\n",
      "447/750 [================>.............] - ETA: 4s - loss: 0.8958 - accuracy: 0.7130\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "176/750 [======>.......................] - ETA: 8s - loss: 0.2744 - accuracy: 0.9040\n",
      "469/750 [=================>............] - ETA: 4s - loss: 0.8961 - accuracy: 0.7130\n",
      "161/750 [=====>........................] - ETA: 8s - loss: 0.2742 - accuracy: 0.9041\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.4593 - accuracy: 0.8448\n",
      "195/750 [======>.......................] - ETA: 7s - loss: 0.2725 - accuracy: 0.9044\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "203/750 [=======>......................] - ETA: 7s - loss: 0.2719 - accuracy: 0.9046\n",
      "220/750 [=======>......................] - ETA: 7s - loss: 0.2712 - accuracy: 0.9043\n",
      "496/750 [==================>...........] - ETA: 3s - loss: 0.8959 - accuracy: 0.7130\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "232/750 [========>.....................] - ETA: 6s - loss: 0.2721 - accuracy: 0.9044\n",
      "237/750 [========>.....................] - ETA: 7s - loss: 0.2715 - accuracy: 0.9046\n",
      "672/750 [=========================>....] - ETA: 1s - loss: 0.8943 - accuracy: 0.7141\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "248/750 [========>.....................] - ETA: 6s - loss: 0.2728 - accuracy: 0.9037\n",
      "263/750 [=========>....................] - ETA: 6s - loss: 0.2734 - accuracy: 0.9039\n",
      "268/750 [=========>....................] - ETA: 6s - loss: 0.2736 - accuracy: 0.9037\n",
      "277/750 [==========>...................] - ETA: 6s - loss: 0.2746 - accuracy: 0.9031\n",
      "565/750 [=====================>........] - ETA: 2s - loss: 0.8957 - accuracy: 0.7139\n",
      "293/750 [==========>...................] - ETA: 6s - loss: 0.2760 - accuracy: 0.9031\n",
      " 10/750 [..............................] - ETA: 5s - loss: 0.4230 - accuracy: 0.8719\n",
      "302/750 [===========>..................] - ETA: 5s - loss: 0.2756 - accuracy: 0.9030\n",
      " 26/750 [>.............................] - ETA: 8s - loss: 0.4290 - accuracy: 0.8624\n",
      "578/750 [======================>.......] - ETA: 2s - loss: 0.8952 - accuracy: 0.7142\n",
      "314/750 [===========>..................] - ETA: 5s - loss: 0.2757 - accuracy: 0.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:03:57,501 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6038241280; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/750 [>.............................] - ETA: 8s - loss: 0.4334 - accuracy: 0.8599\n",
      "318/750 [===========>..................] - ETA: 5s - loss: 0.2756 - accuracy: 0.9030\n",
      " 39/750 [>.............................] - ETA: 9s - loss: 0.4386 - accuracy: 0.8586\n",
      "326/750 [============>.................] - ETA: 5s - loss: 0.2756 - accuracy: 0.9028\n",
      " 45/750 [>.............................] - ETA: 9s - loss: 0.4595 - accuracy: 0.8490\n",
      "337/750 [============>.................] - ETA: 5s - loss: 0.2755 - accuracy: 0.9028\n",
      " 45/750 [>.............................] - ETA: 9s - loss: 0.8851 - accuracy: 0.7153 \n",
      " 57/750 [=>............................] - ETA: 8s - loss: 0.4612 - accuracy: 0.8473\n",
      "345/750 [============>.................] - ETA: 5s - loss: 0.2755 - accuracy: 0.9029\n",
      " 65/750 [=>............................] - ETA: 9s - loss: 0.4624 - accuracy: 0.8457\n",
      "352/750 [=============>................] - ETA: 5s - loss: 0.2759 - accuracy: 0.9023\n",
      " 75/750 [==>...........................] - ETA: 8s - loss: 0.4621 - accuracy: 0.8450\n",
      " 83/750 [==>...........................] - ETA: 8s - loss: 0.4550 - accuracy: 0.8471\n",
      "377/750 [==============>...............] - ETA: 4s - loss: 0.2765 - accuracy: 0.9021\n",
      " 88/750 [==>...........................] - ETA: 8s - loss: 0.4551 - accuracy: 0.8468\n",
      " 95/750 [==>...........................] - ETA: 7s - loss: 0.4522 - accuracy: 0.8457\n",
      "385/750 [==============>...............] - ETA: 4s - loss: 0.2780 - accuracy: 0.9014\n",
      "651/750 [=========================>....] - ETA: 1s - loss: 0.8951 - accuracy: 0.7137\n",
      "645/750 [========================>.....] - ETA: 1s - loss: 0.8952 - accuracy: 0.7135\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.8957 - accuracy: 0.7134 - val_loss: 0.8816 - val_accuracy: 0.7168\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 21/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 7s - loss: 0.8334 - accuracy: 0.8125\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "390/750 [==============>...............] - ETA: 4s - loss: 0.2771 - accuracy: 0.9016\n",
      " 14/750 [..............................] - ETA: 7s - loss: 0.8717 - accuracy: 0.7132 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "397/750 [==============>...............] - ETA: 4s - loss: 0.2761 - accuracy: 0.9021\n",
      "128/750 [====>.........................] - ETA: 7s - loss: 0.4571 - accuracy: 0.8467\n",
      "364/750 [=============>................] - ETA: 5s - loss: 0.2757 - accuracy: 0.9024\n",
      " 28/750 [>.............................] - ETA: 9s - loss: 0.8734 - accuracy: 0.7121 \n",
      "432/750 [================>.............] - ETA: 4s - loss: 0.2765 - accuracy: 0.9019\n",
      "150/750 [=====>........................] - ETA: 7s - loss: 0.4565 - accuracy: 0.8460\n",
      " 37/750 [>.............................] - ETA: 10s - loss: 0.8907 - accuracy: 0.7078\n",
      "440/750 [================>.............] - ETA: 4s - loss: 0.2768 - accuracy: 0.9017\n",
      "161/750 [=====>........................] - ETA: 7s - loss: 0.4572 - accuracy: 0.8471\n",
      " 51/750 [=>............................] - ETA: 9s - loss: 0.8836 - accuracy: 0.7200\n",
      "453/750 [=================>............] - ETA: 3s - loss: 0.2765 - accuracy: 0.9018\n",
      "462/750 [=================>............] - ETA: 3s - loss: 0.2768 - accuracy: 0.9016\n",
      "175/750 [======>.......................] - ETA: 7s - loss: 0.4573 - accuracy: 0.8474\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.8953 - accuracy: 0.7139\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "471/750 [=================>............] - ETA: 3s - loss: 0.2755 - accuracy: 0.9022\n",
      "420/750 [===============>..............] - ETA: 4s - loss: 0.2757 - accuracy: 0.9022\n",
      "488/750 [==================>...........] - ETA: 3s - loss: 0.2758 - accuracy: 0.9022\n",
      "200/750 [=======>......................] - ETA: 6s - loss: 0.8842 - accuracy: 0.7203\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.8959 - accuracy: 0.7134\n",
      "202/750 [=======>......................] - ETA: 6s - loss: 0.8838 - accuracy: 0.7206\n",
      "206/750 [=======>......................] - ETA: 6s - loss: 0.8834 - accuracy: 0.7211\n",
      "225/750 [========>.....................] - ETA: 6s - loss: 0.4607 - accuracy: 0.8456\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.8955 - accuracy: 0.7136\n",
      "105/750 [===>..........................] - ETA: 8s - loss: 0.4522 - accuracy: 0.8458\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "222/750 [=======>......................] - ETA: 6s - loss: 0.8834 - accuracy: 0.7207\n",
      "122/750 [===>..........................] - ETA: 7s - loss: 0.8927 - accuracy: 0.7205\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "406/750 [===============>..............] - ETA: 4s - loss: 0.2754 - accuracy: 0.9022\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "228/750 [========>.....................] - ETA: 6s - loss: 0.8821 - accuracy: 0.7214\n",
      "525/750 [====================>.........] - ETA: 2s - loss: 0.2749 - accuracy: 0.9024\n",
      "520/750 [===================>..........] - ETA: 2s - loss: 0.2751 - accuracy: 0.9024\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "125/750 [====>.........................] - ETA: 8s - loss: 0.8911 - accuracy: 0.7212\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "532/750 [====================>.........] - ETA: 2s - loss: 0.2748 - accuracy: 0.9025\n",
      "554/750 [=====================>........] - ETA: 2s - loss: 0.2752 - accuracy: 0.9021\n",
      "146/750 [====>.........................] - ETA: 7s - loss: 0.8925 - accuracy: 0.7178\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "555/750 [=====================>........] - ETA: 2s - loss: 0.2752 - accuracy: 0.9021\n",
      "565/750 [=====================>........] - ETA: 2s - loss: 0.2752 - accuracy: 0.9021\n",
      "571/750 [=====================>........] - ETA: 2s - loss: 0.2750 - accuracy: 0.9021\n",
      "285/750 [==========>...................] - ETA: 5s - loss: 0.4590 - accuracy: 0.8455\n",
      "289/750 [==========>...................] - ETA: 5s - loss: 0.4589 - accuracy: 0.8455\n",
      "444/750 [================>.............] - ETA: 3s - loss: 0.2769 - accuracy: 0.9018\n",
      "580/750 [======================>.......] - ETA: 2s - loss: 0.2750 - accuracy: 0.9022\n",
      "293/750 [==========>...................] - ETA: 5s - loss: 0.4584 - accuracy: 0.8458\n",
      "590/750 [======================>.......] - ETA: 2s - loss: 0.2748 - accuracy: 0.9021\n",
      "594/750 [======================>.......] - ETA: 2s - loss: 0.2749 - accuracy: 0.9021\n",
      "607/750 [=======================>......] - ETA: 1s - loss: 0.2749 - accuracy: 0.9022\n",
      "197/750 [======>.......................] - ETA: 6s - loss: 0.4596 - accuracy: 0.8464\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.2750 - accuracy: 0.9022\n",
      "217/750 [=======>......................] - ETA: 6s - loss: 0.8844 - accuracy: 0.7204\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.2750 - accuracy: 0.9021\n",
      "497/750 [==================>...........] - ETA: 3s - loss: 0.2756 - accuracy: 0.9022\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "341/750 [============>.................] - ETA: 5s - loss: 0.4577 - accuracy: 0.8458\n",
      "240/750 [========>.....................] - ETA: 6s - loss: 0.8812 - accuracy: 0.7217\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "344/750 [============>.................] - ETA: 5s - loss: 0.4577 - accuracy: 0.8457\n",
      "359/750 [=============>................] - ETA: 4s - loss: 0.4554 - accuracy: 0.8468\n",
      "356/750 [=============>................] - ETA: 4s - loss: 0.8831 - accuracy: 0.7200\n",
      "656/750 [=========================>....] - ETA: 1s - loss: 0.2744 - accuracy: 0.9021\n",
      "665/750 [=========================>....] - ETA: 1s - loss: 0.2741 - accuracy: 0.9022\n",
      "271/750 [=========>....................] - ETA: 5s - loss: 0.4599 - accuracy: 0.8452\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "671/750 [=========================>....] - ETA: 1s - loss: 0.2743 - accuracy: 0.9021\n",
      "269/750 [=========>....................] - ETA: 5s - loss: 0.8823 - accuracy: 0.7198\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.2744 - accuracy: 0.9020\n",
      "277/750 [==========>...................] - ETA: 5s - loss: 0.8819 - accuracy: 0.7206\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.2744 - accuracy: 0.9020\n",
      "403/750 [===============>..............] - ETA: 4s - loss: 0.4560 - accuracy: 0.8462\n",
      "294/750 [==========>...................] - ETA: 5s - loss: 0.8804 - accuracy: 0.7222\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 17/750 [..............................] - ETA: 11s - loss: 0.8629 - accuracy: 0.7197\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.2743 - accuracy: 0.9021\n",
      "303/750 [===========>..................] - ETA: 5s - loss: 0.4569 - accuracy: 0.8460\n",
      "319/750 [===========>..................] - ETA: 5s - loss: 0.8812 - accuracy: 0.7220\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2749 - accuracy: 0.9021\n",
      "427/750 [================>.............] - ETA: 4s - loss: 0.4562 - accuracy: 0.8459\n",
      " 31/750 [>.............................] - ETA: 10s - loss: 0.8777 - accuracy: 0.7122\n",
      "312/750 [===========>..................] - ETA: 5s - loss: 0.8805 - accuracy: 0.7228\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2745 - accuracy: 0.9021\n",
      "328/750 [============>.................] - ETA: 5s - loss: 0.8813 - accuracy: 0.7215\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2742 - accuracy: 0.9023\n",
      "345/750 [============>.................] - ETA: 5s - loss: 0.8819 - accuracy: 0.7207\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2740 - accuracy: 0.9023\n",
      "451/750 [=================>............] - ETA: 3s - loss: 0.4547 - accuracy: 0.8465\n",
      " 69/750 [=>............................] - ETA: 9s - loss: 0.8808 - accuracy: 0.7246\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.2738 - accuracy: 0.9024\n",
      "371/750 [=============>................] - ETA: 4s - loss: 0.8819 - accuracy: 0.7206\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 81/750 [==>...........................] - ETA: 8s - loss: 0.8888 - accuracy: 0.7205\n",
      " 97/750 [==>...........................] - ETA: 8s - loss: 0.8906 - accuracy: 0.7221\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "377/750 [==============>...............] - ETA: 4s - loss: 0.4554 - accuracy: 0.8467\n",
      "398/750 [==============>...............] - ETA: 4s - loss: 0.4560 - accuracy: 0.8461\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "644/750 [========================>.....] - ETA: 1s - loss: 0.2752 - accuracy: 0.9019\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "503/750 [===================>..........] - ETA: 3s - loss: 0.4577 - accuracy: 0.8459\n",
      "394/750 [==============>...............] - ETA: 4s - loss: 0.8827 - accuracy: 0.7201\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "516/750 [===================>..........] - ETA: 2s - loss: 0.4584 - accuracy: 0.8458\n",
      "525/750 [====================>.........] - ETA: 2s - loss: 0.8847 - accuracy: 0.7181\n",
      "523/750 [===================>..........] - ETA: 2s - loss: 0.4584 - accuracy: 0.8458\n",
      "537/750 [====================>.........] - ETA: 2s - loss: 0.8840 - accuracy: 0.7185\n",
      "448/750 [================>.............] - ETA: 3s - loss: 0.8835 - accuracy: 0.7192\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "552/750 [=====================>........] - ETA: 2s - loss: 0.8845 - accuracy: 0.7184\n",
      "168/750 [=====>........................] - ETA: 7s - loss: 0.8884 - accuracy: 0.7191\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "471/750 [=================>............] - ETA: 3s - loss: 0.8836 - accuracy: 0.7190\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "587/750 [======================>.......] - ETA: 2s - loss: 0.4586 - accuracy: 0.8457\n",
      "195/750 [======>.......................] - ETA: 6s - loss: 0.8857 - accuracy: 0.7200\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2747 - accuracy: 0.9021\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 0.8845 - accuracy: 0.7178\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.4590 - accuracy: 0.8454\n",
      "491/750 [==================>...........] - ETA: 3s - loss: 0.4581 - accuracy: 0.8455\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.4578 - accuracy: 0.8456\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.2738 - accuracy: 0.9024 - val_loss: 0.3253 - val_accuracy: 0.8838\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 22/30\n",
      " 10/750 [..............................] - ETA: 4s - loss: 0.2304 - accuracy: 0.9219\n",
      "249/750 [========>.....................] - ETA: 6s - loss: 0.8820 - accuracy: 0.7200\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 16/750 [..............................] - ETA: 8s - loss: 0.2396 - accuracy: 0.9150\n",
      "640/750 [========================>.....] - ETA: 1s - loss: 0.4559 - accuracy: 0.8462\n",
      "417/750 [===============>..............] - ETA: 4s - loss: 0.4564 - accuracy: 0.8460\n",
      "545/750 [====================>.........] - ETA: 2s - loss: 0.4588 - accuracy: 0.8455\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "660/750 [=========================>....] - ETA: 1s - loss: 0.8849 - accuracy: 0.7177\n",
      " 27/750 [>.............................] - ETA: 7s - loss: 0.2510 - accuracy: 0.9103\n",
      "517/750 [===================>..........] - ETA: 2s - loss: 0.8843 - accuracy: 0.7186\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "664/750 [=========================>....] - ETA: 1s - loss: 0.8848 - accuracy: 0.7177\n",
      " 31/750 [>.............................] - ETA: 9s - loss: 0.2534 - accuracy: 0.9103\n",
      " 46/750 [>.............................] - ETA: 8s - loss: 0.2591 - accuracy: 0.9096\n",
      "681/750 [==========================>...] - ETA: 0s - loss: 0.8847 - accuracy: 0.7175\n",
      "572/750 [=====================>........] - ETA: 2s - loss: 0.4604 - accuracy: 0.8451\n",
      " 59/750 [=>............................] - ETA: 8s - loss: 0.2641 - accuracy: 0.9092\n",
      "567/750 [=====================>........] - ETA: 2s - loss: 0.4606 - accuracy: 0.8450\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.8842 - accuracy: 0.7173\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.8846 - accuracy: 0.7173\n",
      " 74/750 [=>............................] - ETA: 8s - loss: 0.2620 - accuracy: 0.9107\n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.8846 - accuracy: 0.7184\n",
      " 83/750 [==>...........................] - ETA: 8s - loss: 0.2698 - accuracy: 0.9057\n",
      "599/750 [======================>.......] - ETA: 1s - loss: 0.4591 - accuracy: 0.8455\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.8845 - accuracy: 0.7178\n",
      " 95/750 [==>...........................] - ETA: 8s - loss: 0.2679 - accuracy: 0.9069\n",
      "623/750 [=======================>......] - ETA: 1s - loss: 0.8848 - accuracy: 0.7177\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "109/750 [===>..........................] - ETA: 8s - loss: 0.2665 - accuracy: 0.9068\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.4571 - accuracy: 0.8459\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.8839 - accuracy: 0.7178\n",
      "119/750 [===>..........................] - ETA: 8s - loss: 0.2656 - accuracy: 0.9074\n",
      "494/750 [==================>...........] - ETA: 3s - loss: 0.8843 - accuracy: 0.7190\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "125/750 [====>.........................] - ETA: 8s - loss: 0.2646 - accuracy: 0.9070\n",
      "138/750 [====>.........................] - ETA: 8s - loss: 0.2634 - accuracy: 0.9067\n",
      "145/750 [====>.........................] - ETA: 8s - loss: 0.2655 - accuracy: 0.9053\n",
      "366/750 [=============>................] - ETA: 4s - loss: 0.8820 - accuracy: 0.7205\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.4549 - accuracy: 0.8465\n",
      "163/750 [=====>........................] - ETA: 7s - loss: 0.2642 - accuracy: 0.9059\n",
      "177/750 [======>.......................] - ETA: 7s - loss: 0.2638 - accuracy: 0.9065\n",
      "183/750 [======>.......................] - ETA: 7s - loss: 0.2658 - accuracy: 0.9060\n",
      "684/750 [==========================>...] - ETA: 0s - loss: 0.4552 - accuracy: 0.8463\n",
      "196/750 [======>.......................] - ETA: 7s - loss: 0.2649 - accuracy: 0.9064\n",
      "420/750 [===============>..............] - ETA: 4s - loss: 0.8846 - accuracy: 0.7188\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "204/750 [=======>......................] - ETA: 7s - loss: 0.2644 - accuracy: 0.9069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:04:07,503 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6037938176; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/750 [=======>......................] - ETA: 6s - loss: 0.2650 - accuracy: 0.9071\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.4556 - accuracy: 0.8466\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "216/750 [=======>......................] - ETA: 6s - loss: 0.2655 - accuracy: 0.9066\n",
      "219/750 [=======>......................] - ETA: 7s - loss: 0.2649 - accuracy: 0.9068\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.4559 - accuracy: 0.8464\n",
      "234/750 [========>.....................] - ETA: 6s - loss: 0.2655 - accuracy: 0.9062\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.4563 - accuracy: 0.8462\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "260/750 [=========>....................] - ETA: 6s - loss: 0.2643 - accuracy: 0.9071\n",
      "451/750 [=================>............] - ETA: 3s - loss: 0.8836 - accuracy: 0.7190\n",
      " 70/750 [=>............................] - ETA: 8s - loss: 0.2650 - accuracy: 0.9089\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "265/750 [=========>....................] - ETA: 6s - loss: 0.2646 - accuracy: 0.9068\n",
      "279/750 [==========>...................] - ETA: 5s - loss: 0.2648 - accuracy: 0.9069\n",
      " 86/750 [==>...........................] - ETA: 8s - loss: 0.2706 - accuracy: 0.9055\n",
      "291/750 [==========>...................] - ETA: 5s - loss: 0.2672 - accuracy: 0.9061\n",
      "  1/750 [..............................] - ETA: 12s - loss: 0.4488 - accuracy: 0.8750\n",
      "648/750 [========================>.....] - ETA: 1s - loss: 0.8849 - accuracy: 0.7180\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "307/750 [===========>..................] - ETA: 5s - loss: 0.2659 - accuracy: 0.9065\n",
      "  3/750 [..............................] - ETA: 35s - loss: 0.4309 - accuracy: 0.8646\n",
      " 14/750 [..............................] - ETA: 9s - loss: 0.8969 - accuracy: 0.7109\n",
      "318/750 [===========>..................] - ETA: 5s - loss: 0.2659 - accuracy: 0.9065\n",
      " 23/750 [..............................] - ETA: 6s - loss: 0.4510 - accuracy: 0.8492 \n",
      "326/750 [============>.................] - ETA: 5s - loss: 0.2658 - accuracy: 0.9065\n",
      "339/750 [============>.................] - ETA: 4s - loss: 0.2672 - accuracy: 0.9059\n",
      "540/750 [====================>.........] - ETA: 2s - loss: 0.4587 - accuracy: 0.8456\n",
      "348/750 [============>.................] - ETA: 4s - loss: 0.2663 - accuracy: 0.9062\n",
      "556/750 [=====================>........] - ETA: 2s - loss: 0.4607 - accuracy: 0.8450\n",
      "351/750 [=============>................] - ETA: 4s - loss: 0.2663 - accuracy: 0.9062\n",
      "361/750 [=============>................] - ETA: 4s - loss: 0.2658 - accuracy: 0.9062\n",
      "155/750 [=====>........................] - ETA: 7s - loss: 0.2645 - accuracy: 0.9058\n",
      "368/750 [=============>................] - ETA: 4s - loss: 0.2658 - accuracy: 0.9062\n",
      " 77/750 [==>...........................] - ETA: 8s - loss: 0.8794 - accuracy: 0.7159\n",
      "378/750 [==============>...............] - ETA: 4s - loss: 0.2670 - accuracy: 0.9057\n",
      "387/750 [==============>...............] - ETA: 4s - loss: 0.2669 - accuracy: 0.9056\n",
      " 97/750 [==>...........................] - ETA: 7s - loss: 0.8762 - accuracy: 0.7226\n",
      "396/750 [==============>...............] - ETA: 4s - loss: 0.2665 - accuracy: 0.9058\n",
      "100/750 [===>..........................] - ETA: 8s - loss: 0.8757 - accuracy: 0.7230\n",
      "106/750 [===>..........................] - ETA: 8s - loss: 0.8777 - accuracy: 0.7223\n",
      "112/750 [===>..........................] - ETA: 7s - loss: 0.8766 - accuracy: 0.7217\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.4564 - accuracy: 0.8462 - val_loss: 0.4616 - val_accuracy: 0.8404\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 22/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "242/750 [========>.....................] - ETA: 6s - loss: 0.2653 - accuracy: 0.9064\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "421/750 [===============>..............] - ETA: 4s - loss: 0.2664 - accuracy: 0.9058\n",
      "672/750 [=========================>....] - ETA: 0s - loss: 0.4553 - accuracy: 0.8462\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 25/750 [>.............................] - ETA: 8s - loss: 0.8863 - accuracy: 0.7150\n",
      "427/750 [================>.............] - ETA: 4s - loss: 0.2664 - accuracy: 0.9059\n",
      " 28/750 [>.............................] - ETA: 8s - loss: 0.4421 - accuracy: 0.8471\n",
      "441/750 [================>.............] - ETA: 3s - loss: 0.2657 - accuracy: 0.9062\n",
      " 47/750 [>.............................] - ETA: 8s - loss: 0.4387 - accuracy: 0.8464\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "449/750 [================>.............] - ETA: 3s - loss: 0.2653 - accuracy: 0.9063\n",
      "154/750 [=====>........................] - ETA: 7s - loss: 0.4552 - accuracy: 0.8458\n",
      "694/750 [==========================>...] - ETA: 0s - loss: 0.4552 - accuracy: 0.8462\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "457/750 [=================>............] - ETA: 3s - loss: 0.2654 - accuracy: 0.9061\n",
      "160/750 [=====>........................] - ETA: 7s - loss: 0.4532 - accuracy: 0.8461\n",
      " 65/750 [=>............................] - ETA: 8s - loss: 0.4532 - accuracy: 0.8425\n",
      "465/750 [=================>............] - ETA: 3s - loss: 0.2659 - accuracy: 0.9062\n",
      "468/750 [=================>............] - ETA: 3s - loss: 0.2657 - accuracy: 0.9062\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.8849 - accuracy: 0.7173\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "479/750 [==================>...........] - ETA: 3s - loss: 0.2668 - accuracy: 0.9057\n",
      " 93/750 [==>...........................] - ETA: 8s - loss: 0.4506 - accuracy: 0.8468\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "506/750 [===================>..........] - ETA: 3s - loss: 0.2677 - accuracy: 0.9051\n",
      "124/750 [===>..........................] - ETA: 8s - loss: 0.8740 - accuracy: 0.7239\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "520/750 [===================>..........] - ETA: 2s - loss: 0.2681 - accuracy: 0.9051\n",
      "225/750 [========>.....................] - ETA: 6s - loss: 0.8758 - accuracy: 0.7208\n",
      "523/750 [===================>..........] - ETA: 2s - loss: 0.2691 - accuracy: 0.9048\n",
      "531/750 [====================>.........] - ETA: 2s - loss: 0.2690 - accuracy: 0.9047\n",
      "497/750 [==================>...........] - ETA: 3s - loss: 0.2669 - accuracy: 0.9053\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "541/750 [====================>.........] - ETA: 2s - loss: 0.2693 - accuracy: 0.9046\n",
      "143/750 [====>.........................] - ETA: 8s - loss: 0.8759 - accuracy: 0.7233\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "264/750 [=========>....................] - ETA: 6s - loss: 0.8745 - accuracy: 0.7226\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.2698 - accuracy: 0.9044\n",
      "558/750 [=====================>........] - ETA: 2s - loss: 0.2698 - accuracy: 0.9043\n",
      "568/750 [=====================>........] - ETA: 2s - loss: 0.2698 - accuracy: 0.9042\n",
      "579/750 [======================>.......] - ETA: 2s - loss: 0.2699 - accuracy: 0.9040\n",
      "178/750 [======>.......................] - ETA: 7s - loss: 0.4528 - accuracy: 0.8473\n",
      "588/750 [======================>.......] - ETA: 2s - loss: 0.2696 - accuracy: 0.9041\n",
      "300/750 [===========>..................] - ETA: 5s - loss: 0.4582 - accuracy: 0.8451\n",
      "198/750 [======>.......................] - ETA: 7s - loss: 0.8756 - accuracy: 0.7208\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "595/750 [======================>.......] - ETA: 1s - loss: 0.2696 - accuracy: 0.9042\n",
      "192/750 [======>.......................] - ETA: 7s - loss: 0.8753 - accuracy: 0.7206\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "413/750 [===============>..............] - ETA: 4s - loss: 0.2658 - accuracy: 0.9060\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "606/750 [=======================>......] - ETA: 1s - loss: 0.2697 - accuracy: 0.9041\n",
      "204/750 [=======>......................] - ETA: 7s - loss: 0.4556 - accuracy: 0.8455\n",
      "618/750 [=======================>......] - ETA: 1s - loss: 0.2706 - accuracy: 0.9037\n",
      "224/750 [=======>......................] - ETA: 6s - loss: 0.4580 - accuracy: 0.8447\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "327/750 [============>.................] - ETA: 5s - loss: 0.8748 - accuracy: 0.7216\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.2706 - accuracy: 0.9038\n",
      "218/750 [=======>......................] - ETA: 6s - loss: 0.8758 - accuracy: 0.7210\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.2705 - accuracy: 0.9037\n",
      "247/750 [========>.....................] - ETA: 6s - loss: 0.8759 - accuracy: 0.7207\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.2705 - accuracy: 0.9035\n",
      "356/750 [=============>................] - ETA: 5s - loss: 0.4555 - accuracy: 0.8460\n",
      "653/750 [=========================>....] - ETA: 1s - loss: 0.2705 - accuracy: 0.9036\n",
      " 72/750 [=>............................] - ETA: 8s - loss: 0.4522 - accuracy: 0.8448\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "256/750 [=========>....................] - ETA: 6s - loss: 0.4579 - accuracy: 0.8459\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "275/750 [==========>...................] - ETA: 6s - loss: 0.8754 - accuracy: 0.7219\n",
      "675/750 [==========================>...] - ETA: 0s - loss: 0.2703 - accuracy: 0.9037\n",
      "295/750 [==========>...................] - ETA: 5s - loss: 0.8743 - accuracy: 0.7218\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 5s - loss: 0.7998 - accuracy: 0.7812\n",
      "641/750 [========================>.....] - ETA: 1s - loss: 0.2704 - accuracy: 0.9036\n",
      "322/750 [===========>..................] - ETA: 5s - loss: 0.8743 - accuracy: 0.7219\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "401/750 [===============>..............] - ETA: 4s - loss: 0.8747 - accuracy: 0.7201\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2703 - accuracy: 0.9035\n",
      "349/750 [============>.................] - ETA: 5s - loss: 0.8754 - accuracy: 0.7201\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "431/750 [================>.............] - ETA: 4s - loss: 0.4542 - accuracy: 0.8465\n",
      "364/750 [=============>................] - ETA: 5s - loss: 0.4558 - accuracy: 0.8458\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2700 - accuracy: 0.9036\n",
      "353/750 [=============>................] - ETA: 5s - loss: 0.8760 - accuracy: 0.7202\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2700 - accuracy: 0.9035\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.9033\n",
      "376/750 [==============>...............] - ETA: 4s - loss: 0.4559 - accuracy: 0.8455\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "476/750 [==================>...........] - ETA: 3s - loss: 0.8758 - accuracy: 0.7198\n",
      " 95/750 [==>...........................] - ETA: 8s - loss: 0.4504 - accuracy: 0.8474\n",
      "398/750 [==============>...............] - ETA: 4s - loss: 0.4559 - accuracy: 0.8456\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "111/750 [===>..........................] - ETA: 8s - loss: 0.4547 - accuracy: 0.8468\n",
      "504/750 [===================>..........] - ETA: 3s - loss: 0.8745 - accuracy: 0.7206\n",
      "247/750 [========>.....................] - ETA: 6s - loss: 0.4583 - accuracy: 0.8453\n",
      "422/750 [===============>..............] - ETA: 4s - loss: 0.4543 - accuracy: 0.8464\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "664/750 [=========================>....] - ETA: 1s - loss: 0.2705 - accuracy: 0.9037\n",
      "426/750 [================>.............] - ETA: 4s - loss: 0.4540 - accuracy: 0.8466\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "444/750 [================>.............] - ETA: 3s - loss: 0.4539 - accuracy: 0.8465\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "157/750 [=====>........................] - ETA: 7s - loss: 0.8742 - accuracy: 0.7215\n",
      "699/750 [==========================>...] - ETA: 0s - loss: 0.2703 - accuracy: 0.9035\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "465/750 [=================>............] - ETA: 3s - loss: 0.4528 - accuracy: 0.8468\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "171/750 [=====>........................] - ETA: 7s - loss: 0.8758 - accuracy: 0.7202\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "469/750 [=================>............] - ETA: 3s - loss: 0.4529 - accuracy: 0.8468\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2700 - accuracy: 0.9036\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "480/750 [==================>...........] - ETA: 3s - loss: 0.4530 - accuracy: 0.8470\n",
      "573/750 [=====================>........] - ETA: 2s - loss: 0.8747 - accuracy: 0.7202\n",
      "524/750 [===================>..........] - ETA: 2s - loss: 0.4521 - accuracy: 0.8471\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "510/750 [===================>..........] - ETA: 3s - loss: 0.8743 - accuracy: 0.7205\n",
      "546/750 [====================>.........] - ETA: 2s - loss: 0.4532 - accuracy: 0.8468\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "602/750 [=======================>......] - ETA: 2s - loss: 0.8747 - accuracy: 0.7200\n",
      "490/750 [==================>...........] - ETA: 3s - loss: 0.8747 - accuracy: 0.7202\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 0.8749 - accuracy: 0.7200\n",
      "272/750 [=========>....................] - ETA: 6s - loss: 0.4592 - accuracy: 0.8450\n",
      "531/750 [====================>.........] - ETA: 2s - loss: 0.8741 - accuracy: 0.7199\n",
      "574/750 [=====================>........] - ETA: 2s - loss: 0.4528 - accuracy: 0.8466\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2701 - accuracy: 0.9033 - val_loss: 0.3219 - val_accuracy: 0.8840\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 23/30\n",
      "  1/750 [..............................] - ETA: 6s - loss: 0.1820 - accuracy: 0.9375\n",
      "590/750 [======================>.......] - ETA: 2s - loss: 0.4532 - accuracy: 0.8466\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "634/750 [========================>.....] - ETA: 1s - loss: 0.8740 - accuracy: 0.7203\n",
      "595/750 [======================>.......] - ETA: 2s - loss: 0.4532 - accuracy: 0.8466\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "  8/750 [..............................] - ETA: 5s - loss: 0.2470 - accuracy: 0.9043\n",
      "417/750 [===============>..............] - ETA: 4s - loss: 0.8751 - accuracy: 0.7199\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "623/750 [=======================>......] - ETA: 1s - loss: 0.4516 - accuracy: 0.8476\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "641/750 [========================>.....] - ETA: 1s - loss: 0.8741 - accuracy: 0.7202\n",
      " 15/750 [..............................] - ETA: 13s - loss: 0.2467 - accuracy: 0.9115\n",
      " 23/750 [..............................] - ETA: 11s - loss: 0.2540 - accuracy: 0.9076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:04:17,507 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6037540864; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/750 [============>.................] - ETA: 5s - loss: 0.4572 - accuracy: 0.8455\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 28/750 [>.............................] - ETA: 11s - loss: 0.2488 - accuracy: 0.9113\n",
      "634/750 [========================>.....] - ETA: 1s - loss: 0.4515 - accuracy: 0.8476\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      " 33/750 [>.............................] - ETA: 13s - loss: 0.2491 - accuracy: 0.9119\n",
      " 37/750 [>.............................] - ETA: 13s - loss: 0.2510 - accuracy: 0.9096\n",
      "673/750 [=========================>....] - ETA: 1s - loss: 0.8735 - accuracy: 0.7198\n",
      " 46/750 [>.............................] - ETA: 12s - loss: 0.2455 - accuracy: 0.9120\n",
      "655/750 [=========================>....] - ETA: 1s - loss: 0.4519 - accuracy: 0.8473\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      " 51/750 [=>............................] - ETA: 13s - loss: 0.2506 - accuracy: 0.9115\n",
      " 62/750 [=>............................] - ETA: 11s - loss: 0.2545 - accuracy: 0.9088\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.8733 - accuracy: 0.7199\n",
      " 73/750 [=>............................] - ETA: 10s - loss: 0.2575 - accuracy: 0.9088\n",
      "681/750 [==========================>...] - ETA: 0s - loss: 0.4513 - accuracy: 0.8472\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.4512 - accuracy: 0.8472\n",
      " 77/750 [==>...........................] - ETA: 10s - loss: 0.2589 - accuracy: 0.9087\n",
      " 81/750 [==>...........................] - ETA: 11s - loss: 0.2586 - accuracy: 0.9088\n",
      " 88/750 [==>...........................] - ETA: 11s - loss: 0.2603 - accuracy: 0.9080\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.8721 - accuracy: 0.7204\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.8726 - accuracy: 0.7204\n",
      " 98/750 [==>...........................] - ETA: 10s - loss: 0.2587 - accuracy: 0.9090\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.8728 - accuracy: 0.7205\n",
      "105/750 [===>..........................] - ETA: 10s - loss: 0.2613 - accuracy: 0.9079\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.8731 - accuracy: 0.7203\n",
      "114/750 [===>..........................] - ETA: 10s - loss: 0.2658 - accuracy: 0.9056\n",
      "449/750 [================>.............] - ETA: 3s - loss: 0.8748 - accuracy: 0.7205\n",
      "115/750 [===>..........................] - ETA: 10s - loss: 0.2656 - accuracy: 0.9057\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.8731 - accuracy: 0.7206\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.4529 - accuracy: 0.8469\n",
      "130/750 [====>.........................] - ETA: 9s - loss: 0.2680 - accuracy: 0.9050 \n",
      "743/750 [============================>.] - ETA: 0s - loss: 0.4525 - accuracy: 0.8471\n",
      "147/750 [====>.........................] - ETA: 9s - loss: 0.2676 - accuracy: 0.9064\n",
      "149/750 [====>.........................] - ETA: 9s - loss: 0.2670 - accuracy: 0.9068\n",
      "498/750 [==================>...........] - ETA: 3s - loss: 0.4533 - accuracy: 0.8467\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "176/750 [======>.......................] - ETA: 8s - loss: 0.2680 - accuracy: 0.9063\n",
      "184/750 [======>.......................] - ETA: 8s - loss: 0.2698 - accuracy: 0.9055\n",
      "190/750 [======>.......................] - ETA: 8s - loss: 0.2695 - accuracy: 0.9056\n",
      "198/750 [======>.......................] - ETA: 8s - loss: 0.2696 - accuracy: 0.9054\n",
      "202/750 [=======>......................] - ETA: 8s - loss: 0.2693 - accuracy: 0.9052\n",
      "210/750 [=======>......................] - ETA: 8s - loss: 0.2691 - accuracy: 0.9050\n",
      "224/750 [=======>......................] - ETA: 7s - loss: 0.2686 - accuracy: 0.9050\n",
      "227/750 [========>.....................] - ETA: 7s - loss: 0.2686 - accuracy: 0.9053\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.4526 - accuracy: 0.8467\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "228/750 [========>.....................] - ETA: 7s - loss: 0.2688 - accuracy: 0.9052\n",
      "235/750 [========>.....................] - ETA: 7s - loss: 0.2695 - accuracy: 0.9055\n",
      "169/750 [=====>........................] - ETA: 8s - loss: 0.2681 - accuracy: 0.9064\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "245/750 [========>.....................] - ETA: 7s - loss: 0.2688 - accuracy: 0.9061\n",
      "250/750 [=========>....................] - ETA: 7s - loss: 0.2681 - accuracy: 0.9064\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.4531 - accuracy: 0.8469\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "264/750 [=========>....................] - ETA: 7s - loss: 0.2686 - accuracy: 0.9060\n",
      "567/750 [=====================>........] - ETA: 2s - loss: 0.4524 - accuracy: 0.8470\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "270/750 [=========>....................] - ETA: 7s - loss: 0.2681 - accuracy: 0.9062\n",
      "276/750 [==========>...................] - ETA: 7s - loss: 0.2681 - accuracy: 0.9060\n",
      "281/750 [==========>...................] - ETA: 6s - loss: 0.2674 - accuracy: 0.9062\n",
      "285/750 [==========>...................] - ETA: 7s - loss: 0.2675 - accuracy: 0.9061\n",
      "602/750 [=======================>......] - ETA: 2s - loss: 0.4530 - accuracy: 0.8466\n",
      "294/750 [==========>...................] - ETA: 6s - loss: 0.2671 - accuracy: 0.9061\n",
      "  4/750 [..............................] - ETA: 19s - loss: 0.8209 - accuracy: 0.7539\n",
      "299/750 [==========>...................] - ETA: 6s - loss: 0.2677 - accuracy: 0.9055\n",
      "312/750 [===========>..................] - ETA: 6s - loss: 0.2669 - accuracy: 0.9057\n",
      " 27/750 [>.............................] - ETA: 8s - loss: 0.8710 - accuracy: 0.7228 \n",
      "318/750 [===========>..................] - ETA: 6s - loss: 0.2680 - accuracy: 0.9055\n",
      " 38/750 [>.............................] - ETA: 8s - loss: 0.8803 - accuracy: 0.7171\n",
      "328/750 [============>.................] - ETA: 6s - loss: 0.2676 - accuracy: 0.9056\n",
      " 30/750 [>.............................] - ETA: 6s - loss: 0.4253 - accuracy: 0.8620\n",
      "340/750 [============>.................] - ETA: 6s - loss: 0.2669 - accuracy: 0.9059\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.4531 - accuracy: 0.8469 - val_loss: 0.4582 - val_accuracy: 0.8426\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 23/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 49s - loss: 0.4562 - accuracy: 0.8906\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 57/750 [=>............................] - ETA: 7s - loss: 0.8818 - accuracy: 0.7177\n",
      "353/750 [=============>................] - ETA: 5s - loss: 0.2671 - accuracy: 0.9057\n",
      " 51/750 [=>............................] - ETA: 6s - loss: 0.4549 - accuracy: 0.8505\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.4512 - accuracy: 0.8477\n",
      " 69/750 [=>............................] - ETA: 7s - loss: 0.8750 - accuracy: 0.7208\n",
      "366/750 [=============>................] - ETA: 5s - loss: 0.2673 - accuracy: 0.9054\n",
      " 78/750 [==>...........................] - ETA: 7s - loss: 0.8736 - accuracy: 0.7194\n",
      "377/750 [==============>...............] - ETA: 5s - loss: 0.2676 - accuracy: 0.9053\n",
      " 64/750 [=>............................] - ETA: 6s - loss: 0.4584 - accuracy: 0.8491\n",
      " 13/750 [..............................] - ETA: 6s - loss: 0.4369 - accuracy: 0.8594 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 92/750 [==>...........................] - ETA: 7s - loss: 0.8723 - accuracy: 0.7196\n",
      "388/750 [==============>...............] - ETA: 5s - loss: 0.2677 - accuracy: 0.9051\n",
      " 68/750 [=>............................] - ETA: 7s - loss: 0.4533 - accuracy: 0.8516\n",
      "645/750 [========================>.....] - ETA: 1s - loss: 0.4515 - accuracy: 0.8475\n",
      " 93/750 [==>...........................] - ETA: 7s - loss: 0.8710 - accuracy: 0.7201\n",
      "394/750 [==============>...............] - ETA: 5s - loss: 0.2689 - accuracy: 0.9047\n",
      " 76/750 [==>...........................] - ETA: 9s - loss: 0.4486 - accuracy: 0.8532\n",
      " 94/750 [==>...........................] - ETA: 8s - loss: 0.8711 - accuracy: 0.7191\n",
      " 95/750 [==>...........................] - ETA: 9s - loss: 0.8706 - accuracy: 0.7191\n",
      "665/750 [=========================>....] - ETA: 1s - loss: 0.4518 - accuracy: 0.8473\n",
      "396/750 [==============>...............] - ETA: 5s - loss: 0.2690 - accuracy: 0.9048\n",
      "674/750 [=========================>....] - ETA: 1s - loss: 0.4518 - accuracy: 0.8471\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "113/750 [===>..........................] - ETA: 8s - loss: 0.8736 - accuracy: 0.7205\n",
      "411/750 [===============>..............] - ETA: 4s - loss: 0.2696 - accuracy: 0.9043\n",
      " 87/750 [==>...........................] - ETA: 10s - loss: 0.4495 - accuracy: 0.8513\n",
      "114/750 [===>..........................] - ETA: 9s - loss: 0.8733 - accuracy: 0.7208\n",
      "412/750 [===============>..............] - ETA: 4s - loss: 0.2702 - accuracy: 0.9042\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.4527 - accuracy: 0.8468\n",
      "118/750 [===>..........................] - ETA: 8s - loss: 0.8738 - accuracy: 0.7213\n",
      "416/750 [===============>..............] - ETA: 4s - loss: 0.2698 - accuracy: 0.9040\n",
      "120/750 [===>..........................] - ETA: 9s - loss: 0.8740 - accuracy: 0.7207\n",
      " 91/750 [==>...........................] - ETA: 9s - loss: 0.4490 - accuracy: 0.8515 \n",
      "124/750 [===>..........................] - ETA: 9s - loss: 0.8717 - accuracy: 0.7219\n",
      "417/750 [===============>..............] - ETA: 5s - loss: 0.2696 - accuracy: 0.9042\n",
      " 93/750 [==>...........................] - ETA: 11s - loss: 0.4502 - accuracy: 0.8508\n",
      "426/750 [================>.............] - ETA: 4s - loss: 0.2705 - accuracy: 0.9039\n",
      "428/750 [================>.............] - ETA: 4s - loss: 0.2705 - accuracy: 0.9039\n",
      "430/750 [================>.............] - ETA: 4s - loss: 0.2707 - accuracy: 0.9038\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.4532 - accuracy: 0.8467\n",
      "434/750 [================>.............] - ETA: 4s - loss: 0.2703 - accuracy: 0.9041\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.4532 - accuracy: 0.8468\n",
      "102/750 [===>..........................] - ETA: 11s - loss: 0.4503 - accuracy: 0.8497\n",
      "440/750 [================>.............] - ETA: 4s - loss: 0.2702 - accuracy: 0.9041\n",
      "155/750 [=====>........................] - ETA: 9s - loss: 0.8706 - accuracy: 0.7227\n",
      "447/750 [================>.............] - ETA: 4s - loss: 0.2705 - accuracy: 0.9039\n",
      "139/750 [====>.........................] - ETA: 9s - loss: 0.4503 - accuracy: 0.8494 \n",
      "119/750 [===>..........................] - ETA: 10s - loss: 0.4483 - accuracy: 0.8512\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "461/750 [=================>............] - ETA: 4s - loss: 0.2694 - accuracy: 0.9044\n",
      "130/750 [====>.........................] - ETA: 10s - loss: 0.4512 - accuracy: 0.8508\n",
      "172/750 [=====>........................] - ETA: 8s - loss: 0.8719 - accuracy: 0.7217\n",
      "463/750 [=================>............] - ETA: 4s - loss: 0.2699 - accuracy: 0.9042\n",
      "147/750 [====>.........................] - ETA: 10s - loss: 0.4488 - accuracy: 0.8502\n",
      "144/750 [====>.........................] - ETA: 10s - loss: 0.4479 - accuracy: 0.8502\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "469/750 [=================>............] - ETA: 4s - loss: 0.2697 - accuracy: 0.9042\n",
      "162/750 [=====>........................] - ETA: 9s - loss: 0.4466 - accuracy: 0.8505\n",
      "476/750 [==================>...........] - ETA: 4s - loss: 0.2700 - accuracy: 0.9041\n",
      "206/750 [=======>......................] - ETA: 7s - loss: 0.8647 - accuracy: 0.7251\n",
      "487/750 [==================>...........] - ETA: 4s - loss: 0.2694 - accuracy: 0.9043\n",
      "493/750 [==================>...........] - ETA: 3s - loss: 0.2693 - accuracy: 0.9041\n",
      "175/750 [======>.......................] - ETA: 9s - loss: 0.4433 - accuracy: 0.8508\n",
      "502/750 [===================>..........] - ETA: 3s - loss: 0.2695 - accuracy: 0.9041\n",
      "503/750 [===================>..........] - ETA: 3s - loss: 0.2697 - accuracy: 0.9040\n",
      "506/750 [===================>..........] - ETA: 3s - loss: 0.2701 - accuracy: 0.9038\n",
      "232/750 [========>.....................] - ETA: 7s - loss: 0.8633 - accuracy: 0.7261\n",
      "189/750 [======>.......................] - ETA: 9s - loss: 0.4425 - accuracy: 0.8505\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "510/750 [===================>..........] - ETA: 3s - loss: 0.2703 - accuracy: 0.9037\n",
      "196/750 [======>.......................] - ETA: 9s - loss: 0.4425 - accuracy: 0.8503\n",
      "220/750 [=======>......................] - ETA: 8s - loss: 0.8643 - accuracy: 0.7251\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "513/750 [===================>..........] - ETA: 3s - loss: 0.2701 - accuracy: 0.9039\n",
      "199/750 [======>.......................] - ETA: 9s - loss: 0.4420 - accuracy: 0.8503\n",
      "520/750 [===================>..........] - ETA: 3s - loss: 0.2704 - accuracy: 0.9038\n",
      "208/750 [=======>......................] - ETA: 9s - loss: 0.4449 - accuracy: 0.8486\n",
      "529/750 [====================>.........] - ETA: 3s - loss: 0.2704 - accuracy: 0.9038\n",
      "235/750 [========>.....................] - ETA: 7s - loss: 0.8623 - accuracy: 0.7269\n",
      "537/750 [====================>.........] - ETA: 3s - loss: 0.2700 - accuracy: 0.9039\n",
      "539/750 [====================>.........] - ETA: 3s - loss: 0.2700 - accuracy: 0.9040\n",
      "220/750 [=======>......................] - ETA: 9s - loss: 0.4458 - accuracy: 0.8494\n",
      "165/750 [=====>........................] - ETA: 9s - loss: 0.4460 - accuracy: 0.8505\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "248/750 [========>.....................] - ETA: 7s - loss: 0.8630 - accuracy: 0.7263\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "264/750 [=========>....................] - ETA: 7s - loss: 0.8607 - accuracy: 0.7268\n",
      "542/750 [====================>.........] - ETA: 3s - loss: 0.2703 - accuracy: 0.9040\n",
      "266/750 [=========>....................] - ETA: 7s - loss: 0.8606 - accuracy: 0.7268\n",
      "555/750 [=====================>........] - ETA: 3s - loss: 0.2701 - accuracy: 0.9039\n",
      "268/750 [=========>....................] - ETA: 7s - loss: 0.8615 - accuracy: 0.7266\n",
      "257/750 [=========>....................] - ETA: 7s - loss: 0.8611 - accuracy: 0.7268\n",
      "564/750 [=====================>........] - ETA: 2s - loss: 0.2692 - accuracy: 0.9042\n",
      "256/750 [=========>....................] - ETA: 8s - loss: 0.4432 - accuracy: 0.8503\n",
      "568/750 [=====================>........] - ETA: 2s - loss: 0.2691 - accuracy: 0.9042\n",
      "291/750 [==========>...................] - ETA: 7s - loss: 0.8640 - accuracy: 0.7243\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "302/750 [===========>..................] - ETA: 7s - loss: 0.8648 - accuracy: 0.7244\n",
      "580/750 [======================>.......] - ETA: 2s - loss: 0.2681 - accuracy: 0.9045\n",
      "276/750 [==========>...................] - ETA: 7s - loss: 0.4453 - accuracy: 0.8497\n",
      "592/750 [======================>.......] - ETA: 2s - loss: 0.2685 - accuracy: 0.9044\n",
      "601/750 [=======================>......] - ETA: 2s - loss: 0.2685 - accuracy: 0.9043\n",
      "327/750 [============>.................] - ETA: 6s - loss: 0.8667 - accuracy: 0.7229\n",
      "608/750 [=======================>......] - ETA: 2s - loss: 0.2682 - accuracy: 0.9043\n",
      "618/750 [=======================>......] - ETA: 2s - loss: 0.2678 - accuracy: 0.9045\n",
      "322/750 [===========>..................] - ETA: 6s - loss: 0.8666 - accuracy: 0.7230\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.2682 - accuracy: 0.9043\n",
      "312/750 [===========>..................] - ETA: 6s - loss: 0.4441 - accuracy: 0.8490\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.2681 - accuracy: 0.9043\n",
      "325/750 [============>.................] - ETA: 6s - loss: 0.4463 - accuracy: 0.8479\n",
      "359/750 [=============>................] - ETA: 5s - loss: 0.8674 - accuracy: 0.7218\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.2669 - accuracy: 0.9046\n",
      " 38/750 [>.............................] - ETA: 6s - loss: 0.4341 - accuracy: 0.8581\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "336/750 [============>.................] - ETA: 6s - loss: 0.4454 - accuracy: 0.8483\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "651/750 [=========================>....] - ETA: 1s - loss: 0.2664 - accuracy: 0.9050\n",
      " 60/750 [=>............................] - ETA: 6s - loss: 0.4527 - accuracy: 0.8497\n",
      "374/750 [=============>................] - ETA: 5s - loss: 0.8685 - accuracy: 0.7209\n",
      "656/750 [=========================>....] - ETA: 1s - loss: 0.2664 - accuracy: 0.9050\n",
      "350/750 [=============>................] - ETA: 6s - loss: 0.4455 - accuracy: 0.8483\n",
      "371/750 [=============>................] - ETA: 5s - loss: 0.8682 - accuracy: 0.7211\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "667/750 [=========================>....] - ETA: 1s - loss: 0.2664 - accuracy: 0.9049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:04:27,517 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6036381696; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80/750 [==>...........................] - ETA: 10s - loss: 0.4501 - accuracy: 0.8521\n",
      "390/750 [==============>...............] - ETA: 5s - loss: 0.8691 - accuracy: 0.7208\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "403/750 [===============>..............] - ETA: 5s - loss: 0.8703 - accuracy: 0.7201\n",
      "678/750 [==========================>...] - ETA: 1s - loss: 0.2665 - accuracy: 0.9050\n",
      "377/750 [==============>...............] - ETA: 5s - loss: 0.4474 - accuracy: 0.8476\n",
      "688/750 [==========================>...] - ETA: 0s - loss: 0.2665 - accuracy: 0.9050\n",
      " 92/750 [==>...........................] - ETA: 10s - loss: 0.4484 - accuracy: 0.8519\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.2674 - accuracy: 0.9047\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.2672 - accuracy: 0.9050\n",
      "673/750 [=========================>....] - ETA: 1s - loss: 0.2666 - accuracy: 0.9049\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "421/750 [===============>..............] - ETA: 4s - loss: 0.8688 - accuracy: 0.7212\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2669 - accuracy: 0.9049\n",
      "402/750 [===============>..............] - ETA: 5s - loss: 0.4504 - accuracy: 0.8463\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.2675 - accuracy: 0.9048\n",
      "450/750 [=================>............] - ETA: 4s - loss: 0.8684 - accuracy: 0.7212\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.9050\n",
      "420/750 [===============>..............] - ETA: 5s - loss: 0.4502 - accuracy: 0.8463\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2672 - accuracy: 0.9050\n",
      "421/750 [===============>..............] - ETA: 5s - loss: 0.4504 - accuracy: 0.8463\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.9048\n",
      "434/750 [================>.............] - ETA: 4s - loss: 0.8686 - accuracy: 0.7212\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.9049\n",
      "443/750 [================>.............] - ETA: 4s - loss: 0.4513 - accuracy: 0.8461\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2668 - accuracy: 0.9051\n",
      "447/750 [================>.............] - ETA: 4s - loss: 0.4506 - accuracy: 0.8466\n",
      "457/750 [=================>............] - ETA: 4s - loss: 0.4501 - accuracy: 0.8469\n",
      "500/750 [===================>..........] - ETA: 3s - loss: 0.8662 - accuracy: 0.7222\n",
      "462/750 [=================>............] - ETA: 4s - loss: 0.4504 - accuracy: 0.8469\n",
      "470/750 [=================>............] - ETA: 4s - loss: 0.8678 - accuracy: 0.7216\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "469/750 [=================>............] - ETA: 4s - loss: 0.4510 - accuracy: 0.8468\n",
      "483/750 [==================>...........] - ETA: 4s - loss: 0.4504 - accuracy: 0.8475\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "488/750 [==================>...........] - ETA: 4s - loss: 0.4504 - accuracy: 0.8475\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "505/750 [===================>..........] - ETA: 3s - loss: 0.4500 - accuracy: 0.8480\n",
      "506/750 [===================>..........] - ETA: 3s - loss: 0.8659 - accuracy: 0.7225\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "223/750 [=======>......................] - ETA: 9s - loss: 0.4450 - accuracy: 0.8498\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "526/750 [====================>.........] - ETA: 3s - loss: 0.4490 - accuracy: 0.8483\n",
      "519/750 [===================>..........] - ETA: 3s - loss: 0.4489 - accuracy: 0.8485\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "534/750 [====================>.........] - ETA: 3s - loss: 0.4494 - accuracy: 0.8483\n",
      "540/750 [====================>.........] - ETA: 3s - loss: 0.4495 - accuracy: 0.8479\n",
      "547/750 [====================>.........] - ETA: 3s - loss: 0.4493 - accuracy: 0.8479\n",
      "535/750 [====================>.........] - ETA: 3s - loss: 0.8641 - accuracy: 0.7234\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "239/750 [========>.....................] - ETA: 8s - loss: 0.4426 - accuracy: 0.8506\n",
      "261/750 [=========>....................] - ETA: 8s - loss: 0.4438 - accuracy: 0.8499\n",
      "551/750 [=====================>........] - ETA: 3s - loss: 0.8637 - accuracy: 0.7237\n",
      "577/750 [======================>.......] - ETA: 2s - loss: 0.4497 - accuracy: 0.8479\n",
      "572/750 [=====================>........] - ETA: 2s - loss: 0.4493 - accuracy: 0.8477\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "634/750 [========================>.....] - ETA: 1s - loss: 0.8650 - accuracy: 0.7232\n",
      "579/750 [======================>.......] - ETA: 2s - loss: 0.4496 - accuracy: 0.8479\n",
      "568/750 [=====================>........] - ETA: 2s - loss: 0.8644 - accuracy: 0.7232\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "286/750 [==========>...................] - ETA: 7s - loss: 0.4460 - accuracy: 0.8492\n",
      "300/750 [===========>..................] - ETA: 7s - loss: 0.4449 - accuracy: 0.8490\n",
      "576/750 [======================>.......] - ETA: 2s - loss: 0.8643 - accuracy: 0.7234\n",
      "640/750 [========================>.....] - ETA: 1s - loss: 0.8644 - accuracy: 0.7234\n",
      "593/750 [======================>.......] - ETA: 2s - loss: 0.4495 - accuracy: 0.8481\n",
      "588/750 [======================>.......] - ETA: 2s - loss: 0.4492 - accuracy: 0.8482\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "646/750 [========================>.....] - ETA: 1s - loss: 0.8649 - accuracy: 0.7234\n",
      "598/750 [======================>.......] - ETA: 2s - loss: 0.4496 - accuracy: 0.8481\n",
      "602/750 [=======================>......] - ETA: 2s - loss: 0.8642 - accuracy: 0.7232\n",
      "750/750 [==============================] - 14s 19ms/step - loss: 0.2668 - accuracy: 0.9052 - val_loss: 0.3289 - val_accuracy: 0.8823\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 24/30\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.2778 - accuracy: 0.9219\n",
      "607/750 [=======================>......] - ETA: 2s - loss: 0.4496 - accuracy: 0.8479\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  8/750 [..............................] - ETA: 7s - loss: 0.2379 - accuracy: 0.9102\n",
      "676/750 [==========================>...] - ETA: 1s - loss: 0.8633 - accuracy: 0.7243\n",
      " 14/750 [..............................] - ETA: 14s - loss: 0.2379 - accuracy: 0.9107\n",
      "315/750 [===========>..................] - ETA: 7s - loss: 0.4449 - accuracy: 0.8487\n",
      "609/750 [=======================>......] - ETA: 2s - loss: 0.4499 - accuracy: 0.8477\n",
      " 20/750 [..............................] - ETA: 14s - loss: 0.2380 - accuracy: 0.9125\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.4487 - accuracy: 0.8478\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 31/750 [>.............................] - ETA: 11s - loss: 0.2564 - accuracy: 0.9073\n",
      "366/750 [=============>................] - ETA: 6s - loss: 0.4476 - accuracy: 0.8477\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.8640 - accuracy: 0.7238\n",
      " 41/750 [>.............................] - ETA: 10s - loss: 0.2605 - accuracy: 0.9059\n",
      "342/750 [============>.................] - ETA: 6s - loss: 0.4450 - accuracy: 0.8485\n",
      " 53/750 [=>............................] - ETA: 9s - loss: 0.2630 - accuracy: 0.9021\n",
      "665/750 [=========================>....] - ETA: 1s - loss: 0.4491 - accuracy: 0.8475\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 62/750 [=>............................] - ETA: 9s - loss: 0.2634 - accuracy: 0.9020\n",
      "361/750 [=============>................] - ETA: 6s - loss: 0.4468 - accuracy: 0.8482\n",
      " 73/750 [=>............................] - ETA: 8s - loss: 0.2645 - accuracy: 0.9022\n",
      " 81/750 [==>...........................] - ETA: 8s - loss: 0.2651 - accuracy: 0.9026\n",
      "396/750 [==============>...............] - ETA: 5s - loss: 0.4501 - accuracy: 0.8464\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "682/750 [==========================>...] - ETA: 1s - loss: 0.8634 - accuracy: 0.7241\n",
      " 94/750 [==>...........................] - ETA: 8s - loss: 0.2693 - accuracy: 0.9018\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.4508 - accuracy: 0.8472\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "102/750 [===>..........................] - ETA: 7s - loss: 0.2693 - accuracy: 0.9007\n",
      "108/750 [===>..........................] - ETA: 7s - loss: 0.2704 - accuracy: 0.9002\n",
      "112/750 [===>..........................] - ETA: 8s - loss: 0.2710 - accuracy: 0.8994\n",
      "719/750 [===========================>..] - ETA: 0s - loss: 0.4504 - accuracy: 0.8476\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.4508 - accuracy: 0.8477\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.4509 - accuracy: 0.8473\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "120/750 [===>..........................] - ETA: 7s - loss: 0.2715 - accuracy: 0.9004\n",
      "653/750 [=========================>....] - ETA: 1s - loss: 0.4481 - accuracy: 0.8479\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "416/750 [===============>..............] - ETA: 5s - loss: 0.4501 - accuracy: 0.8465\n",
      "125/750 [====>.........................] - ETA: 8s - loss: 0.2690 - accuracy: 0.9015\n",
      "139/750 [====>.........................] - ETA: 7s - loss: 0.2722 - accuracy: 0.9011\n",
      "454/750 [=================>............] - ETA: 4s - loss: 0.4508 - accuracy: 0.8466\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.4502 - accuracy: 0.8480\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "151/750 [=====>........................] - ETA: 7s - loss: 0.2710 - accuracy: 0.9014\n",
      "744/750 [============================>.] - ETA: 0s - loss: 0.4499 - accuracy: 0.8480\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "158/750 [=====>........................] - ETA: 7s - loss: 0.2710 - accuracy: 0.9016\n",
      "166/750 [=====>........................] - ETA: 7s - loss: 0.2694 - accuracy: 0.9024\n",
      "172/750 [=====>........................] - ETA: 7s - loss: 0.2689 - accuracy: 0.9025\n",
      "182/750 [======>.......................] - ETA: 7s - loss: 0.2707 - accuracy: 0.9018\n",
      "196/750 [======>.......................] - ETA: 6s - loss: 0.2679 - accuracy: 0.9031\n",
      "206/750 [=======>......................] - ETA: 6s - loss: 0.2658 - accuracy: 0.9038\n",
      "213/750 [=======>......................] - ETA: 6s - loss: 0.2677 - accuracy: 0.9029\n",
      "225/750 [========>.....................] - ETA: 6s - loss: 0.2662 - accuracy: 0.9034\n",
      "236/750 [========>.....................] - ETA: 6s - loss: 0.2656 - accuracy: 0.9040\n",
      "246/750 [========>.....................] - ETA: 6s - loss: 0.2640 - accuracy: 0.9048\n",
      "  8/750 [..............................] - ETA: 5s - loss: 0.8403 - accuracy: 0.7246\n",
      "250/750 [=========>....................] - ETA: 6s - loss: 0.2634 - accuracy: 0.9051\n",
      "252/750 [=========>....................] - ETA: 6s - loss: 0.2636 - accuracy: 0.9053\n",
      "491/750 [==================>...........] - ETA: 4s - loss: 0.4506 - accuracy: 0.8476\n",
      "258/750 [=========>....................] - ETA: 6s - loss: 0.2640 - accuracy: 0.9051\n",
      " 22/750 [..............................] - ETA: 14s - loss: 0.8577 - accuracy: 0.7180\n",
      "512/750 [===================>..........] - ETA: 3s - loss: 0.4494 - accuracy: 0.8483\n",
      "270/750 [=========>....................] - ETA: 6s - loss: 0.2632 - accuracy: 0.9057\n",
      " 27/750 [>.............................] - ETA: 14s - loss: 0.8733 - accuracy: 0.7164\n",
      "277/750 [==========>...................] - ETA: 6s - loss: 0.2627 - accuracy: 0.9060\n",
      "279/750 [==========>...................] - ETA: 6s - loss: 0.2630 - accuracy: 0.9059\n",
      " 32/750 [>.............................] - ETA: 14s - loss: 0.8751 - accuracy: 0.7139\n",
      "287/750 [==========>...................] - ETA: 5s - loss: 0.2637 - accuracy: 0.9058\n",
      "294/750 [==========>...................] - ETA: 5s - loss: 0.2641 - accuracy: 0.9056\n",
      " 46/750 [>.............................] - ETA: 12s - loss: 0.8659 - accuracy: 0.7225\n",
      "298/750 [==========>...................] - ETA: 6s - loss: 0.2638 - accuracy: 0.9056\n",
      " 47/750 [>.............................] - ETA: 16s - loss: 0.8656 - accuracy: 0.7237\n",
      "300/750 [===========>..................] - ETA: 6s - loss: 0.2641 - accuracy: 0.9055\n",
      " 54/750 [=>............................] - ETA: 15s - loss: 0.8582 - accuracy: 0.7260\n",
      " 56/750 [=>............................] - ETA: 15s - loss: 0.8558 - accuracy: 0.7277\n",
      "305/750 [===========>..................] - ETA: 6s - loss: 0.2641 - accuracy: 0.9054\n",
      " 65/750 [=>............................] - ETA: 14s - loss: 0.8590 - accuracy: 0.7274\n",
      "320/750 [===========>..................] - ETA: 5s - loss: 0.2639 - accuracy: 0.9055\n",
      " 71/750 [=>............................] - ETA: 13s - loss: 0.8617 - accuracy: 0.7276\n",
      " 73/750 [=>............................] - ETA: 14s - loss: 0.8611 - accuracy: 0.7273\n",
      "327/750 [============>.................] - ETA: 5s - loss: 0.2641 - accuracy: 0.9052\n",
      " 80/750 [==>...........................] - ETA: 13s - loss: 0.8624 - accuracy: 0.7271\n",
      "332/750 [============>.................] - ETA: 5s - loss: 0.2645 - accuracy: 0.9050\n",
      "334/750 [============>.................] - ETA: 5s - loss: 0.2661 - accuracy: 0.9046\n",
      " 88/750 [==>...........................] - ETA: 13s - loss: 0.8639 - accuracy: 0.7262\n",
      "338/750 [============>.................] - ETA: 5s - loss: 0.2660 - accuracy: 0.9047\n",
      " 95/750 [==>...........................] - ETA: 13s - loss: 0.8633 - accuracy: 0.7252\n",
      "346/750 [============>.................] - ETA: 5s - loss: 0.2655 - accuracy: 0.9050\n",
      "106/750 [===>..........................] - ETA: 12s - loss: 0.8684 - accuracy: 0.7220\n",
      "114/750 [===>..........................] - ETA: 11s - loss: 0.8648 - accuracy: 0.7251\n",
      "750/750 [==============================] - 14s 19ms/step - loss: 0.4498 - accuracy: 0.8481 - val_loss: 0.4556 - val_accuracy: 0.8422\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 24/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 12s - loss: 0.3197 - accuracy: 0.9062\n",
      "359/750 [=============>................] - ETA: 5s - loss: 0.2658 - accuracy: 0.9050\n",
      "624/750 [=======================>......] - ETA: 2s - loss: 0.4488 - accuracy: 0.8479\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 11/750 [..............................] - ETA: 15s - loss: 0.8638 - accuracy: 0.7045\n",
      "125/750 [====>.........................] - ETA: 11s - loss: 0.8629 - accuracy: 0.7256\n",
      "675/750 [==========================>...] - ETA: 1s - loss: 0.4500 - accuracy: 0.8472\n",
      "132/750 [====>.........................] - ETA: 11s - loss: 0.8610 - accuracy: 0.7257\n",
      "370/750 [=============>................] - ETA: 5s - loss: 0.2651 - accuracy: 0.9051\n",
      " 23/750 [..............................] - ETA: 15s - loss: 0.4483 - accuracy: 0.8512\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "646/750 [========================>.....] - ETA: 1s - loss: 0.4483 - accuracy: 0.8480\n",
      "137/750 [====>.........................] - ETA: 11s - loss: 0.8604 - accuracy: 0.7259\n",
      " 40/750 [>.............................] - ETA: 13s - loss: 0.4396 - accuracy: 0.8477\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "379/750 [==============>...............] - ETA: 5s - loss: 0.2661 - accuracy: 0.9048\n",
      "364/750 [=============>................] - ETA: 5s - loss: 0.2656 - accuracy: 0.9051\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "146/750 [====>.........................] - ETA: 10s - loss: 0.8607 - accuracy: 0.7250\n",
      "388/750 [==============>...............] - ETA: 5s - loss: 0.2652 - accuracy: 0.9052\n",
      "151/750 [=====>........................] - ETA: 10s - loss: 0.8611 - accuracy: 0.7250\n",
      "158/750 [=====>........................] - ETA: 10s - loss: 0.8641 - accuracy: 0.7242\n",
      "402/750 [===============>..............] - ETA: 5s - loss: 0.2661 - accuracy: 0.9050\n",
      " 87/750 [==>...........................] - ETA: 11s - loss: 0.4462 - accuracy: 0.8473\n",
      "159/750 [=====>........................] - ETA: 11s - loss: 0.8649 - accuracy: 0.7239\n",
      "404/750 [===============>..............] - ETA: 5s - loss: 0.2665 - accuracy: 0.9049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:04:37,540 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6035996672; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89/750 [==>...........................] - ETA: 12s - loss: 0.4478 - accuracy: 0.8480\n",
      "160/750 [=====>........................] - ETA: 11s - loss: 0.8653 - accuracy: 0.7234\n",
      "411/750 [===============>..............] - ETA: 5s - loss: 0.2668 - accuracy: 0.9047\n",
      " 91/750 [==>...........................] - ETA: 12s - loss: 0.4468 - accuracy: 0.8484\n",
      "395/750 [==============>...............] - ETA: 5s - loss: 0.2660 - accuracy: 0.9049\n",
      "166/750 [=====>........................] - ETA: 11s - loss: 0.8658 - accuracy: 0.7226\n",
      " 93/750 [==>...........................] - ETA: 14s - loss: 0.4464 - accuracy: 0.8488\n",
      "167/750 [=====>........................] - ETA: 11s - loss: 0.8651 - accuracy: 0.7226\n",
      "416/750 [===============>..............] - ETA: 5s - loss: 0.2665 - accuracy: 0.9049\n",
      " 94/750 [==>...........................] - ETA: 14s - loss: 0.4455 - accuracy: 0.8494\n",
      "168/750 [=====>........................] - ETA: 11s - loss: 0.8650 - accuracy: 0.7225\n",
      "179/750 [======>.......................] - ETA: 11s - loss: 0.8656 - accuracy: 0.7233\n",
      "420/750 [===============>..............] - ETA: 5s - loss: 0.2667 - accuracy: 0.9048\n",
      "180/750 [======>.......................] - ETA: 11s - loss: 0.8655 - accuracy: 0.7234\n",
      "185/750 [======>.......................] - ETA: 11s - loss: 0.8631 - accuracy: 0.7242\n",
      "433/750 [================>.............] - ETA: 4s - loss: 0.2670 - accuracy: 0.9050\n",
      "197/750 [======>.......................] - ETA: 10s - loss: 0.8617 - accuracy: 0.7242\n",
      "436/750 [================>.............] - ETA: 4s - loss: 0.2666 - accuracy: 0.9051\n",
      "198/750 [======>.......................] - ETA: 11s - loss: 0.8620 - accuracy: 0.7240\n",
      "447/750 [================>.............] - ETA: 4s - loss: 0.2659 - accuracy: 0.9054\n",
      "209/750 [=======>......................] - ETA: 10s - loss: 0.8589 - accuracy: 0.7251\n",
      "454/750 [=================>............] - ETA: 4s - loss: 0.2656 - accuracy: 0.9057\n",
      "217/750 [=======>......................] - ETA: 10s - loss: 0.8607 - accuracy: 0.7239\n",
      "461/750 [=================>............] - ETA: 4s - loss: 0.2653 - accuracy: 0.9057\n",
      "151/750 [=====>........................] - ETA: 11s - loss: 0.4453 - accuracy: 0.8516\n",
      "223/750 [=======>......................] - ETA: 10s - loss: 0.8600 - accuracy: 0.7239\n",
      "470/750 [=================>............] - ETA: 4s - loss: 0.2653 - accuracy: 0.9058\n",
      "227/750 [========>.....................] - ETA: 10s - loss: 0.8616 - accuracy: 0.7236\n",
      "473/750 [=================>............] - ETA: 4s - loss: 0.2653 - accuracy: 0.9057\n",
      "235/750 [========>.....................] - ETA: 9s - loss: 0.8601 - accuracy: 0.7256 \n",
      "477/750 [==================>...........] - ETA: 4s - loss: 0.2653 - accuracy: 0.9056\n",
      "237/750 [========>.....................] - ETA: 9s - loss: 0.8598 - accuracy: 0.7257\n",
      "484/750 [==================>...........] - ETA: 4s - loss: 0.2652 - accuracy: 0.9056\n",
      "491/750 [==================>...........] - ETA: 4s - loss: 0.2656 - accuracy: 0.9053\n",
      "244/750 [========>.....................] - ETA: 9s - loss: 0.8596 - accuracy: 0.7266\n",
      "251/750 [=========>....................] - ETA: 9s - loss: 0.8600 - accuracy: 0.7262\n",
      "494/750 [==================>...........] - ETA: 4s - loss: 0.2657 - accuracy: 0.9053\n",
      "503/750 [===================>..........] - ETA: 3s - loss: 0.2656 - accuracy: 0.9054\n",
      "267/750 [=========>....................] - ETA: 9s - loss: 0.8588 - accuracy: 0.7270\n",
      "511/750 [===================>..........] - ETA: 3s - loss: 0.2655 - accuracy: 0.9056\n",
      "519/750 [===================>..........] - ETA: 3s - loss: 0.2651 - accuracy: 0.9058\n",
      "258/750 [=========>....................] - ETA: 9s - loss: 0.8585 - accuracy: 0.7266\n",
      "288/750 [==========>...................] - ETA: 8s - loss: 0.8586 - accuracy: 0.7263\n",
      "529/750 [====================>.........] - ETA: 3s - loss: 0.2655 - accuracy: 0.9057\n",
      "214/750 [=======>......................] - ETA: 10s - loss: 0.4446 - accuracy: 0.8514\n",
      "221/750 [=======>......................] - ETA: 9s - loss: 0.4440 - accuracy: 0.8520\n",
      " 20/750 [..............................] - ETA: 14s - loss: 0.4422 - accuracy: 0.8523\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "538/750 [====================>.........] - ETA: 3s - loss: 0.2652 - accuracy: 0.9058\n",
      " 43/750 [>.............................] - ETA: 13s - loss: 0.4421 - accuracy: 0.8477\n",
      "298/750 [==========>...................] - ETA: 8s - loss: 0.8604 - accuracy: 0.7255\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "540/750 [====================>.........] - ETA: 3s - loss: 0.2652 - accuracy: 0.9058\n",
      "225/750 [========>.....................] - ETA: 10s - loss: 0.4437 - accuracy: 0.8520\n",
      "545/750 [====================>.........] - ETA: 3s - loss: 0.2650 - accuracy: 0.9060\n",
      "237/750 [========>.....................] - ETA: 9s - loss: 0.4421 - accuracy: 0.8527\n",
      "552/750 [=====================>........] - ETA: 3s - loss: 0.2650 - accuracy: 0.9061\n",
      "241/750 [========>.....................] - ETA: 9s - loss: 0.4428 - accuracy: 0.8523\n",
      "559/750 [=====================>........] - ETA: 3s - loss: 0.2651 - accuracy: 0.9061\n",
      "323/750 [===========>..................] - ETA: 8s - loss: 0.8583 - accuracy: 0.7258\n",
      "563/750 [=====================>........] - ETA: 3s - loss: 0.2655 - accuracy: 0.9059\n",
      "251/750 [=========>....................] - ETA: 9s - loss: 0.4450 - accuracy: 0.8507\n",
      " 68/750 [=>............................] - ETA: 12s - loss: 0.4446 - accuracy: 0.8488\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "570/750 [=====================>........] - ETA: 2s - loss: 0.2657 - accuracy: 0.9057\n",
      "256/750 [=========>....................] - ETA: 9s - loss: 0.4453 - accuracy: 0.8511\n",
      "321/750 [===========>..................] - ETA: 7s - loss: 0.8584 - accuracy: 0.7259\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "579/750 [======================>.......] - ETA: 2s - loss: 0.2648 - accuracy: 0.9062\n",
      "266/750 [=========>....................] - ETA: 9s - loss: 0.4436 - accuracy: 0.8515\n",
      " 73/750 [=>............................] - ETA: 12s - loss: 0.4394 - accuracy: 0.8517\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "585/750 [======================>.......] - ETA: 2s - loss: 0.2642 - accuracy: 0.9064\n",
      "273/750 [=========>....................] - ETA: 9s - loss: 0.4425 - accuracy: 0.8520\n",
      "589/750 [======================>.......] - ETA: 2s - loss: 0.2646 - accuracy: 0.9064\n",
      "596/750 [======================>.......] - ETA: 2s - loss: 0.2645 - accuracy: 0.9063\n",
      "287/750 [==========>...................] - ETA: 8s - loss: 0.4421 - accuracy: 0.8519\n",
      "346/750 [============>.................] - ETA: 7s - loss: 0.8565 - accuracy: 0.7273\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "602/750 [=======================>......] - ETA: 2s - loss: 0.2646 - accuracy: 0.9062\n",
      "606/750 [=======================>......] - ETA: 2s - loss: 0.2650 - accuracy: 0.9062\n",
      "349/750 [============>.................] - ETA: 7s - loss: 0.8563 - accuracy: 0.7277\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 99/750 [==>...........................] - ETA: 14s - loss: 0.4474 - accuracy: 0.8496\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "307/750 [===========>..................] - ETA: 7s - loss: 0.4401 - accuracy: 0.8521\n",
      "115/750 [===>..........................] - ETA: 13s - loss: 0.4441 - accuracy: 0.8512\n",
      "391/750 [==============>...............] - ETA: 6s - loss: 0.8538 - accuracy: 0.7287\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.2641 - accuracy: 0.9066\n",
      "112/750 [===>..........................] - ETA: 13s - loss: 0.4453 - accuracy: 0.8511\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "401/750 [===============>..............] - ETA: 6s - loss: 0.8534 - accuracy: 0.7292\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.2645 - accuracy: 0.9063\n",
      "327/750 [============>.................] - ETA: 7s - loss: 0.4401 - accuracy: 0.8522\n",
      "620/750 [=======================>......] - ETA: 2s - loss: 0.2648 - accuracy: 0.9062\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "125/750 [====>.........................] - ETA: 12s - loss: 0.4436 - accuracy: 0.8516\n",
      "644/750 [========================>.....] - ETA: 1s - loss: 0.2643 - accuracy: 0.9062\n",
      "655/750 [=========================>....] - ETA: 1s - loss: 0.2641 - accuracy: 0.9063\n",
      "143/750 [====>.........................] - ETA: 11s - loss: 0.4469 - accuracy: 0.8502\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "427/750 [================>.............] - ETA: 5s - loss: 0.8521 - accuracy: 0.7298\n",
      "381/750 [==============>...............] - ETA: 6s - loss: 0.8546 - accuracy: 0.7287\n",
      "662/750 [=========================>....] - ETA: 1s - loss: 0.2640 - accuracy: 0.9062\n",
      "663/750 [=========================>....] - ETA: 1s - loss: 0.2639 - accuracy: 0.9063\n",
      "428/750 [================>.............] - ETA: 5s - loss: 0.8526 - accuracy: 0.7295\n",
      "353/750 [=============>................] - ETA: 7s - loss: 0.4418 - accuracy: 0.8509\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "384/750 [==============>...............] - ETA: 6s - loss: 0.8543 - accuracy: 0.7287\n",
      "163/750 [=====>........................] - ETA: 11s - loss: 0.4469 - accuracy: 0.8507\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "678/750 [==========================>...] - ETA: 1s - loss: 0.2635 - accuracy: 0.9064\n",
      "361/750 [=============>................] - ETA: 6s - loss: 0.4424 - accuracy: 0.8505\n",
      "439/750 [================>.............] - ETA: 5s - loss: 0.8526 - accuracy: 0.7291\n",
      "679/750 [==========================>...] - ETA: 1s - loss: 0.2634 - accuracy: 0.9064\n",
      "370/750 [=============>................] - ETA: 6s - loss: 0.4427 - accuracy: 0.8505\n",
      "414/750 [===============>..............] - ETA: 5s - loss: 0.8520 - accuracy: 0.7298\n",
      "681/750 [==========================>...] - ETA: 1s - loss: 0.2633 - accuracy: 0.9065\n",
      "379/750 [==============>...............] - ETA: 6s - loss: 0.4452 - accuracy: 0.8497\n",
      "422/750 [===============>..............] - ETA: 5s - loss: 0.8520 - accuracy: 0.7299\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "692/750 [==========================>...] - ETA: 0s - loss: 0.2635 - accuracy: 0.9064\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.2638 - accuracy: 0.9062\n",
      "392/750 [==============>...............] - ETA: 6s - loss: 0.4440 - accuracy: 0.8503\n",
      "707/750 [===========================>..] - ETA: 0s - loss: 0.2635 - accuracy: 0.9064\n",
      "393/750 [==============>...............] - ETA: 6s - loss: 0.4437 - accuracy: 0.8504\n",
      "477/750 [==================>...........] - ETA: 4s - loss: 0.8531 - accuracy: 0.7279\n",
      "709/750 [===========================>..] - ETA: 0s - loss: 0.2635 - accuracy: 0.9063\n",
      "409/750 [===============>..............] - ETA: 5s - loss: 0.4432 - accuracy: 0.8507\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.2633 - accuracy: 0.9065\n",
      "175/750 [======>.......................] - ETA: 11s - loss: 0.4457 - accuracy: 0.8515\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2630 - accuracy: 0.9066\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.2630 - accuracy: 0.9066\n",
      "185/750 [======>.......................] - ETA: 10s - loss: 0.4468 - accuracy: 0.8503\n",
      "419/750 [===============>..............] - ETA: 5s - loss: 0.4448 - accuracy: 0.8500\n",
      "198/750 [======>.......................] - ETA: 10s - loss: 0.4463 - accuracy: 0.8505\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "444/750 [================>.............] - ETA: 5s - loss: 0.8523 - accuracy: 0.7291\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "728/750 [============================>.] - ETA: 0s - loss: 0.2631 - accuracy: 0.9066\n",
      "424/750 [===============>..............] - ETA: 5s - loss: 0.4446 - accuracy: 0.8500\n",
      "501/750 [===================>..........] - ETA: 4s - loss: 0.8546 - accuracy: 0.7267\n",
      "736/750 [============================>.] - ETA: 0s - loss: 0.2631 - accuracy: 0.9067\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2628 - accuracy: 0.9067\n",
      "212/750 [=======>......................] - ETA: 10s - loss: 0.4448 - accuracy: 0.8511\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "467/750 [=================>............] - ETA: 4s - loss: 0.4459 - accuracy: 0.8494\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "228/750 [========>.....................] - ETA: 10s - loss: 0.4433 - accuracy: 0.8521\n",
      "457/750 [=================>............] - ETA: 5s - loss: 0.4462 - accuracy: 0.8493\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "484/750 [==================>...........] - ETA: 4s - loss: 0.4460 - accuracy: 0.8494\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "575/750 [======================>.......] - ETA: 2s - loss: 0.8544 - accuracy: 0.7270\n",
      "249/750 [========>.....................] - ETA: 9s - loss: 0.4439 - accuracy: 0.8513\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "513/750 [===================>..........] - ETA: 3s - loss: 0.4460 - accuracy: 0.8489\n",
      "600/750 [=======================>......] - ETA: 2s - loss: 0.8532 - accuracy: 0.7277\n",
      "509/750 [===================>..........] - ETA: 3s - loss: 0.4465 - accuracy: 0.8488\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "529/750 [====================>.........] - ETA: 3s - loss: 0.4450 - accuracy: 0.8490\n",
      "646/750 [========================>.....] - ETA: 1s - loss: 0.8515 - accuracy: 0.7280\n",
      "547/750 [====================>.........] - ETA: 3s - loss: 0.4470 - accuracy: 0.8480\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "583/750 [======================>.......] - ETA: 2s - loss: 0.4469 - accuracy: 0.8480\n",
      "295/750 [==========>...................] - ETA: 8s - loss: 0.4414 - accuracy: 0.8516\n",
      "541/750 [====================>.........] - ETA: 3s - loss: 0.8557 - accuracy: 0.7261\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "669/750 [=========================>....] - ETA: 1s - loss: 0.8514 - accuracy: 0.7286\n",
      "555/750 [=====================>........] - ETA: 3s - loss: 0.8558 - accuracy: 0.7264\n",
      "314/750 [===========>..................] - ETA: 7s - loss: 0.4400 - accuracy: 0.8523\n",
      "568/750 [=====================>........] - ETA: 2s - loss: 0.4466 - accuracy: 0.8480\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 14s 19ms/step - loss: 0.2630 - accuracy: 0.9066 - val_loss: 0.3205 - val_accuracy: 0.8847\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 25/30\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.1871 - accuracy: 0.9219\n",
      "320/750 [===========>..................] - ETA: 7s - loss: 0.4403 - accuracy: 0.8523\n",
      "599/750 [======================>.......] - ETA: 2s - loss: 0.4471 - accuracy: 0.8482\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.8527 - accuracy: 0.7279\n",
      " 24/750 [..............................] - ETA: 3s - loss: 0.2712 - accuracy: 0.9023\n",
      "588/750 [======================>.......] - ETA: 2s - loss: 0.4473 - accuracy: 0.8477\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.8525 - accuracy: 0.7279\n",
      " 27/750 [>.............................] - ETA: 8s - loss: 0.2698 - accuracy: 0.9028\n",
      "344/750 [============>.................] - ETA: 7s - loss: 0.4416 - accuracy: 0.8512\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.8523 - accuracy: 0.7278\n",
      "622/750 [=======================>......] - ETA: 2s - loss: 0.4473 - accuracy: 0.8483\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 39/750 [>.............................] - ETA: 7s - loss: 0.2639 - accuracy: 0.9042\n",
      " 49/750 [>.............................] - ETA: 7s - loss: 0.2587 - accuracy: 0.9075\n",
      "333/750 [============>.................] - ETA: 7s - loss: 0.4411 - accuracy: 0.8516\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 61/750 [=>............................] - ETA: 7s - loss: 0.2670 - accuracy: 0.9047\n",
      " 71/750 [=>............................] - ETA: 7s - loss: 0.2677 - accuracy: 0.9038\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.4457 - accuracy: 0.8488\n",
      "389/750 [==============>...............] - ETA: 6s - loss: 0.4439 - accuracy: 0.8503\n",
      "644/750 [========================>.....] - ETA: 1s - loss: 0.4465 - accuracy: 0.8484\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 88/750 [==>...........................] - ETA: 6s - loss: 0.2734 - accuracy: 0.9011\n",
      " 99/750 [==>...........................] - ETA: 6s - loss: 0.2704 - accuracy: 0.9040\n",
      "617/750 [=======================>......] - ETA: 2s - loss: 0.4469 - accuracy: 0.8484\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "103/750 [===>..........................] - ETA: 7s - loss: 0.2712 - accuracy: 0.9031\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.8517 - accuracy: 0.7282\n",
      "114/750 [===>..........................] - ETA: 6s - loss: 0.2673 - accuracy: 0.9050\n",
      "118/750 [===>..........................] - ETA: 6s - loss: 0.2677 - accuracy: 0.9045\n",
      "123/750 [===>..........................] - ETA: 6s - loss: 0.2690 - accuracy: 0.9036\n",
      "660/750 [=========================>....] - ETA: 1s - loss: 0.4462 - accuracy: 0.8487\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "139/750 [====>.........................] - ETA: 6s - loss: 0.2645 - accuracy: 0.9055\n",
      "145/750 [====>.........................] - ETA: 6s - loss: 0.2645 - accuracy: 0.9061\n",
      "675/750 [==========================>...] - ETA: 1s - loss: 0.8521 - accuracy: 0.7285\n",
      "156/750 [=====>........................] - ETA: 6s - loss: 0.2675 - accuracy: 0.9049\n",
      "167/750 [=====>........................] - ETA: 6s - loss: 0.2685 - accuracy: 0.9046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:04:47,564 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6035472384; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/750 [=====>........................] - ETA: 6s - loss: 0.2660 - accuracy: 0.9060\n",
      "411/750 [===============>..............] - ETA: 5s - loss: 0.4426 - accuracy: 0.8508\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.4455 - accuracy: 0.8488\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "188/750 [======>.......................] - ETA: 5s - loss: 0.2656 - accuracy: 0.9070\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.8526 - accuracy: 0.7280\n",
      "189/750 [======>.......................] - ETA: 6s - loss: 0.2657 - accuracy: 0.9071\n",
      "197/750 [======>.......................] - ETA: 6s - loss: 0.2656 - accuracy: 0.9075\n",
      "480/750 [==================>...........] - ETA: 4s - loss: 0.4460 - accuracy: 0.8494\n",
      "209/750 [=======>......................] - ETA: 5s - loss: 0.2651 - accuracy: 0.9077\n",
      "217/750 [=======>......................] - ETA: 5s - loss: 0.2628 - accuracy: 0.9088\n",
      "221/750 [=======>......................] - ETA: 5s - loss: 0.2621 - accuracy: 0.9089\n",
      "238/750 [========>.....................] - ETA: 5s - loss: 0.2625 - accuracy: 0.9084\n",
      "447/750 [================>.............] - ETA: 5s - loss: 0.4456 - accuracy: 0.8496\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.4467 - accuracy: 0.8482\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.4465 - accuracy: 0.8483\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  3/750 [..............................] - ETA: 21s - loss: 0.7889 - accuracy: 0.7292\n",
      "254/750 [=========>....................] - ETA: 5s - loss: 0.2609 - accuracy: 0.9091\n",
      " 17/750 [..............................] - ETA: 8s - loss: 0.8390 - accuracy: 0.7224 \n",
      "268/750 [=========>....................] - ETA: 5s - loss: 0.2607 - accuracy: 0.9086\n",
      " 28/750 [>.............................] - ETA: 7s - loss: 0.8385 - accuracy: 0.7238\n",
      "278/750 [==========>...................] - ETA: 5s - loss: 0.2600 - accuracy: 0.9089\n",
      " 35/750 [>.............................] - ETA: 7s - loss: 0.8264 - accuracy: 0.7344\n",
      "287/750 [==========>...................] - ETA: 5s - loss: 0.2610 - accuracy: 0.9087\n",
      "299/750 [==========>...................] - ETA: 4s - loss: 0.2609 - accuracy: 0.9084\n",
      " 54/750 [=>............................] - ETA: 8s - loss: 0.8354 - accuracy: 0.7338\n",
      "496/750 [==================>...........] - ETA: 4s - loss: 0.4465 - accuracy: 0.8492\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "311/750 [===========>..................] - ETA: 4s - loss: 0.2600 - accuracy: 0.9089\n",
      "316/750 [===========>..................] - ETA: 4s - loss: 0.2601 - accuracy: 0.9090\n",
      "246/750 [========>.....................] - ETA: 5s - loss: 0.2625 - accuracy: 0.9083\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "328/750 [============>.................] - ETA: 4s - loss: 0.2601 - accuracy: 0.9090\n",
      " 11/750 [..............................] - ETA: 9s - loss: 0.5177 - accuracy: 0.8125\n",
      " 74/750 [=>............................] - ETA: 8s - loss: 0.8490 - accuracy: 0.7297\n",
      "336/750 [============>.................] - ETA: 4s - loss: 0.2598 - accuracy: 0.9090\n",
      "343/750 [============>.................] - ETA: 4s - loss: 0.2589 - accuracy: 0.9092\n",
      " 18/750 [..............................] - ETA: 14s - loss: 0.4621 - accuracy: 0.8385\n",
      " 24/750 [..............................] - ETA: 14s - loss: 0.4519 - accuracy: 0.8438\n",
      " 29/750 [>.............................] - ETA: 14s - loss: 0.4475 - accuracy: 0.8475\n",
      "354/750 [=============>................] - ETA: 4s - loss: 0.2595 - accuracy: 0.9089\n",
      " 33/750 [>.............................] - ETA: 14s - loss: 0.4496 - accuracy: 0.8480\n",
      " 97/750 [==>...........................] - ETA: 10s - loss: 0.8441 - accuracy: 0.7341\n",
      "365/750 [=============>................] - ETA: 4s - loss: 0.2598 - accuracy: 0.9089\n",
      "102/750 [===>..........................] - ETA: 9s - loss: 0.8439 - accuracy: 0.7345 \n",
      " 42/750 [>.............................] - ETA: 13s - loss: 0.4551 - accuracy: 0.8445\n",
      "628/750 [========================>.....] - ETA: 1s - loss: 0.4474 - accuracy: 0.8482\n",
      "374/750 [=============>................] - ETA: 4s - loss: 0.2602 - accuracy: 0.9087\n",
      " 50/750 [=>............................] - ETA: 12s - loss: 0.4502 - accuracy: 0.8472\n",
      "378/750 [==============>...............] - ETA: 4s - loss: 0.2593 - accuracy: 0.9090\n",
      " 58/750 [=>............................] - ETA: 12s - loss: 0.4444 - accuracy: 0.8497\n",
      "669/750 [=========================>....] - ETA: 1s - loss: 0.4463 - accuracy: 0.8485\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "384/750 [==============>...............] - ETA: 4s - loss: 0.2591 - accuracy: 0.9090\n",
      "389/750 [==============>...............] - ETA: 4s - loss: 0.2594 - accuracy: 0.9091\n",
      " 67/750 [=>............................] - ETA: 11s - loss: 0.4432 - accuracy: 0.8510\n",
      "394/750 [==============>...............] - ETA: 4s - loss: 0.2593 - accuracy: 0.9091\n",
      " 80/750 [==>...........................] - ETA: 10s - loss: 0.4431 - accuracy: 0.8506\n",
      "404/750 [===============>..............] - ETA: 4s - loss: 0.2581 - accuracy: 0.9097\n",
      "414/750 [===============>..............] - ETA: 4s - loss: 0.2583 - accuracy: 0.9096\n",
      "100/750 [===>..........................] - ETA: 9s - loss: 0.4411 - accuracy: 0.8523 \n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.4466 - accuracy: 0.8484 - val_loss: 0.4533 - val_accuracy: 0.8446\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 25/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 14s - loss: 0.4753 - accuracy: 0.8125\n",
      "427/750 [================>.............] - ETA: 3s - loss: 0.2588 - accuracy: 0.9096\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.4461 - accuracy: 0.8485\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 13/750 [..............................] - ETA: 16s - loss: 0.5052 - accuracy: 0.8209\n",
      " 43/750 [>.............................] - ETA: 8s - loss: 0.8252 - accuracy: 0.7380\n",
      "127/750 [====>.........................] - ETA: 9s - loss: 0.4457 - accuracy: 0.8520\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.4462 - accuracy: 0.8484\n",
      "457/750 [=================>............] - ETA: 3s - loss: 0.2613 - accuracy: 0.9088\n",
      "347/750 [============>.................] - ETA: 4s - loss: 0.2589 - accuracy: 0.9093\n",
      " 69/750 [=>............................] - ETA: 8s - loss: 0.8458 - accuracy: 0.7301\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "462/750 [=================>............] - ETA: 3s - loss: 0.2613 - accuracy: 0.9088\n",
      "133/750 [====>.........................] - ETA: 10s - loss: 0.4475 - accuracy: 0.8517\n",
      " 91/750 [==>...........................] - ETA: 10s - loss: 0.8478 - accuracy: 0.7327\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "203/750 [=======>......................] - ETA: 8s - loss: 0.8438 - accuracy: 0.7342\n",
      "466/750 [=================>............] - ETA: 3s - loss: 0.2619 - accuracy: 0.9087\n",
      "134/750 [====>.........................] - ETA: 11s - loss: 0.4473 - accuracy: 0.8519\n",
      "137/750 [====>.........................] - ETA: 10s - loss: 0.4464 - accuracy: 0.8523\n",
      "468/750 [=================>............] - ETA: 3s - loss: 0.2619 - accuracy: 0.9088\n",
      "147/750 [====>.........................] - ETA: 10s - loss: 0.4480 - accuracy: 0.8525\n",
      "109/750 [===>..........................] - ETA: 9s - loss: 0.4478 - accuracy: 0.8508\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "150/750 [=====>........................] - ETA: 10s - loss: 0.4474 - accuracy: 0.8526\n",
      "482/750 [==================>...........] - ETA: 3s - loss: 0.2617 - accuracy: 0.9088\n",
      "154/750 [=====>........................] - ETA: 10s - loss: 0.4462 - accuracy: 0.8527\n",
      "114/750 [===>..........................] - ETA: 9s - loss: 0.4461 - accuracy: 0.8521\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "158/750 [=====>........................] - ETA: 10s - loss: 0.4453 - accuracy: 0.8528\n",
      "173/750 [=====>........................] - ETA: 9s - loss: 0.4444 - accuracy: 0.8530 \n",
      "142/750 [====>.........................] - ETA: 9s - loss: 0.8470 - accuracy: 0.7327\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "503/750 [===================>..........] - ETA: 3s - loss: 0.2606 - accuracy: 0.9087\n",
      "131/750 [====>.........................] - ETA: 10s - loss: 0.4464 - accuracy: 0.8521\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "255/750 [=========>....................] - ETA: 7s - loss: 0.8464 - accuracy: 0.7327\n",
      "512/750 [===================>..........] - ETA: 3s - loss: 0.2613 - accuracy: 0.9086\n",
      "154/750 [=====>........................] - ETA: 8s - loss: 0.8472 - accuracy: 0.7329\n",
      "524/750 [===================>..........] - ETA: 2s - loss: 0.2610 - accuracy: 0.9086\n",
      "171/750 [=====>........................] - ETA: 8s - loss: 0.8483 - accuracy: 0.7321\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "273/750 [=========>....................] - ETA: 7s - loss: 0.8463 - accuracy: 0.7321\n",
      "529/750 [====================>.........] - ETA: 2s - loss: 0.2607 - accuracy: 0.9086\n",
      "538/750 [====================>.........] - ETA: 2s - loss: 0.2603 - accuracy: 0.9086\n",
      "198/750 [======>.......................] - ETA: 9s - loss: 0.4439 - accuracy: 0.8528\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "192/750 [======>.......................] - ETA: 8s - loss: 0.8469 - accuracy: 0.7328\n",
      "555/750 [=====================>........] - ETA: 2s - loss: 0.2603 - accuracy: 0.9086\n",
      "221/750 [=======>......................] - ETA: 8s - loss: 0.4447 - accuracy: 0.8524\n",
      "557/750 [=====================>........] - ETA: 2s - loss: 0.2601 - accuracy: 0.9087\n",
      "558/750 [=====================>........] - ETA: 2s - loss: 0.2599 - accuracy: 0.9088\n",
      "212/750 [=======>......................] - ETA: 8s - loss: 0.4427 - accuracy: 0.8532\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "216/750 [=======>......................] - ETA: 8s - loss: 0.4428 - accuracy: 0.8532\n",
      "562/750 [=====================>........] - ETA: 2s - loss: 0.2599 - accuracy: 0.9087\n",
      "569/750 [=====================>........] - ETA: 2s - loss: 0.2597 - accuracy: 0.9086\n",
      "248/750 [========>.....................] - ETA: 8s - loss: 0.4477 - accuracy: 0.8503\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "447/750 [================>.............] - ETA: 3s - loss: 0.2612 - accuracy: 0.9089\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "583/750 [======================>.......] - ETA: 2s - loss: 0.2604 - accuracy: 0.9082\n",
      "594/750 [======================>.......] - ETA: 2s - loss: 0.2600 - accuracy: 0.9082\n",
      "274/750 [=========>....................] - ETA: 7s - loss: 0.4449 - accuracy: 0.8518\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.2599 - accuracy: 0.9083\n",
      "611/750 [=======================>......] - ETA: 1s - loss: 0.2602 - accuracy: 0.9080\n",
      "617/750 [=======================>......] - ETA: 1s - loss: 0.2601 - accuracy: 0.9080\n",
      "306/750 [===========>..................] - ETA: 6s - loss: 0.4445 - accuracy: 0.8512\n",
      "377/750 [==============>...............] - ETA: 5s - loss: 0.8440 - accuracy: 0.7322\n",
      "628/750 [========================>.....] - ETA: 1s - loss: 0.2595 - accuracy: 0.9083\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.2597 - accuracy: 0.9082\n",
      "294/750 [==========>...................] - ETA: 6s - loss: 0.4448 - accuracy: 0.8513\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "654/750 [=========================>....] - ETA: 1s - loss: 0.2596 - accuracy: 0.9084\n",
      "492/750 [==================>...........] - ETA: 3s - loss: 0.2612 - accuracy: 0.9089\n",
      "318/750 [===========>..................] - ETA: 6s - loss: 0.4467 - accuracy: 0.8505\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "662/750 [=========================>....] - ETA: 1s - loss: 0.2594 - accuracy: 0.9085\n",
      "350/750 [=============>................] - ETA: 5s - loss: 0.4477 - accuracy: 0.8499\n",
      "239/750 [========>.....................] - ETA: 8s - loss: 0.4477 - accuracy: 0.8511\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "327/750 [============>.................] - ETA: 6s - loss: 0.4483 - accuracy: 0.8494\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.2593 - accuracy: 0.9085\n",
      "364/750 [=============>................] - ETA: 5s - loss: 0.4478 - accuracy: 0.8496\n",
      "343/750 [============>.................] - ETA: 5s - loss: 0.4477 - accuracy: 0.8501\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "690/750 [==========================>...] - ETA: 0s - loss: 0.2599 - accuracy: 0.9082\n",
      "450/750 [=================>............] - ETA: 4s - loss: 0.8460 - accuracy: 0.7306\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.2598 - accuracy: 0.9083\n",
      "374/750 [=============>................] - ETA: 5s - loss: 0.4473 - accuracy: 0.8496\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 86/750 [==>...........................] - ETA: 10s - loss: 0.4431 - accuracy: 0.8514\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.2597 - accuracy: 0.9080\n",
      "408/750 [===============>..............] - ETA: 4s - loss: 0.4463 - accuracy: 0.8497\n",
      "721/750 [===========================>..] - ETA: 0s - loss: 0.2595 - accuracy: 0.9081\n",
      "415/750 [===============>..............] - ETA: 4s - loss: 0.4459 - accuracy: 0.8499\n",
      "476/750 [==================>...........] - ETA: 3s - loss: 0.8469 - accuracy: 0.7307\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.2591 - accuracy: 0.9081\n",
      "399/750 [==============>...............] - ETA: 4s - loss: 0.4472 - accuracy: 0.8494\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "483/750 [==================>...........] - ETA: 3s - loss: 0.8462 - accuracy: 0.7309\n",
      "737/750 [============================>.] - ETA: 0s - loss: 0.2592 - accuracy: 0.9081\n",
      "423/750 [===============>..............] - ETA: 4s - loss: 0.4456 - accuracy: 0.8505\n",
      "671/750 [=========================>....] - ETA: 1s - loss: 0.2598 - accuracy: 0.9084\n",
      "394/750 [==============>...............] - ETA: 5s - loss: 0.4471 - accuracy: 0.8494\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "499/750 [==================>...........] - ETA: 3s - loss: 0.8467 - accuracy: 0.7307\n",
      "742/750 [============================>.] - ETA: 0s - loss: 0.2592 - accuracy: 0.9082\n",
      "427/750 [================>.............] - ETA: 4s - loss: 0.4457 - accuracy: 0.8504\n",
      "429/750 [================>.............] - ETA: 4s - loss: 0.4459 - accuracy: 0.8502\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.2592 - accuracy: 0.9081\n",
      "420/750 [===============>..............] - ETA: 4s - loss: 0.4465 - accuracy: 0.8501\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.2595 - accuracy: 0.9081\n",
      "526/750 [====================>.........] - ETA: 3s - loss: 0.8461 - accuracy: 0.7305\n",
      "429/750 [================>.............] - ETA: 4s - loss: 0.8449 - accuracy: 0.7313\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2596 - accuracy: 0.9081\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "466/750 [=================>............] - ETA: 4s - loss: 0.4448 - accuracy: 0.8504\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "499/750 [==================>...........] - ETA: 3s - loss: 0.4453 - accuracy: 0.8502\n",
      "504/750 [===================>..........] - ETA: 3s - loss: 0.4458 - accuracy: 0.8499\n",
      "579/750 [======================>.......] - ETA: 2s - loss: 0.8462 - accuracy: 0.7288\n",
      "471/750 [=================>............] - ETA: 3s - loss: 0.4452 - accuracy: 0.8500\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "512/750 [===================>..........] - ETA: 3s - loss: 0.4450 - accuracy: 0.8501\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "657/750 [=========================>....] - ETA: 1s - loss: 0.8460 - accuracy: 0.7291\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 0.4451 - accuracy: 0.8501\n",
      "670/750 [=========================>....] - ETA: 1s - loss: 0.8456 - accuracy: 0.7297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:04:57,585 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6034747392; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529/750 [====================>.........] - ETA: 3s - loss: 0.8460 - accuracy: 0.7304\n",
      "541/750 [====================>.........] - ETA: 2s - loss: 0.4458 - accuracy: 0.8497\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "690/750 [==========================>...] - ETA: 0s - loss: 0.8450 - accuracy: 0.7298\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2595 - accuracy: 0.9080 - val_loss: 0.3177 - val_accuracy: 0.8867\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 26/30\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.2452 - accuracy: 0.9062\n",
      "  8/750 [..............................] - ETA: 17s - loss: 0.2569 - accuracy: 0.9082\n",
      "554/750 [=====================>........] - ETA: 2s - loss: 0.4459 - accuracy: 0.8497\n",
      " 20/750 [..............................] - ETA: 10s - loss: 0.2631 - accuracy: 0.9055\n",
      "641/750 [========================>.....] - ETA: 1s - loss: 0.4441 - accuracy: 0.8506\n",
      "559/750 [=====================>........] - ETA: 2s - loss: 0.4457 - accuracy: 0.8498\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 28/750 [>.............................] - ETA: 10s - loss: 0.2847 - accuracy: 0.8973\n",
      " 30/750 [>.............................] - ETA: 11s - loss: 0.2834 - accuracy: 0.8979\n",
      "571/750 [=====================>........] - ETA: 2s - loss: 0.4450 - accuracy: 0.8499\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.8443 - accuracy: 0.7303\n",
      " 36/750 [>.............................] - ETA: 12s - loss: 0.2829 - accuracy: 0.9002\n",
      "449/750 [================>.............] - ETA: 4s - loss: 0.4457 - accuracy: 0.8503\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "580/750 [======================>.......] - ETA: 2s - loss: 0.4458 - accuracy: 0.8497\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 49/750 [>.............................] - ETA: 10s - loss: 0.2794 - accuracy: 0.9043\n",
      " 56/750 [=>............................] - ETA: 9s - loss: 0.2689 - accuracy: 0.9079 \n",
      " 63/750 [=>............................] - ETA: 9s - loss: 0.2665 - accuracy: 0.9095\n",
      "600/750 [=======================>......] - ETA: 2s - loss: 0.8461 - accuracy: 0.7287\n",
      " 65/750 [=>............................] - ETA: 10s - loss: 0.2646 - accuracy: 0.9103\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.8461 - accuracy: 0.7285\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 72/750 [=>............................] - ETA: 9s - loss: 0.2607 - accuracy: 0.9106 \n",
      "621/750 [=======================>......] - ETA: 1s - loss: 0.4453 - accuracy: 0.8501\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 80/750 [==>...........................] - ETA: 10s - loss: 0.2648 - accuracy: 0.9078\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.4448 - accuracy: 0.8503\n",
      "636/750 [========================>.....] - ETA: 1s - loss: 0.4446 - accuracy: 0.8502\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.4437 - accuracy: 0.8507\n",
      " 90/750 [==>...........................] - ETA: 10s - loss: 0.2591 - accuracy: 0.9095\n",
      "674/750 [=========================>....] - ETA: 1s - loss: 0.4439 - accuracy: 0.8504\n",
      " 93/750 [==>...........................] - ETA: 10s - loss: 0.2585 - accuracy: 0.9088\n",
      "109/750 [===>..........................] - ETA: 9s - loss: 0.2616 - accuracy: 0.9074 \n",
      "116/750 [===>..........................] - ETA: 9s - loss: 0.2645 - accuracy: 0.9064\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.4438 - accuracy: 0.8503\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "122/750 [===>..........................] - ETA: 9s - loss: 0.2630 - accuracy: 0.9066\n",
      "124/750 [===>..........................] - ETA: 9s - loss: 0.2628 - accuracy: 0.9066\n",
      "133/750 [====>.........................] - ETA: 9s - loss: 0.2636 - accuracy: 0.9071\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.8449 - accuracy: 0.7299\n",
      "136/750 [====>.........................] - ETA: 9s - loss: 0.2631 - accuracy: 0.9074\n",
      "143/750 [====>.........................] - ETA: 9s - loss: 0.2645 - accuracy: 0.9065\n",
      "159/750 [=====>........................] - ETA: 9s - loss: 0.2617 - accuracy: 0.9067\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.4443 - accuracy: 0.8498\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "161/750 [=====>........................] - ETA: 9s - loss: 0.2628 - accuracy: 0.9065\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.8441 - accuracy: 0.7304\n",
      "165/750 [=====>........................] - ETA: 9s - loss: 0.2618 - accuracy: 0.9067\n",
      "497/750 [==================>...........] - ETA: 3s - loss: 0.4456 - accuracy: 0.8500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "734/750 [============================>.] - ETA: 0s - loss: 0.4440 - accuracy: 0.8499\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "175/750 [======>.......................] - ETA: 9s - loss: 0.2593 - accuracy: 0.9080\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.4436 - accuracy: 0.8499\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "185/750 [======>.......................] - ETA: 8s - loss: 0.2584 - accuracy: 0.9084\n",
      "192/750 [======>.......................] - ETA: 8s - loss: 0.2583 - accuracy: 0.9091\n",
      "202/750 [=======>......................] - ETA: 8s - loss: 0.2572 - accuracy: 0.9093\n",
      "531/750 [====================>.........] - ETA: 3s - loss: 0.4457 - accuracy: 0.8499\n",
      "210/750 [=======>......................] - ETA: 8s - loss: 0.2563 - accuracy: 0.9093\n",
      "219/750 [=======>......................] - ETA: 8s - loss: 0.2554 - accuracy: 0.9096\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.4441 - accuracy: 0.8497\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 10/750 [..............................] - ETA: 5s - loss: 0.8142 - accuracy: 0.7500\n",
      "229/750 [========>.....................] - ETA: 7s - loss: 0.2576 - accuracy: 0.9091\n",
      " 14/750 [..............................] - ETA: 8s - loss: 0.8201 - accuracy: 0.7600\n",
      "242/750 [========>.....................] - ETA: 7s - loss: 0.2589 - accuracy: 0.9084\n",
      " 26/750 [>.............................] - ETA: 7s - loss: 0.8194 - accuracy: 0.7584\n",
      "247/750 [========>.....................] - ETA: 7s - loss: 0.2596 - accuracy: 0.9081\n",
      "259/750 [=========>....................] - ETA: 7s - loss: 0.2582 - accuracy: 0.9088\n",
      "588/750 [======================>.......] - ETA: 2s - loss: 0.4461 - accuracy: 0.8498\n",
      " 39/750 [>.............................] - ETA: 9s - loss: 0.8210 - accuracy: 0.7524 \n",
      "262/750 [=========>....................] - ETA: 7s - loss: 0.2585 - accuracy: 0.9089\n",
      " 52/750 [=>............................] - ETA: 8s - loss: 0.8276 - accuracy: 0.7470\n",
      "274/750 [=========>....................] - ETA: 6s - loss: 0.2562 - accuracy: 0.9100\n",
      " 62/750 [=>............................] - ETA: 8s - loss: 0.8308 - accuracy: 0.7450\n",
      "287/750 [==========>...................] - ETA: 6s - loss: 0.2567 - accuracy: 0.9098\n",
      " 71/750 [=>............................] - ETA: 8s - loss: 0.8298 - accuracy: 0.7449\n",
      "297/750 [==========>...................] - ETA: 6s - loss: 0.2565 - accuracy: 0.9098\n",
      " 80/750 [==>...........................] - ETA: 8s - loss: 0.8374 - accuracy: 0.7412\n",
      "306/750 [===========>..................] - ETA: 6s - loss: 0.2567 - accuracy: 0.9098\n",
      " 24/750 [..............................] - ETA: 8s - loss: 0.4430 - accuracy: 0.8418 \n",
      "309/750 [===========>..................] - ETA: 6s - loss: 0.2569 - accuracy: 0.9095\n",
      " 30/750 [>.............................] - ETA: 10s - loss: 0.4440 - accuracy: 0.8432\n",
      " 93/750 [==>...........................] - ETA: 8s - loss: 0.8375 - accuracy: 0.7414\n",
      "329/750 [============>.................] - ETA: 5s - loss: 0.2560 - accuracy: 0.9101\n",
      " 44/750 [>.............................] - ETA: 8s - loss: 0.4405 - accuracy: 0.8441\n",
      "335/750 [============>.................] - ETA: 5s - loss: 0.2554 - accuracy: 0.9105\n",
      "667/750 [=========================>....] - ETA: 1s - loss: 0.4440 - accuracy: 0.8505\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "344/750 [============>.................] - ETA: 5s - loss: 0.2550 - accuracy: 0.9105\n",
      "127/750 [====>.........................] - ETA: 7s - loss: 0.8384 - accuracy: 0.7403\n",
      "355/750 [=============>................] - ETA: 5s - loss: 0.2557 - accuracy: 0.9102\n",
      "360/750 [=============>................] - ETA: 5s - loss: 0.2553 - accuracy: 0.9103\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.4442 - accuracy: 0.8503\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 12s 17ms/step - loss: 0.4436 - accuracy: 0.8500 - val_loss: 0.4505 - val_accuracy: 0.8449\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 26/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 9s - loss: 0.5313 - accuracy: 0.8125\n",
      "150/750 [=====>........................] - ETA: 7s - loss: 0.8376 - accuracy: 0.7390\n",
      "367/750 [=============>................] - ETA: 5s - loss: 0.2558 - accuracy: 0.9103\n",
      " 15/750 [..............................] - ETA: 11s - loss: 0.4456 - accuracy: 0.8427\n",
      "383/750 [==============>...............] - ETA: 5s - loss: 0.2560 - accuracy: 0.9100\n",
      "167/750 [=====>........................] - ETA: 7s - loss: 0.8347 - accuracy: 0.7382\n",
      "397/750 [==============>...............] - ETA: 4s - loss: 0.2555 - accuracy: 0.9103\n",
      "399/750 [==============>...............] - ETA: 4s - loss: 0.2552 - accuracy: 0.9106\n",
      "407/750 [===============>..............] - ETA: 4s - loss: 0.2559 - accuracy: 0.9103\n",
      "422/750 [===============>..............] - ETA: 4s - loss: 0.2566 - accuracy: 0.9098\n",
      "202/750 [=======>......................] - ETA: 6s - loss: 0.8359 - accuracy: 0.7362\n",
      "438/750 [================>.............] - ETA: 4s - loss: 0.2557 - accuracy: 0.9100\n",
      " 71/750 [=>............................] - ETA: 8s - loss: 0.4531 - accuracy: 0.8396\n",
      "444/750 [================>.............] - ETA: 4s - loss: 0.2562 - accuracy: 0.9095\n",
      "457/750 [=================>............] - ETA: 3s - loss: 0.2552 - accuracy: 0.9098\n",
      "468/750 [=================>............] - ETA: 3s - loss: 0.2550 - accuracy: 0.9099\n",
      "180/750 [======>.......................] - ETA: 6s - loss: 0.4489 - accuracy: 0.8479\n",
      " 99/750 [==>...........................] - ETA: 8s - loss: 0.4503 - accuracy: 0.8434\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "479/750 [==================>...........] - ETA: 3s - loss: 0.2545 - accuracy: 0.9101\n",
      "184/750 [======>.......................] - ETA: 6s - loss: 0.4470 - accuracy: 0.8488\n",
      "192/750 [======>.......................] - ETA: 6s - loss: 0.4464 - accuracy: 0.8490\n",
      "503/750 [===================>..........] - ETA: 3s - loss: 0.2550 - accuracy: 0.9101\n",
      "510/750 [===================>..........] - ETA: 3s - loss: 0.2552 - accuracy: 0.9101\n",
      "518/750 [===================>..........] - ETA: 3s - loss: 0.2556 - accuracy: 0.9099\n",
      "123/750 [===>..........................] - ETA: 7s - loss: 0.4496 - accuracy: 0.8458\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "527/750 [====================>.........] - ETA: 2s - loss: 0.2553 - accuracy: 0.9098\n",
      "114/750 [===>..........................] - ETA: 8s - loss: 0.4533 - accuracy: 0.8438\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "537/750 [====================>.........] - ETA: 2s - loss: 0.2553 - accuracy: 0.9098\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.2552 - accuracy: 0.9098\n",
      "136/750 [====>.........................] - ETA: 7s - loss: 0.4483 - accuracy: 0.8466\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "327/750 [============>.................] - ETA: 4s - loss: 0.8343 - accuracy: 0.7348\n",
      "562/750 [=====================>........] - ETA: 2s - loss: 0.2554 - accuracy: 0.9098\n",
      "140/750 [====>.........................] - ETA: 7s - loss: 0.4483 - accuracy: 0.8460\n",
      "572/750 [=====================>........] - ETA: 2s - loss: 0.2554 - accuracy: 0.9097\n",
      "584/750 [======================>.......] - ETA: 2s - loss: 0.2566 - accuracy: 0.9093\n",
      "291/750 [==========>...................] - ETA: 5s - loss: 0.4418 - accuracy: 0.8487\n",
      "299/750 [==========>...................] - ETA: 5s - loss: 0.4423 - accuracy: 0.8482\n",
      "166/750 [=====>........................] - ETA: 7s - loss: 0.4514 - accuracy: 0.8458\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "366/750 [=============>................] - ETA: 4s - loss: 0.8343 - accuracy: 0.7341\n",
      "594/750 [======================>.......] - ETA: 1s - loss: 0.2563 - accuracy: 0.9094\n",
      "173/750 [=====>........................] - ETA: 6s - loss: 0.4491 - accuracy: 0.8471\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.2563 - accuracy: 0.9093\n",
      "490/750 [==================>...........] - ETA: 3s - loss: 0.2545 - accuracy: 0.9101\n",
      "616/750 [=======================>......] - ETA: 1s - loss: 0.2554 - accuracy: 0.9095\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.2554 - accuracy: 0.9094\n",
      "194/750 [======>.......................] - ETA: 6s - loss: 0.8340 - accuracy: 0.7375\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "645/750 [========================>.....] - ETA: 1s - loss: 0.2555 - accuracy: 0.9096\n",
      "653/750 [=========================>....] - ETA: 1s - loss: 0.2550 - accuracy: 0.9097\n",
      "670/750 [=========================>....] - ETA: 0s - loss: 0.2552 - accuracy: 0.9097\n",
      "214/750 [=======>......................] - ETA: 6s - loss: 0.4435 - accuracy: 0.8496\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.2554 - accuracy: 0.9098\n",
      "225/750 [========>.....................] - ETA: 6s - loss: 0.4448 - accuracy: 0.8485\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "451/750 [=================>............] - ETA: 3s - loss: 0.8321 - accuracy: 0.7359\n",
      "687/750 [==========================>...] - ETA: 0s - loss: 0.2556 - accuracy: 0.9097\n",
      "402/750 [===============>..............] - ETA: 3s - loss: 0.4372 - accuracy: 0.8509\n",
      "  8/750 [..............................] - ETA: 6s - loss: 0.4580 - accuracy: 0.8418\n",
      "245/750 [========>.....................] - ETA: 5s - loss: 0.4416 - accuracy: 0.8488\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.2558 - accuracy: 0.9096\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2560 - accuracy: 0.9096\n",
      "425/750 [================>.............] - ETA: 3s - loss: 0.4399 - accuracy: 0.8507\n",
      "270/750 [=========>....................] - ETA: 5s - loss: 0.4406 - accuracy: 0.8487\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "486/750 [==================>...........] - ETA: 2s - loss: 0.8309 - accuracy: 0.7360\n",
      "710/750 [===========================>..] - ETA: 0s - loss: 0.2559 - accuracy: 0.9095\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2563 - accuracy: 0.9094\n",
      "274/750 [=========>....................] - ETA: 5s - loss: 0.4405 - accuracy: 0.8484\n",
      "487/750 [==================>...........] - ETA: 2s - loss: 0.8310 - accuracy: 0.7359\n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.2566 - accuracy: 0.9093\n",
      "499/750 [==================>...........] - ETA: 2s - loss: 0.8312 - accuracy: 0.7358\n",
      "733/750 [============================>.] - ETA: 0s - loss: 0.2561 - accuracy: 0.9096\n",
      " 65/750 [=>............................] - ETA: 8s - loss: 0.4537 - accuracy: 0.8399\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "287/750 [==========>...................] - ETA: 5s - loss: 0.4419 - accuracy: 0.8488\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.2562 - accuracy: 0.9095\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.2565 - accuracy: 0.9094\n",
      " 78/750 [==>...........................] - ETA: 8s - loss: 0.4535 - accuracy: 0.8413\n",
      "323/750 [===========>..................] - ETA: 4s - loss: 0.4417 - accuracy: 0.8479\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 82/750 [==>...........................] - ETA: 8s - loss: 0.4533 - accuracy: 0.8422\n",
      "556/750 [=====================>........] - ETA: 2s - loss: 0.8329 - accuracy: 0.7353\n",
      "342/750 [============>.................] - ETA: 4s - loss: 0.4407 - accuracy: 0.8485\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "561/750 [=====================>........] - ETA: 2s - loss: 0.8332 - accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:05:07,586 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6034558976; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/750 [=========================>....] - ETA: 1s - loss: 0.2551 - accuracy: 0.9097\n",
      "366/750 [=============>................] - ETA: 4s - loss: 0.4385 - accuracy: 0.8496\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "580/750 [======================>.......] - ETA: 1s - loss: 0.8337 - accuracy: 0.7347\n",
      "373/750 [=============>................] - ETA: 4s - loss: 0.8337 - accuracy: 0.7349\n",
      "539/750 [====================>.........] - ETA: 2s - loss: 0.4426 - accuracy: 0.8497\n",
      "541/750 [====================>.........] - ETA: 2s - loss: 0.4428 - accuracy: 0.8495\n",
      "379/750 [==============>...............] - ETA: 4s - loss: 0.4377 - accuracy: 0.8503\n",
      "543/750 [====================>.........] - ETA: 2s - loss: 0.4433 - accuracy: 0.8494\n",
      "547/750 [====================>.........] - ETA: 2s - loss: 0.4430 - accuracy: 0.8495\n",
      "391/750 [==============>...............] - ETA: 3s - loss: 0.4369 - accuracy: 0.8503\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "409/750 [===============>..............] - ETA: 3s - loss: 0.4386 - accuracy: 0.8507\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "636/750 [========================>.....] - ETA: 1s - loss: 0.8353 - accuracy: 0.7330\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.8354 - accuracy: 0.7330\n",
      "444/750 [================>.............] - ETA: 3s - loss: 0.4412 - accuracy: 0.8500\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "659/750 [=========================>....] - ETA: 1s - loss: 0.8353 - accuracy: 0.7333\n",
      "576/750 [======================>.......] - ETA: 2s - loss: 0.4424 - accuracy: 0.8496\n",
      "666/750 [=========================>....] - ETA: 0s - loss: 0.8354 - accuracy: 0.7333\n",
      "474/750 [=================>............] - ETA: 3s - loss: 0.4426 - accuracy: 0.8495\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 0.4430 - accuracy: 0.8495\n",
      "694/750 [==========================>...] - ETA: 0s - loss: 0.8352 - accuracy: 0.7334\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.2568 - accuracy: 0.9094 - val_loss: 0.3223 - val_accuracy: 0.8852\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 27/30\n",
      "  1/750 [..............................] - ETA: 4s - loss: 0.2001 - accuracy: 0.9375\n",
      "615/750 [=======================>......] - ETA: 1s - loss: 0.4430 - accuracy: 0.8496\n",
      " 14/750 [..............................] - ETA: 2s - loss: 0.2456 - accuracy: 0.9085\n",
      "624/750 [=======================>......] - ETA: 1s - loss: 0.4420 - accuracy: 0.8501\n",
      " 23/750 [..............................] - ETA: 6s - loss: 0.2533 - accuracy: 0.9096\n",
      "520/750 [===================>..........] - ETA: 2s - loss: 0.4437 - accuracy: 0.8490\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      " 25/750 [>.............................] - ETA: 9s - loss: 0.2592 - accuracy: 0.9081\n",
      " 39/750 [>.............................] - ETA: 8s - loss: 0.2617 - accuracy: 0.9058\n",
      "531/750 [====================>.........] - ETA: 2s - loss: 0.8320 - accuracy: 0.7356\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.8355 - accuracy: 0.7337\n",
      "537/750 [====================>.........] - ETA: 2s - loss: 0.4427 - accuracy: 0.8496\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 61/750 [=>............................] - ETA: 7s - loss: 0.2573 - accuracy: 0.9083\n",
      "570/750 [=====================>........] - ETA: 2s - loss: 0.4429 - accuracy: 0.8493\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 78/750 [==>...........................] - ETA: 7s - loss: 0.2488 - accuracy: 0.9135\n",
      " 89/750 [==>...........................] - ETA: 7s - loss: 0.2478 - accuracy: 0.9134\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.4425 - accuracy: 0.8496\n",
      "597/750 [======================>.......] - ETA: 1s - loss: 0.4432 - accuracy: 0.8492\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "101/750 [===>..........................] - ETA: 7s - loss: 0.2531 - accuracy: 0.9120\n",
      "109/750 [===>..........................] - ETA: 7s - loss: 0.2514 - accuracy: 0.9118\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.4416 - accuracy: 0.8502\n",
      "602/750 [=======================>......] - ETA: 1s - loss: 0.8338 - accuracy: 0.7341\n",
      "116/750 [===>..........................] - ETA: 7s - loss: 0.2525 - accuracy: 0.9106\n",
      "121/750 [===>..........................] - ETA: 7s - loss: 0.2526 - accuracy: 0.9109\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.4431 - accuracy: 0.8496\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "125/750 [====>.........................] - ETA: 7s - loss: 0.2522 - accuracy: 0.9115\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.8342 - accuracy: 0.7337\n",
      "136/750 [====>.........................] - ETA: 7s - loss: 0.2538 - accuracy: 0.9112\n",
      "648/750 [========================>.....] - ETA: 1s - loss: 0.4426 - accuracy: 0.8498\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "144/750 [====>.........................] - ETA: 7s - loss: 0.2546 - accuracy: 0.9110\n",
      "149/750 [====>.........................] - ETA: 7s - loss: 0.2539 - accuracy: 0.9119\n",
      "156/750 [=====>........................] - ETA: 7s - loss: 0.2525 - accuracy: 0.9127\n",
      "171/750 [=====>........................] - ETA: 6s - loss: 0.2564 - accuracy: 0.9115\n",
      "655/750 [=========================>....] - ETA: 1s - loss: 0.4424 - accuracy: 0.8500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "179/750 [======>.......................] - ETA: 6s - loss: 0.2574 - accuracy: 0.9108\n",
      "192/750 [======>.......................] - ETA: 6s - loss: 0.2555 - accuracy: 0.9117\n",
      "450/750 [=================>............] - ETA: 3s - loss: 0.4419 - accuracy: 0.8497\n",
      "682/750 [==========================>...] - ETA: 0s - loss: 0.4427 - accuracy: 0.8496\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "206/750 [=======>......................] - ETA: 6s - loss: 0.2554 - accuracy: 0.9116\n",
      "208/750 [=======>......................] - ETA: 6s - loss: 0.2556 - accuracy: 0.9116\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.4426 - accuracy: 0.8498\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "223/750 [=======>......................] - ETA: 6s - loss: 0.2541 - accuracy: 0.9126\n",
      "497/750 [==================>...........] - ETA: 2s - loss: 0.4435 - accuracy: 0.8493\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "718/750 [===========================>..] - ETA: 0s - loss: 0.8353 - accuracy: 0.7335\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "232/750 [========>.....................] - ETA: 6s - loss: 0.2553 - accuracy: 0.9119\n",
      "739/750 [============================>.] - ETA: 0s - loss: 0.4415 - accuracy: 0.8502\n",
      "234/750 [========>.....................] - ETA: 6s - loss: 0.2550 - accuracy: 0.9121\n",
      "244/750 [========>.....................] - ETA: 5s - loss: 0.2544 - accuracy: 0.9118\n",
      " 70/750 [=>............................] - ETA: 7s - loss: 0.2527 - accuracy: 0.9116\n",
      "248/750 [========>.....................] - ETA: 5s - loss: 0.2548 - accuracy: 0.9117\n",
      " 17/750 [..............................] - ETA: 14s - loss: 0.8106 - accuracy: 0.7482\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.4410 - accuracy: 0.8504\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "253/750 [=========>....................] - ETA: 5s - loss: 0.2549 - accuracy: 0.9114\n",
      " 21/750 [..............................] - ETA: 14s - loss: 0.8199 - accuracy: 0.7433\n",
      " 27/750 [>.............................] - ETA: 15s - loss: 0.8252 - accuracy: 0.7454\n",
      "255/750 [=========>....................] - ETA: 6s - loss: 0.2546 - accuracy: 0.9113\n",
      " 29/750 [>.............................] - ETA: 17s - loss: 0.8297 - accuracy: 0.7441\n",
      "574/750 [=====================>........] - ETA: 2s - loss: 0.4424 - accuracy: 0.8495\n",
      "262/750 [=========>....................] - ETA: 6s - loss: 0.2539 - accuracy: 0.9118\n",
      "264/750 [=========>....................] - ETA: 6s - loss: 0.2539 - accuracy: 0.9118\n",
      " 32/750 [>.............................] - ETA: 19s - loss: 0.8312 - accuracy: 0.7446\n",
      "266/750 [=========>....................] - ETA: 6s - loss: 0.2535 - accuracy: 0.9118\n",
      " 41/750 [>.............................] - ETA: 16s - loss: 0.8303 - accuracy: 0.7424\n",
      "273/750 [=========>....................] - ETA: 6s - loss: 0.2532 - accuracy: 0.9121\n",
      " 47/750 [>.............................] - ETA: 16s - loss: 0.8318 - accuracy: 0.7404\n",
      "286/750 [==========>...................] - ETA: 6s - loss: 0.2539 - accuracy: 0.9117\n",
      " 60/750 [=>............................] - ETA: 13s - loss: 0.8331 - accuracy: 0.7380\n",
      "292/750 [==========>...................] - ETA: 6s - loss: 0.2530 - accuracy: 0.9120\n",
      " 66/750 [=>............................] - ETA: 13s - loss: 0.8351 - accuracy: 0.7377\n",
      "304/750 [===========>..................] - ETA: 5s - loss: 0.2523 - accuracy: 0.9123\n",
      " 77/750 [==>...........................] - ETA: 12s - loss: 0.8340 - accuracy: 0.7356\n",
      "313/750 [===========>..................] - ETA: 5s - loss: 0.2521 - accuracy: 0.9124\n",
      " 80/750 [==>...........................] - ETA: 12s - loss: 0.8328 - accuracy: 0.7365\n",
      "316/750 [===========>..................] - ETA: 5s - loss: 0.2520 - accuracy: 0.9125\n",
      " 10/750 [..............................] - ETA: 8s - loss: 0.4548 - accuracy: 0.8422\n",
      "632/750 [========================>.....] - ETA: 1s - loss: 0.4419 - accuracy: 0.8501\n",
      " 93/750 [==>...........................] - ETA: 11s - loss: 0.8330 - accuracy: 0.7354\n",
      "324/750 [===========>..................] - ETA: 5s - loss: 0.2518 - accuracy: 0.9124\n",
      " 98/750 [==>...........................] - ETA: 11s - loss: 0.8320 - accuracy: 0.7358\n",
      "334/750 [============>.................] - ETA: 5s - loss: 0.2517 - accuracy: 0.9127\n",
      "670/750 [=========================>....] - ETA: 0s - loss: 0.4428 - accuracy: 0.8496\n",
      "105/750 [===>..........................] - ETA: 11s - loss: 0.8309 - accuracy: 0.7378\n",
      "344/750 [============>.................] - ETA: 5s - loss: 0.2519 - accuracy: 0.9127\n",
      "117/750 [===>..........................] - ETA: 10s - loss: 0.8290 - accuracy: 0.7370\n",
      "352/750 [=============>................] - ETA: 5s - loss: 0.2518 - accuracy: 0.9126\n",
      " 44/750 [>.............................] - ETA: 8s - loss: 0.4501 - accuracy: 0.8466\n",
      "122/750 [===>..........................] - ETA: 10s - loss: 0.8307 - accuracy: 0.7350\n",
      "361/750 [=============>................] - ETA: 5s - loss: 0.2522 - accuracy: 0.9123\n",
      " 54/750 [=>............................] - ETA: 8s - loss: 0.4554 - accuracy: 0.8469\n",
      "135/750 [====>.........................] - ETA: 10s - loss: 0.8282 - accuracy: 0.7360\n",
      "370/750 [=============>................] - ETA: 4s - loss: 0.2508 - accuracy: 0.9128\n",
      " 66/750 [=>............................] - ETA: 7s - loss: 0.4549 - accuracy: 0.8459\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.4423 - accuracy: 0.8496\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "147/750 [====>.........................] - ETA: 9s - loss: 0.8296 - accuracy: 0.7364\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.4409 - accuracy: 0.8504 - val_loss: 0.4481 - val_accuracy: 0.8453\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 27/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  1/750 [..............................] - ETA: 40s - loss: 0.3494 - accuracy: 0.8906\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "381/750 [==============>...............] - ETA: 4s - loss: 0.2510 - accuracy: 0.9124\n",
      " 72/750 [=>............................] - ETA: 8s - loss: 0.4475 - accuracy: 0.8511\n",
      " 16/750 [..............................] - ETA: 9s - loss: 0.4482 - accuracy: 0.8477\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "151/750 [=====>........................] - ETA: 9s - loss: 0.8301 - accuracy: 0.7353\n",
      "387/750 [==============>...............] - ETA: 4s - loss: 0.2511 - accuracy: 0.9122\n",
      "153/750 [=====>........................] - ETA: 9s - loss: 0.8309 - accuracy: 0.7354\n",
      "391/750 [==============>...............] - ETA: 4s - loss: 0.2513 - accuracy: 0.9121\n",
      " 75/750 [==>...........................] - ETA: 8s - loss: 0.4474 - accuracy: 0.8512\n",
      "155/750 [=====>........................] - ETA: 9s - loss: 0.8304 - accuracy: 0.7351\n",
      "393/750 [==============>...............] - ETA: 4s - loss: 0.2512 - accuracy: 0.9123\n",
      " 30/750 [>.............................] - ETA: 7s - loss: 0.4599 - accuracy: 0.8432\n",
      "400/750 [===============>..............] - ETA: 4s - loss: 0.2510 - accuracy: 0.9123\n",
      "412/750 [===============>..............] - ETA: 4s - loss: 0.2520 - accuracy: 0.9119\n",
      " 39/750 [>.............................] - ETA: 8s - loss: 0.4536 - accuracy: 0.8458\n",
      "426/750 [================>.............] - ETA: 4s - loss: 0.2524 - accuracy: 0.9117\n",
      "435/750 [================>.............] - ETA: 4s - loss: 0.2525 - accuracy: 0.9115\n",
      "452/750 [=================>............] - ETA: 3s - loss: 0.2521 - accuracy: 0.9116\n",
      "454/750 [=================>............] - ETA: 3s - loss: 0.2517 - accuracy: 0.9118\n",
      " 95/750 [==>...........................] - ETA: 8s - loss: 0.4382 - accuracy: 0.8525\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "460/750 [=================>............] - ETA: 3s - loss: 0.2520 - accuracy: 0.9116\n",
      "465/750 [=================>............] - ETA: 3s - loss: 0.2524 - accuracy: 0.9114\n",
      "152/750 [=====>........................] - ETA: 7s - loss: 0.4358 - accuracy: 0.8526\n",
      "477/750 [==================>...........] - ETA: 3s - loss: 0.2526 - accuracy: 0.9115\n",
      "108/750 [===>..........................] - ETA: 7s - loss: 0.4364 - accuracy: 0.8520\n",
      "486/750 [==================>...........] - ETA: 3s - loss: 0.2526 - accuracy: 0.9114\n",
      "119/750 [===>..........................] - ETA: 8s - loss: 0.4341 - accuracy: 0.8522\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "251/750 [=========>....................] - ETA: 7s - loss: 0.8296 - accuracy: 0.7354\n",
      "140/750 [====>.........................] - ETA: 7s - loss: 0.4338 - accuracy: 0.8532\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "506/750 [===================>..........] - ETA: 3s - loss: 0.2527 - accuracy: 0.9114\n",
      "275/750 [==========>...................] - ETA: 6s - loss: 0.8277 - accuracy: 0.7368\n",
      "513/750 [===================>..........] - ETA: 3s - loss: 0.2520 - accuracy: 0.9116\n",
      "522/750 [===================>..........] - ETA: 2s - loss: 0.2525 - accuracy: 0.9113\n",
      "532/750 [====================>.........] - ETA: 2s - loss: 0.2527 - accuracy: 0.9110\n",
      "539/750 [====================>.........] - ETA: 2s - loss: 0.2527 - accuracy: 0.9111\n",
      "170/750 [=====>........................] - ETA: 6s - loss: 0.4359 - accuracy: 0.8519\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "545/750 [====================>.........] - ETA: 2s - loss: 0.2522 - accuracy: 0.9114\n",
      "553/750 [=====================>........] - ETA: 2s - loss: 0.2523 - accuracy: 0.9114\n",
      "177/750 [======>.......................] - ETA: 9s - loss: 0.8309 - accuracy: 0.7355\n",
      "331/750 [============>.................] - ETA: 5s - loss: 0.8274 - accuracy: 0.7378\n",
      "568/750 [=====================>........] - ETA: 2s - loss: 0.2519 - accuracy: 0.9117\n",
      "192/750 [======>.......................] - ETA: 6s - loss: 0.4357 - accuracy: 0.8521\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "581/750 [======================>.......] - ETA: 2s - loss: 0.2517 - accuracy: 0.9118\n",
      "204/750 [=======>......................] - ETA: 6s - loss: 0.4353 - accuracy: 0.8516\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "353/750 [=============>................] - ETA: 5s - loss: 0.8277 - accuracy: 0.7383\n",
      "591/750 [======================>.......] - ETA: 1s - loss: 0.2525 - accuracy: 0.9116\n",
      "278/750 [==========>...................] - ETA: 5s - loss: 0.4319 - accuracy: 0.8526\n",
      "218/750 [=======>......................] - ETA: 8s - loss: 0.8282 - accuracy: 0.7360\n",
      "611/750 [=======================>......] - ETA: 1s - loss: 0.2533 - accuracy: 0.9113\n",
      "280/750 [==========>...................] - ETA: 5s - loss: 0.4327 - accuracy: 0.8523\n",
      "223/750 [=======>......................] - ETA: 6s - loss: 0.4359 - accuracy: 0.8519\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "493/750 [==================>...........] - ETA: 3s - loss: 0.2523 - accuracy: 0.9115\n",
      "613/750 [=======================>......] - ETA: 1s - loss: 0.2531 - accuracy: 0.9113\n",
      "248/750 [========>.....................] - ETA: 6s - loss: 0.4328 - accuracy: 0.8534\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "619/750 [=======================>......] - ETA: 1s - loss: 0.2533 - accuracy: 0.9112\n",
      "633/750 [========================>.....] - ETA: 1s - loss: 0.2537 - accuracy: 0.9109\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.2536 - accuracy: 0.9110\n",
      "643/750 [========================>.....] - ETA: 1s - loss: 0.2537 - accuracy: 0.9109\n",
      "648/750 [========================>.....] - ETA: 1s - loss: 0.2536 - accuracy: 0.9110\n",
      "326/750 [============>.................] - ETA: 5s - loss: 0.4359 - accuracy: 0.8507\n",
      "268/750 [=========>....................] - ETA: 5s - loss: 0.4315 - accuracy: 0.8530\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "663/750 [=========================>....] - ETA: 1s - loss: 0.2537 - accuracy: 0.9111\n",
      "423/750 [===============>..............] - ETA: 4s - loss: 0.8291 - accuracy: 0.7364\n",
      "670/750 [=========================>....] - ETA: 0s - loss: 0.2535 - accuracy: 0.9111\n",
      "347/750 [============>.................] - ETA: 4s - loss: 0.4361 - accuracy: 0.8506\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.2533 - accuracy: 0.9109\n",
      "439/750 [================>.............] - ETA: 4s - loss: 0.8302 - accuracy: 0.7358\n",
      "448/750 [================>.............] - ETA: 3s - loss: 0.8295 - accuracy: 0.7362\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.2537 - accuracy: 0.9108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:05:17,640 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6033862656; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377/750 [==============>...............] - ETA: 4s - loss: 0.4380 - accuracy: 0.8497\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.2533 - accuracy: 0.9110\n",
      "711/750 [===========================>..] - ETA: 0s - loss: 0.2534 - accuracy: 0.9109\n",
      "294/750 [==========>...................] - ETA: 5s - loss: 0.4327 - accuracy: 0.8520\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.2533 - accuracy: 0.9109\n",
      "488/750 [==================>...........] - ETA: 3s - loss: 0.8286 - accuracy: 0.7358\n",
      "735/750 [============================>.] - ETA: 0s - loss: 0.2533 - accuracy: 0.9108\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2531 - accuracy: 0.9108\n",
      "321/750 [===========>..................] - ETA: 5s - loss: 0.4361 - accuracy: 0.8508\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "500/750 [===================>..........] - ETA: 3s - loss: 0.8286 - accuracy: 0.7358\n",
      "300/750 [===========>..................] - ETA: 5s - loss: 0.4340 - accuracy: 0.8515\n",
      "337/750 [============>.................] - ETA: 4s - loss: 0.4361 - accuracy: 0.8506\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "526/750 [====================>.........] - ETA: 2s - loss: 0.8279 - accuracy: 0.7363\n",
      "365/750 [=============>................] - ETA: 4s - loss: 0.4358 - accuracy: 0.8509\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "357/750 [=============>................] - ETA: 4s - loss: 0.4365 - accuracy: 0.8504\n",
      "388/750 [==============>...............] - ETA: 4s - loss: 0.4372 - accuracy: 0.8503\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "569/750 [=====================>........] - ETA: 2s - loss: 0.8290 - accuracy: 0.7354\n",
      "172/750 [=====>........................] - ETA: 7s - loss: 0.4356 - accuracy: 0.8516\n",
      "398/750 [==============>...............] - ETA: 4s - loss: 0.8284 - accuracy: 0.7368\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "577/750 [======================>.......] - ETA: 2s - loss: 0.8293 - accuracy: 0.7356\n",
      "404/750 [===============>..............] - ETA: 3s - loss: 0.4375 - accuracy: 0.8502\n",
      "412/750 [===============>..............] - ETA: 3s - loss: 0.4370 - accuracy: 0.8505\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "442/750 [================>.............] - ETA: 3s - loss: 0.4380 - accuracy: 0.8506\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.8287 - accuracy: 0.7359\n",
      "470/750 [=================>............] - ETA: 3s - loss: 0.4383 - accuracy: 0.8509\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "650/750 [=========================>....] - ETA: 1s - loss: 0.8288 - accuracy: 0.7357\n",
      "577/750 [======================>.......] - ETA: 2s - loss: 0.4387 - accuracy: 0.8505\n",
      "481/750 [==================>...........] - ETA: 3s - loss: 0.8285 - accuracy: 0.7362\n",
      "498/750 [==================>...........] - ETA: 3s - loss: 0.4391 - accuracy: 0.8506\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "675/750 [==========================>...] - ETA: 0s - loss: 0.8277 - accuracy: 0.7364\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.2530 - accuracy: 0.9108 - val_loss: 0.3190 - val_accuracy: 0.8851\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 28/30\n",
      "600/750 [=======================>......] - ETA: 1s - loss: 0.4394 - accuracy: 0.8502\n",
      "509/750 [===================>..........] - ETA: 2s - loss: 0.4391 - accuracy: 0.8504\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  3/750 [..............................] - ETA: 18s - loss: 0.2044 - accuracy: 0.9375\n",
      " 16/750 [..............................] - ETA: 7s - loss: 0.2297 - accuracy: 0.9229\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.8275 - accuracy: 0.7362\n",
      " 23/750 [..............................] - ETA: 10s - loss: 0.2512 - accuracy: 0.9171\n",
      "632/750 [========================>.....] - ETA: 1s - loss: 0.4386 - accuracy: 0.8503\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.4393 - accuracy: 0.8505\n",
      "528/750 [====================>.........] - ETA: 2s - loss: 0.4388 - accuracy: 0.8508\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "715/750 [===========================>..] - ETA: 0s - loss: 0.8275 - accuracy: 0.7361\n",
      " 28/750 [>.............................] - ETA: 9s - loss: 0.2499 - accuracy: 0.9174 \n",
      "724/750 [===========================>..] - ETA: 0s - loss: 0.8278 - accuracy: 0.7356\n",
      " 33/750 [>.............................] - ETA: 12s - loss: 0.2587 - accuracy: 0.9124\n",
      "552/750 [=====================>........] - ETA: 2s - loss: 0.8296 - accuracy: 0.7352\n",
      " 40/750 [>.............................] - ETA: 11s - loss: 0.2628 - accuracy: 0.9102\n",
      "726/750 [============================>.] - ETA: 0s - loss: 0.8279 - accuracy: 0.7357\n",
      "573/750 [=====================>........] - ETA: 2s - loss: 0.4385 - accuracy: 0.8506\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "592/750 [======================>.......] - ETA: 1s - loss: 0.4391 - accuracy: 0.8502\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 43/750 [>.............................] - ETA: 14s - loss: 0.2589 - accuracy: 0.9110\n",
      " 49/750 [>.............................] - ETA: 14s - loss: 0.2547 - accuracy: 0.9129\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.4393 - accuracy: 0.8502\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 58/750 [=>............................] - ETA: 14s - loss: 0.2566 - accuracy: 0.9122\n",
      "606/750 [=======================>......] - ETA: 1s - loss: 0.4394 - accuracy: 0.8500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - ETA: 0s - loss: 0.8273 - accuracy: 0.7360\n",
      " 59/750 [=>............................] - ETA: 14s - loss: 0.2557 - accuracy: 0.9123\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.8288 - accuracy: 0.7356\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 65/750 [=>............................] - ETA: 14s - loss: 0.2536 - accuracy: 0.9132\n",
      "648/750 [========================>.....] - ETA: 1s - loss: 0.4384 - accuracy: 0.8504\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 73/750 [=>............................] - ETA: 13s - loss: 0.2529 - accuracy: 0.9135\n",
      " 78/750 [==>...........................] - ETA: 14s - loss: 0.2503 - accuracy: 0.9147\n",
      "665/750 [=========================>....] - ETA: 1s - loss: 0.4394 - accuracy: 0.8498\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 82/750 [==>...........................] - ETA: 14s - loss: 0.2491 - accuracy: 0.9156\n",
      "420/750 [===============>..............] - ETA: 3s - loss: 0.4374 - accuracy: 0.8506\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 89/750 [==>...........................] - ETA: 14s - loss: 0.2465 - accuracy: 0.9163\n",
      "693/750 [==========================>...] - ETA: 0s - loss: 0.4394 - accuracy: 0.8495\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "448/750 [================>.............] - ETA: 3s - loss: 0.4372 - accuracy: 0.8510\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 94/750 [==>...........................] - ETA: 14s - loss: 0.2449 - accuracy: 0.9169\n",
      "102/750 [===>..........................] - ETA: 14s - loss: 0.2449 - accuracy: 0.9168\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.4397 - accuracy: 0.8494\n",
      "103/750 [===>..........................] - ETA: 15s - loss: 0.2448 - accuracy: 0.9167\n",
      "708/750 [===========================>..] - ETA: 0s - loss: 0.4396 - accuracy: 0.8496\n",
      "110/750 [===>..........................] - ETA: 14s - loss: 0.2451 - accuracy: 0.9166\n",
      "713/750 [===========================>..] - ETA: 0s - loss: 0.4391 - accuracy: 0.8498\n",
      "493/750 [==================>...........] - ETA: 3s - loss: 0.4393 - accuracy: 0.8505\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.8274 - accuracy: 0.7360\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "114/750 [===>..........................] - ETA: 14s - loss: 0.2452 - accuracy: 0.9163\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.4391 - accuracy: 0.8498\n",
      "118/750 [===>..........................] - ETA: 14s - loss: 0.2469 - accuracy: 0.9159\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.4389 - accuracy: 0.8500\n",
      "501/750 [===================>..........] - ETA: 3s - loss: 0.4394 - accuracy: 0.8506\n",
      "125/750 [====>.........................] - ETA: 14s - loss: 0.2480 - accuracy: 0.9158\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.4393 - accuracy: 0.8499\n",
      "126/750 [====>.........................] - ETA: 14s - loss: 0.2481 - accuracy: 0.9157\n",
      "741/750 [============================>.] - ETA: 0s - loss: 0.4389 - accuracy: 0.8501\n",
      "525/750 [====================>.........] - ETA: 2s - loss: 0.4389 - accuracy: 0.8509\n",
      "137/750 [====>.........................] - ETA: 13s - loss: 0.2487 - accuracy: 0.9151\n",
      "146/750 [====>.........................] - ETA: 13s - loss: 0.2493 - accuracy: 0.9138\n",
      "152/750 [=====>........................] - ETA: 12s - loss: 0.2490 - accuracy: 0.9147\n",
      "162/750 [=====>........................] - ETA: 12s - loss: 0.2480 - accuracy: 0.9151\n",
      "171/750 [=====>........................] - ETA: 11s - loss: 0.2474 - accuracy: 0.9152\n",
      "177/750 [======>.......................] - ETA: 12s - loss: 0.2466 - accuracy: 0.9154\n",
      "186/750 [======>.......................] - ETA: 11s - loss: 0.2465 - accuracy: 0.9155\n",
      "194/750 [======>.......................] - ETA: 11s - loss: 0.2458 - accuracy: 0.9159\n",
      "201/750 [=======>......................] - ETA: 10s - loss: 0.2457 - accuracy: 0.9157\n",
      "216/750 [=======>......................] - ETA: 10s - loss: 0.2464 - accuracy: 0.9146\n",
      "225/750 [========>.....................] - ETA: 9s - loss: 0.2487 - accuracy: 0.9134\n",
      "232/750 [========>.....................] - ETA: 9s - loss: 0.2506 - accuracy: 0.9126\n",
      "244/750 [========>.....................] - ETA: 9s - loss: 0.2510 - accuracy: 0.9125\n",
      " 13/750 [..............................] - ETA: 10s - loss: 0.8342 - accuracy: 0.7560\n",
      "253/750 [=========>....................] - ETA: 9s - loss: 0.2511 - accuracy: 0.9131\n",
      " 21/750 [..............................] - ETA: 10s - loss: 0.8297 - accuracy: 0.7560\n",
      "674/750 [=========================>....] - ETA: 0s - loss: 0.4392 - accuracy: 0.8498\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "260/750 [=========>....................] - ETA: 8s - loss: 0.2518 - accuracy: 0.9128\n",
      " 28/750 [>.............................] - ETA: 10s - loss: 0.8381 - accuracy: 0.7494\n",
      "283/750 [==========>...................] - ETA: 7s - loss: 0.2518 - accuracy: 0.9123\n",
      "696/750 [==========================>...] - ETA: 0s - loss: 0.4394 - accuracy: 0.8495\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.8273 - accuracy: 0.7360 - val_loss: 0.8160 - val_accuracy: 0.7395\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 28/30\n",
      "290/750 [==========>...................] - ETA: 7s - loss: 0.2508 - accuracy: 0.9131\n",
      " 52/750 [=>............................] - ETA: 10s - loss: 0.8402 - accuracy: 0.7452\n",
      " 12/750 [..............................] - ETA: 3s - loss: 0.8342 - accuracy: 0.7578\n",
      "301/750 [===========>..................] - ETA: 7s - loss: 0.2509 - accuracy: 0.9131\n",
      "308/750 [===========>..................] - ETA: 7s - loss: 0.2508 - accuracy: 0.9131\n",
      "703/750 [===========================>..] - ETA: 0s - loss: 0.4396 - accuracy: 0.8494\n",
      "317/750 [===========>..................] - ETA: 7s - loss: 0.2507 - accuracy: 0.9133\n",
      " 32/750 [>.............................] - ETA: 11s - loss: 0.8303 - accuracy: 0.7539\n",
      "327/750 [============>.................] - ETA: 7s - loss: 0.2509 - accuracy: 0.9134\n",
      " 79/750 [==>...........................] - ETA: 10s - loss: 0.8275 - accuracy: 0.7456\n",
      "339/750 [============>.................] - ETA: 6s - loss: 0.2514 - accuracy: 0.9132\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.4384 - accuracy: 0.8505 - val_loss: 0.4463 - val_accuracy: 0.8474\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 28/30\n",
      " 44/750 [>.............................] - ETA: 9s - loss: 0.8345 - accuracy: 0.7496 \n",
      " 94/750 [==>...........................] - ETA: 9s - loss: 0.8282 - accuracy: 0.7447\n",
      "353/750 [=============>................] - ETA: 6s - loss: 0.2521 - accuracy: 0.9128\n",
      "  4/750 [..............................] - ETA: 13s - loss: 0.4136 - accuracy: 0.8711\n",
      "746/750 [============================>.] - ETA: 0s - loss: 0.4384 - accuracy: 0.8504\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "100/750 [===>..........................] - ETA: 9s - loss: 0.8273 - accuracy: 0.7447\n",
      "357/750 [=============>................] - ETA: 6s - loss: 0.2530 - accuracy: 0.9125\n",
      " 16/750 [..............................] - ETA: 7s - loss: 0.4506 - accuracy: 0.8486\n",
      "108/750 [===>..........................] - ETA: 9s - loss: 0.8261 - accuracy: 0.7449\n",
      "364/750 [=============>................] - ETA: 6s - loss: 0.2523 - accuracy: 0.9128\n",
      "117/750 [===>..........................] - ETA: 9s - loss: 0.8222 - accuracy: 0.7459\n",
      "371/750 [=============>................] - ETA: 6s - loss: 0.2524 - accuracy: 0.9129\n",
      "127/750 [====>.........................] - ETA: 8s - loss: 0.8220 - accuracy: 0.7441\n",
      "381/750 [==============>...............] - ETA: 5s - loss: 0.2521 - accuracy: 0.9131\n",
      "132/750 [====>.........................] - ETA: 8s - loss: 0.8228 - accuracy: 0.7436\n",
      "388/750 [==============>...............] - ETA: 5s - loss: 0.2525 - accuracy: 0.9130\n",
      "135/750 [====>.........................] - ETA: 8s - loss: 0.8214 - accuracy: 0.7446\n",
      "391/750 [==============>...............] - ETA: 5s - loss: 0.2523 - accuracy: 0.9130\n",
      " 53/750 [=>............................] - ETA: 8s - loss: 0.4640 - accuracy: 0.8399\n",
      " 74/750 [=>............................] - ETA: 9s - loss: 0.8273 - accuracy: 0.7458 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "145/750 [====>.........................] - ETA: 8s - loss: 0.8213 - accuracy: 0.7452\n",
      "403/750 [===============>..............] - ETA: 5s - loss: 0.2520 - accuracy: 0.9130\n",
      " 69/750 [=>............................] - ETA: 7s - loss: 0.4502 - accuracy: 0.8447\n",
      " 67/750 [=>............................] - ETA: 10s - loss: 0.8310 - accuracy: 0.7446\n",
      "149/750 [====>.........................] - ETA: 8s - loss: 0.8206 - accuracy: 0.7451\n",
      " 80/750 [==>...........................] - ETA: 7s - loss: 0.4537 - accuracy: 0.8432\n",
      "163/750 [=====>........................] - ETA: 8s - loss: 0.8158 - accuracy: 0.7468\n",
      "418/750 [===============>..............] - ETA: 5s - loss: 0.2520 - accuracy: 0.9128\n",
      " 86/750 [==>...........................] - ETA: 7s - loss: 0.4524 - accuracy: 0.8430\n",
      "176/750 [======>.......................] - ETA: 7s - loss: 0.8149 - accuracy: 0.7472\n",
      "429/750 [================>.............] - ETA: 5s - loss: 0.2510 - accuracy: 0.9131\n",
      "183/750 [======>.......................] - ETA: 7s - loss: 0.8138 - accuracy: 0.7474\n",
      "101/750 [===>..........................] - ETA: 7s - loss: 0.4512 - accuracy: 0.8427\n",
      "193/750 [======>.......................] - ETA: 7s - loss: 0.8133 - accuracy: 0.7479\n",
      "407/750 [===============>..............] - ETA: 5s - loss: 0.2520 - accuracy: 0.9130\n",
      "443/750 [================>.............] - ETA: 4s - loss: 0.2507 - accuracy: 0.9132\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "198/750 [======>.......................] - ETA: 7s - loss: 0.8161 - accuracy: 0.7469\n",
      "450/750 [=================>............] - ETA: 4s - loss: 0.2508 - accuracy: 0.9131\n",
      "210/750 [=======>......................] - ETA: 7s - loss: 0.8175 - accuracy: 0.7459\n",
      "465/750 [=================>............] - ETA: 4s - loss: 0.2511 - accuracy: 0.9127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:05:27,668 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6078341120; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/750 [=======>......................] - ETA: 7s - loss: 0.8174 - accuracy: 0.7457\n",
      "476/750 [==================>...........] - ETA: 4s - loss: 0.2506 - accuracy: 0.9129\n",
      "224/750 [=======>......................] - ETA: 7s - loss: 0.8168 - accuracy: 0.7460\n",
      "153/750 [=====>........................] - ETA: 7s - loss: 0.4442 - accuracy: 0.8457\n",
      "158/750 [=====>........................] - ETA: 7s - loss: 0.4454 - accuracy: 0.8459\n",
      "488/750 [==================>...........] - ETA: 4s - loss: 0.2502 - accuracy: 0.9130\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "235/750 [========>.....................] - ETA: 7s - loss: 0.8209 - accuracy: 0.7439\n",
      "511/750 [===================>..........] - ETA: 3s - loss: 0.2494 - accuracy: 0.9129\n",
      "523/750 [===================>..........] - ETA: 3s - loss: 0.2493 - accuracy: 0.9131\n",
      "535/750 [====================>.........] - ETA: 3s - loss: 0.2485 - accuracy: 0.9137\n",
      "205/750 [=======>......................] - ETA: 6s - loss: 0.4415 - accuracy: 0.8471\n",
      "541/750 [====================>.........] - ETA: 3s - loss: 0.2485 - accuracy: 0.9138\n",
      "294/750 [==========>...................] - ETA: 5s - loss: 0.8226 - accuracy: 0.7420\n",
      "554/750 [=====================>........] - ETA: 2s - loss: 0.2492 - accuracy: 0.9134\n",
      "313/750 [===========>..................] - ETA: 5s - loss: 0.8236 - accuracy: 0.7403\n",
      "566/750 [=====================>........] - ETA: 2s - loss: 0.2492 - accuracy: 0.9131\n",
      "316/750 [===========>..................] - ETA: 5s - loss: 0.8232 - accuracy: 0.7403\n",
      "568/750 [=====================>........] - ETA: 2s - loss: 0.2493 - accuracy: 0.9130\n",
      "577/750 [======================>.......] - ETA: 2s - loss: 0.2492 - accuracy: 0.9129\n",
      "586/750 [======================>.......] - ETA: 2s - loss: 0.2501 - accuracy: 0.9124\n",
      "345/750 [============>.................] - ETA: 5s - loss: 0.8223 - accuracy: 0.7397\n",
      "600/750 [=======================>......] - ETA: 2s - loss: 0.2505 - accuracy: 0.9123\n",
      "611/750 [=======================>......] - ETA: 2s - loss: 0.2506 - accuracy: 0.9122\n",
      "622/750 [=======================>......] - ETA: 1s - loss: 0.2505 - accuracy: 0.9121\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.2507 - accuracy: 0.9120\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.2506 - accuracy: 0.9120\n",
      "655/750 [=========================>....] - ETA: 1s - loss: 0.2501 - accuracy: 0.9122\n",
      "239/750 [========>.....................] - ETA: 6s - loss: 0.4396 - accuracy: 0.8475\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "669/750 [=========================>....] - ETA: 1s - loss: 0.2505 - accuracy: 0.9119\n",
      "331/750 [============>.................] - ETA: 4s - loss: 0.4376 - accuracy: 0.8495\n",
      " 18/750 [..............................] - ETA: 11s - loss: 0.4483 - accuracy: 0.8524\n",
      "675/750 [==========================>...] - ETA: 1s - loss: 0.2504 - accuracy: 0.9119\n",
      "258/750 [=========>....................] - ETA: 5s - loss: 0.4381 - accuracy: 0.8490\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.2507 - accuracy: 0.9119\n",
      "270/750 [=========>....................] - ETA: 5s - loss: 0.4385 - accuracy: 0.8492\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 37/750 [>.............................] - ETA: 7s - loss: 0.4538 - accuracy: 0.8467 \n",
      "712/750 [===========================>..] - ETA: 0s - loss: 0.2503 - accuracy: 0.9120\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.2501 - accuracy: 0.9122\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "292/750 [==========>...................] - ETA: 5s - loss: 0.4394 - accuracy: 0.8489\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "454/750 [=================>............] - ETA: 3s - loss: 0.8191 - accuracy: 0.7395\n",
      "720/750 [===========================>..] - ETA: 0s - loss: 0.2499 - accuracy: 0.9121\n",
      " 50/750 [=>............................] - ETA: 7s - loss: 0.4689 - accuracy: 0.8388\n",
      "305/750 [===========>..................] - ETA: 5s - loss: 0.4394 - accuracy: 0.8488\n",
      "731/750 [============================>.] - ETA: 0s - loss: 0.2504 - accuracy: 0.9119\n",
      "322/750 [===========>..................] - ETA: 4s - loss: 0.4389 - accuracy: 0.8492\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2503 - accuracy: 0.9120\n",
      "426/750 [================>.............] - ETA: 3s - loss: 0.4371 - accuracy: 0.8494\n",
      "504/750 [===================>..........] - ETA: 3s - loss: 0.8196 - accuracy: 0.7395\n",
      " 90/750 [==>...........................] - ETA: 7s - loss: 0.4526 - accuracy: 0.8425\n",
      "344/750 [============>.................] - ETA: 4s - loss: 0.4379 - accuracy: 0.8496\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "353/750 [=============>................] - ETA: 5s - loss: 0.8217 - accuracy: 0.7399\n",
      "529/750 [====================>.........] - ETA: 2s - loss: 0.8202 - accuracy: 0.7385\n",
      "371/750 [=============>................] - ETA: 4s - loss: 0.4367 - accuracy: 0.8493\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "119/750 [===>..........................] - ETA: 7s - loss: 0.4489 - accuracy: 0.8438\n",
      "358/750 [=============>................] - ETA: 4s - loss: 0.4383 - accuracy: 0.8492\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "479/750 [==================>...........] - ETA: 3s - loss: 0.4355 - accuracy: 0.8498\n",
      "114/750 [===>..........................] - ETA: 7s - loss: 0.4460 - accuracy: 0.8442\n",
      "483/750 [==================>...........] - ETA: 3s - loss: 0.4364 - accuracy: 0.8497\n",
      "389/750 [==============>...............] - ETA: 4s - loss: 0.4355 - accuracy: 0.8493\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "564/750 [=====================>........] - ETA: 2s - loss: 0.8188 - accuracy: 0.7393\n",
      "142/750 [====>.........................] - ETA: 7s - loss: 0.4438 - accuracy: 0.8462\n",
      "378/750 [==============>...............] - ETA: 4s - loss: 0.4361 - accuracy: 0.8492\n",
      "574/750 [=====================>........] - ETA: 2s - loss: 0.8192 - accuracy: 0.7389\n",
      "138/750 [====>.........................] - ETA: 6s - loss: 0.4461 - accuracy: 0.8453\n",
      "401/750 [===============>..............] - ETA: 3s - loss: 0.4360 - accuracy: 0.8492\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "170/750 [=====>........................] - ETA: 6s - loss: 0.4438 - accuracy: 0.8470\n",
      "410/750 [===============>..............] - ETA: 3s - loss: 0.4352 - accuracy: 0.8496\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "449/750 [================>.............] - ETA: 3s - loss: 0.4355 - accuracy: 0.8499\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "191/750 [======>.......................] - ETA: 6s - loss: 0.4401 - accuracy: 0.8480\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "615/750 [=======================>......] - ETA: 1s - loss: 0.8176 - accuracy: 0.7397\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.8175 - accuracy: 0.7402\n",
      "434/750 [================>.............] - ETA: 4s - loss: 0.8186 - accuracy: 0.7404\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "219/750 [=======>......................] - ETA: 5s - loss: 0.4408 - accuracy: 0.8476\n",
      "471/750 [=================>............] - ETA: 3s - loss: 0.4352 - accuracy: 0.8500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "480/750 [==================>...........] - ETA: 3s - loss: 0.8183 - accuracy: 0.7402\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2503 - accuracy: 0.9121 - val_loss: 0.3233 - val_accuracy: 0.8837\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 29/30\n",
      "221/750 [=======>......................] - ETA: 6s - loss: 0.4406 - accuracy: 0.8476\n",
      "  5/750 [..............................] - ETA: 9s - loss: 0.2677 - accuracy: 0.9156 \n",
      "673/750 [=========================>....] - ETA: 0s - loss: 0.8180 - accuracy: 0.7399\n",
      "  6/750 [..............................] - ETA: 21s - loss: 0.2566 - accuracy: 0.9193\n",
      "690/750 [==========================>...] - ETA: 0s - loss: 0.8180 - accuracy: 0.7396\n",
      "488/750 [==================>...........] - ETA: 2s - loss: 0.4361 - accuracy: 0.8501\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 16/750 [..............................] - ETA: 13s - loss: 0.2392 - accuracy: 0.9219\n",
      "511/750 [===================>..........] - ETA: 2s - loss: 0.4365 - accuracy: 0.8503\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 23/750 [..............................] - ETA: 12s - loss: 0.2386 - accuracy: 0.9219\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.8180 - accuracy: 0.7396\n",
      " 34/750 [>.............................] - ETA: 10s - loss: 0.2334 - accuracy: 0.9223\n",
      "546/750 [====================>.........] - ETA: 2s - loss: 0.4378 - accuracy: 0.8500\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 44/750 [>.............................] - ETA: 10s - loss: 0.2401 - accuracy: 0.9158\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.8191 - accuracy: 0.7390\n",
      " 54/750 [=>............................] - ETA: 9s - loss: 0.2429 - accuracy: 0.9152 \n",
      "295/750 [==========>...................] - ETA: 5s - loss: 0.4403 - accuracy: 0.8487\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "556/750 [=====================>........] - ETA: 2s - loss: 0.4378 - accuracy: 0.8502\n",
      " 65/750 [=>............................] - ETA: 9s - loss: 0.2385 - accuracy: 0.9192 \n",
      " 77/750 [==>...........................] - ETA: 8s - loss: 0.2373 - accuracy: 0.9190\n",
      "560/750 [=====================>........] - ETA: 2s - loss: 0.8185 - accuracy: 0.7396\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "749/750 [============================>.] - ETA: 0s - loss: 0.8195 - accuracy: 0.7390\n",
      " 85/750 [==>...........................] - ETA: 8s - loss: 0.2438 - accuracy: 0.9167\n",
      "579/750 [======================>.......] - ETA: 1s - loss: 0.4375 - accuracy: 0.8507\n",
      " 98/750 [==>...........................] - ETA: 8s - loss: 0.2439 - accuracy: 0.9147\n",
      "598/750 [======================>.......] - ETA: 1s - loss: 0.4369 - accuracy: 0.8511\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "108/750 [===>..........................] - ETA: 7s - loss: 0.2448 - accuracy: 0.9142\n",
      "347/750 [============>.................] - ETA: 4s - loss: 0.4382 - accuracy: 0.8494\n",
      "603/750 [=======================>......] - ETA: 1s - loss: 0.8185 - accuracy: 0.7395\n",
      "122/750 [===>..........................] - ETA: 7s - loss: 0.2452 - accuracy: 0.9137\n",
      "725/750 [============================>.] - ETA: 0s - loss: 0.4357 - accuracy: 0.8511\n",
      "613/750 [=======================>......] - ETA: 1s - loss: 0.4368 - accuracy: 0.8512\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "134/750 [====>.........................] - ETA: 7s - loss: 0.2448 - accuracy: 0.9148\n",
      "138/750 [====>.........................] - ETA: 7s - loss: 0.2442 - accuracy: 0.9146\n",
      "637/750 [========================>.....] - ETA: 1s - loss: 0.4354 - accuracy: 0.8515\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "147/750 [====>.........................] - ETA: 7s - loss: 0.2433 - accuracy: 0.9150\n",
      "157/750 [=====>........................] - ETA: 7s - loss: 0.2441 - accuracy: 0.9141\n",
      "170/750 [=====>........................] - ETA: 6s - loss: 0.2432 - accuracy: 0.9138\n",
      "650/750 [=========================>....] - ETA: 1s - loss: 0.4356 - accuracy: 0.8511\n",
      "180/750 [======>.......................] - ETA: 6s - loss: 0.2427 - accuracy: 0.9139\n",
      "662/750 [=========================>....] - ETA: 1s - loss: 0.4359 - accuracy: 0.8509\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "190/750 [======>.......................] - ETA: 6s - loss: 0.2427 - accuracy: 0.9132\n",
      "682/750 [==========================>...] - ETA: 0s - loss: 0.4365 - accuracy: 0.8507\n",
      "201/750 [=======>......................] - ETA: 6s - loss: 0.2451 - accuracy: 0.9121\n",
      "214/750 [=======>......................] - ETA: 6s - loss: 0.2443 - accuracy: 0.9125\n",
      "695/750 [==========================>...] - ETA: 0s - loss: 0.4367 - accuracy: 0.8506\n",
      "221/750 [=======>......................] - ETA: 6s - loss: 0.2440 - accuracy: 0.9123\n",
      "232/750 [========>.....................] - ETA: 5s - loss: 0.2437 - accuracy: 0.9133\n",
      "248/750 [========>.....................] - ETA: 5s - loss: 0.2461 - accuracy: 0.9127\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 0.8190 - accuracy: 0.7390\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "694/750 [==========================>...] - ETA: 0s - loss: 0.8177 - accuracy: 0.7396\n",
      "  1/750 [..............................] - ETA: 5s - loss: 0.7803 - accuracy: 0.7656\n",
      "456/750 [=================>............] - ETA: 3s - loss: 0.4351 - accuracy: 0.8501\n",
      "267/750 [=========>....................] - ETA: 5s - loss: 0.2477 - accuracy: 0.9129\n",
      " 26/750 [>.............................] - ETA: 4s - loss: 0.8307 - accuracy: 0.7278\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.4360 - accuracy: 0.8513\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "275/750 [==========>...................] - ETA: 5s - loss: 0.2485 - accuracy: 0.9127\n",
      " 28/750 [>.............................] - ETA: 6s - loss: 0.8277 - accuracy: 0.7316\n",
      "288/750 [==========>...................] - ETA: 4s - loss: 0.2495 - accuracy: 0.9129\n",
      " 34/750 [>.............................] - ETA: 7s - loss: 0.8146 - accuracy: 0.7385\n",
      "294/750 [==========>...................] - ETA: 5s - loss: 0.2500 - accuracy: 0.9126\n",
      " 45/750 [>.............................] - ETA: 7s - loss: 0.8167 - accuracy: 0.7403\n",
      "503/750 [===================>..........] - ETA: 2s - loss: 0.4367 - accuracy: 0.8502\n",
      "309/750 [===========>..................] - ETA: 4s - loss: 0.2499 - accuracy: 0.9126\n",
      "314/750 [===========>..................] - ETA: 4s - loss: 0.2499 - accuracy: 0.9127\n",
      " 65/750 [=>............................] - ETA: 6s - loss: 0.8003 - accuracy: 0.7447\n",
      "528/750 [====================>.........] - ETA: 2s - loss: 0.4375 - accuracy: 0.8501\n",
      "325/750 [============>.................] - ETA: 4s - loss: 0.2504 - accuracy: 0.9125\n",
      "331/750 [============>.................] - ETA: 4s - loss: 0.2498 - accuracy: 0.9124\n",
      " 76/750 [==>...........................] - ETA: 7s - loss: 0.8020 - accuracy: 0.7444\n",
      "336/750 [============>.................] - ETA: 4s - loss: 0.2499 - accuracy: 0.9126\n",
      "569/750 [=====================>........] - ETA: 2s - loss: 0.4378 - accuracy: 0.8506\n",
      "343/750 [============>.................] - ETA: 4s - loss: 0.2502 - accuracy: 0.9125\n",
      " 82/750 [==>...........................] - ETA: 8s - loss: 0.8047 - accuracy: 0.7409\n",
      "351/750 [=============>................] - ETA: 4s - loss: 0.2509 - accuracy: 0.9118\n",
      " 88/750 [==>...........................] - ETA: 8s - loss: 0.8022 - accuracy: 0.7431\n",
      " 90/750 [==>...........................] - ETA: 9s - loss: 0.8044 - accuracy: 0.7431\n",
      "356/750 [=============>................] - ETA: 4s - loss: 0.2510 - accuracy: 0.9120\n",
      "365/750 [=============>................] - ETA: 4s - loss: 0.2507 - accuracy: 0.9119\n",
      "370/750 [=============>................] - ETA: 4s - loss: 0.2514 - accuracy: 0.9117\n",
      "385/750 [==============>...............] - ETA: 4s - loss: 0.2514 - accuracy: 0.9117\n",
      "600/750 [=======================>......] - ETA: 1s - loss: 0.4369 - accuracy: 0.8511\n",
      "390/750 [==============>...............] - ETA: 4s - loss: 0.2508 - accuracy: 0.9120\n",
      "626/750 [========================>.....] - ETA: 1s - loss: 0.4357 - accuracy: 0.8515\n",
      "402/750 [===============>..............] - ETA: 4s - loss: 0.2505 - accuracy: 0.9123\n",
      "147/750 [====>.........................] - ETA: 8s - loss: 0.8025 - accuracy: 0.7460\n",
      "408/750 [===============>..............] - ETA: 4s - loss: 0.2507 - accuracy: 0.9121\n",
      "409/750 [===============>..............] - ETA: 4s - loss: 0.2509 - accuracy: 0.9120\n",
      " 23/750 [..............................] - ETA: 8s - loss: 0.4234 - accuracy: 0.8628\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.4359 - accuracy: 0.8512 - val_loss: 0.4444 - val_accuracy: 0.8464\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 29/30\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "411/750 [===============>..............] - ETA: 4s - loss: 0.2507 - accuracy: 0.9121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:05:37,768 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6077894656; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14/750 [..............................] - ETA: 2s - loss: 0.4312 - accuracy: 0.8549 \n",
      "156/750 [=====>........................] - ETA: 8s - loss: 0.8018 - accuracy: 0.7457\n",
      "415/750 [===============>..............] - ETA: 4s - loss: 0.2506 - accuracy: 0.9120\n",
      "665/750 [=========================>....] - ETA: 0s - loss: 0.4357 - accuracy: 0.8510\n",
      " 19/750 [..............................] - ETA: 4s - loss: 0.4303 - accuracy: 0.8577\n",
      "424/750 [===============>..............] - ETA: 3s - loss: 0.2511 - accuracy: 0.9122\n",
      "432/750 [================>.............] - ETA: 3s - loss: 0.2504 - accuracy: 0.9124\n",
      "183/750 [======>.......................] - ETA: 8s - loss: 0.8065 - accuracy: 0.7433\n",
      "440/750 [================>.............] - ETA: 3s - loss: 0.2502 - accuracy: 0.9125\n",
      "700/750 [===========================>..] - ETA: 0s - loss: 0.4369 - accuracy: 0.8506\n",
      "193/750 [======>.......................] - ETA: 7s - loss: 0.8099 - accuracy: 0.7417\n",
      "449/750 [================>.............] - ETA: 3s - loss: 0.2502 - accuracy: 0.9123\n",
      "461/750 [=================>............] - ETA: 3s - loss: 0.2515 - accuracy: 0.9117\n",
      "469/750 [=================>............] - ETA: 3s - loss: 0.2526 - accuracy: 0.9109\n",
      " 64/750 [=>............................] - ETA: 9s - loss: 0.4235 - accuracy: 0.8596\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "473/750 [=================>............] - ETA: 3s - loss: 0.2524 - accuracy: 0.9109\n",
      " 75/750 [==>...........................] - ETA: 8s - loss: 0.4291 - accuracy: 0.8571\n",
      "475/750 [==================>...........] - ETA: 3s - loss: 0.2524 - accuracy: 0.9109\n",
      "730/750 [============================>.] - ETA: 0s - loss: 0.4366 - accuracy: 0.8511\n",
      " 94/750 [==>...........................] - ETA: 9s - loss: 0.4340 - accuracy: 0.8547\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "481/750 [==================>...........] - ETA: 3s - loss: 0.2514 - accuracy: 0.9114\n",
      "228/750 [========>.....................] - ETA: 7s - loss: 0.8058 - accuracy: 0.7442\n",
      "488/750 [==================>...........] - ETA: 3s - loss: 0.2513 - accuracy: 0.9115\n",
      "101/750 [===>..........................] - ETA: 10s - loss: 0.4351 - accuracy: 0.8544\n",
      "231/750 [========>.....................] - ETA: 7s - loss: 0.8066 - accuracy: 0.7436\n",
      "103/750 [===>..........................] - ETA: 10s - loss: 0.4346 - accuracy: 0.8550\n",
      "122/750 [===>..........................] - ETA: 8s - loss: 0.8036 - accuracy: 0.7441\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "232/750 [========>.....................] - ETA: 7s - loss: 0.8069 - accuracy: 0.7435\n",
      "490/750 [==================>...........] - ETA: 3s - loss: 0.2514 - accuracy: 0.9115\n",
      "109/750 [===>..........................] - ETA: 10s - loss: 0.4345 - accuracy: 0.8554\n",
      "128/750 [====>.........................] - ETA: 8s - loss: 0.8054 - accuracy: 0.7437\n",
      "500/750 [===================>..........] - ETA: 3s - loss: 0.2511 - accuracy: 0.9116\n",
      "503/750 [===================>..........] - ETA: 3s - loss: 0.2512 - accuracy: 0.9116\n",
      "110/750 [===>..........................] - ETA: 10s - loss: 0.4349 - accuracy: 0.8550\n",
      "118/750 [===>..........................] - ETA: 10s - loss: 0.4342 - accuracy: 0.8546\n",
      "148/750 [====>.........................] - ETA: 8s - loss: 0.8030 - accuracy: 0.7456\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "121/750 [===>..........................] - ETA: 10s - loss: 0.4352 - accuracy: 0.8541\n",
      "248/750 [========>.....................] - ETA: 7s - loss: 0.8073 - accuracy: 0.7430\n",
      "127/750 [====>.........................] - ETA: 10s - loss: 0.4364 - accuracy: 0.8551\n",
      "518/750 [===================>..........] - ETA: 3s - loss: 0.2501 - accuracy: 0.9120\n",
      "131/750 [====>.........................] - ETA: 10s - loss: 0.4382 - accuracy: 0.8545\n",
      "260/750 [=========>....................] - ETA: 7s - loss: 0.8065 - accuracy: 0.7435\n",
      "520/750 [===================>..........] - ETA: 3s - loss: 0.2499 - accuracy: 0.9120\n",
      "141/750 [====>.........................] - ETA: 10s - loss: 0.4373 - accuracy: 0.8549\n",
      "174/750 [=====>........................] - ETA: 8s - loss: 0.8060 - accuracy: 0.7436\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "525/750 [====================>.........] - ETA: 3s - loss: 0.2503 - accuracy: 0.9118\n",
      "150/750 [=====>........................] - ETA: 9s - loss: 0.4346 - accuracy: 0.8543 \n",
      "535/750 [====================>.........] - ETA: 2s - loss: 0.2503 - accuracy: 0.9119\n",
      "540/750 [====================>.........] - ETA: 2s - loss: 0.2503 - accuracy: 0.9119\n",
      "207/750 [=======>......................] - ETA: 7s - loss: 0.8096 - accuracy: 0.7425\n",
      "549/750 [====================>.........] - ETA: 2s - loss: 0.2511 - accuracy: 0.9115\n",
      "224/750 [=======>......................] - ETA: 7s - loss: 0.8061 - accuracy: 0.7444\n",
      "305/750 [===========>..................] - ETA: 6s - loss: 0.8066 - accuracy: 0.7429\n",
      "560/750 [=====================>........] - ETA: 2s - loss: 0.2513 - accuracy: 0.9117\n",
      "218/750 [=======>......................] - ETA: 7s - loss: 0.8083 - accuracy: 0.7433\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "568/750 [=====================>........] - ETA: 2s - loss: 0.2507 - accuracy: 0.9121\n",
      "584/750 [======================>.......] - ETA: 2s - loss: 0.2496 - accuracy: 0.9124\n",
      "201/750 [=======>......................] - ETA: 8s - loss: 0.4369 - accuracy: 0.8545\n",
      "245/750 [========>.....................] - ETA: 7s - loss: 0.8075 - accuracy: 0.7430\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "586/750 [======================>.......] - ETA: 2s - loss: 0.2494 - accuracy: 0.9125\n",
      "213/750 [=======>......................] - ETA: 8s - loss: 0.4361 - accuracy: 0.8551\n",
      "266/750 [=========>....................] - ETA: 7s - loss: 0.8074 - accuracy: 0.7432\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "596/750 [======================>.......] - ETA: 2s - loss: 0.2494 - accuracy: 0.9126\n",
      "222/750 [=======>......................] - ETA: 7s - loss: 0.4358 - accuracy: 0.8549\n",
      "605/750 [=======================>......] - ETA: 1s - loss: 0.2492 - accuracy: 0.9126\n",
      "295/750 [==========>...................] - ETA: 6s - loss: 0.8066 - accuracy: 0.7435\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "613/750 [=======================>......] - ETA: 1s - loss: 0.2494 - accuracy: 0.9123\n",
      " 47/750 [>.............................] - ETA: 9s - loss: 0.4136 - accuracy: 0.8674\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "619/750 [=======================>......] - ETA: 1s - loss: 0.2495 - accuracy: 0.9122\n",
      "316/750 [===========>..................] - ETA: 6s - loss: 0.8074 - accuracy: 0.7429\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.2493 - accuracy: 0.9123\n",
      "320/750 [===========>..................] - ETA: 6s - loss: 0.8071 - accuracy: 0.7425\n",
      "633/750 [========================>.....] - ETA: 1s - loss: 0.2493 - accuracy: 0.9124\n",
      "640/750 [========================>.....] - ETA: 1s - loss: 0.2486 - accuracy: 0.9125\n",
      "334/750 [============>.................] - ETA: 6s - loss: 0.8081 - accuracy: 0.7413\n",
      "648/750 [========================>.....] - ETA: 1s - loss: 0.2480 - accuracy: 0.9128\n",
      " 98/750 [==>...........................] - ETA: 10s - loss: 0.4341 - accuracy: 0.8549\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "653/750 [=========================>....] - ETA: 1s - loss: 0.2483 - accuracy: 0.9127\n",
      "349/750 [============>.................] - ETA: 5s - loss: 0.8077 - accuracy: 0.7413\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "661/750 [=========================>....] - ETA: 1s - loss: 0.2483 - accuracy: 0.9127\n",
      "290/750 [==========>...................] - ETA: 6s - loss: 0.4349 - accuracy: 0.8547\n",
      "361/750 [=============>................] - ETA: 5s - loss: 0.8083 - accuracy: 0.7411\n",
      "670/750 [=========================>....] - ETA: 1s - loss: 0.2484 - accuracy: 0.9127\n",
      "368/750 [=============>................] - ETA: 5s - loss: 0.8088 - accuracy: 0.7410\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "427/750 [================>.............] - ETA: 4s - loss: 0.8102 - accuracy: 0.7411\n",
      "680/750 [==========================>...] - ETA: 0s - loss: 0.2488 - accuracy: 0.9124\n",
      "311/750 [===========>..................] - ETA: 6s - loss: 0.4315 - accuracy: 0.8559\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.2491 - accuracy: 0.9122\n",
      "320/750 [===========>..................] - ETA: 6s - loss: 0.4310 - accuracy: 0.8562\n",
      "443/750 [================>.............] - ETA: 4s - loss: 0.8109 - accuracy: 0.7408\n",
      "697/750 [==========================>...] - ETA: 0s - loss: 0.2487 - accuracy: 0.9123\n",
      "392/750 [==============>...............] - ETA: 5s - loss: 0.8102 - accuracy: 0.7404\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "454/750 [=================>............] - ETA: 4s - loss: 0.8108 - accuracy: 0.7408\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2485 - accuracy: 0.9124\n",
      "714/750 [===========================>..] - ETA: 0s - loss: 0.2480 - accuracy: 0.9126\n",
      "346/750 [============>.................] - ETA: 5s - loss: 0.4300 - accuracy: 0.8558\n",
      "401/750 [===============>..............] - ETA: 5s - loss: 0.8101 - accuracy: 0.7406\n",
      "471/750 [=================>............] - ETA: 4s - loss: 0.8115 - accuracy: 0.7406\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2477 - accuracy: 0.9127\n",
      "353/750 [=============>................] - ETA: 5s - loss: 0.4307 - accuracy: 0.8551\n",
      "408/750 [===============>..............] - ETA: 5s - loss: 0.8102 - accuracy: 0.7410\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.2470 - accuracy: 0.9130\n",
      "415/750 [===============>..............] - ETA: 4s - loss: 0.8108 - accuracy: 0.7411\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.2469 - accuracy: 0.9132\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.2473 - accuracy: 0.9128\n",
      "511/750 [===================>..........] - ETA: 3s - loss: 0.8135 - accuracy: 0.7400\n",
      "436/750 [================>.............] - ETA: 4s - loss: 0.8108 - accuracy: 0.7408\n",
      "522/750 [===================>..........] - ETA: 3s - loss: 0.8136 - accuracy: 0.7399\n",
      "407/750 [===============>..............] - ETA: 4s - loss: 0.4316 - accuracy: 0.8546\n",
      "193/750 [======>.......................] - ETA: 8s - loss: 0.4369 - accuracy: 0.8542\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "416/750 [===============>..............] - ETA: 4s - loss: 0.4314 - accuracy: 0.8545\n",
      "424/750 [===============>..............] - ETA: 4s - loss: 0.4317 - accuracy: 0.8544\n",
      "463/750 [=================>............] - ETA: 4s - loss: 0.8119 - accuracy: 0.7404\n",
      "556/750 [=====================>........] - ETA: 2s - loss: 0.8132 - accuracy: 0.7397\n",
      "561/750 [=====================>........] - ETA: 2s - loss: 0.8128 - accuracy: 0.7400\n",
      "436/750 [================>.............] - ETA: 4s - loss: 0.4314 - accuracy: 0.8547\n",
      "576/750 [======================>.......] - ETA: 2s - loss: 0.8123 - accuracy: 0.7405\n",
      "444/750 [================>.............] - ETA: 4s - loss: 0.4322 - accuracy: 0.8543\n",
      "462/750 [=================>............] - ETA: 4s - loss: 0.4328 - accuracy: 0.8541\n",
      "499/750 [==================>...........] - ETA: 3s - loss: 0.8128 - accuracy: 0.7404\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "601/750 [=======================>......] - ETA: 2s - loss: 0.8119 - accuracy: 0.7407\n",
      "603/750 [=======================>......] - ETA: 2s - loss: 0.8117 - accuracy: 0.7406\n",
      "474/750 [=================>............] - ETA: 3s - loss: 0.4327 - accuracy: 0.8540\n",
      "630/750 [========================>.....] - ETA: 1s - loss: 0.8120 - accuracy: 0.7407\n",
      "263/750 [=========>....................] - ETA: 7s - loss: 0.4352 - accuracy: 0.8543\n",
      "647/750 [========================>.....] - ETA: 1s - loss: 0.8111 - accuracy: 0.7409\n",
      "501/750 [===================>..........] - ETA: 3s - loss: 0.4328 - accuracy: 0.8542\n",
      "174/750 [=====>........................] - ETA: 9s - loss: 0.4356 - accuracy: 0.8536\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "507/750 [===================>..........] - ETA: 3s - loss: 0.4328 - accuracy: 0.8541\n",
      "538/750 [====================>.........] - ETA: 3s - loss: 0.8134 - accuracy: 0.7400\n",
      "653/750 [=========================>....] - ETA: 1s - loss: 0.8111 - accuracy: 0.7409\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2473 - accuracy: 0.9129 - val_loss: 0.3160 - val_accuracy: 0.8879\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Epoch 30/30\n",
      "  1/750 [..............................] - ETA: 59s - loss: 0.1990 - accuracy: 0.8906\n",
      "539/750 [====================>.........] - ETA: 3s - loss: 0.8134 - accuracy: 0.7400\n",
      "  2/750 [..............................] - ETA: 56s - loss: 0.2437 - accuracy: 0.8984\n",
      "  3/750 [..............................] - ETA: 55s - loss: 0.2537 - accuracy: 0.9062\n",
      " 24/750 [..............................] - ETA: 7s - loss: 0.2534 - accuracy: 0.9043 \n",
      "528/750 [====================>.........] - ETA: 3s - loss: 0.4340 - accuracy: 0.8535\n",
      "303/750 [===========>..................] - ETA: 6s - loss: 0.4323 - accuracy: 0.8558\n",
      " 28/750 [>.............................] - ETA: 9s - loss: 0.2560 - accuracy: 0.9012\n",
      " 30/750 [>.............................] - ETA: 10s - loss: 0.2547 - accuracy: 0.9021\n",
      "534/750 [====================>.........] - ETA: 3s - loss: 0.4345 - accuracy: 0.8531\n",
      "599/750 [======================>.......] - ETA: 2s - loss: 0.8116 - accuracy: 0.7409\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 31/750 [>.............................] - ETA: 14s - loss: 0.2501 - accuracy: 0.9047\n",
      "540/750 [====================>.........] - ETA: 3s - loss: 0.4351 - accuracy: 0.8528\n",
      "248/750 [========>.....................] - ETA: 7s - loss: 0.4358 - accuracy: 0.8542\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "592/750 [======================>.......] - ETA: 2s - loss: 0.8118 - accuracy: 0.7409\n",
      " 40/750 [>.............................] - ETA: 13s - loss: 0.2464 - accuracy: 0.9102\n",
      "545/750 [====================>.........] - ETA: 3s - loss: 0.4348 - accuracy: 0.8530\n",
      "273/750 [=========>....................] - ETA: 7s - loss: 0.4331 - accuracy: 0.8553\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 45/750 [>.............................] - ETA: 12s - loss: 0.2456 - accuracy: 0.9101\n",
      "547/750 [====================>.........] - ETA: 3s - loss: 0.4347 - accuracy: 0.8531\n",
      "704/750 [===========================>..] - ETA: 0s - loss: 0.8116 - accuracy: 0.7417\n",
      "623/750 [=======================>......] - ETA: 1s - loss: 0.8124 - accuracy: 0.7406\n",
      " 47/750 [>.............................] - ETA: 13s - loss: 0.2474 - accuracy: 0.9099\n",
      "551/750 [=====================>........] - ETA: 3s - loss: 0.4348 - accuracy: 0.8531\n",
      "282/750 [==========>...................] - ETA: 7s - loss: 0.4337 - accuracy: 0.8551\n",
      " 49/750 [>.............................] - ETA: 14s - loss: 0.2503 - accuracy: 0.9098\n",
      " 52/750 [=>............................] - ETA: 15s - loss: 0.2509 - accuracy: 0.9096\n",
      "561/750 [=====================>........] - ETA: 2s - loss: 0.4356 - accuracy: 0.8527\n",
      " 56/750 [=>............................] - ETA: 16s - loss: 0.2505 - accuracy: 0.9096\n",
      "639/750 [========================>.....] - ETA: 1s - loss: 0.8119 - accuracy: 0.7408\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 70/750 [=>............................] - ETA: 13s - loss: 0.2503 - accuracy: 0.9089\n",
      " 72/750 [=>............................] - ETA: 13s - loss: 0.2482 - accuracy: 0.9091\n",
      "587/750 [======================>.......] - ETA: 2s - loss: 0.4352 - accuracy: 0.8527\n",
      " 76/750 [==>...........................] - ETA: 14s - loss: 0.2449 - accuracy: 0.9104\n",
      "674/750 [=========================>....] - ETA: 1s - loss: 0.8115 - accuracy: 0.7414\n",
      " 97/750 [==>...........................] - ETA: 12s - loss: 0.2453 - accuracy: 0.9104\n",
      "602/750 [=======================>......] - ETA: 2s - loss: 0.4359 - accuracy: 0.8524\n",
      "341/750 [============>.................] - ETA: 5s - loss: 0.4297 - accuracy: 0.8560\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "665/750 [=========================>....] - ETA: 1s - loss: 0.8120 - accuracy: 0.7408\n",
      "100/750 [===>..........................] - ETA: 11s - loss: 0.2454 - accuracy: 0.9106\n",
      "614/750 [=======================>......] - ETA: 2s - loss: 0.4365 - accuracy: 0.8524\n",
      "107/750 [===>..........................] - ETA: 11s - loss: 0.2436 - accuracy: 0.9124\n",
      "623/750 [=======================>......] - ETA: 1s - loss: 0.4357 - accuracy: 0.8526\n",
      "372/750 [=============>................] - ETA: 5s - loss: 0.4317 - accuracy: 0.8547\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "691/750 [==========================>...] - ETA: 0s - loss: 0.8122 - accuracy: 0.7413\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "114/750 [===>..........................] - ETA: 11s - loss: 0.2430 - accuracy: 0.9135\n",
      "629/750 [========================>.....] - ETA: 1s - loss: 0.4354 - accuracy: 0.8528\n",
      "698/750 [==========================>...] - ETA: 0s - loss: 0.8117 - accuracy: 0.7416\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "125/750 [====>.........................] - ETA: 11s - loss: 0.2444 - accuracy: 0.9134\n",
      "429/750 [================>.............] - ETA: 4s - loss: 0.4313 - accuracy: 0.8546\n",
      "132/750 [====>.........................] - ETA: 10s - loss: 0.2441 - accuracy: 0.9135\n",
      "652/750 [=========================>....] - ETA: 1s - loss: 0.4347 - accuracy: 0.8530\n",
      "397/750 [==============>...............] - ETA: 5s - loss: 0.4311 - accuracy: 0.8549\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.8124 - accuracy: 0.7410\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "139/750 [====>.........................] - ETA: 10s - loss: 0.2426 - accuracy: 0.9138\n",
      "658/750 [=========================>....] - ETA: 1s - loss: 0.4352 - accuracy: 0.8526\n",
      "150/750 [=====>........................] - ETA: 10s - loss: 0.2422 - accuracy: 0.9144\n",
      "668/750 [=========================>....] - ETA: 1s - loss: 0.4360 - accuracy: 0.8522\n",
      "470/750 [=================>............] - ETA: 3s - loss: 0.4334 - accuracy: 0.8538\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "167/750 [=====>........................] - ETA: 9s - loss: 0.2425 - accuracy: 0.9140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:05:47,774 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6090194944; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737/750 [============================>.] - ETA: 0s - loss: 0.8125 - accuracy: 0.7412\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "745/750 [============================>.] - ETA: 0s - loss: 0.8123 - accuracy: 0.7414\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.4346 - accuracy: 0.8528\n",
      "193/750 [======>.......................] - ETA: 8s - loss: 0.2438 - accuracy: 0.9143\n",
      "522/750 [===================>..........] - ETA: 3s - loss: 0.4341 - accuracy: 0.8538\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "204/750 [=======>......................] - ETA: 8s - loss: 0.2446 - accuracy: 0.9138\n",
      "729/750 [============================>.] - ETA: 0s - loss: 0.4339 - accuracy: 0.8528\n",
      "217/750 [=======>......................] - ETA: 8s - loss: 0.2462 - accuracy: 0.9127\n",
      "190/750 [======>.......................] - ETA: 8s - loss: 0.2434 - accuracy: 0.9147\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "229/750 [========>.....................] - ETA: 7s - loss: 0.2460 - accuracy: 0.9128\n",
      "563/750 [=====================>........] - ETA: 2s - loss: 0.4355 - accuracy: 0.8528\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 15/750 [..............................] - ETA: 2s - loss: 0.8403 - accuracy: 0.7250\n",
      "578/750 [======================>.......] - ETA: 2s - loss: 0.4357 - accuracy: 0.8526\n",
      "279/750 [==========>...................] - ETA: 6s - loss: 0.2493 - accuracy: 0.9109\n",
      " 32/750 [>.............................] - ETA: 5s - loss: 0.8360 - accuracy: 0.7314\n",
      "493/750 [==================>...........] - ETA: 3s - loss: 0.4320 - accuracy: 0.8542\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "290/750 [==========>...................] - ETA: 6s - loss: 0.2478 - accuracy: 0.9119\n",
      "298/750 [==========>...................] - ETA: 6s - loss: 0.2477 - accuracy: 0.9119\n",
      "607/750 [=======================>......] - ETA: 2s - loss: 0.4365 - accuracy: 0.8522\n",
      "306/750 [===========>..................] - ETA: 6s - loss: 0.2484 - accuracy: 0.9118\n",
      " 53/750 [=>............................] - ETA: 8s - loss: 0.8161 - accuracy: 0.7388\n",
      "314/750 [===========>..................] - ETA: 6s - loss: 0.2480 - accuracy: 0.9121\n",
      " 75/750 [==>...........................] - ETA: 6s - loss: 0.8169 - accuracy: 0.7377\n",
      "322/750 [===========>..................] - ETA: 6s - loss: 0.2469 - accuracy: 0.9124\n",
      " 76/750 [==>...........................] - ETA: 7s - loss: 0.8182 - accuracy: 0.7364\n",
      "642/750 [========================>.....] - ETA: 1s - loss: 0.4345 - accuracy: 0.8529\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 82/750 [==>...........................] - ETA: 7s - loss: 0.8153 - accuracy: 0.7369\n",
      "342/750 [============>.................] - ETA: 5s - loss: 0.2473 - accuracy: 0.9117\n",
      " 91/750 [==>...........................] - ETA: 7s - loss: 0.8164 - accuracy: 0.7380\n",
      "173/750 [=====>........................] - ETA: 9s - loss: 0.2428 - accuracy: 0.9139\n",
      "351/750 [=============>................] - ETA: 5s - loss: 0.2462 - accuracy: 0.9119\n",
      "101/750 [===>..........................] - ETA: 7s - loss: 0.8133 - accuracy: 0.7390\n",
      "114/750 [===>..........................] - ETA: 7s - loss: 0.8099 - accuracy: 0.7405\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.8123 - accuracy: 0.7414 - val_loss: 0.8015 - val_accuracy: 0.7452\n",
      "\u001b[36m(train_model pid=77690)\u001b[0m Epoch 30/30\n",
      "125/750 [====>.........................] - ETA: 7s - loss: 0.8090 - accuracy: 0.7395\n",
      "138/750 [====>.........................] - ETA: 6s - loss: 0.8131 - accuracy: 0.7363\n",
      "400/750 [===============>..............] - ETA: 4s - loss: 0.2447 - accuracy: 0.9127\n",
      "141/750 [====>.........................] - ETA: 6s - loss: 0.8120 - accuracy: 0.7370\n",
      " 47/750 [>.............................] - ETA: 7s - loss: 0.8191 - accuracy: 0.7377\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "402/750 [===============>..............] - ETA: 4s - loss: 0.2448 - accuracy: 0.9125\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.4335 - accuracy: 0.8528 - val_loss: 0.4432 - val_accuracy: 0.8458\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Epoch 30/30\n",
      "150/750 [=====>........................] - ETA: 6s - loss: 0.8103 - accuracy: 0.7386\n",
      "412/750 [===============>..............] - ETA: 4s - loss: 0.2447 - accuracy: 0.9122\n",
      " 12/750 [..............................] - ETA: 12s - loss: 0.4053 - accuracy: 0.8750\n",
      "592/750 [======================>.......] - ETA: 2s - loss: 0.4357 - accuracy: 0.8525\n",
      "156/750 [=====>........................] - ETA: 6s - loss: 0.8115 - accuracy: 0.7387\n",
      "419/750 [===============>..............] - ETA: 4s - loss: 0.2449 - accuracy: 0.9120\n",
      " 27/750 [>.............................] - ETA: 8s - loss: 0.4290 - accuracy: 0.8640 \n",
      "244/750 [========>.....................] - ETA: 7s - loss: 0.2489 - accuracy: 0.9115\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "166/750 [=====>........................] - ETA: 6s - loss: 0.8134 - accuracy: 0.7375\n",
      "430/750 [================>.............] - ETA: 4s - loss: 0.2445 - accuracy: 0.9124\n",
      "273/750 [=========>....................] - ETA: 6s - loss: 0.2494 - accuracy: 0.9109\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "179/750 [======>.......................] - ETA: 6s - loss: 0.8153 - accuracy: 0.7354\n",
      "441/750 [================>.............] - ETA: 4s - loss: 0.2439 - accuracy: 0.9127\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.4346 - accuracy: 0.8527\n",
      "453/750 [=================>............] - ETA: 3s - loss: 0.2432 - accuracy: 0.9130\n",
      " 55/750 [=>............................] - ETA: 7s - loss: 0.4519 - accuracy: 0.8511\n",
      "462/750 [=================>............] - ETA: 3s - loss: 0.2429 - accuracy: 0.9130\n",
      "200/750 [=======>......................] - ETA: 6s - loss: 0.8114 - accuracy: 0.7382\n",
      " 61/750 [=>............................] - ETA: 8s - loss: 0.4446 - accuracy: 0.8545\n",
      "473/750 [=================>............] - ETA: 3s - loss: 0.2432 - accuracy: 0.9128\n",
      "476/750 [==================>...........] - ETA: 3s - loss: 0.2432 - accuracy: 0.9129\n",
      "502/750 [===================>..........] - ETA: 3s - loss: 0.2451 - accuracy: 0.9123\n",
      "251/750 [=========>....................] - ETA: 5s - loss: 0.8076 - accuracy: 0.7405\n",
      "116/750 [===>..........................] - ETA: 6s - loss: 0.4374 - accuracy: 0.8521\n",
      "256/750 [=========>....................] - ETA: 5s - loss: 0.8077 - accuracy: 0.7404\n",
      "516/750 [===================>..........] - ETA: 3s - loss: 0.2450 - accuracy: 0.9125\n",
      "259/750 [=========>....................] - ETA: 5s - loss: 0.8066 - accuracy: 0.7406\n",
      "518/750 [===================>..........] - ETA: 3s - loss: 0.2448 - accuracy: 0.9125\n",
      "119/750 [===>..........................] - ETA: 7s - loss: 0.4397 - accuracy: 0.8512\n",
      "335/750 [============>.................] - ETA: 5s - loss: 0.2481 - accuracy: 0.9115\n",
      "533/750 [====================>.........] - ETA: 2s - loss: 0.2448 - accuracy: 0.9129\n",
      "535/750 [====================>.........] - ETA: 2s - loss: 0.2448 - accuracy: 0.9129\n",
      "539/750 [====================>.........] - ETA: 2s - loss: 0.2449 - accuracy: 0.9129\n",
      "372/750 [=============>................] - ETA: 5s - loss: 0.2456 - accuracy: 0.9121\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "691/750 [==========================>...] - ETA: 0s - loss: 0.4351 - accuracy: 0.8527\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "557/750 [=====================>........] - ETA: 2s - loss: 0.2451 - accuracy: 0.9132\n",
      "571/750 [=====================>........] - ETA: 2s - loss: 0.2448 - accuracy: 0.9133\n",
      "386/750 [==============>...............] - ETA: 4s - loss: 0.2450 - accuracy: 0.9122\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.4340 - accuracy: 0.8528\n",
      "327/750 [============>.................] - ETA: 4s - loss: 0.8063 - accuracy: 0.7417\n",
      "586/750 [======================>.......] - ETA: 2s - loss: 0.2445 - accuracy: 0.9134\n",
      "342/750 [============>.................] - ETA: 4s - loss: 0.8056 - accuracy: 0.7424\n",
      "596/750 [======================>.......] - ETA: 1s - loss: 0.2447 - accuracy: 0.9131\n",
      "604/750 [=======================>......] - ETA: 1s - loss: 0.2447 - accuracy: 0.9133\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.4337 - accuracy: 0.8528\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "364/750 [=============>................] - ETA: 4s - loss: 0.8038 - accuracy: 0.7433\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.2452 - accuracy: 0.9133\n",
      "631/750 [========================>.....] - ETA: 1s - loss: 0.2451 - accuracy: 0.9133\n",
      "382/750 [==============>...............] - ETA: 4s - loss: 0.8048 - accuracy: 0.7429\n",
      "636/750 [========================>.....] - ETA: 1s - loss: 0.2447 - accuracy: 0.9134\n",
      "253/750 [=========>....................] - ETA: 5s - loss: 0.4427 - accuracy: 0.8488\n",
      "195/750 [======>.......................] - ETA: 6s - loss: 0.8125 - accuracy: 0.7375\n",
      "391/750 [==============>...............] - ETA: 3s - loss: 0.8046 - accuracy: 0.7430\n",
      "646/750 [========================>.....] - ETA: 1s - loss: 0.2449 - accuracy: 0.9134\n",
      "510/750 [===================>..........] - ETA: 3s - loss: 0.2449 - accuracy: 0.9123\n",
      "200/750 [=======>......................] - ETA: 5s - loss: 0.4384 - accuracy: 0.8501\n",
      "660/750 [=========================>....] - ETA: 1s - loss: 0.2444 - accuracy: 0.9134\n",
      "277/750 [==========>...................] - ETA: 4s - loss: 0.4392 - accuracy: 0.8499\n",
      "209/750 [=======>......................] - ETA: 5s - loss: 0.4388 - accuracy: 0.8500\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "665/750 [=========================>....] - ETA: 1s - loss: 0.2446 - accuracy: 0.9132\n",
      "186/750 [======>.......................] - ETA: 6s - loss: 0.4378 - accuracy: 0.8503\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "225/750 [========>.....................] - ETA: 5s - loss: 0.4407 - accuracy: 0.8502\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "678/750 [==========================>...] - ETA: 0s - loss: 0.2449 - accuracy: 0.9131\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.2451 - accuracy: 0.9129\n",
      "702/750 [===========================>..] - ETA: 0s - loss: 0.2451 - accuracy: 0.9129\n",
      "561/750 [=====================>........] - ETA: 2s - loss: 0.2452 - accuracy: 0.9131\n",
      "454/750 [=================>............] - ETA: 3s - loss: 0.8068 - accuracy: 0.7422\n",
      "706/750 [===========================>..] - ETA: 0s - loss: 0.2448 - accuracy: 0.9130\n",
      "  5/750 [..............................] - ETA: 9s - loss: 0.3861 - accuracy: 0.8781\n",
      "716/750 [===========================>..] - ETA: 0s - loss: 0.2445 - accuracy: 0.9132\n",
      "288/750 [==========>...................] - ETA: 4s - loss: 0.4386 - accuracy: 0.8502\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "477/750 [==================>...........] - ETA: 2s - loss: 0.8067 - accuracy: 0.7426\n",
      "727/750 [============================>.] - ETA: 0s - loss: 0.2448 - accuracy: 0.9133\n",
      " 48/750 [>.............................] - ETA: 7s - loss: 0.4533 - accuracy: 0.8490\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "490/750 [==================>...........] - ETA: 3s - loss: 0.2442 - accuracy: 0.9126\n",
      "488/750 [==================>...........] - ETA: 2s - loss: 0.8068 - accuracy: 0.7427\n",
      "367/750 [=============>................] - ETA: 3s - loss: 0.4354 - accuracy: 0.8510\n",
      "292/750 [==========>...................] - ETA: 4s - loss: 0.4379 - accuracy: 0.8504\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "314/750 [===========>..................] - ETA: 4s - loss: 0.8059 - accuracy: 0.7421\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "515/750 [===================>..........] - ETA: 2s - loss: 0.8065 - accuracy: 0.7431\n",
      "385/750 [==============>...............] - ETA: 3s - loss: 0.4359 - accuracy: 0.8506\n",
      "316/750 [===========>..................] - ETA: 4s - loss: 0.4378 - accuracy: 0.8499\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 79/750 [==>...........................] - ETA: 7s - loss: 0.4356 - accuracy: 0.8552\n",
      " 82/750 [==>...........................] - ETA: 7s - loss: 0.4369 - accuracy: 0.8544\n",
      " 99/750 [==>...........................] - ETA: 6s - loss: 0.4347 - accuracy: 0.8535\n",
      "347/750 [============>.................] - ETA: 4s - loss: 0.4358 - accuracy: 0.8505\n",
      "435/750 [================>.............] - ETA: 3s - loss: 0.4349 - accuracy: 0.8515\n",
      "580/750 [======================>.......] - ETA: 1s - loss: 0.8065 - accuracy: 0.7431\n",
      "112/750 [===>..........................] - ETA: 6s - loss: 0.4355 - accuracy: 0.8523\n",
      "583/750 [======================>.......] - ETA: 1s - loss: 0.8063 - accuracy: 0.7433\n",
      "446/750 [================>.............] - ETA: 3s - loss: 0.4354 - accuracy: 0.8515\n",
      "137/750 [====>.........................] - ETA: 7s - loss: 0.4351 - accuracy: 0.8533\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "401/750 [===============>..............] - ETA: 3s - loss: 0.8036 - accuracy: 0.7440\n",
      "595/750 [======================>.......] - ETA: 1s - loss: 0.8065 - accuracy: 0.7430\n",
      "154/750 [=====>........................] - ETA: 6s - loss: 0.4348 - accuracy: 0.8522\n",
      "416/750 [===============>..............] - ETA: 3s - loss: 0.4356 - accuracy: 0.8513\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "172/750 [=====>........................] - ETA: 6s - loss: 0.4393 - accuracy: 0.8495\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "240/750 [========>.....................] - ETA: 5s - loss: 0.4408 - accuracy: 0.8488\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "427/750 [================>.............] - ETA: 3s - loss: 0.8049 - accuracy: 0.7430\n",
      "266/750 [=========>....................] - ETA: 5s - loss: 0.4411 - accuracy: 0.8495\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "444/750 [================>.............] - ETA: 3s - loss: 0.4349 - accuracy: 0.8518\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "456/750 [=================>............] - ETA: 3s - loss: 0.4349 - accuracy: 0.8515\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "465/750 [=================>............] - ETA: 3s - loss: 0.8075 - accuracy: 0.7423\n",
      "527/750 [====================>.........] - ETA: 2s - loss: 0.4345 - accuracy: 0.8520\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.2447 - accuracy: 0.9132 - val_loss: 0.3169 - val_accuracy: 0.8878\n",
      "500/750 [===================>..........] - ETA: 2s - loss: 0.8075 - accuracy: 0.7424\n",
      "562/750 [=====================>........] - ETA: 2s - loss: 0.4333 - accuracy: 0.8527\n",
      "521/750 [===================>..........] - ETA: 2s - loss: 0.8066 - accuracy: 0.7431\n",
      "544/750 [====================>.........] - ETA: 2s - loss: 0.4337 - accuracy: 0.8523\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "537/750 [====================>.........] - ETA: 2s - loss: 0.4337 - accuracy: 0.8524\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "738/750 [============================>.] - ETA: 0s - loss: 0.8048 - accuracy: 0.7441\n",
      "372/750 [=============>................] - ETA: 4s - loss: 0.8038 - accuracy: 0.7431\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "556/750 [=====================>........] - ETA: 2s - loss: 0.4337 - accuracy: 0.8526\n",
      "573/750 [=====================>........] - ETA: 1s - loss: 0.4337 - accuracy: 0.8524\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "329/750 [============>.................] - ETA: 4s - loss: 0.4370 - accuracy: 0.8497\n",
      "590/750 [======================>.......] - ETA: 1s - loss: 0.4324 - accuracy: 0.8528\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "340/750 [============>.................] - ETA: 4s - loss: 0.4363 - accuracy: 0.8502\n",
      "651/750 [=========================>....] - ETA: 1s - loss: 0.4331 - accuracy: 0.8518\n",
      "600/750 [=======================>......] - ETA: 1s - loss: 0.8061 - accuracy: 0.7430\n",
      "747/750 [============================>.] - ETA: 0s - loss: 0.8053 - accuracy: 0.7439\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "614/750 [=======================>......] - ETA: 1s - loss: 0.4336 - accuracy: 0.8519\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-22 22:05:57,874 E 77599 531302] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2024-02-22_22-00-01_519598_76496 is over 95% full, available space: 6089842688; capacity: 245107195904. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/750 [==========================>...] - ETA: 0s - loss: 0.4325 - accuracy: 0.8523\n",
      "627/750 [========================>.....] - ETA: 1s - loss: 0.4339 - accuracy: 0.8517\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "392/750 [==============>...............] - ETA: 3s - loss: 0.4360 - accuracy: 0.8508\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "638/750 [========================>.....] - ETA: 1s - loss: 0.4338 - accuracy: 0.8518\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "701/750 [===========================>..] - ETA: 0s - loss: 0.4323 - accuracy: 0.8527\n",
      "672/750 [=========================>....] - ETA: 0s - loss: 0.4329 - accuracy: 0.8521\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "655/750 [=========================>....] - ETA: 1s - loss: 0.4332 - accuracy: 0.8520\n",
      "682/750 [==========================>...] - ETA: 0s - loss: 0.8043 - accuracy: 0.7442\n",
      "686/750 [==========================>...] - ETA: 0s - loss: 0.4323 - accuracy: 0.8525\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "465/750 [=================>............] - ETA: 3s - loss: 0.4346 - accuracy: 0.8516\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "705/750 [===========================>..] - ETA: 0s - loss: 0.4326 - accuracy: 0.8526\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "717/750 [===========================>..] - ETA: 0s - loss: 0.4321 - accuracy: 0.8529\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "478/750 [==================>...........] - ETA: 2s - loss: 0.4348 - accuracy: 0.8512\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m 313/313 - 3s - loss: 0.3403 - accuracy: 0.8796 - 3s/epoch - 9ms/step\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m \n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Training accuracy : 0.9132291674613953\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Validation accuracy : 0.8878333568572998\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Loss : 0.3402516841888428\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m Accuracy : 0.8795999884605408\n",
      "\u001b[36m(train_model pid=77688)\u001b[0m \n",
      "498/750 [==================>...........] - ETA: 2s - loss: 0.4349 - accuracy: 0.8514\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "518/750 [===================>..........] - ETA: 2s - loss: 0.4353 - accuracy: 0.8517\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">    loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_a904e_00000</td><td style=\"text-align: right;\">    0.8796</td><td style=\"text-align: right;\">         0.01  </td><td style=\"text-align: right;\">0.340252</td></tr>\n",
       "<tr><td>train_model_a904e_00001</td><td style=\"text-align: right;\">    0.8387</td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">0.462487</td></tr>\n",
       "<tr><td>train_model_a904e_00002</td><td style=\"text-align: right;\">    0.7353</td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">0.81565 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/750 [======================>.......] - ETA: 1s - loss: 0.4327 - accuracy: 0.8524\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "750/750 [==============================] - 10s 14ms/step - loss: 0.4314 - accuracy: 0.8533 - val_loss: 0.4405 - val_accuracy: 0.8500\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "740/750 [============================>.] - ETA: 0s - loss: 0.4315 - accuracy: 0.8532\n",
      "748/750 [============================>.] - ETA: 0s - loss: 0.4312 - accuracy: 0.8533\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m 313/313 - 3s - loss: 0.4625 - accuracy: 0.8387 - 3s/epoch - 11ms/step\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Training accuracy : 0.8532500267028809\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Validation accuracy : 0.8500000238418579\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Loss : 0.4624873101711273\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_model pid=77689)\u001b[0m Accuracy : 0.838699996471405\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 22:06:04,689\tINFO tune.py:1042 -- Total run time: 352.95 seconds (346.83 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter tuning\n",
    "analysis = tune.run(\n",
    "    train_model,\n",
    "    config=search_space,\n",
    "    metric=\"accuracy\",\n",
    "    mode=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FMM.plot_analysis_results(analysis, x_axis=\"learning_rate\", y_axis=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.01}\n",
      "Best accuracy: 0.8795999884605408\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters and results\n",
    "best_config = analysis.best_config\n",
    "print(\"Best hyperparameters:\", best_config)\n",
    "print(\"Best accuracy:\", analysis.best_result[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adagrad` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adagrad`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adagrad`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Adagrad optimizer...\n",
      "Epoch 1/30\n",
      "750/750 [==============================] - 10s 12ms/step - loss: 0.6986 - accuracy: 0.7644 - val_loss: 0.5162 - val_accuracy: 0.8207\n",
      "Epoch 2/30\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.4790 - accuracy: 0.8351 - val_loss: 0.4606 - val_accuracy: 0.8378\n",
      "Epoch 3/30\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.4367 - accuracy: 0.8481 - val_loss: 0.4300 - val_accuracy: 0.8453\n",
      "Epoch 4/30\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.4116 - accuracy: 0.8559 - val_loss: 0.4099 - val_accuracy: 0.8572\n",
      "Epoch 5/30\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.3927 - accuracy: 0.8621 - val_loss: 0.3979 - val_accuracy: 0.8623\n",
      "Epoch 6/30\n",
      "750/750 [==============================] - 8s 10ms/step - loss: 0.3775 - accuracy: 0.8675 - val_loss: 0.4025 - val_accuracy: 0.8592\n",
      "Epoch 7/30\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.3652 - accuracy: 0.8715 - val_loss: 0.3810 - val_accuracy: 0.8653\n",
      "Epoch 8/30\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.3544 - accuracy: 0.8761 - val_loss: 0.3792 - val_accuracy: 0.8660\n",
      "Epoch 9/30\n",
      "750/750 [==============================] - 7s 10ms/step - loss: 0.3460 - accuracy: 0.8781 - val_loss: 0.3714 - val_accuracy: 0.8685\n",
      "Epoch 10/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.3367 - accuracy: 0.8812 - val_loss: 0.3697 - val_accuracy: 0.8706\n",
      "Epoch 11/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.3295 - accuracy: 0.8833 - val_loss: 0.3622 - val_accuracy: 0.8716\n",
      "Epoch 12/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.3222 - accuracy: 0.8855 - val_loss: 0.3541 - val_accuracy: 0.8743\n",
      "Epoch 13/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.3157 - accuracy: 0.8870 - val_loss: 0.3596 - val_accuracy: 0.8724\n",
      "Epoch 14/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.3112 - accuracy: 0.8882 - val_loss: 0.3545 - val_accuracy: 0.8758\n",
      "Epoch 15/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.3040 - accuracy: 0.8902 - val_loss: 0.3589 - val_accuracy: 0.8737\n",
      "Epoch 16/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2995 - accuracy: 0.8931 - val_loss: 0.3374 - val_accuracy: 0.8803\n",
      "Epoch 17/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2953 - accuracy: 0.8947 - val_loss: 0.3384 - val_accuracy: 0.8802\n",
      "Epoch 18/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2896 - accuracy: 0.8970 - val_loss: 0.3337 - val_accuracy: 0.8805\n",
      "Epoch 19/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2854 - accuracy: 0.8986 - val_loss: 0.3313 - val_accuracy: 0.8813\n",
      "Epoch 20/30\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.2813 - accuracy: 0.8989 - val_loss: 0.3343 - val_accuracy: 0.8802\n",
      "Epoch 21/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.2772 - accuracy: 0.9011 - val_loss: 0.3306 - val_accuracy: 0.8812\n",
      "Epoch 22/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2729 - accuracy: 0.9035 - val_loss: 0.3350 - val_accuracy: 0.8792\n",
      "Epoch 23/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.2691 - accuracy: 0.9041 - val_loss: 0.3314 - val_accuracy: 0.8814\n",
      "Epoch 24/30\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.2659 - accuracy: 0.9052 - val_loss: 0.3248 - val_accuracy: 0.8825\n",
      "Epoch 25/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2623 - accuracy: 0.9062 - val_loss: 0.3215 - val_accuracy: 0.8864\n",
      "Epoch 26/30\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.2591 - accuracy: 0.9074 - val_loss: 0.3264 - val_accuracy: 0.8822\n",
      "Epoch 27/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2562 - accuracy: 0.9087 - val_loss: 0.3196 - val_accuracy: 0.8868\n",
      "Epoch 28/30\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.2528 - accuracy: 0.9105 - val_loss: 0.3215 - val_accuracy: 0.8845\n",
      "Epoch 29/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2498 - accuracy: 0.9106 - val_loss: 0.3224 - val_accuracy: 0.8842\n",
      "Epoch 30/30\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.2470 - accuracy: 0.9123 - val_loss: 0.3189 - val_accuracy: 0.8851\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adagrad(**best_config)\n",
    "model = FMM.get_model()\n",
    "print(f\"Training with {optimizer.__class__.__name__} optimizer...\")\n",
    "history = FMM.compile_and_train(\n",
    "    model, X_train, y_train, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.3393 - accuracy: 0.8784 - 1s/epoch - 4ms/step\n",
      "\n",
      "Training accuracy : 0.9123333096504211\n",
      "Validation accuracy : 0.8850833177566528\n",
      "Loss : 0.3392971158027649\n",
      "Accuracy : 0.8784000277519226\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FMM.evaluate(model, X_test, y_test, history)\n",
    "FMM.plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
