{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a9ceb5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0a9ceb5",
    "outputId": "95aa309c-5cef-400e-d02b-88d6f817dcdb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 20:52:44.966181: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'fashionmnist_model' from '/Users/matthewkolawole/Desktop/school/classes/2nd semester/Advanced Deep Learning - AIGC-5500-IRB/midterm/fashionmnist_model.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD, Adadelta, Nadam\n",
    "import fashionmnist_model as fmm_module\n",
    "import pandas as pd\n",
    "# Reload the module to apply any changes (useful during development)\n",
    "import importlib\n",
    "importlib.reload(fmm_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c588bca5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c588bca5",
    "outputId": "33ba71d0-efb2-4bea-c34c-c42d9141dd13"
   },
   "outputs": [],
   "source": [
    "# Load the Fashion MNIST data using the utility function from the custom module\n",
    "X_train, y_train, X_test, y_test = fmm_module.FMM.load_data()\n",
    "\n",
    "# Normalizes and preprocesses the data\n",
    "X_train_scaled, X_test_scaled = X_train / 255.0, X_test / 255.0\n",
    "# Reshape data for CNN compatibility for; this will not affect dense models due to the Flatten layer\n",
    "X_train = X_train.reshape((-1, 28, 28, 1))  # Adding a single color channel dimension\n",
    "X_test = X_test.reshape((-1, 28, 28, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed54881",
   "metadata": {
    "id": "eed54881"
   },
   "outputs": [],
   "source": [
    "# Defines hyperparameters for tuning\n",
    "optimizers = {'RMSprop': RMSprop,\n",
    "              'Adam': Adam,\n",
    "             'Adadelta': Adadelta\n",
    "              }\n",
    "learning_rates = [0.001, 0.0005, 0.0001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "n_splits = 5\n",
    "\n",
    "# Setups k-fold cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b29b636c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b29b636c",
    "outputId": "9eae24b7-37c4-4058-d9b2-75327f4a8efc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.5361 - accuracy: 0.8057 - val_loss: 0.4317 - val_accuracy: 0.8423\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3961 - accuracy: 0.8554 - val_loss: 0.3894 - val_accuracy: 0.8641\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3642 - accuracy: 0.8677 - val_loss: 0.3620 - val_accuracy: 0.8678\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3442 - accuracy: 0.8741 - val_loss: 0.4019 - val_accuracy: 0.8618\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3322 - accuracy: 0.8805 - val_loss: 0.3945 - val_accuracy: 0.8652\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3197 - accuracy: 0.8829 - val_loss: 0.3836 - val_accuracy: 0.8631\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3115 - accuracy: 0.8890 - val_loss: 0.4045 - val_accuracy: 0.8763\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3082 - accuracy: 0.8920 - val_loss: 0.4016 - val_accuracy: 0.8744\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.2978 - accuracy: 0.8948 - val_loss: 0.3939 - val_accuracy: 0.8804\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.2914 - accuracy: 0.8949 - val_loss: 0.3908 - val_accuracy: 0.8720\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.5434 - accuracy: 0.8043 - val_loss: 0.5023 - val_accuracy: 0.8268\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3975 - accuracy: 0.8562 - val_loss: 0.4179 - val_accuracy: 0.8505\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3597 - accuracy: 0.8696 - val_loss: 0.3845 - val_accuracy: 0.8615\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3410 - accuracy: 0.8766 - val_loss: 0.4036 - val_accuracy: 0.8633\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3269 - accuracy: 0.8828 - val_loss: 0.3893 - val_accuracy: 0.8680\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3158 - accuracy: 0.8873 - val_loss: 0.4202 - val_accuracy: 0.8609\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3082 - accuracy: 0.8907 - val_loss: 0.3715 - val_accuracy: 0.8761\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3029 - accuracy: 0.8930 - val_loss: 0.3685 - val_accuracy: 0.8818\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.2961 - accuracy: 0.8935 - val_loss: 0.4014 - val_accuracy: 0.8764\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.2912 - accuracy: 0.8966 - val_loss: 0.3891 - val_accuracy: 0.8766\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.5447 - accuracy: 0.8039 - val_loss: 0.4379 - val_accuracy: 0.8418\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3957 - accuracy: 0.8558 - val_loss: 0.3987 - val_accuracy: 0.8559\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3621 - accuracy: 0.8689 - val_loss: 0.4201 - val_accuracy: 0.8618\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3423 - accuracy: 0.8780 - val_loss: 0.4175 - val_accuracy: 0.8582\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3293 - accuracy: 0.8830 - val_loss: 0.3839 - val_accuracy: 0.8766\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3207 - accuracy: 0.8846 - val_loss: 0.3823 - val_accuracy: 0.8710\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3102 - accuracy: 0.8911 - val_loss: 0.4175 - val_accuracy: 0.8723\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3034 - accuracy: 0.8904 - val_loss: 0.4446 - val_accuracy: 0.8667\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.2942 - accuracy: 0.8938 - val_loss: 0.3955 - val_accuracy: 0.8723\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.2934 - accuracy: 0.8975 - val_loss: 0.3958 - val_accuracy: 0.8755\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.5385 - accuracy: 0.8042 - val_loss: 0.4562 - val_accuracy: 0.8354\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3945 - accuracy: 0.8564 - val_loss: 0.3774 - val_accuracy: 0.8627\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3590 - accuracy: 0.8688 - val_loss: 0.4351 - val_accuracy: 0.8389\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3432 - accuracy: 0.8763 - val_loss: 0.3586 - val_accuracy: 0.8740\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3249 - accuracy: 0.8824 - val_loss: 0.3620 - val_accuracy: 0.8786\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3195 - accuracy: 0.8883 - val_loss: 0.3765 - val_accuracy: 0.8720\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3061 - accuracy: 0.8897 - val_loss: 0.3575 - val_accuracy: 0.8861\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3011 - accuracy: 0.8916 - val_loss: 0.4537 - val_accuracy: 0.8631\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.2957 - accuracy: 0.8960 - val_loss: 0.3860 - val_accuracy: 0.8886\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.2880 - accuracy: 0.8971 - val_loss: 0.3948 - val_accuracy: 0.8780\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.5474 - accuracy: 0.8005 - val_loss: 0.4157 - val_accuracy: 0.8428\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3998 - accuracy: 0.8546 - val_loss: 0.4248 - val_accuracy: 0.8554\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3678 - accuracy: 0.8667 - val_loss: 0.3789 - val_accuracy: 0.8655\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3428 - accuracy: 0.8765 - val_loss: 0.3813 - val_accuracy: 0.8641\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3303 - accuracy: 0.8817 - val_loss: 0.3880 - val_accuracy: 0.8696\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3193 - accuracy: 0.8866 - val_loss: 0.3706 - val_accuracy: 0.8808\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3108 - accuracy: 0.8895 - val_loss: 0.4020 - val_accuracy: 0.8723\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3028 - accuracy: 0.8925 - val_loss: 0.4237 - val_accuracy: 0.8682\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.3003 - accuracy: 0.8937 - val_loss: 0.3864 - val_accuracy: 0.8790\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 2s 2ms/step - loss: 0.2926 - accuracy: 0.8982 - val_loss: 0.4906 - val_accuracy: 0.8724\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7946 - val_loss: 0.4567 - val_accuracy: 0.8339\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8533 - val_loss: 0.4494 - val_accuracy: 0.8306\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3558 - accuracy: 0.8683 - val_loss: 0.3700 - val_accuracy: 0.8695\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8785 - val_loss: 0.3645 - val_accuracy: 0.8702\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3084 - accuracy: 0.8866 - val_loss: 0.3461 - val_accuracy: 0.8766\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2951 - accuracy: 0.8909 - val_loss: 0.3370 - val_accuracy: 0.8800\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.8950 - val_loss: 0.3345 - val_accuracy: 0.8834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2694 - accuracy: 0.8995 - val_loss: 0.3455 - val_accuracy: 0.8803\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2596 - accuracy: 0.9039 - val_loss: 0.3404 - val_accuracy: 0.8836\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2511 - accuracy: 0.9068 - val_loss: 0.3411 - val_accuracy: 0.8799\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 2ms/step - loss: 0.5702 - accuracy: 0.7955 - val_loss: 0.4464 - val_accuracy: 0.8363\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.4009 - accuracy: 0.8529 - val_loss: 0.4250 - val_accuracy: 0.8476\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3547 - accuracy: 0.8688 - val_loss: 0.3603 - val_accuracy: 0.8715\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8780 - val_loss: 0.3270 - val_accuracy: 0.8850\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3055 - accuracy: 0.8859 - val_loss: 0.3350 - val_accuracy: 0.8815\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2927 - accuracy: 0.8903 - val_loss: 0.3326 - val_accuracy: 0.8836\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2771 - accuracy: 0.8969 - val_loss: 0.3239 - val_accuracy: 0.8904\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2675 - accuracy: 0.9003 - val_loss: 0.3643 - val_accuracy: 0.8737\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2584 - accuracy: 0.9032 - val_loss: 0.3230 - val_accuracy: 0.8881\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2475 - accuracy: 0.9055 - val_loss: 0.3586 - val_accuracy: 0.8851\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 2ms/step - loss: 0.5650 - accuracy: 0.7964 - val_loss: 0.6969 - val_accuracy: 0.7631\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3980 - accuracy: 0.8525 - val_loss: 0.3680 - val_accuracy: 0.8686\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8683 - val_loss: 0.3549 - val_accuracy: 0.8715\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8779 - val_loss: 0.3661 - val_accuracy: 0.8695\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3059 - accuracy: 0.8874 - val_loss: 0.3744 - val_accuracy: 0.8637\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2914 - accuracy: 0.8913 - val_loss: 0.3476 - val_accuracy: 0.8780\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2797 - accuracy: 0.8969 - val_loss: 0.3307 - val_accuracy: 0.8865\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.8998 - val_loss: 0.3641 - val_accuracy: 0.8758\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2567 - accuracy: 0.9042 - val_loss: 0.3353 - val_accuracy: 0.8874\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2500 - accuracy: 0.9060 - val_loss: 0.3324 - val_accuracy: 0.8885\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 2ms/step - loss: 0.5758 - accuracy: 0.7927 - val_loss: 0.4525 - val_accuracy: 0.8378\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.4040 - accuracy: 0.8530 - val_loss: 0.3855 - val_accuracy: 0.8568\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3596 - accuracy: 0.8680 - val_loss: 0.3664 - val_accuracy: 0.8692\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8774 - val_loss: 0.3608 - val_accuracy: 0.8732\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3124 - accuracy: 0.8852 - val_loss: 0.3573 - val_accuracy: 0.8700\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2978 - accuracy: 0.8909 - val_loss: 0.3525 - val_accuracy: 0.8746\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.8965 - val_loss: 0.4265 - val_accuracy: 0.8546\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2718 - accuracy: 0.8987 - val_loss: 0.3439 - val_accuracy: 0.8825\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2625 - accuracy: 0.9018 - val_loss: 0.3546 - val_accuracy: 0.8781\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.9053 - val_loss: 0.3640 - val_accuracy: 0.8785\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 2ms/step - loss: 0.5768 - accuracy: 0.7936 - val_loss: 0.4185 - val_accuracy: 0.8424\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.4035 - accuracy: 0.8529 - val_loss: 0.3675 - val_accuracy: 0.8687\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3564 - accuracy: 0.8691 - val_loss: 0.3814 - val_accuracy: 0.8614\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8773 - val_loss: 0.3715 - val_accuracy: 0.8662\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3084 - accuracy: 0.8858 - val_loss: 0.3545 - val_accuracy: 0.8755\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2939 - accuracy: 0.8900 - val_loss: 0.3448 - val_accuracy: 0.8797\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2799 - accuracy: 0.8955 - val_loss: 0.3647 - val_accuracy: 0.8730\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2716 - accuracy: 0.9001 - val_loss: 0.3529 - val_accuracy: 0.8805\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9033 - val_loss: 0.3304 - val_accuracy: 0.8866\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2505 - accuracy: 0.9065 - val_loss: 0.3479 - val_accuracy: 0.8841\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6193 - accuracy: 0.7821 - val_loss: 0.4699 - val_accuracy: 0.8365\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4219 - accuracy: 0.8451 - val_loss: 0.3905 - val_accuracy: 0.8568\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3709 - accuracy: 0.8625 - val_loss: 0.3758 - val_accuracy: 0.8629\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8757 - val_loss: 0.3645 - val_accuracy: 0.8676\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3152 - accuracy: 0.8833 - val_loss: 0.3652 - val_accuracy: 0.8673\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2978 - accuracy: 0.8878 - val_loss: 0.3400 - val_accuracy: 0.8788\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2806 - accuracy: 0.8959 - val_loss: 0.3341 - val_accuracy: 0.8817\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.8981 - val_loss: 0.3440 - val_accuracy: 0.8797\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2562 - accuracy: 0.9032 - val_loss: 0.3413 - val_accuracy: 0.8775\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2463 - accuracy: 0.9058 - val_loss: 0.3242 - val_accuracy: 0.8873\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.6230 - accuracy: 0.7782 - val_loss: 0.4660 - val_accuracy: 0.8339\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4213 - accuracy: 0.8459 - val_loss: 0.4362 - val_accuracy: 0.8407\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3693 - accuracy: 0.8632 - val_loss: 0.3464 - val_accuracy: 0.8731\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3394 - accuracy: 0.8740 - val_loss: 0.3425 - val_accuracy: 0.8739\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3158 - accuracy: 0.8838 - val_loss: 0.3535 - val_accuracy: 0.8747\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2987 - accuracy: 0.8891 - val_loss: 0.3711 - val_accuracy: 0.8678\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2836 - accuracy: 0.8925 - val_loss: 0.3202 - val_accuracy: 0.8836\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2689 - accuracy: 0.8983 - val_loss: 0.3158 - val_accuracy: 0.8876\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2585 - accuracy: 0.9041 - val_loss: 0.3339 - val_accuracy: 0.8822\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2483 - accuracy: 0.9078 - val_loss: 0.3265 - val_accuracy: 0.8851\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6350 - accuracy: 0.7776 - val_loss: 0.4656 - val_accuracy: 0.8289\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4233 - accuracy: 0.8419 - val_loss: 0.3739 - val_accuracy: 0.8629\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3726 - accuracy: 0.8607 - val_loss: 0.4692 - val_accuracy: 0.8258\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3411 - accuracy: 0.8758 - val_loss: 0.3748 - val_accuracy: 0.8669\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3198 - accuracy: 0.8817 - val_loss: 0.3401 - val_accuracy: 0.8801\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3008 - accuracy: 0.8878 - val_loss: 0.3154 - val_accuracy: 0.8870\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2864 - accuracy: 0.8921 - val_loss: 0.3404 - val_accuracy: 0.8760\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2712 - accuracy: 0.8971 - val_loss: 0.3541 - val_accuracy: 0.8677\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2599 - accuracy: 0.9018 - val_loss: 0.3481 - val_accuracy: 0.8765\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2492 - accuracy: 0.9051 - val_loss: 0.3239 - val_accuracy: 0.8852\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6295 - accuracy: 0.7770 - val_loss: 0.4729 - val_accuracy: 0.8314\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4281 - accuracy: 0.8430 - val_loss: 0.4363 - val_accuracy: 0.8442\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3717 - accuracy: 0.8621 - val_loss: 0.4045 - val_accuracy: 0.8546\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8743 - val_loss: 0.4319 - val_accuracy: 0.8508\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3192 - accuracy: 0.8810 - val_loss: 0.3324 - val_accuracy: 0.8822\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2978 - accuracy: 0.8891 - val_loss: 0.3294 - val_accuracy: 0.8799\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2828 - accuracy: 0.8932 - val_loss: 0.3426 - val_accuracy: 0.8832\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2696 - accuracy: 0.8984 - val_loss: 0.3346 - val_accuracy: 0.8784\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2580 - accuracy: 0.9025 - val_loss: 0.3392 - val_accuracy: 0.8783\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2446 - accuracy: 0.9073 - val_loss: 0.3514 - val_accuracy: 0.8752\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.6237 - accuracy: 0.7756 - val_loss: 0.4479 - val_accuracy: 0.8379\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4264 - accuracy: 0.8442 - val_loss: 0.4026 - val_accuracy: 0.8515\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8614 - val_loss: 0.3637 - val_accuracy: 0.8723\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3466 - accuracy: 0.8723 - val_loss: 0.3846 - val_accuracy: 0.8573\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3242 - accuracy: 0.8794 - val_loss: 0.4055 - val_accuracy: 0.8507\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3047 - accuracy: 0.8867 - val_loss: 0.3220 - val_accuracy: 0.8833\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2893 - accuracy: 0.8920 - val_loss: 0.3395 - val_accuracy: 0.8773\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2767 - accuracy: 0.8958 - val_loss: 0.3660 - val_accuracy: 0.8624\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2659 - accuracy: 0.9007 - val_loss: 0.3345 - val_accuracy: 0.8803\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2522 - accuracy: 0.9052 - val_loss: 0.3222 - val_accuracy: 0.8851\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5486 - accuracy: 0.8048 - val_loss: 0.4109 - val_accuracy: 0.8519\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3922 - accuracy: 0.8583 - val_loss: 0.3869 - val_accuracy: 0.8685\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3484 - accuracy: 0.8748 - val_loss: 0.3719 - val_accuracy: 0.8637\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3225 - accuracy: 0.8818 - val_loss: 0.3532 - val_accuracy: 0.8753\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3051 - accuracy: 0.8877 - val_loss: 0.3673 - val_accuracy: 0.8758\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2932 - accuracy: 0.8939 - val_loss: 0.3521 - val_accuracy: 0.8778\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2789 - accuracy: 0.8988 - val_loss: 0.3501 - val_accuracy: 0.8815\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2697 - accuracy: 0.9004 - val_loss: 0.3627 - val_accuracy: 0.8745\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2607 - accuracy: 0.9041 - val_loss: 0.3748 - val_accuracy: 0.8808\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2537 - accuracy: 0.9077 - val_loss: 0.3570 - val_accuracy: 0.8820\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5586 - accuracy: 0.8034 - val_loss: 0.4397 - val_accuracy: 0.8380\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3975 - accuracy: 0.8554 - val_loss: 0.3858 - val_accuracy: 0.8622\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3536 - accuracy: 0.8712 - val_loss: 0.3696 - val_accuracy: 0.8671\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3283 - accuracy: 0.8810 - val_loss: 0.3768 - val_accuracy: 0.8636\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3106 - accuracy: 0.8866 - val_loss: 0.3910 - val_accuracy: 0.8660\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2960 - accuracy: 0.8926 - val_loss: 0.3381 - val_accuracy: 0.8839\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2848 - accuracy: 0.8962 - val_loss: 0.3670 - val_accuracy: 0.8757\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2753 - accuracy: 0.8997 - val_loss: 0.3709 - val_accuracy: 0.8700\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2638 - accuracy: 0.9025 - val_loss: 0.3592 - val_accuracy: 0.8845\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2585 - accuracy: 0.9057 - val_loss: 0.3752 - val_accuracy: 0.8817\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5449 - accuracy: 0.8059 - val_loss: 0.4411 - val_accuracy: 0.8430\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3949 - accuracy: 0.8561 - val_loss: 0.4009 - val_accuracy: 0.8565\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3532 - accuracy: 0.8714 - val_loss: 0.4027 - val_accuracy: 0.8485\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3292 - accuracy: 0.8795 - val_loss: 0.3337 - val_accuracy: 0.8786\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3094 - accuracy: 0.8885 - val_loss: 0.3636 - val_accuracy: 0.8725\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2959 - accuracy: 0.8920 - val_loss: 0.3548 - val_accuracy: 0.8754\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2849 - accuracy: 0.8957 - val_loss: 0.3517 - val_accuracy: 0.8806\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2748 - accuracy: 0.8986 - val_loss: 0.3387 - val_accuracy: 0.8858\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2636 - accuracy: 0.9046 - val_loss: 0.3538 - val_accuracy: 0.8824\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2565 - accuracy: 0.9065 - val_loss: 0.3537 - val_accuracy: 0.8849\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5597 - accuracy: 0.8035 - val_loss: 0.4589 - val_accuracy: 0.8355\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4000 - accuracy: 0.8552 - val_loss: 0.3727 - val_accuracy: 0.8662\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3570 - accuracy: 0.8702 - val_loss: 0.3673 - val_accuracy: 0.8667\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3294 - accuracy: 0.8803 - val_loss: 0.3498 - val_accuracy: 0.8760\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3112 - accuracy: 0.8869 - val_loss: 0.3506 - val_accuracy: 0.8785\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2975 - accuracy: 0.8906 - val_loss: 0.3616 - val_accuracy: 0.8734\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2844 - accuracy: 0.8961 - val_loss: 0.3449 - val_accuracy: 0.8810\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2738 - accuracy: 0.8988 - val_loss: 0.3388 - val_accuracy: 0.8869\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2665 - accuracy: 0.9031 - val_loss: 0.3483 - val_accuracy: 0.8834\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2559 - accuracy: 0.9068 - val_loss: 0.3740 - val_accuracy: 0.8806\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5478 - accuracy: 0.8073 - val_loss: 0.4309 - val_accuracy: 0.8493\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3959 - accuracy: 0.8544 - val_loss: 0.3890 - val_accuracy: 0.8555\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3537 - accuracy: 0.8715 - val_loss: 0.3629 - val_accuracy: 0.8694\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3285 - accuracy: 0.8791 - val_loss: 0.3683 - val_accuracy: 0.8699\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3111 - accuracy: 0.8846 - val_loss: 0.3490 - val_accuracy: 0.8752\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2974 - accuracy: 0.8902 - val_loss: 0.3555 - val_accuracy: 0.8772\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2847 - accuracy: 0.8956 - val_loss: 0.3758 - val_accuracy: 0.8777\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2728 - accuracy: 0.8993 - val_loss: 0.3500 - val_accuracy: 0.8785\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2654 - accuracy: 0.9021 - val_loss: 0.3649 - val_accuracy: 0.8776\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2558 - accuracy: 0.9069 - val_loss: 0.3563 - val_accuracy: 0.8861\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.6015 - accuracy: 0.7924 - val_loss: 0.4295 - val_accuracy: 0.8498\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4228 - accuracy: 0.8493 - val_loss: 0.4248 - val_accuracy: 0.8558\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3742 - accuracy: 0.8643 - val_loss: 0.3787 - val_accuracy: 0.8649\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3414 - accuracy: 0.8767 - val_loss: 0.3528 - val_accuracy: 0.8706\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3186 - accuracy: 0.8842 - val_loss: 0.3367 - val_accuracy: 0.8779\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2999 - accuracy: 0.8889 - val_loss: 0.3473 - val_accuracy: 0.8722\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2848 - accuracy: 0.8951 - val_loss: 0.3578 - val_accuracy: 0.8723\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2731 - accuracy: 0.8993 - val_loss: 0.3277 - val_accuracy: 0.8822\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2598 - accuracy: 0.9041 - val_loss: 0.3472 - val_accuracy: 0.8801\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2503 - accuracy: 0.9070 - val_loss: 0.3252 - val_accuracy: 0.8839\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.5756 - accuracy: 0.7992 - val_loss: 0.4555 - val_accuracy: 0.8358\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4088 - accuracy: 0.8526 - val_loss: 0.3802 - val_accuracy: 0.8669\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3600 - accuracy: 0.8691 - val_loss: 0.3851 - val_accuracy: 0.8648\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3312 - accuracy: 0.8797 - val_loss: 0.3702 - val_accuracy: 0.8647\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3095 - accuracy: 0.8866 - val_loss: 0.3518 - val_accuracy: 0.8778\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2942 - accuracy: 0.8906 - val_loss: 0.3445 - val_accuracy: 0.8782\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2774 - accuracy: 0.8976 - val_loss: 0.3588 - val_accuracy: 0.8695\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2674 - accuracy: 0.9014 - val_loss: 0.3274 - val_accuracy: 0.8847\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2538 - accuracy: 0.9064 - val_loss: 0.3360 - val_accuracy: 0.8852\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2459 - accuracy: 0.9083 - val_loss: 0.3439 - val_accuracy: 0.8836\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.5840 - accuracy: 0.7971 - val_loss: 0.4487 - val_accuracy: 0.8377\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4143 - accuracy: 0.8504 - val_loss: 0.3903 - val_accuracy: 0.8618\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3665 - accuracy: 0.8659 - val_loss: 0.3522 - val_accuracy: 0.8707\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3349 - accuracy: 0.8784 - val_loss: 0.3692 - val_accuracy: 0.8705\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3135 - accuracy: 0.8852 - val_loss: 0.3671 - val_accuracy: 0.8692\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2959 - accuracy: 0.8910 - val_loss: 0.3353 - val_accuracy: 0.8770\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2813 - accuracy: 0.8961 - val_loss: 0.3265 - val_accuracy: 0.8860\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2683 - accuracy: 0.9020 - val_loss: 0.3393 - val_accuracy: 0.8795\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2577 - accuracy: 0.9048 - val_loss: 0.3314 - val_accuracy: 0.8813\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2480 - accuracy: 0.9085 - val_loss: 0.3620 - val_accuracy: 0.8722\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.5869 - accuracy: 0.7942 - val_loss: 0.4605 - val_accuracy: 0.8323\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4148 - accuracy: 0.8513 - val_loss: 0.3872 - val_accuracy: 0.8585\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3659 - accuracy: 0.8677 - val_loss: 0.3693 - val_accuracy: 0.8634\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3354 - accuracy: 0.8769 - val_loss: 0.3645 - val_accuracy: 0.8645\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3139 - accuracy: 0.8845 - val_loss: 0.3372 - val_accuracy: 0.8801\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2967 - accuracy: 0.8902 - val_loss: 0.3457 - val_accuracy: 0.8749\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2831 - accuracy: 0.8955 - val_loss: 0.3272 - val_accuracy: 0.8823\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2696 - accuracy: 0.8998 - val_loss: 0.3311 - val_accuracy: 0.8802\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2589 - accuracy: 0.9039 - val_loss: 0.3177 - val_accuracy: 0.8900\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2476 - accuracy: 0.9080 - val_loss: 0.3251 - val_accuracy: 0.8866\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.5880 - accuracy: 0.7956 - val_loss: 0.5129 - val_accuracy: 0.8181\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4177 - accuracy: 0.8492 - val_loss: 0.3959 - val_accuracy: 0.8572\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3681 - accuracy: 0.8670 - val_loss: 0.3725 - val_accuracy: 0.8676\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3398 - accuracy: 0.8761 - val_loss: 0.3615 - val_accuracy: 0.8695\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3186 - accuracy: 0.8831 - val_loss: 0.3661 - val_accuracy: 0.8696\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2992 - accuracy: 0.8901 - val_loss: 0.3453 - val_accuracy: 0.8767\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2855 - accuracy: 0.8946 - val_loss: 0.3446 - val_accuracy: 0.8771\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2742 - accuracy: 0.8992 - val_loss: 0.3369 - val_accuracy: 0.8810\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2615 - accuracy: 0.9042 - val_loss: 0.3516 - val_accuracy: 0.8799\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2512 - accuracy: 0.9058 - val_loss: 0.3515 - val_accuracy: 0.8772\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.6441 - accuracy: 0.7771 - val_loss: 0.4803 - val_accuracy: 0.8257\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4429 - accuracy: 0.8435 - val_loss: 0.4154 - val_accuracy: 0.8489\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3940 - accuracy: 0.8574 - val_loss: 0.4030 - val_accuracy: 0.8625\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3575 - accuracy: 0.8708 - val_loss: 0.3567 - val_accuracy: 0.8748\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3348 - accuracy: 0.8778 - val_loss: 0.3820 - val_accuracy: 0.8635\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3173 - accuracy: 0.8833 - val_loss: 0.3388 - val_accuracy: 0.8811\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3009 - accuracy: 0.8897 - val_loss: 0.3396 - val_accuracy: 0.8771\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2883 - accuracy: 0.8945 - val_loss: 0.3521 - val_accuracy: 0.8773\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2759 - accuracy: 0.8979 - val_loss: 0.3407 - val_accuracy: 0.8840\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2658 - accuracy: 0.9029 - val_loss: 0.3273 - val_accuracy: 0.8841\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.6582 - accuracy: 0.7758 - val_loss: 0.4612 - val_accuracy: 0.8407\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4510 - accuracy: 0.8400 - val_loss: 0.4227 - val_accuracy: 0.8533\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3980 - accuracy: 0.8585 - val_loss: 0.3966 - val_accuracy: 0.8595\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3638 - accuracy: 0.8704 - val_loss: 0.3870 - val_accuracy: 0.8605\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3426 - accuracy: 0.8740 - val_loss: 0.3949 - val_accuracy: 0.8627\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3227 - accuracy: 0.8815 - val_loss: 0.3604 - val_accuracy: 0.8679\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3084 - accuracy: 0.8882 - val_loss: 0.3398 - val_accuracy: 0.8783\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2928 - accuracy: 0.8928 - val_loss: 0.3636 - val_accuracy: 0.8655\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2832 - accuracy: 0.8964 - val_loss: 0.3376 - val_accuracy: 0.8766\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2728 - accuracy: 0.8995 - val_loss: 0.3476 - val_accuracy: 0.8729\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.6363 - accuracy: 0.7823 - val_loss: 0.4911 - val_accuracy: 0.8252\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4383 - accuracy: 0.8442 - val_loss: 0.5219 - val_accuracy: 0.8062\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3909 - accuracy: 0.8609 - val_loss: 0.3793 - val_accuracy: 0.8662\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3593 - accuracy: 0.8692 - val_loss: 0.3998 - val_accuracy: 0.8572\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3350 - accuracy: 0.8780 - val_loss: 0.3785 - val_accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3173 - accuracy: 0.8838 - val_loss: 0.3833 - val_accuracy: 0.8625\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3011 - accuracy: 0.8886 - val_loss: 0.3645 - val_accuracy: 0.8695\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2871 - accuracy: 0.8958 - val_loss: 0.3836 - val_accuracy: 0.8671\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2777 - accuracy: 0.8990 - val_loss: 0.3317 - val_accuracy: 0.8851\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2645 - accuracy: 0.9031 - val_loss: 0.3444 - val_accuracy: 0.8767\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.6395 - accuracy: 0.7841 - val_loss: 0.5281 - val_accuracy: 0.8127\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4436 - accuracy: 0.8422 - val_loss: 0.4162 - val_accuracy: 0.8546\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3928 - accuracy: 0.8586 - val_loss: 0.3785 - val_accuracy: 0.8650\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3618 - accuracy: 0.8691 - val_loss: 0.3612 - val_accuracy: 0.8694\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3381 - accuracy: 0.8754 - val_loss: 0.3587 - val_accuracy: 0.8712\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3194 - accuracy: 0.8826 - val_loss: 0.3401 - val_accuracy: 0.8735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3046 - accuracy: 0.8879 - val_loss: 0.3598 - val_accuracy: 0.8659\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2915 - accuracy: 0.8919 - val_loss: 0.3421 - val_accuracy: 0.8735\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2805 - accuracy: 0.8972 - val_loss: 0.3209 - val_accuracy: 0.8824\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2704 - accuracy: 0.9008 - val_loss: 0.3108 - val_accuracy: 0.8892\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.6588 - accuracy: 0.7751 - val_loss: 0.4859 - val_accuracy: 0.8323\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4583 - accuracy: 0.8371 - val_loss: 0.4243 - val_accuracy: 0.8526\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4086 - accuracy: 0.8542 - val_loss: 0.3855 - val_accuracy: 0.8653\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3763 - accuracy: 0.8638 - val_loss: 0.3674 - val_accuracy: 0.8697\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3500 - accuracy: 0.8734 - val_loss: 0.3686 - val_accuracy: 0.8652\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3300 - accuracy: 0.8778 - val_loss: 0.3761 - val_accuracy: 0.8608\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3124 - accuracy: 0.8851 - val_loss: 0.4249 - val_accuracy: 0.8420\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2981 - accuracy: 0.8892 - val_loss: 0.3658 - val_accuracy: 0.8701\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2849 - accuracy: 0.8949 - val_loss: 0.3545 - val_accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2737 - accuracy: 0.8985 - val_loss: 0.3314 - val_accuracy: 0.8797\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.6944 - accuracy: 0.7804 - val_loss: 0.5080 - val_accuracy: 0.8314\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4642 - accuracy: 0.8413 - val_loss: 0.4443 - val_accuracy: 0.8477\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4189 - accuracy: 0.8539 - val_loss: 0.4166 - val_accuracy: 0.8581\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3923 - accuracy: 0.8622 - val_loss: 0.3971 - val_accuracy: 0.8625\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3720 - accuracy: 0.8696 - val_loss: 0.3935 - val_accuracy: 0.8631\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3570 - accuracy: 0.8740 - val_loss: 0.4057 - val_accuracy: 0.8525\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3435 - accuracy: 0.8783 - val_loss: 0.3615 - val_accuracy: 0.8739\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3326 - accuracy: 0.8813 - val_loss: 0.3669 - val_accuracy: 0.8728\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3219 - accuracy: 0.8843 - val_loss: 0.3536 - val_accuracy: 0.8795\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3122 - accuracy: 0.8884 - val_loss: 0.3468 - val_accuracy: 0.8781\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.6915 - accuracy: 0.7763 - val_loss: 0.4924 - val_accuracy: 0.8311\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4584 - accuracy: 0.8428 - val_loss: 0.4301 - val_accuracy: 0.8521\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4134 - accuracy: 0.8572 - val_loss: 0.4171 - val_accuracy: 0.8508\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3862 - accuracy: 0.8645 - val_loss: 0.4107 - val_accuracy: 0.8561\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3653 - accuracy: 0.8720 - val_loss: 0.3997 - val_accuracy: 0.8578\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3512 - accuracy: 0.8761 - val_loss: 0.3599 - val_accuracy: 0.8736\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3375 - accuracy: 0.8813 - val_loss: 0.3557 - val_accuracy: 0.8760\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3264 - accuracy: 0.8846 - val_loss: 0.3562 - val_accuracy: 0.8720\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3157 - accuracy: 0.8887 - val_loss: 0.3561 - val_accuracy: 0.8751\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3072 - accuracy: 0.8909 - val_loss: 0.3453 - val_accuracy: 0.8810\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.7055 - accuracy: 0.7709 - val_loss: 0.5092 - val_accuracy: 0.8218\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4686 - accuracy: 0.8370 - val_loss: 0.4404 - val_accuracy: 0.8512\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4224 - accuracy: 0.8534 - val_loss: 0.4128 - val_accuracy: 0.8566\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3940 - accuracy: 0.8624 - val_loss: 0.3929 - val_accuracy: 0.8621\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3715 - accuracy: 0.8698 - val_loss: 0.3940 - val_accuracy: 0.8607\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3554 - accuracy: 0.8729 - val_loss: 0.3758 - val_accuracy: 0.8695\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3420 - accuracy: 0.8793 - val_loss: 0.3611 - val_accuracy: 0.8741\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3285 - accuracy: 0.8840 - val_loss: 0.3623 - val_accuracy: 0.8746\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3191 - accuracy: 0.8848 - val_loss: 0.3531 - val_accuracy: 0.8799\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3098 - accuracy: 0.8899 - val_loss: 0.3396 - val_accuracy: 0.8792\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.7236 - accuracy: 0.7733 - val_loss: 0.5062 - val_accuracy: 0.8291\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.4606 - accuracy: 0.8422 - val_loss: 0.4458 - val_accuracy: 0.8442\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4136 - accuracy: 0.8573 - val_loss: 0.4114 - val_accuracy: 0.8553\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3873 - accuracy: 0.8655 - val_loss: 0.4169 - val_accuracy: 0.8544\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 2ms/step - loss: 0.3672 - accuracy: 0.8714 - val_loss: 0.4047 - val_accuracy: 0.8582\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3519 - accuracy: 0.8761 - val_loss: 0.3840 - val_accuracy: 0.8607\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3388 - accuracy: 0.8800 - val_loss: 0.3660 - val_accuracy: 0.8709\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3271 - accuracy: 0.8831 - val_loss: 0.3721 - val_accuracy: 0.8697\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3178 - accuracy: 0.8882 - val_loss: 0.3675 - val_accuracy: 0.8716\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3089 - accuracy: 0.8902 - val_loss: 0.3684 - val_accuracy: 0.8726\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.7153 - accuracy: 0.7699 - val_loss: 0.5168 - val_accuracy: 0.8191\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4711 - accuracy: 0.8377 - val_loss: 0.4585 - val_accuracy: 0.8375\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4225 - accuracy: 0.8533 - val_loss: 0.4190 - val_accuracy: 0.8521\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3951 - accuracy: 0.8616 - val_loss: 0.3980 - val_accuracy: 0.8596\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3743 - accuracy: 0.8685 - val_loss: 0.3865 - val_accuracy: 0.8622\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3580 - accuracy: 0.8731 - val_loss: 0.3881 - val_accuracy: 0.8621\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3454 - accuracy: 0.8768 - val_loss: 0.3756 - val_accuracy: 0.8658\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3346 - accuracy: 0.8803 - val_loss: 0.3611 - val_accuracy: 0.8720\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3247 - accuracy: 0.8851 - val_loss: 0.3534 - val_accuracy: 0.8767\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3148 - accuracy: 0.8888 - val_loss: 0.3533 - val_accuracy: 0.8760\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.7624 - accuracy: 0.7608 - val_loss: 0.5335 - val_accuracy: 0.8219\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4986 - accuracy: 0.8314 - val_loss: 0.4724 - val_accuracy: 0.8347\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4494 - accuracy: 0.8454 - val_loss: 0.4424 - val_accuracy: 0.8444\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4210 - accuracy: 0.8549 - val_loss: 0.4223 - val_accuracy: 0.8542\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4013 - accuracy: 0.8610 - val_loss: 0.4039 - val_accuracy: 0.8600\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3857 - accuracy: 0.8655 - val_loss: 0.3932 - val_accuracy: 0.8647\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3724 - accuracy: 0.8701 - val_loss: 0.3858 - val_accuracy: 0.8669\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3613 - accuracy: 0.8726 - val_loss: 0.3873 - val_accuracy: 0.8622\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3511 - accuracy: 0.8763 - val_loss: 0.3930 - val_accuracy: 0.8603\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3424 - accuracy: 0.8799 - val_loss: 0.3653 - val_accuracy: 0.8706\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.8140 - accuracy: 0.7362 - val_loss: 0.5586 - val_accuracy: 0.8080\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.5138 - accuracy: 0.8281 - val_loss: 0.4797 - val_accuracy: 0.8369\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4562 - accuracy: 0.8444 - val_loss: 0.4465 - val_accuracy: 0.8458\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4252 - accuracy: 0.8553 - val_loss: 0.4350 - val_accuracy: 0.8472\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4040 - accuracy: 0.8612 - val_loss: 0.4210 - val_accuracy: 0.8524\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3874 - accuracy: 0.8648 - val_loss: 0.4132 - val_accuracy: 0.8520\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3741 - accuracy: 0.8709 - val_loss: 0.3984 - val_accuracy: 0.8607\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3627 - accuracy: 0.8743 - val_loss: 0.4047 - val_accuracy: 0.8602\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3524 - accuracy: 0.8764 - val_loss: 0.3814 - val_accuracy: 0.8699\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3424 - accuracy: 0.8807 - val_loss: 0.3784 - val_accuracy: 0.8695\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.7919 - accuracy: 0.7573 - val_loss: 0.5510 - val_accuracy: 0.8105\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4991 - accuracy: 0.8329 - val_loss: 0.4726 - val_accuracy: 0.8367\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4471 - accuracy: 0.8469 - val_loss: 0.4457 - val_accuracy: 0.8439\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4178 - accuracy: 0.8557 - val_loss: 0.4210 - val_accuracy: 0.8553\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3984 - accuracy: 0.8618 - val_loss: 0.4032 - val_accuracy: 0.8598\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3830 - accuracy: 0.8676 - val_loss: 0.4081 - val_accuracy: 0.8533\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3707 - accuracy: 0.8705 - val_loss: 0.3815 - val_accuracy: 0.8651\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3592 - accuracy: 0.8743 - val_loss: 0.3764 - val_accuracy: 0.8674\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3503 - accuracy: 0.8774 - val_loss: 0.3647 - val_accuracy: 0.8714\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3406 - accuracy: 0.8806 - val_loss: 0.3694 - val_accuracy: 0.8741\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 3ms/step - loss: 0.8150 - accuracy: 0.7468 - val_loss: 0.5447 - val_accuracy: 0.8165\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4979 - accuracy: 0.8341 - val_loss: 0.4793 - val_accuracy: 0.8373\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4438 - accuracy: 0.8474 - val_loss: 0.4582 - val_accuracy: 0.8390\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4146 - accuracy: 0.8562 - val_loss: 0.4223 - val_accuracy: 0.8525\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3941 - accuracy: 0.8641 - val_loss: 0.4204 - val_accuracy: 0.8529\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3792 - accuracy: 0.8679 - val_loss: 0.4196 - val_accuracy: 0.8546\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3653 - accuracy: 0.8736 - val_loss: 0.3972 - val_accuracy: 0.8593\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3542 - accuracy: 0.8753 - val_loss: 0.3807 - val_accuracy: 0.8662\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3434 - accuracy: 0.8791 - val_loss: 0.3785 - val_accuracy: 0.8659\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3345 - accuracy: 0.8831 - val_loss: 0.3749 - val_accuracy: 0.8683\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 3ms/step - loss: 0.7753 - accuracy: 0.7563 - val_loss: 0.5389 - val_accuracy: 0.8214\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4973 - accuracy: 0.8345 - val_loss: 0.4712 - val_accuracy: 0.8358\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4427 - accuracy: 0.8484 - val_loss: 0.4430 - val_accuracy: 0.8460\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4147 - accuracy: 0.8548 - val_loss: 0.4113 - val_accuracy: 0.8542\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3934 - accuracy: 0.8624 - val_loss: 0.4133 - val_accuracy: 0.8587\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3772 - accuracy: 0.8683 - val_loss: 0.3909 - val_accuracy: 0.8640\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3628 - accuracy: 0.8726 - val_loss: 0.3971 - val_accuracy: 0.8573\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3523 - accuracy: 0.8761 - val_loss: 0.3721 - val_accuracy: 0.8679\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3428 - accuracy: 0.8788 - val_loss: 0.3638 - val_accuracy: 0.8728\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8819 - val_loss: 0.3586 - val_accuracy: 0.8743\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 2s 5ms/step - loss: 0.9521 - accuracy: 0.7154 - val_loss: 0.6100 - val_accuracy: 0.7972\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5483 - accuracy: 0.8173 - val_loss: 0.5158 - val_accuracy: 0.8261\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4840 - accuracy: 0.8359 - val_loss: 0.4735 - val_accuracy: 0.8358\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4503 - accuracy: 0.8459 - val_loss: 0.4479 - val_accuracy: 0.8459\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4272 - accuracy: 0.8532 - val_loss: 0.4402 - val_accuracy: 0.8491\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4112 - accuracy: 0.8592 - val_loss: 0.4253 - val_accuracy: 0.8531\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.8626 - val_loss: 0.4177 - val_accuracy: 0.8562\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3854 - accuracy: 0.8658 - val_loss: 0.4077 - val_accuracy: 0.8548\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3753 - accuracy: 0.8710 - val_loss: 0.4002 - val_accuracy: 0.8609\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3670 - accuracy: 0.8720 - val_loss: 0.3920 - val_accuracy: 0.8628\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.9234 - accuracy: 0.7212 - val_loss: 0.6080 - val_accuracy: 0.8007\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5541 - accuracy: 0.8184 - val_loss: 0.5098 - val_accuracy: 0.8273\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4886 - accuracy: 0.8345 - val_loss: 0.4709 - val_accuracy: 0.8372\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4533 - accuracy: 0.8441 - val_loss: 0.4519 - val_accuracy: 0.8422\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4321 - accuracy: 0.8504 - val_loss: 0.4523 - val_accuracy: 0.8395\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4166 - accuracy: 0.8559 - val_loss: 0.4232 - val_accuracy: 0.8528\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4020 - accuracy: 0.8608 - val_loss: 0.4120 - val_accuracy: 0.8592\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3900 - accuracy: 0.8642 - val_loss: 0.3993 - val_accuracy: 0.8623\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3802 - accuracy: 0.8668 - val_loss: 0.4000 - val_accuracy: 0.8623\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3714 - accuracy: 0.8702 - val_loss: 0.3917 - val_accuracy: 0.8630\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.9555 - accuracy: 0.7101 - val_loss: 0.6234 - val_accuracy: 0.7935\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5573 - accuracy: 0.8158 - val_loss: 0.5142 - val_accuracy: 0.8254\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4893 - accuracy: 0.8339 - val_loss: 0.4716 - val_accuracy: 0.8402\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4539 - accuracy: 0.8458 - val_loss: 0.4510 - val_accuracy: 0.8416\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4316 - accuracy: 0.8511 - val_loss: 0.4420 - val_accuracy: 0.8485\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4125 - accuracy: 0.8585 - val_loss: 0.4264 - val_accuracy: 0.8527\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3991 - accuracy: 0.8614 - val_loss: 0.4072 - val_accuracy: 0.8593\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3879 - accuracy: 0.8663 - val_loss: 0.4001 - val_accuracy: 0.8628\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3776 - accuracy: 0.8686 - val_loss: 0.4054 - val_accuracy: 0.8573\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3677 - accuracy: 0.8719 - val_loss: 0.3877 - val_accuracy: 0.8655\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.9390 - accuracy: 0.7260 - val_loss: 0.6065 - val_accuracy: 0.8065\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5529 - accuracy: 0.8172 - val_loss: 0.5070 - val_accuracy: 0.8268\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4855 - accuracy: 0.8339 - val_loss: 0.4607 - val_accuracy: 0.8416\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4490 - accuracy: 0.8458 - val_loss: 0.4398 - val_accuracy: 0.8485\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4275 - accuracy: 0.8523 - val_loss: 0.4243 - val_accuracy: 0.8540\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4116 - accuracy: 0.8568 - val_loss: 0.4123 - val_accuracy: 0.8550\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3977 - accuracy: 0.8613 - val_loss: 0.3960 - val_accuracy: 0.8619\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3867 - accuracy: 0.8657 - val_loss: 0.4110 - val_accuracy: 0.8532\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3758 - accuracy: 0.8678 - val_loss: 0.3907 - val_accuracy: 0.8626\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3676 - accuracy: 0.8714 - val_loss: 0.3858 - val_accuracy: 0.8637\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.8866 - accuracy: 0.7267 - val_loss: 0.6011 - val_accuracy: 0.8012\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5426 - accuracy: 0.8214 - val_loss: 0.5081 - val_accuracy: 0.8256\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4786 - accuracy: 0.8382 - val_loss: 0.4793 - val_accuracy: 0.8348\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4457 - accuracy: 0.8475 - val_loss: 0.4429 - val_accuracy: 0.8467\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4236 - accuracy: 0.8526 - val_loss: 0.4345 - val_accuracy: 0.8506\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4066 - accuracy: 0.8601 - val_loss: 0.4185 - val_accuracy: 0.8519\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3931 - accuracy: 0.8628 - val_loss: 0.4116 - val_accuracy: 0.8553\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3816 - accuracy: 0.8675 - val_loss: 0.4135 - val_accuracy: 0.8530\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3719 - accuracy: 0.8707 - val_loss: 0.3909 - val_accuracy: 0.8641\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3629 - accuracy: 0.8742 - val_loss: 0.3857 - val_accuracy: 0.8639\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5234 - accuracy: 0.8143 - val_loss: 0.4388 - val_accuracy: 0.8469\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3861 - accuracy: 0.8601 - val_loss: 0.3864 - val_accuracy: 0.8599\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3424 - accuracy: 0.8747 - val_loss: 0.3439 - val_accuracy: 0.8784\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3156 - accuracy: 0.8820 - val_loss: 0.3563 - val_accuracy: 0.8719\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2968 - accuracy: 0.8890 - val_loss: 0.3451 - val_accuracy: 0.8773\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2785 - accuracy: 0.8962 - val_loss: 0.3336 - val_accuracy: 0.8806\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2659 - accuracy: 0.8985 - val_loss: 0.3566 - val_accuracy: 0.8777\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2518 - accuracy: 0.9052 - val_loss: 0.3313 - val_accuracy: 0.8815\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2411 - accuracy: 0.9091 - val_loss: 0.3435 - val_accuracy: 0.8817\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2336 - accuracy: 0.9110 - val_loss: 0.3287 - val_accuracy: 0.8848\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5240 - accuracy: 0.8147 - val_loss: 0.4458 - val_accuracy: 0.8392\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3871 - accuracy: 0.8596 - val_loss: 0.4010 - val_accuracy: 0.8568\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3447 - accuracy: 0.8724 - val_loss: 0.3764 - val_accuracy: 0.8629\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3212 - accuracy: 0.8820 - val_loss: 0.3746 - val_accuracy: 0.8589\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2986 - accuracy: 0.8895 - val_loss: 0.3269 - val_accuracy: 0.8816\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2847 - accuracy: 0.8925 - val_loss: 0.3258 - val_accuracy: 0.8825\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2726 - accuracy: 0.8975 - val_loss: 0.3289 - val_accuracy: 0.8802\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2547 - accuracy: 0.9047 - val_loss: 0.3195 - val_accuracy: 0.8832\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2478 - accuracy: 0.9076 - val_loss: 0.3462 - val_accuracy: 0.8826\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2360 - accuracy: 0.9122 - val_loss: 0.3181 - val_accuracy: 0.8876\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5233 - accuracy: 0.8174 - val_loss: 0.4194 - val_accuracy: 0.8500\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3890 - accuracy: 0.8588 - val_loss: 0.4209 - val_accuracy: 0.8378\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3454 - accuracy: 0.8727 - val_loss: 0.3518 - val_accuracy: 0.8706\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3184 - accuracy: 0.8824 - val_loss: 0.3527 - val_accuracy: 0.8734\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2994 - accuracy: 0.8877 - val_loss: 0.3513 - val_accuracy: 0.8741\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2848 - accuracy: 0.8940 - val_loss: 0.3564 - val_accuracy: 0.8726\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2705 - accuracy: 0.8999 - val_loss: 0.3540 - val_accuracy: 0.8776\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2583 - accuracy: 0.9029 - val_loss: 0.3297 - val_accuracy: 0.8839\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2452 - accuracy: 0.9084 - val_loss: 0.3397 - val_accuracy: 0.8789\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2352 - accuracy: 0.9120 - val_loss: 0.3442 - val_accuracy: 0.8781\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5207 - accuracy: 0.8130 - val_loss: 0.3966 - val_accuracy: 0.8567\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3825 - accuracy: 0.8602 - val_loss: 0.3655 - val_accuracy: 0.8689\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3414 - accuracy: 0.8738 - val_loss: 0.3539 - val_accuracy: 0.8702\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3177 - accuracy: 0.8824 - val_loss: 0.3374 - val_accuracy: 0.8784\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2994 - accuracy: 0.8885 - val_loss: 0.3396 - val_accuracy: 0.8791\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2831 - accuracy: 0.8926 - val_loss: 0.3565 - val_accuracy: 0.8753\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2707 - accuracy: 0.8991 - val_loss: 0.3352 - val_accuracy: 0.8841\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2572 - accuracy: 0.9043 - val_loss: 0.3430 - val_accuracy: 0.8805\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2457 - accuracy: 0.9092 - val_loss: 0.3334 - val_accuracy: 0.8853\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2373 - accuracy: 0.9097 - val_loss: 0.3236 - val_accuracy: 0.8891\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5292 - accuracy: 0.8115 - val_loss: 0.4441 - val_accuracy: 0.8398\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3831 - accuracy: 0.8611 - val_loss: 0.3727 - val_accuracy: 0.8681\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3430 - accuracy: 0.8726 - val_loss: 0.3579 - val_accuracy: 0.8729\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3158 - accuracy: 0.8832 - val_loss: 0.3410 - val_accuracy: 0.8800\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2953 - accuracy: 0.8901 - val_loss: 0.3374 - val_accuracy: 0.8759\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2838 - accuracy: 0.8942 - val_loss: 0.3309 - val_accuracy: 0.8816\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2668 - accuracy: 0.8998 - val_loss: 0.3723 - val_accuracy: 0.8699\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2556 - accuracy: 0.9032 - val_loss: 0.3376 - val_accuracy: 0.8891\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2445 - accuracy: 0.9084 - val_loss: 0.3181 - val_accuracy: 0.8888\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2345 - accuracy: 0.9116 - val_loss: 0.3642 - val_accuracy: 0.8752\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.5328 - accuracy: 0.8124 - val_loss: 0.4407 - val_accuracy: 0.8434\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3876 - accuracy: 0.8587 - val_loss: 0.3948 - val_accuracy: 0.8587\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3455 - accuracy: 0.8742 - val_loss: 0.3475 - val_accuracy: 0.8745\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3198 - accuracy: 0.8816 - val_loss: 0.3489 - val_accuracy: 0.8725\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3029 - accuracy: 0.8881 - val_loss: 0.3395 - val_accuracy: 0.8783\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2846 - accuracy: 0.8938 - val_loss: 0.3325 - val_accuracy: 0.8799\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2712 - accuracy: 0.8975 - val_loss: 0.3458 - val_accuracy: 0.8770\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2605 - accuracy: 0.9017 - val_loss: 0.3186 - val_accuracy: 0.8857\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2460 - accuracy: 0.9081 - val_loss: 0.3214 - val_accuracy: 0.8874\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2379 - accuracy: 0.9090 - val_loss: 0.3287 - val_accuracy: 0.8876\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 3ms/step - loss: 0.5366 - accuracy: 0.8112 - val_loss: 0.4318 - val_accuracy: 0.8479\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3947 - accuracy: 0.8563 - val_loss: 0.4067 - val_accuracy: 0.8528\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3453 - accuracy: 0.8729 - val_loss: 0.3698 - val_accuracy: 0.8641\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3215 - accuracy: 0.8807 - val_loss: 0.3500 - val_accuracy: 0.8744\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3000 - accuracy: 0.8878 - val_loss: 0.3652 - val_accuracy: 0.8722\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2854 - accuracy: 0.8934 - val_loss: 0.3214 - val_accuracy: 0.8846\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2708 - accuracy: 0.8988 - val_loss: 0.3551 - val_accuracy: 0.8717\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2619 - accuracy: 0.9018 - val_loss: 0.3241 - val_accuracy: 0.8853\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2492 - accuracy: 0.9063 - val_loss: 0.3484 - val_accuracy: 0.8757\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2350 - accuracy: 0.9123 - val_loss: 0.3364 - val_accuracy: 0.8850\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.8073 - val_loss: 0.5242 - val_accuracy: 0.8019\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3924 - accuracy: 0.8595 - val_loss: 0.3929 - val_accuracy: 0.8601\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3519 - accuracy: 0.8733 - val_loss: 0.3545 - val_accuracy: 0.8717\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3265 - accuracy: 0.8810 - val_loss: 0.3477 - val_accuracy: 0.8777\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3025 - accuracy: 0.8881 - val_loss: 0.3297 - val_accuracy: 0.8824\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2887 - accuracy: 0.8934 - val_loss: 0.3406 - val_accuracy: 0.8777\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2716 - accuracy: 0.8980 - val_loss: 0.3239 - val_accuracy: 0.8834\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2570 - accuracy: 0.9033 - val_loss: 0.3270 - val_accuracy: 0.8827\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2458 - accuracy: 0.9080 - val_loss: 0.3525 - val_accuracy: 0.8737\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2332 - accuracy: 0.9124 - val_loss: 0.3388 - val_accuracy: 0.8780\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.5397 - accuracy: 0.8120 - val_loss: 0.4410 - val_accuracy: 0.8442\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3933 - accuracy: 0.8575 - val_loss: 0.3777 - val_accuracy: 0.8631\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3499 - accuracy: 0.8730 - val_loss: 0.3583 - val_accuracy: 0.8691\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3198 - accuracy: 0.8831 - val_loss: 0.3484 - val_accuracy: 0.8734\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3015 - accuracy: 0.8876 - val_loss: 0.3517 - val_accuracy: 0.8706\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2864 - accuracy: 0.8935 - val_loss: 0.3375 - val_accuracy: 0.8749\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2729 - accuracy: 0.8969 - val_loss: 0.3223 - val_accuracy: 0.8852\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2591 - accuracy: 0.9035 - val_loss: 0.3402 - val_accuracy: 0.8736\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2506 - accuracy: 0.9069 - val_loss: 0.3546 - val_accuracy: 0.8797\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2381 - accuracy: 0.9116 - val_loss: 0.3235 - val_accuracy: 0.8827\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 3ms/step - loss: 0.5407 - accuracy: 0.8115 - val_loss: 0.4094 - val_accuracy: 0.8565\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3940 - accuracy: 0.8591 - val_loss: 0.3911 - val_accuracy: 0.8606\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3502 - accuracy: 0.8721 - val_loss: 0.3652 - val_accuracy: 0.8691\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3190 - accuracy: 0.8829 - val_loss: 0.3551 - val_accuracy: 0.8739\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2996 - accuracy: 0.8889 - val_loss: 0.3441 - val_accuracy: 0.8785\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2853 - accuracy: 0.8940 - val_loss: 0.3345 - val_accuracy: 0.8806\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2728 - accuracy: 0.8975 - val_loss: 0.3330 - val_accuracy: 0.8836\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2560 - accuracy: 0.9043 - val_loss: 0.3440 - val_accuracy: 0.8798\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2477 - accuracy: 0.9065 - val_loss: 0.3243 - val_accuracy: 0.8841\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2373 - accuracy: 0.9102 - val_loss: 0.3184 - val_accuracy: 0.8855\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.5931 - accuracy: 0.7962 - val_loss: 0.4527 - val_accuracy: 0.8382\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4096 - accuracy: 0.8551 - val_loss: 0.4049 - val_accuracy: 0.8530\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3643 - accuracy: 0.8686 - val_loss: 0.3693 - val_accuracy: 0.8671\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3351 - accuracy: 0.8773 - val_loss: 0.3689 - val_accuracy: 0.8666\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3080 - accuracy: 0.8870 - val_loss: 0.3556 - val_accuracy: 0.8700\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2933 - accuracy: 0.8919 - val_loss: 0.3334 - val_accuracy: 0.8789\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2736 - accuracy: 0.9000 - val_loss: 0.3147 - val_accuracy: 0.8846\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2590 - accuracy: 0.9033 - val_loss: 0.4055 - val_accuracy: 0.8480\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2513 - accuracy: 0.9059 - val_loss: 0.3162 - val_accuracy: 0.8869\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2396 - accuracy: 0.9122 - val_loss: 0.3412 - val_accuracy: 0.8805\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.5618 - accuracy: 0.8034 - val_loss: 0.4413 - val_accuracy: 0.8474\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3903 - accuracy: 0.8615 - val_loss: 0.3892 - val_accuracy: 0.8607\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3470 - accuracy: 0.8736 - val_loss: 0.3480 - val_accuracy: 0.8749\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3244 - accuracy: 0.8824 - val_loss: 0.3686 - val_accuracy: 0.8623\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3007 - accuracy: 0.8908 - val_loss: 0.3376 - val_accuracy: 0.8798\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2864 - accuracy: 0.8936 - val_loss: 0.3326 - val_accuracy: 0.8808\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2702 - accuracy: 0.9007 - val_loss: 0.3267 - val_accuracy: 0.8798\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2599 - accuracy: 0.9016 - val_loss: 0.3178 - val_accuracy: 0.8878\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2460 - accuracy: 0.9087 - val_loss: 0.3293 - val_accuracy: 0.8822\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2378 - accuracy: 0.9120 - val_loss: 0.3468 - val_accuracy: 0.8768\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.5793 - accuracy: 0.7993 - val_loss: 0.4383 - val_accuracy: 0.8504\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4091 - accuracy: 0.8544 - val_loss: 0.3987 - val_accuracy: 0.8590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3629 - accuracy: 0.8703 - val_loss: 0.3648 - val_accuracy: 0.8696\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3324 - accuracy: 0.8781 - val_loss: 0.3769 - val_accuracy: 0.8679\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3108 - accuracy: 0.8858 - val_loss: 0.3366 - val_accuracy: 0.8806\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2910 - accuracy: 0.8915 - val_loss: 0.3462 - val_accuracy: 0.8764\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2790 - accuracy: 0.8961 - val_loss: 0.3472 - val_accuracy: 0.8763\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2678 - accuracy: 0.9010 - val_loss: 0.3283 - val_accuracy: 0.8811\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2511 - accuracy: 0.9067 - val_loss: 0.3363 - val_accuracy: 0.8801\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2466 - accuracy: 0.9078 - val_loss: 0.3443 - val_accuracy: 0.8789\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.5781 - accuracy: 0.8018 - val_loss: 0.4206 - val_accuracy: 0.8531\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4109 - accuracy: 0.8533 - val_loss: 0.4115 - val_accuracy: 0.8523\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3590 - accuracy: 0.8685 - val_loss: 0.3600 - val_accuracy: 0.8685\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3342 - accuracy: 0.8781 - val_loss: 0.3588 - val_accuracy: 0.8676\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3095 - accuracy: 0.8876 - val_loss: 0.3353 - val_accuracy: 0.8778\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2919 - accuracy: 0.8933 - val_loss: 0.3339 - val_accuracy: 0.8770\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2767 - accuracy: 0.8968 - val_loss: 0.3257 - val_accuracy: 0.8804\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2636 - accuracy: 0.9024 - val_loss: 0.3273 - val_accuracy: 0.8833\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2524 - accuracy: 0.9060 - val_loss: 0.3176 - val_accuracy: 0.8853\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2419 - accuracy: 0.9094 - val_loss: 0.3353 - val_accuracy: 0.8778\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 4ms/step - loss: 0.5732 - accuracy: 0.8010 - val_loss: 0.4201 - val_accuracy: 0.8521\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4044 - accuracy: 0.8564 - val_loss: 0.4127 - val_accuracy: 0.8544\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3611 - accuracy: 0.8698 - val_loss: 0.3806 - val_accuracy: 0.8657\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3318 - accuracy: 0.8792 - val_loss: 0.3537 - val_accuracy: 0.8765\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3084 - accuracy: 0.8858 - val_loss: 0.3403 - val_accuracy: 0.8801\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2914 - accuracy: 0.8932 - val_loss: 0.3342 - val_accuracy: 0.8840\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2774 - accuracy: 0.8975 - val_loss: 0.3320 - val_accuracy: 0.8838\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2671 - accuracy: 0.9012 - val_loss: 0.3313 - val_accuracy: 0.8797\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2544 - accuracy: 0.9045 - val_loss: 0.3235 - val_accuracy: 0.8846\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2449 - accuracy: 0.9085 - val_loss: 0.3403 - val_accuracy: 0.8799\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5453 - accuracy: 0.8111 - val_loss: 0.4161 - val_accuracy: 0.8525\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3958 - accuracy: 0.8577 - val_loss: 0.3853 - val_accuracy: 0.8612\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3517 - accuracy: 0.8727 - val_loss: 0.3864 - val_accuracy: 0.8618\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3229 - accuracy: 0.8822 - val_loss: 0.3378 - val_accuracy: 0.8796\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3004 - accuracy: 0.8895 - val_loss: 0.3393 - val_accuracy: 0.8838\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2819 - accuracy: 0.8953 - val_loss: 0.3374 - val_accuracy: 0.8769\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2680 - accuracy: 0.9003 - val_loss: 0.3566 - val_accuracy: 0.8796\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2556 - accuracy: 0.9062 - val_loss: 0.3308 - val_accuracy: 0.8765\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2418 - accuracy: 0.9108 - val_loss: 0.3429 - val_accuracy: 0.8760\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2334 - accuracy: 0.9136 - val_loss: 0.3072 - val_accuracy: 0.8905\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5402 - accuracy: 0.8111 - val_loss: 0.4523 - val_accuracy: 0.8377\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3901 - accuracy: 0.8589 - val_loss: 0.3776 - val_accuracy: 0.8633\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3460 - accuracy: 0.8732 - val_loss: 0.3541 - val_accuracy: 0.8757\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3184 - accuracy: 0.8836 - val_loss: 0.3375 - val_accuracy: 0.8793\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2973 - accuracy: 0.8897 - val_loss: 0.3517 - val_accuracy: 0.8731\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2826 - accuracy: 0.8953 - val_loss: 0.3557 - val_accuracy: 0.8753\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2666 - accuracy: 0.9014 - val_loss: 0.3329 - val_accuracy: 0.8828\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2540 - accuracy: 0.9054 - val_loss: 0.3133 - val_accuracy: 0.8873\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2436 - accuracy: 0.9094 - val_loss: 0.3259 - val_accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2332 - accuracy: 0.9132 - val_loss: 0.3294 - val_accuracy: 0.8853\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5349 - accuracy: 0.8136 - val_loss: 0.4072 - val_accuracy: 0.8551\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3872 - accuracy: 0.8610 - val_loss: 0.3980 - val_accuracy: 0.8549\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3453 - accuracy: 0.8736 - val_loss: 0.3443 - val_accuracy: 0.8757\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3154 - accuracy: 0.8832 - val_loss: 0.3433 - val_accuracy: 0.8742\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2964 - accuracy: 0.8914 - val_loss: 0.3274 - val_accuracy: 0.8823\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2767 - accuracy: 0.8965 - val_loss: 0.3310 - val_accuracy: 0.8771\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2658 - accuracy: 0.9007 - val_loss: 0.3472 - val_accuracy: 0.8743\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2511 - accuracy: 0.9054 - val_loss: 0.3260 - val_accuracy: 0.8835\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2402 - accuracy: 0.9106 - val_loss: 0.3402 - val_accuracy: 0.8761\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2299 - accuracy: 0.9128 - val_loss: 0.3189 - val_accuracy: 0.8873\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5381 - accuracy: 0.8133 - val_loss: 0.4405 - val_accuracy: 0.8379\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3916 - accuracy: 0.8595 - val_loss: 0.3991 - val_accuracy: 0.8573\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3521 - accuracy: 0.8692 - val_loss: 0.3650 - val_accuracy: 0.8707\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3202 - accuracy: 0.8830 - val_loss: 0.3541 - val_accuracy: 0.8714\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3016 - accuracy: 0.8887 - val_loss: 0.3414 - val_accuracy: 0.8723\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2837 - accuracy: 0.8951 - val_loss: 0.3379 - val_accuracy: 0.8767\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2708 - accuracy: 0.8986 - val_loss: 0.3200 - val_accuracy: 0.8850\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2565 - accuracy: 0.9043 - val_loss: 0.3149 - val_accuracy: 0.8843\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2454 - accuracy: 0.9085 - val_loss: 0.3251 - val_accuracy: 0.8851\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2335 - accuracy: 0.9134 - val_loss: 0.3234 - val_accuracy: 0.8839\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.5392 - accuracy: 0.8158 - val_loss: 0.4255 - val_accuracy: 0.8461\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3917 - accuracy: 0.8589 - val_loss: 0.3786 - val_accuracy: 0.8657\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3463 - accuracy: 0.8746 - val_loss: 0.3704 - val_accuracy: 0.8736\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3186 - accuracy: 0.8840 - val_loss: 0.3377 - val_accuracy: 0.8776\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2971 - accuracy: 0.8901 - val_loss: 0.3343 - val_accuracy: 0.8824\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2807 - accuracy: 0.8957 - val_loss: 0.3461 - val_accuracy: 0.8734\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2654 - accuracy: 0.9012 - val_loss: 0.3178 - val_accuracy: 0.8874\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2517 - accuracy: 0.9074 - val_loss: 0.3287 - val_accuracy: 0.8805\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2424 - accuracy: 0.9085 - val_loss: 0.3084 - val_accuracy: 0.8913\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2290 - accuracy: 0.9152 - val_loss: 0.3373 - val_accuracy: 0.8791\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 3ms/step - loss: 0.5692 - accuracy: 0.8043 - val_loss: 0.4560 - val_accuracy: 0.8367\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4014 - accuracy: 0.8583 - val_loss: 0.4549 - val_accuracy: 0.8285\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3556 - accuracy: 0.8726 - val_loss: 0.3775 - val_accuracy: 0.8667\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3291 - accuracy: 0.8814 - val_loss: 0.3533 - val_accuracy: 0.8715\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3084 - accuracy: 0.8864 - val_loss: 0.3301 - val_accuracy: 0.8810\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2888 - accuracy: 0.8930 - val_loss: 0.3405 - val_accuracy: 0.8764\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2751 - accuracy: 0.8968 - val_loss: 0.3335 - val_accuracy: 0.8806\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2602 - accuracy: 0.9041 - val_loss: 0.3209 - val_accuracy: 0.8864\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2511 - accuracy: 0.9073 - val_loss: 0.3283 - val_accuracy: 0.8823\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2403 - accuracy: 0.9105 - val_loss: 0.3224 - val_accuracy: 0.8857\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 3ms/step - loss: 0.5759 - accuracy: 0.8028 - val_loss: 0.4485 - val_accuracy: 0.8433\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4112 - accuracy: 0.8541 - val_loss: 0.4200 - val_accuracy: 0.8534\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3632 - accuracy: 0.8686 - val_loss: 0.3761 - val_accuracy: 0.8616\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3364 - accuracy: 0.8783 - val_loss: 0.3581 - val_accuracy: 0.8722\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3130 - accuracy: 0.8870 - val_loss: 0.3646 - val_accuracy: 0.8681\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2954 - accuracy: 0.8927 - val_loss: 0.3398 - val_accuracy: 0.8791\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2796 - accuracy: 0.8979 - val_loss: 0.3305 - val_accuracy: 0.8830\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2703 - accuracy: 0.9010 - val_loss: 0.3252 - val_accuracy: 0.8830\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2573 - accuracy: 0.9054 - val_loss: 0.3435 - val_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2469 - accuracy: 0.9079 - val_loss: 0.3603 - val_accuracy: 0.8726\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 3ms/step - loss: 0.5650 - accuracy: 0.8057 - val_loss: 0.4429 - val_accuracy: 0.8481\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4030 - accuracy: 0.8561 - val_loss: 0.3894 - val_accuracy: 0.8617\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3584 - accuracy: 0.8690 - val_loss: 0.3650 - val_accuracy: 0.8707\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3290 - accuracy: 0.8808 - val_loss: 0.3479 - val_accuracy: 0.8770\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3072 - accuracy: 0.8871 - val_loss: 0.3408 - val_accuracy: 0.8816\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2902 - accuracy: 0.8941 - val_loss: 0.3336 - val_accuracy: 0.8831\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2721 - accuracy: 0.9002 - val_loss: 0.3331 - val_accuracy: 0.8826\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2585 - accuracy: 0.9055 - val_loss: 0.3233 - val_accuracy: 0.8854\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2485 - accuracy: 0.9088 - val_loss: 0.3154 - val_accuracy: 0.8893\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2380 - accuracy: 0.9130 - val_loss: 0.3379 - val_accuracy: 0.8843\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 3ms/step - loss: 0.5787 - accuracy: 0.8027 - val_loss: 0.4357 - val_accuracy: 0.8461\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4093 - accuracy: 0.8533 - val_loss: 0.3886 - val_accuracy: 0.8607\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3634 - accuracy: 0.8699 - val_loss: 0.3804 - val_accuracy: 0.8624\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3328 - accuracy: 0.8801 - val_loss: 0.3611 - val_accuracy: 0.8712\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3123 - accuracy: 0.8857 - val_loss: 0.4055 - val_accuracy: 0.8537\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2961 - accuracy: 0.8897 - val_loss: 0.3505 - val_accuracy: 0.8757\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2804 - accuracy: 0.8965 - val_loss: 0.3465 - val_accuracy: 0.8773\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2678 - accuracy: 0.9001 - val_loss: 0.3325 - val_accuracy: 0.8773\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2522 - accuracy: 0.9071 - val_loss: 0.3317 - val_accuracy: 0.8801\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2443 - accuracy: 0.9097 - val_loss: 0.3188 - val_accuracy: 0.8863\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 3ms/step - loss: 0.5725 - accuracy: 0.8040 - val_loss: 0.4439 - val_accuracy: 0.8385\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4055 - accuracy: 0.8556 - val_loss: 0.4100 - val_accuracy: 0.8569\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3607 - accuracy: 0.8704 - val_loss: 0.3600 - val_accuracy: 0.8731\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3284 - accuracy: 0.8822 - val_loss: 0.3495 - val_accuracy: 0.8737\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3091 - accuracy: 0.8875 - val_loss: 0.3684 - val_accuracy: 0.8648\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2942 - accuracy: 0.8905 - val_loss: 0.3461 - val_accuracy: 0.8742\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2786 - accuracy: 0.8966 - val_loss: 0.3400 - val_accuracy: 0.8783\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2626 - accuracy: 0.9030 - val_loss: 0.3208 - val_accuracy: 0.8844\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2505 - accuracy: 0.9075 - val_loss: 0.3361 - val_accuracy: 0.8793\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2416 - accuracy: 0.9128 - val_loss: 0.3291 - val_accuracy: 0.8820\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.6202 - accuracy: 0.7895 - val_loss: 0.4701 - val_accuracy: 0.8375\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4301 - accuracy: 0.8486 - val_loss: 0.4114 - val_accuracy: 0.8582\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3811 - accuracy: 0.8652 - val_loss: 0.3961 - val_accuracy: 0.8643\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3512 - accuracy: 0.8729 - val_loss: 0.3890 - val_accuracy: 0.8614\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3273 - accuracy: 0.8810 - val_loss: 0.3486 - val_accuracy: 0.8743\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3093 - accuracy: 0.8876 - val_loss: 0.3494 - val_accuracy: 0.8754\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2925 - accuracy: 0.8931 - val_loss: 0.3359 - val_accuracy: 0.8803\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2816 - accuracy: 0.8972 - val_loss: 0.3299 - val_accuracy: 0.8843\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.9001 - val_loss: 0.3240 - val_accuracy: 0.8838\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2575 - accuracy: 0.9057 - val_loss: 0.3242 - val_accuracy: 0.8842\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.6260 - accuracy: 0.7864 - val_loss: 0.4673 - val_accuracy: 0.8328\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4263 - accuracy: 0.8516 - val_loss: 0.4186 - val_accuracy: 0.8484\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3813 - accuracy: 0.8658 - val_loss: 0.3846 - val_accuracy: 0.8633\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3517 - accuracy: 0.8742 - val_loss: 0.3899 - val_accuracy: 0.8668\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3289 - accuracy: 0.8810 - val_loss: 0.3581 - val_accuracy: 0.8696\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3098 - accuracy: 0.8878 - val_loss: 0.3431 - val_accuracy: 0.8774\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2917 - accuracy: 0.8949 - val_loss: 0.3368 - val_accuracy: 0.8803\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2818 - accuracy: 0.8976 - val_loss: 0.3369 - val_accuracy: 0.8780\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.9012 - val_loss: 0.3361 - val_accuracy: 0.8827\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2583 - accuracy: 0.9060 - val_loss: 0.3300 - val_accuracy: 0.8783\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.6245 - accuracy: 0.7924 - val_loss: 0.4480 - val_accuracy: 0.8458\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4232 - accuracy: 0.8503 - val_loss: 0.4132 - val_accuracy: 0.8532\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3770 - accuracy: 0.8672 - val_loss: 0.4297 - val_accuracy: 0.8386\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3456 - accuracy: 0.8772 - val_loss: 0.3723 - val_accuracy: 0.8651\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3235 - accuracy: 0.8839 - val_loss: 0.3659 - val_accuracy: 0.8716\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3080 - accuracy: 0.8878 - val_loss: 0.3419 - val_accuracy: 0.8774\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2933 - accuracy: 0.8943 - val_loss: 0.3454 - val_accuracy: 0.8782\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2814 - accuracy: 0.8967 - val_loss: 0.3306 - val_accuracy: 0.8813\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2681 - accuracy: 0.9016 - val_loss: 0.3639 - val_accuracy: 0.8679\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2546 - accuracy: 0.9075 - val_loss: 0.3387 - val_accuracy: 0.8806\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.6316 - accuracy: 0.7883 - val_loss: 0.4621 - val_accuracy: 0.8408\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4218 - accuracy: 0.8523 - val_loss: 0.4013 - val_accuracy: 0.8575\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3769 - accuracy: 0.8672 - val_loss: 0.3769 - val_accuracy: 0.8696\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3467 - accuracy: 0.8760 - val_loss: 0.3819 - val_accuracy: 0.8668\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3257 - accuracy: 0.8821 - val_loss: 0.3591 - val_accuracy: 0.8739\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3060 - accuracy: 0.8889 - val_loss: 0.3646 - val_accuracy: 0.8699\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2961 - accuracy: 0.8929 - val_loss: 0.3528 - val_accuracy: 0.8755\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2781 - accuracy: 0.8986 - val_loss: 0.3303 - val_accuracy: 0.8797\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2673 - accuracy: 0.9021 - val_loss: 0.3234 - val_accuracy: 0.8826\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2552 - accuracy: 0.9072 - val_loss: 0.3281 - val_accuracy: 0.8808\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.6293 - accuracy: 0.7891 - val_loss: 0.4568 - val_accuracy: 0.8423\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4313 - accuracy: 0.8487 - val_loss: 0.4168 - val_accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3853 - accuracy: 0.8640 - val_loss: 0.3671 - val_accuracy: 0.8691\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3578 - accuracy: 0.8717 - val_loss: 0.3655 - val_accuracy: 0.8682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3304 - accuracy: 0.8826 - val_loss: 0.3423 - val_accuracy: 0.8758\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3131 - accuracy: 0.8863 - val_loss: 0.3388 - val_accuracy: 0.8786\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2980 - accuracy: 0.8911 - val_loss: 0.3331 - val_accuracy: 0.8792\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2833 - accuracy: 0.8976 - val_loss: 0.3276 - val_accuracy: 0.8846\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2762 - accuracy: 0.9006 - val_loss: 0.3442 - val_accuracy: 0.8742\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2630 - accuracy: 0.9042 - val_loss: 0.3152 - val_accuracy: 0.8881\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.7007 - accuracy: 0.7741 - val_loss: 0.4915 - val_accuracy: 0.8314\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4583 - accuracy: 0.8421 - val_loss: 0.4355 - val_accuracy: 0.8520\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4131 - accuracy: 0.8562 - val_loss: 0.4029 - val_accuracy: 0.8609\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3866 - accuracy: 0.8652 - val_loss: 0.3872 - val_accuracy: 0.8670\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3669 - accuracy: 0.8706 - val_loss: 0.3841 - val_accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3504 - accuracy: 0.8761 - val_loss: 0.3659 - val_accuracy: 0.8716\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3358 - accuracy: 0.8817 - val_loss: 0.3620 - val_accuracy: 0.8742\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3234 - accuracy: 0.8847 - val_loss: 0.3513 - val_accuracy: 0.8758\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3126 - accuracy: 0.8880 - val_loss: 0.3454 - val_accuracy: 0.8798\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3033 - accuracy: 0.8919 - val_loss: 0.3541 - val_accuracy: 0.8739\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.7238 - accuracy: 0.7646 - val_loss: 0.5029 - val_accuracy: 0.8264\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4570 - accuracy: 0.8420 - val_loss: 0.4368 - val_accuracy: 0.8479\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4091 - accuracy: 0.8578 - val_loss: 0.4191 - val_accuracy: 0.8546\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3810 - accuracy: 0.8669 - val_loss: 0.4078 - val_accuracy: 0.8571\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3615 - accuracy: 0.8718 - val_loss: 0.3824 - val_accuracy: 0.8644\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3436 - accuracy: 0.8779 - val_loss: 0.3672 - val_accuracy: 0.8704\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3301 - accuracy: 0.8809 - val_loss: 0.3600 - val_accuracy: 0.8701\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3180 - accuracy: 0.8861 - val_loss: 0.3570 - val_accuracy: 0.8728\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3083 - accuracy: 0.8893 - val_loss: 0.3498 - val_accuracy: 0.8777\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2995 - accuracy: 0.8915 - val_loss: 0.3554 - val_accuracy: 0.8743\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.7056 - accuracy: 0.7748 - val_loss: 0.4997 - val_accuracy: 0.8277\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4627 - accuracy: 0.8401 - val_loss: 0.4405 - val_accuracy: 0.8492\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4173 - accuracy: 0.8553 - val_loss: 0.4072 - val_accuracy: 0.8617\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3889 - accuracy: 0.8633 - val_loss: 0.3947 - val_accuracy: 0.8644\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3693 - accuracy: 0.8708 - val_loss: 0.3852 - val_accuracy: 0.8655\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3527 - accuracy: 0.8767 - val_loss: 0.3715 - val_accuracy: 0.8685\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3375 - accuracy: 0.8812 - val_loss: 0.3577 - val_accuracy: 0.8761\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3248 - accuracy: 0.8848 - val_loss: 0.3526 - val_accuracy: 0.8788\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3161 - accuracy: 0.8864 - val_loss: 0.3520 - val_accuracy: 0.8782\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3068 - accuracy: 0.8893 - val_loss: 0.3447 - val_accuracy: 0.8786\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.6956 - accuracy: 0.7789 - val_loss: 0.4874 - val_accuracy: 0.8324\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4534 - accuracy: 0.8441 - val_loss: 0.4412 - val_accuracy: 0.8428\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4071 - accuracy: 0.8570 - val_loss: 0.4152 - val_accuracy: 0.8581\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3828 - accuracy: 0.8643 - val_loss: 0.4076 - val_accuracy: 0.8579\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3612 - accuracy: 0.8722 - val_loss: 0.3832 - val_accuracy: 0.8653\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3440 - accuracy: 0.8789 - val_loss: 0.3813 - val_accuracy: 0.8693\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3299 - accuracy: 0.8824 - val_loss: 0.3632 - val_accuracy: 0.8704\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3193 - accuracy: 0.8863 - val_loss: 0.3715 - val_accuracy: 0.8642\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3081 - accuracy: 0.8897 - val_loss: 0.3402 - val_accuracy: 0.8792\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.2968 - accuracy: 0.8939 - val_loss: 0.3546 - val_accuracy: 0.8706\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.7168 - accuracy: 0.7665 - val_loss: 0.4907 - val_accuracy: 0.8340\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4557 - accuracy: 0.8431 - val_loss: 0.4362 - val_accuracy: 0.8468\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.4093 - accuracy: 0.8582 - val_loss: 0.4216 - val_accuracy: 0.8502\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3812 - accuracy: 0.8674 - val_loss: 0.3951 - val_accuracy: 0.8591\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3614 - accuracy: 0.8752 - val_loss: 0.3767 - val_accuracy: 0.8676\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3439 - accuracy: 0.8785 - val_loss: 0.3911 - val_accuracy: 0.8591\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3317 - accuracy: 0.8822 - val_loss: 0.3615 - val_accuracy: 0.8705\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3190 - accuracy: 0.8852 - val_loss: 0.3533 - val_accuracy: 0.8745\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3078 - accuracy: 0.8893 - val_loss: 0.3572 - val_accuracy: 0.8720\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 0.3001 - accuracy: 0.8924 - val_loss: 0.3491 - val_accuracy: 0.8748\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.8170 - accuracy: 0.7359 - val_loss: 0.5436 - val_accuracy: 0.8165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.5005 - accuracy: 0.8317 - val_loss: 0.4720 - val_accuracy: 0.8418\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4429 - accuracy: 0.8479 - val_loss: 0.4366 - val_accuracy: 0.8493\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4109 - accuracy: 0.8577 - val_loss: 0.4122 - val_accuracy: 0.8587\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3869 - accuracy: 0.8658 - val_loss: 0.4060 - val_accuracy: 0.8590\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3710 - accuracy: 0.8707 - val_loss: 0.3869 - val_accuracy: 0.8671\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3571 - accuracy: 0.8742 - val_loss: 0.3723 - val_accuracy: 0.8704\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3441 - accuracy: 0.8773 - val_loss: 0.3671 - val_accuracy: 0.8721\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3340 - accuracy: 0.8826 - val_loss: 0.3851 - val_accuracy: 0.8627\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3246 - accuracy: 0.8847 - val_loss: 0.3585 - val_accuracy: 0.8717\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 3ms/step - loss: 0.8073 - accuracy: 0.7395 - val_loss: 0.5406 - val_accuracy: 0.8216\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.5005 - accuracy: 0.8324 - val_loss: 0.4720 - val_accuracy: 0.8378\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4421 - accuracy: 0.8494 - val_loss: 0.4327 - val_accuracy: 0.8522\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4106 - accuracy: 0.8598 - val_loss: 0.4072 - val_accuracy: 0.8582\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3904 - accuracy: 0.8652 - val_loss: 0.3998 - val_accuracy: 0.8586\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3733 - accuracy: 0.8702 - val_loss: 0.3874 - val_accuracy: 0.8651\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3594 - accuracy: 0.8741 - val_loss: 0.3755 - val_accuracy: 0.8673\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3483 - accuracy: 0.8771 - val_loss: 0.3712 - val_accuracy: 0.8694\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3390 - accuracy: 0.8795 - val_loss: 0.3599 - val_accuracy: 0.8734\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3288 - accuracy: 0.8835 - val_loss: 0.3595 - val_accuracy: 0.8734\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 3ms/step - loss: 0.8150 - accuracy: 0.7460 - val_loss: 0.5412 - val_accuracy: 0.8134\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4947 - accuracy: 0.8320 - val_loss: 0.4702 - val_accuracy: 0.8376\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4396 - accuracy: 0.8484 - val_loss: 0.4411 - val_accuracy: 0.8469\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4096 - accuracy: 0.8568 - val_loss: 0.4155 - val_accuracy: 0.8572\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3875 - accuracy: 0.8663 - val_loss: 0.3953 - val_accuracy: 0.8630\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3695 - accuracy: 0.8698 - val_loss: 0.3812 - val_accuracy: 0.8676\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3553 - accuracy: 0.8749 - val_loss: 0.3746 - val_accuracy: 0.8676\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3439 - accuracy: 0.8791 - val_loss: 0.3751 - val_accuracy: 0.8699\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3319 - accuracy: 0.8827 - val_loss: 0.3614 - val_accuracy: 0.8737\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3217 - accuracy: 0.8850 - val_loss: 0.3552 - val_accuracy: 0.8733\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.7826 - accuracy: 0.7551 - val_loss: 0.5403 - val_accuracy: 0.8132\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4914 - accuracy: 0.8347 - val_loss: 0.4689 - val_accuracy: 0.8382\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4401 - accuracy: 0.8486 - val_loss: 0.4327 - val_accuracy: 0.8473\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4103 - accuracy: 0.8587 - val_loss: 0.4146 - val_accuracy: 0.8575\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3885 - accuracy: 0.8656 - val_loss: 0.4085 - val_accuracy: 0.8544\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3717 - accuracy: 0.8704 - val_loss: 0.3867 - val_accuracy: 0.8653\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3586 - accuracy: 0.8738 - val_loss: 0.3816 - val_accuracy: 0.8646\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3467 - accuracy: 0.8782 - val_loss: 0.3852 - val_accuracy: 0.8682\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3355 - accuracy: 0.8818 - val_loss: 0.3668 - val_accuracy: 0.8714\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3251 - accuracy: 0.8848 - val_loss: 0.3739 - val_accuracy: 0.8670\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 3ms/step - loss: 0.8072 - accuracy: 0.7405 - val_loss: 0.5411 - val_accuracy: 0.8142\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4950 - accuracy: 0.8330 - val_loss: 0.4700 - val_accuracy: 0.8360\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4390 - accuracy: 0.8503 - val_loss: 0.4342 - val_accuracy: 0.8493\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4079 - accuracy: 0.8578 - val_loss: 0.4145 - val_accuracy: 0.8541\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3883 - accuracy: 0.8654 - val_loss: 0.4015 - val_accuracy: 0.8598\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3710 - accuracy: 0.8709 - val_loss: 0.3961 - val_accuracy: 0.8615\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3586 - accuracy: 0.8743 - val_loss: 0.3841 - val_accuracy: 0.8625\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3460 - accuracy: 0.8793 - val_loss: 0.3698 - val_accuracy: 0.8710\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3361 - accuracy: 0.8817 - val_loss: 0.3657 - val_accuracy: 0.8692\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.3252 - accuracy: 0.8841 - val_loss: 0.3649 - val_accuracy: 0.8725\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.0635 - accuracy: 0.6826 - val_loss: 0.6264 - val_accuracy: 0.8006\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5572 - accuracy: 0.8171 - val_loss: 0.5117 - val_accuracy: 0.8260\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4827 - accuracy: 0.8376 - val_loss: 0.4747 - val_accuracy: 0.8363\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4485 - accuracy: 0.8486 - val_loss: 0.4537 - val_accuracy: 0.8455\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4227 - accuracy: 0.8574 - val_loss: 0.4292 - val_accuracy: 0.8546\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4064 - accuracy: 0.8625 - val_loss: 0.4224 - val_accuracy: 0.8521\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3912 - accuracy: 0.8670 - val_loss: 0.4096 - val_accuracy: 0.8582\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3803 - accuracy: 0.8695 - val_loss: 0.3960 - val_accuracy: 0.8646\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3681 - accuracy: 0.8726 - val_loss: 0.3953 - val_accuracy: 0.8644\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3599 - accuracy: 0.8753 - val_loss: 0.3833 - val_accuracy: 0.8658\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.9784 - accuracy: 0.7006 - val_loss: 0.6141 - val_accuracy: 0.7975\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5452 - accuracy: 0.8204 - val_loss: 0.5109 - val_accuracy: 0.8257\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4737 - accuracy: 0.8383 - val_loss: 0.4764 - val_accuracy: 0.8322\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4368 - accuracy: 0.8497 - val_loss: 0.4407 - val_accuracy: 0.8477\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4132 - accuracy: 0.8565 - val_loss: 0.4217 - val_accuracy: 0.8542\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3951 - accuracy: 0.8613 - val_loss: 0.4129 - val_accuracy: 0.8580\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3792 - accuracy: 0.8678 - val_loss: 0.3970 - val_accuracy: 0.8607\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3675 - accuracy: 0.8703 - val_loss: 0.3946 - val_accuracy: 0.8607\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3571 - accuracy: 0.8742 - val_loss: 0.3814 - val_accuracy: 0.8656\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3482 - accuracy: 0.8782 - val_loss: 0.3783 - val_accuracy: 0.8689\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.9761 - accuracy: 0.6925 - val_loss: 0.5963 - val_accuracy: 0.8082\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5412 - accuracy: 0.8216 - val_loss: 0.4976 - val_accuracy: 0.8290\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4751 - accuracy: 0.8397 - val_loss: 0.4678 - val_accuracy: 0.8395\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4401 - accuracy: 0.8487 - val_loss: 0.4481 - val_accuracy: 0.8436\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4204 - accuracy: 0.8548 - val_loss: 0.4213 - val_accuracy: 0.8542\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3998 - accuracy: 0.8626 - val_loss: 0.4087 - val_accuracy: 0.8579\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3849 - accuracy: 0.8659 - val_loss: 0.3950 - val_accuracy: 0.8626\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3729 - accuracy: 0.8700 - val_loss: 0.3894 - val_accuracy: 0.8651\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3629 - accuracy: 0.8742 - val_loss: 0.3783 - val_accuracy: 0.8677\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3540 - accuracy: 0.8752 - val_loss: 0.3755 - val_accuracy: 0.8689\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.9789 - accuracy: 0.6930 - val_loss: 0.6007 - val_accuracy: 0.7982\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5377 - accuracy: 0.8239 - val_loss: 0.4988 - val_accuracy: 0.8318\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4674 - accuracy: 0.8419 - val_loss: 0.4553 - val_accuracy: 0.8397\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4324 - accuracy: 0.8530 - val_loss: 0.4308 - val_accuracy: 0.8482\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4093 - accuracy: 0.8583 - val_loss: 0.4178 - val_accuracy: 0.8532\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3921 - accuracy: 0.8637 - val_loss: 0.4033 - val_accuracy: 0.8596\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3787 - accuracy: 0.8680 - val_loss: 0.3898 - val_accuracy: 0.8614\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3654 - accuracy: 0.8734 - val_loss: 0.3891 - val_accuracy: 0.8649\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3561 - accuracy: 0.8759 - val_loss: 0.3748 - val_accuracy: 0.8682\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3463 - accuracy: 0.8791 - val_loss: 0.3865 - val_accuracy: 0.8611\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.9459 - accuracy: 0.7174 - val_loss: 0.5961 - val_accuracy: 0.8033\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.5434 - accuracy: 0.8220 - val_loss: 0.4998 - val_accuracy: 0.8335\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4772 - accuracy: 0.8380 - val_loss: 0.4646 - val_accuracy: 0.8385\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4419 - accuracy: 0.8484 - val_loss: 0.4444 - val_accuracy: 0.8499\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.4186 - accuracy: 0.8562 - val_loss: 0.4208 - val_accuracy: 0.8546\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4018 - accuracy: 0.8612 - val_loss: 0.4094 - val_accuracy: 0.8579\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3857 - accuracy: 0.8665 - val_loss: 0.4018 - val_accuracy: 0.8575\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3747 - accuracy: 0.8698 - val_loss: 0.3968 - val_accuracy: 0.8632\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3628 - accuracy: 0.8743 - val_loss: 0.3860 - val_accuracy: 0.8650\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.3552 - accuracy: 0.8772 - val_loss: 0.3823 - val_accuracy: 0.8665\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 2.2594 - accuracy: 0.2148 - val_loss: 2.0946 - val_accuracy: 0.3428\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9585 - accuracy: 0.4840 - val_loss: 1.8227 - val_accuracy: 0.5797\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.7193 - accuracy: 0.5940 - val_loss: 1.6096 - val_accuracy: 0.6266\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 1.5277 - accuracy: 0.6292 - val_loss: 1.4361 - val_accuracy: 0.6521\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.3738 - accuracy: 0.6503 - val_loss: 1.2980 - val_accuracy: 0.6671\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.2524 - accuracy: 0.6629 - val_loss: 1.1905 - val_accuracy: 0.6794\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.1581 - accuracy: 0.6748 - val_loss: 1.1065 - val_accuracy: 0.6882\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 1.0837 - accuracy: 0.6841 - val_loss: 1.0400 - val_accuracy: 0.7000\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.0240 - accuracy: 0.6939 - val_loss: 0.9865 - val_accuracy: 0.7093\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.9755 - accuracy: 0.7036 - val_loss: 0.9426 - val_accuracy: 0.7178\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 2.2223 - accuracy: 0.1723 - val_loss: 2.0641 - val_accuracy: 0.2457\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9554 - accuracy: 0.3620 - val_loss: 1.8366 - val_accuracy: 0.4910\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7493 - accuracy: 0.5567 - val_loss: 1.6447 - val_accuracy: 0.6160\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.5688 - accuracy: 0.6239 - val_loss: 1.4754 - val_accuracy: 0.6510\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.4175 - accuracy: 0.6475 - val_loss: 1.3416 - val_accuracy: 0.6630\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.2988 - accuracy: 0.6609 - val_loss: 1.2356 - val_accuracy: 0.6746\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.2040 - accuracy: 0.6697 - val_loss: 1.1501 - val_accuracy: 0.6845\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.1265 - accuracy: 0.6791 - val_loss: 1.0803 - val_accuracy: 0.6943\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.0642 - accuracy: 0.6881 - val_loss: 1.0247 - val_accuracy: 0.7045\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.0135 - accuracy: 0.6963 - val_loss: 0.9786 - val_accuracy: 0.7109\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 2.1796 - accuracy: 0.1665 - val_loss: 2.0204 - val_accuracy: 0.3812\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9030 - accuracy: 0.4958 - val_loss: 1.7888 - val_accuracy: 0.5655\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6945 - accuracy: 0.5942 - val_loss: 1.6035 - val_accuracy: 0.6126\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.5297 - accuracy: 0.6247 - val_loss: 1.4565 - val_accuracy: 0.6342\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 1.3980 - accuracy: 0.6420 - val_loss: 1.3392 - val_accuracy: 0.6474\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.2931 - accuracy: 0.6529 - val_loss: 1.2450 - val_accuracy: 0.6529\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.2076 - accuracy: 0.6576 - val_loss: 1.1670 - val_accuracy: 0.6608\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.1373 - accuracy: 0.6641 - val_loss: 1.1032 - val_accuracy: 0.6647\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.0787 - accuracy: 0.6702 - val_loss: 1.0490 - val_accuracy: 0.6708\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.0285 - accuracy: 0.6780 - val_loss: 1.0031 - val_accuracy: 0.6797\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 2.2410 - accuracy: 0.1447 - val_loss: 2.0947 - val_accuracy: 0.2892\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9711 - accuracy: 0.3953 - val_loss: 1.8524 - val_accuracy: 0.4806\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7493 - accuracy: 0.5305 - val_loss: 1.6460 - val_accuracy: 0.5804\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.5634 - accuracy: 0.6025 - val_loss: 1.4743 - val_accuracy: 0.6303\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.4106 - accuracy: 0.6333 - val_loss: 1.3353 - val_accuracy: 0.6542\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.2888 - accuracy: 0.6516 - val_loss: 1.2257 - val_accuracy: 0.6652\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.1930 - accuracy: 0.6625 - val_loss: 1.1404 - val_accuracy: 0.6760\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.1176 - accuracy: 0.6723 - val_loss: 1.0727 - val_accuracy: 0.6878\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.0569 - accuracy: 0.6827 - val_loss: 1.0179 - val_accuracy: 0.6953\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.0069 - accuracy: 0.6910 - val_loss: 0.9722 - val_accuracy: 0.7070\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 2.2136 - accuracy: 0.2169 - val_loss: 2.0710 - val_accuracy: 0.3574\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9661 - accuracy: 0.4323 - val_loss: 1.8546 - val_accuracy: 0.5111\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7662 - accuracy: 0.5447 - val_loss: 1.6666 - val_accuracy: 0.5861\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.5909 - accuracy: 0.5996 - val_loss: 1.5024 - val_accuracy: 0.6208\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.4421 - accuracy: 0.6295 - val_loss: 1.3673 - val_accuracy: 0.6440\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.3221 - accuracy: 0.6474 - val_loss: 1.2595 - val_accuracy: 0.6596\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.2266 - accuracy: 0.6589 - val_loss: 1.1745 - val_accuracy: 0.6708\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.1501 - accuracy: 0.6678 - val_loss: 1.1053 - val_accuracy: 0.6805\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.0883 - accuracy: 0.6768 - val_loss: 1.0495 - val_accuracy: 0.6866\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.0374 - accuracy: 0.6852 - val_loss: 1.0028 - val_accuracy: 0.6951\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.3668 - accuracy: 0.1023 - val_loss: 2.2375 - val_accuracy: 0.1214\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.1366 - accuracy: 0.2197 - val_loss: 2.0438 - val_accuracy: 0.3220\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.9618 - accuracy: 0.3846 - val_loss: 1.8840 - val_accuracy: 0.4364\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.8139 - accuracy: 0.4828 - val_loss: 1.7431 - val_accuracy: 0.5300\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.6819 - accuracy: 0.5613 - val_loss: 1.6186 - val_accuracy: 0.5910\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.5687 - accuracy: 0.6054 - val_loss: 1.5125 - val_accuracy: 0.6247\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.4710 - accuracy: 0.6325 - val_loss: 1.4207 - val_accuracy: 0.6485\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.3862 - accuracy: 0.6496 - val_loss: 1.3408 - val_accuracy: 0.6605\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.3123 - accuracy: 0.6598 - val_loss: 1.2717 - val_accuracy: 0.6707\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.2485 - accuracy: 0.6684 - val_loss: 1.2119 - val_accuracy: 0.6765\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.2887 - accuracy: 0.1289 - val_loss: 2.1602 - val_accuracy: 0.2129\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.0659 - accuracy: 0.2853 - val_loss: 1.9734 - val_accuracy: 0.3722\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.9009 - accuracy: 0.4397 - val_loss: 1.8231 - val_accuracy: 0.5065\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.7604 - accuracy: 0.5504 - val_loss: 1.6913 - val_accuracy: 0.5911\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.6354 - accuracy: 0.6149 - val_loss: 1.5724 - val_accuracy: 0.6335\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.5217 - accuracy: 0.6472 - val_loss: 1.4642 - val_accuracy: 0.6591\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.4207 - accuracy: 0.6651 - val_loss: 1.3703 - val_accuracy: 0.6685\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.3334 - accuracy: 0.6739 - val_loss: 1.2893 - val_accuracy: 0.6761\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.2586 - accuracy: 0.6796 - val_loss: 1.2199 - val_accuracy: 0.6848\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.1939 - accuracy: 0.6863 - val_loss: 1.1599 - val_accuracy: 0.6873\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.2222 - accuracy: 0.1557 - val_loss: 2.1172 - val_accuracy: 0.2200\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.0320 - accuracy: 0.3051 - val_loss: 1.9507 - val_accuracy: 0.3819\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 2s 3ms/step - loss: 1.8830 - accuracy: 0.4552 - val_loss: 1.8138 - val_accuracy: 0.5122\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.7565 - accuracy: 0.5519 - val_loss: 1.6946 - val_accuracy: 0.5845\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.6450 - accuracy: 0.5993 - val_loss: 1.5879 - val_accuracy: 0.6208\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.5438 - accuracy: 0.6247 - val_loss: 1.4900 - val_accuracy: 0.6386\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.4522 - accuracy: 0.6406 - val_loss: 1.4027 - val_accuracy: 0.6538\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.3711 - accuracy: 0.6513 - val_loss: 1.3258 - val_accuracy: 0.6607\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.2995 - accuracy: 0.6576 - val_loss: 1.2580 - val_accuracy: 0.6691\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.2361 - accuracy: 0.6640 - val_loss: 1.1977 - val_accuracy: 0.6758\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.2659 - accuracy: 0.1272 - val_loss: 2.1483 - val_accuracy: 0.2050\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.0585 - accuracy: 0.3249 - val_loss: 1.9616 - val_accuracy: 0.4169\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.8862 - accuracy: 0.4826 - val_loss: 1.8035 - val_accuracy: 0.5367\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.7430 - accuracy: 0.5639 - val_loss: 1.6718 - val_accuracy: 0.5905\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.6209 - accuracy: 0.6015 - val_loss: 1.5580 - val_accuracy: 0.6175\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.5145 - accuracy: 0.6228 - val_loss: 1.4578 - val_accuracy: 0.6351\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.4202 - accuracy: 0.6358 - val_loss: 1.3690 - val_accuracy: 0.6451\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.3372 - accuracy: 0.6446 - val_loss: 1.2909 - val_accuracy: 0.6544\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.2643 - accuracy: 0.6524 - val_loss: 1.2225 - val_accuracy: 0.6607\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.2013 - accuracy: 0.6590 - val_loss: 1.1640 - val_accuracy: 0.6687\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.3208 - accuracy: 0.1599 - val_loss: 2.1997 - val_accuracy: 0.2031\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.1074 - accuracy: 0.3102 - val_loss: 2.0116 - val_accuracy: 0.4194\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.9330 - accuracy: 0.4778 - val_loss: 1.8492 - val_accuracy: 0.5206\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.7822 - accuracy: 0.5536 - val_loss: 1.7070 - val_accuracy: 0.5769\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.6516 - accuracy: 0.5939 - val_loss: 1.5849 - val_accuracy: 0.6092\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.5392 - accuracy: 0.6175 - val_loss: 1.4792 - val_accuracy: 0.6268\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.4424 - accuracy: 0.6306 - val_loss: 1.3880 - val_accuracy: 0.6431\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.3586 - accuracy: 0.6415 - val_loss: 1.3088 - val_accuracy: 0.6514\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.2858 - accuracy: 0.6485 - val_loss: 1.2402 - val_accuracy: 0.6600\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.2230 - accuracy: 0.6553 - val_loss: 1.1815 - val_accuracy: 0.6684\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.2529 - accuracy: 0.0914 - val_loss: 2.1731 - val_accuracy: 0.1375\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1127 - accuracy: 0.2029 - val_loss: 2.0438 - val_accuracy: 0.2811\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9906 - accuracy: 0.3326 - val_loss: 1.9254 - val_accuracy: 0.3961\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.8788 - accuracy: 0.4366 - val_loss: 1.8191 - val_accuracy: 0.4835\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.7803 - accuracy: 0.4968 - val_loss: 1.7267 - val_accuracy: 0.5230\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.6939 - accuracy: 0.5288 - val_loss: 1.6451 - val_accuracy: 0.5506\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.6166 - accuracy: 0.5578 - val_loss: 1.5713 - val_accuracy: 0.5798\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5455 - accuracy: 0.5899 - val_loss: 1.5029 - val_accuracy: 0.6111\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.4797 - accuracy: 0.6171 - val_loss: 1.4397 - val_accuracy: 0.6352\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.4195 - accuracy: 0.6349 - val_loss: 1.3823 - val_accuracy: 0.6484\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.2491 - accuracy: 0.1727 - val_loss: 2.1668 - val_accuracy: 0.2078\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.0966 - accuracy: 0.2806 - val_loss: 2.0245 - val_accuracy: 0.3407\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.9646 - accuracy: 0.3973 - val_loss: 1.8972 - val_accuracy: 0.4370\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.8445 - accuracy: 0.4733 - val_loss: 1.7801 - val_accuracy: 0.5077\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.7346 - accuracy: 0.5297 - val_loss: 1.6753 - val_accuracy: 0.5580\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.6378 - accuracy: 0.5642 - val_loss: 1.5840 - val_accuracy: 0.5875\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5532 - accuracy: 0.5866 - val_loss: 1.5044 - val_accuracy: 0.6052\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.4794 - accuracy: 0.6051 - val_loss: 1.4349 - val_accuracy: 0.6175\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.4145 - accuracy: 0.6184 - val_loss: 1.3733 - val_accuracy: 0.6314\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.3567 - accuracy: 0.6299 - val_loss: 1.3182 - val_accuracy: 0.6435\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.3391 - accuracy: 0.1132 - val_loss: 2.2834 - val_accuracy: 0.1146\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2312 - accuracy: 0.1329 - val_loss: 2.1829 - val_accuracy: 0.1491\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.1368 - accuracy: 0.1846 - val_loss: 2.0932 - val_accuracy: 0.2231\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.0506 - accuracy: 0.2766 - val_loss: 2.0091 - val_accuracy: 0.3260\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.9686 - accuracy: 0.3785 - val_loss: 1.9292 - val_accuracy: 0.4173\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.8917 - accuracy: 0.4570 - val_loss: 1.8549 - val_accuracy: 0.4768\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.8194 - accuracy: 0.5021 - val_loss: 1.7843 - val_accuracy: 0.5157\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.7507 - accuracy: 0.5392 - val_loss: 1.7175 - val_accuracy: 0.5547\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.6862 - accuracy: 0.5695 - val_loss: 1.6545 - val_accuracy: 0.5816\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.6253 - accuracy: 0.5933 - val_loss: 1.5950 - val_accuracy: 0.6039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.3220 - accuracy: 0.0639 - val_loss: 2.2538 - val_accuracy: 0.0900\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1903 - accuracy: 0.1542 - val_loss: 2.1288 - val_accuracy: 0.2307\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0729 - accuracy: 0.3046 - val_loss: 2.0165 - val_accuracy: 0.3818\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9673 - accuracy: 0.4291 - val_loss: 1.9152 - val_accuracy: 0.4794\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.8708 - accuracy: 0.5061 - val_loss: 1.8217 - val_accuracy: 0.5424\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.7815 - accuracy: 0.5570 - val_loss: 1.7349 - val_accuracy: 0.5851\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.6982 - accuracy: 0.5953 - val_loss: 1.6538 - val_accuracy: 0.6147\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.6207 - accuracy: 0.6182 - val_loss: 1.5791 - val_accuracy: 0.6330\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5499 - accuracy: 0.6343 - val_loss: 1.5112 - val_accuracy: 0.6466\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.4855 - accuracy: 0.6466 - val_loss: 1.4494 - val_accuracy: 0.6564\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.3294 - accuracy: 0.0765 - val_loss: 2.2530 - val_accuracy: 0.1108\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1924 - accuracy: 0.1717 - val_loss: 2.1215 - val_accuracy: 0.2581\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.0671 - accuracy: 0.3329 - val_loss: 2.0005 - val_accuracy: 0.4147\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.9532 - accuracy: 0.4527 - val_loss: 1.8915 - val_accuracy: 0.5048\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.8487 - accuracy: 0.5241 - val_loss: 1.7897 - val_accuracy: 0.5633\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.7505 - accuracy: 0.5726 - val_loss: 1.6951 - val_accuracy: 0.6058\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.6608 - accuracy: 0.6035 - val_loss: 1.6088 - val_accuracy: 0.6307\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.5790 - accuracy: 0.6250 - val_loss: 1.5303 - val_accuracy: 0.6463\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.5050 - accuracy: 0.6384 - val_loss: 1.4594 - val_accuracy: 0.6568\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.4386 - accuracy: 0.6477 - val_loss: 1.3961 - val_accuracy: 0.6645\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 2.2036 - accuracy: 0.1750 - val_loss: 2.1214 - val_accuracy: 0.2374\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 2.0460 - accuracy: 0.3103 - val_loss: 1.9725 - val_accuracy: 0.3797\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.9107 - accuracy: 0.4360 - val_loss: 1.8458 - val_accuracy: 0.4822\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7934 - accuracy: 0.5163 - val_loss: 1.7350 - val_accuracy: 0.5469\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.6894 - accuracy: 0.5642 - val_loss: 1.6361 - val_accuracy: 0.5871\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.5961 - accuracy: 0.5956 - val_loss: 1.5476 - val_accuracy: 0.6103\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.5131 - accuracy: 0.6175 - val_loss: 1.4694 - val_accuracy: 0.6265\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 1.4394 - accuracy: 0.6321 - val_loss: 1.4004 - val_accuracy: 0.6390\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 1.3741 - accuracy: 0.6432 - val_loss: 1.3390 - val_accuracy: 0.6489\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.3156 - accuracy: 0.6528 - val_loss: 1.2840 - val_accuracy: 0.6582\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 2.2462 - accuracy: 0.2080 - val_loss: 2.1621 - val_accuracy: 0.2926\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 2.0940 - accuracy: 0.3707 - val_loss: 2.0195 - val_accuracy: 0.4473\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.9578 - accuracy: 0.4985 - val_loss: 1.8901 - val_accuracy: 0.5425\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8358 - accuracy: 0.5610 - val_loss: 1.7734 - val_accuracy: 0.5824\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7247 - accuracy: 0.5884 - val_loss: 1.6663 - val_accuracy: 0.6052\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6243 - accuracy: 0.6084 - val_loss: 1.5707 - val_accuracy: 0.6288\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.5353 - accuracy: 0.6283 - val_loss: 1.4866 - val_accuracy: 0.6465\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.4573 - accuracy: 0.6413 - val_loss: 1.4128 - val_accuracy: 0.6565\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.3888 - accuracy: 0.6522 - val_loss: 1.3480 - val_accuracy: 0.6653\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.3284 - accuracy: 0.6579 - val_loss: 1.2901 - val_accuracy: 0.6692\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 2.3421 - accuracy: 0.0993 - val_loss: 2.2205 - val_accuracy: 0.1299\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1319 - accuracy: 0.2190 - val_loss: 2.0616 - val_accuracy: 0.2675\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.9949 - accuracy: 0.3162 - val_loss: 1.9373 - val_accuracy: 0.3543\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.8782 - accuracy: 0.4052 - val_loss: 1.8272 - val_accuracy: 0.4386\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7748 - accuracy: 0.4807 - val_loss: 1.7287 - val_accuracy: 0.5094\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6822 - accuracy: 0.5392 - val_loss: 1.6399 - val_accuracy: 0.5624\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.5977 - accuracy: 0.5796 - val_loss: 1.5576 - val_accuracy: 0.5952\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.5199 - accuracy: 0.6063 - val_loss: 1.4828 - val_accuracy: 0.6156\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.4498 - accuracy: 0.6237 - val_loss: 1.4158 - val_accuracy: 0.6304\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 1.3871 - accuracy: 0.6350 - val_loss: 1.3556 - val_accuracy: 0.6431\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.2423 - accuracy: 0.1752 - val_loss: 2.1660 - val_accuracy: 0.2537\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0981 - accuracy: 0.3137 - val_loss: 2.0298 - val_accuracy: 0.3744\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.9711 - accuracy: 0.4090 - val_loss: 1.9072 - val_accuracy: 0.4495\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8563 - accuracy: 0.4827 - val_loss: 1.7967 - val_accuracy: 0.5165\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7515 - accuracy: 0.5470 - val_loss: 1.6955 - val_accuracy: 0.5731\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.6551 - accuracy: 0.5921 - val_loss: 1.6024 - val_accuracy: 0.6093\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.5676 - accuracy: 0.6184 - val_loss: 1.5191 - val_accuracy: 0.6320\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.4895 - accuracy: 0.6307 - val_loss: 1.4448 - val_accuracy: 0.6426\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.4198 - accuracy: 0.6415 - val_loss: 1.3785 - val_accuracy: 0.6520\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.3576 - accuracy: 0.6487 - val_loss: 1.3197 - val_accuracy: 0.6592\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 5s 3ms/step - loss: 2.3132 - accuracy: 0.1214 - val_loss: 2.2244 - val_accuracy: 0.1632\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 2.1497 - accuracy: 0.2176 - val_loss: 2.0811 - val_accuracy: 0.2663\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0197 - accuracy: 0.3253 - val_loss: 1.9591 - val_accuracy: 0.3989\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 1.9071 - accuracy: 0.4623 - val_loss: 1.8514 - val_accuracy: 0.5257\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.8051 - accuracy: 0.5492 - val_loss: 1.7526 - val_accuracy: 0.5835\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.7107 - accuracy: 0.5889 - val_loss: 1.6615 - val_accuracy: 0.6103\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.6244 - accuracy: 0.6101 - val_loss: 1.5782 - val_accuracy: 0.6266\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.5455 - accuracy: 0.6255 - val_loss: 1.5026 - val_accuracy: 0.6372\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.4741 - accuracy: 0.6359 - val_loss: 1.4346 - val_accuracy: 0.6466\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 1.4094 - accuracy: 0.6447 - val_loss: 1.3721 - val_accuracy: 0.6535\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.3526 - accuracy: 0.0922 - val_loss: 2.2916 - val_accuracy: 0.0983\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.2395 - accuracy: 0.1116 - val_loss: 2.1899 - val_accuracy: 0.1278\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.1464 - accuracy: 0.1654 - val_loss: 2.1019 - val_accuracy: 0.2064\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.0644 - accuracy: 0.2624 - val_loss: 2.0235 - val_accuracy: 0.3116\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.9909 - accuracy: 0.3525 - val_loss: 1.9525 - val_accuracy: 0.3864\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 1.9233 - accuracy: 0.4143 - val_loss: 1.8868 - val_accuracy: 0.4383\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.8603 - accuracy: 0.4627 - val_loss: 1.8253 - val_accuracy: 0.4804\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.8010 - accuracy: 0.5004 - val_loss: 1.7667 - val_accuracy: 0.5157\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.7447 - accuracy: 0.5337 - val_loss: 1.7117 - val_accuracy: 0.5473\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.6923 - accuracy: 0.5597 - val_loss: 1.6610 - val_accuracy: 0.5741\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.2593 - accuracy: 0.1502 - val_loss: 2.1798 - val_accuracy: 0.1920\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.1236 - accuracy: 0.2319 - val_loss: 2.0573 - val_accuracy: 0.2803\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.0112 - accuracy: 0.3204 - val_loss: 1.9526 - val_accuracy: 0.3675\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.9127 - accuracy: 0.3910 - val_loss: 1.8596 - val_accuracy: 0.4301\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.8247 - accuracy: 0.4505 - val_loss: 1.7763 - val_accuracy: 0.4880\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.7453 - accuracy: 0.5033 - val_loss: 1.7006 - val_accuracy: 0.5306\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.6730 - accuracy: 0.5418 - val_loss: 1.6315 - val_accuracy: 0.5616\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 1.6068 - accuracy: 0.5699 - val_loss: 1.5685 - val_accuracy: 0.5864\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.5471 - accuracy: 0.5934 - val_loss: 1.5118 - val_accuracy: 0.6040\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.4933 - accuracy: 0.6114 - val_loss: 1.4604 - val_accuracy: 0.6235\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.3237 - accuracy: 0.1158 - val_loss: 2.2531 - val_accuracy: 0.1336\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.2051 - accuracy: 0.1610 - val_loss: 2.1487 - val_accuracy: 0.2005\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.1099 - accuracy: 0.2327 - val_loss: 2.0599 - val_accuracy: 0.2796\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.0247 - accuracy: 0.3127 - val_loss: 1.9779 - val_accuracy: 0.3648\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.9449 - accuracy: 0.3929 - val_loss: 1.9007 - val_accuracy: 0.4466\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 1.8702 - accuracy: 0.4688 - val_loss: 1.8289 - val_accuracy: 0.5039\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 1.8007 - accuracy: 0.5165 - val_loss: 1.7622 - val_accuracy: 0.5418\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.7361 - accuracy: 0.5470 - val_loss: 1.7002 - val_accuracy: 0.5661\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 1.6758 - accuracy: 0.5694 - val_loss: 1.6417 - val_accuracy: 0.5828\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.6190 - accuracy: 0.5864 - val_loss: 1.5865 - val_accuracy: 0.6022\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.4257 - accuracy: 0.1273 - val_loss: 2.3485 - val_accuracy: 0.1294\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.2796 - accuracy: 0.1414 - val_loss: 2.2220 - val_accuracy: 0.1540\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.1668 - accuracy: 0.1900 - val_loss: 2.1177 - val_accuracy: 0.2286\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 2.0700 - accuracy: 0.2810 - val_loss: 2.0242 - val_accuracy: 0.3345\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 1.9828 - accuracy: 0.3837 - val_loss: 1.9404 - val_accuracy: 0.4336\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 1.9061 - accuracy: 0.4718 - val_loss: 1.8666 - val_accuracy: 0.5031\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.8374 - accuracy: 0.5209 - val_loss: 1.7998 - val_accuracy: 0.5372\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.7743 - accuracy: 0.5426 - val_loss: 1.7379 - val_accuracy: 0.5571\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.7152 - accuracy: 0.5582 - val_loss: 1.6797 - val_accuracy: 0.5694\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.6591 - accuracy: 0.5712 - val_loss: 1.6241 - val_accuracy: 0.5815\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.2664 - accuracy: 0.0863 - val_loss: 2.2157 - val_accuracy: 0.1441\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.1747 - accuracy: 0.2017 - val_loss: 2.1322 - val_accuracy: 0.2589\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.0973 - accuracy: 0.2938 - val_loss: 2.0569 - val_accuracy: 0.3326\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.0248 - accuracy: 0.3612 - val_loss: 1.9850 - val_accuracy: 0.3969\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 2s 4ms/step - loss: 1.9553 - accuracy: 0.4199 - val_loss: 1.9167 - val_accuracy: 0.4555\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.8900 - accuracy: 0.4647 - val_loss: 1.8534 - val_accuracy: 0.4894\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.8299 - accuracy: 0.4954 - val_loss: 1.7950 - val_accuracy: 0.5149\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 1.7743 - accuracy: 0.5170 - val_loss: 1.7408 - val_accuracy: 0.5309\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.7225 - accuracy: 0.5328 - val_loss: 1.6903 - val_accuracy: 0.5434\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.6747 - accuracy: 0.5434 - val_loss: 1.6440 - val_accuracy: 0.5523\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.3823 - accuracy: 0.0529 - val_loss: 2.3434 - val_accuracy: 0.0640\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.3083 - accuracy: 0.0887 - val_loss: 2.2709 - val_accuracy: 0.1168\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.2379 - accuracy: 0.1459 - val_loss: 2.2028 - val_accuracy: 0.1728\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1721 - accuracy: 0.2102 - val_loss: 2.1391 - val_accuracy: 0.2369\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.1101 - accuracy: 0.2758 - val_loss: 2.0783 - val_accuracy: 0.3061\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.0507 - accuracy: 0.3407 - val_loss: 2.0196 - val_accuracy: 0.3742\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9934 - accuracy: 0.3980 - val_loss: 1.9628 - val_accuracy: 0.4232\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.9382 - accuracy: 0.4410 - val_loss: 1.9082 - val_accuracy: 0.4606\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.8853 - accuracy: 0.4730 - val_loss: 1.8560 - val_accuracy: 0.4911\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.8348 - accuracy: 0.4974 - val_loss: 1.8060 - val_accuracy: 0.5109\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 3s 6ms/step - loss: 2.3704 - accuracy: 0.1123 - val_loss: 2.3282 - val_accuracy: 0.1171\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.2848 - accuracy: 0.1352 - val_loss: 2.2468 - val_accuracy: 0.1379\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.2081 - accuracy: 0.1631 - val_loss: 2.1724 - val_accuracy: 0.1777\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.1373 - accuracy: 0.2159 - val_loss: 2.1035 - val_accuracy: 0.2360\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.0713 - accuracy: 0.2689 - val_loss: 2.0389 - val_accuracy: 0.2870\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.0088 - accuracy: 0.3196 - val_loss: 1.9772 - val_accuracy: 0.3396\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.9490 - accuracy: 0.3713 - val_loss: 1.9182 - val_accuracy: 0.3939\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.8919 - accuracy: 0.4252 - val_loss: 1.8621 - val_accuracy: 0.4473\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.8377 - accuracy: 0.4712 - val_loss: 1.8089 - val_accuracy: 0.4930\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.7867 - accuracy: 0.5096 - val_loss: 1.7587 - val_accuracy: 0.5307\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.3749 - accuracy: 0.0583 - val_loss: 2.3354 - val_accuracy: 0.0775\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.2918 - accuracy: 0.1060 - val_loss: 2.2529 - val_accuracy: 0.1390\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.2139 - accuracy: 0.1698 - val_loss: 2.1753 - val_accuracy: 0.2115\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.1398 - accuracy: 0.2406 - val_loss: 2.1013 - val_accuracy: 0.2844\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.0685 - accuracy: 0.3201 - val_loss: 2.0300 - val_accuracy: 0.3684\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.9995 - accuracy: 0.3982 - val_loss: 1.9611 - val_accuracy: 0.4330\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.9330 - accuracy: 0.4521 - val_loss: 1.8954 - val_accuracy: 0.4753\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.8700 - accuracy: 0.4876 - val_loss: 1.8336 - val_accuracy: 0.5092\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.8102 - accuracy: 0.5196 - val_loss: 1.7745 - val_accuracy: 0.5396\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.7527 - accuracy: 0.5501 - val_loss: 1.7176 - val_accuracy: 0.5659\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.3135 - accuracy: 0.1395 - val_loss: 2.2738 - val_accuracy: 0.1734\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2492 - accuracy: 0.1824 - val_loss: 2.2098 - val_accuracy: 0.2087\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.1875 - accuracy: 0.2178 - val_loss: 2.1488 - val_accuracy: 0.2421\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.1285 - accuracy: 0.2588 - val_loss: 2.0902 - val_accuracy: 0.2893\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.0719 - accuracy: 0.3165 - val_loss: 2.0343 - val_accuracy: 0.3531\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.0178 - accuracy: 0.3812 - val_loss: 1.9807 - val_accuracy: 0.4168\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.9657 - accuracy: 0.4320 - val_loss: 1.9290 - val_accuracy: 0.4616\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.9151 - accuracy: 0.4671 - val_loss: 1.8785 - val_accuracy: 0.4906\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.8657 - accuracy: 0.4894 - val_loss: 1.8293 - val_accuracy: 0.5106\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.8178 - accuracy: 0.5066 - val_loss: 1.7824 - val_accuracy: 0.5241\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 4s 5ms/step - loss: 2.3245 - accuracy: 0.1793 - val_loss: 2.2875 - val_accuracy: 0.1906\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.2586 - accuracy: 0.1952 - val_loss: 2.2230 - val_accuracy: 0.2141\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.1950 - accuracy: 0.2162 - val_loss: 2.1603 - val_accuracy: 0.2335\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.1332 - accuracy: 0.2411 - val_loss: 2.0993 - val_accuracy: 0.2596\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0740 - accuracy: 0.2648 - val_loss: 2.0412 - val_accuracy: 0.2821\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.0179 - accuracy: 0.2885 - val_loss: 1.9871 - val_accuracy: 0.3054\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9656 - accuracy: 0.3119 - val_loss: 1.9366 - val_accuracy: 0.3294\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.9168 - accuracy: 0.3391 - val_loss: 1.8894 - val_accuracy: 0.3587\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.8712 - accuracy: 0.3722 - val_loss: 1.8453 - val_accuracy: 0.3944\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.8282 - accuracy: 0.4127 - val_loss: 1.8031 - val_accuracy: 0.4370\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3707 - accuracy: 0.1115 - val_loss: 2.3418 - val_accuracy: 0.1297\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3249 - accuracy: 0.1501 - val_loss: 2.2976 - val_accuracy: 0.1679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.2829 - accuracy: 0.1862 - val_loss: 2.2569 - val_accuracy: 0.2030\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.2442 - accuracy: 0.2187 - val_loss: 2.2192 - val_accuracy: 0.2377\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.2082 - accuracy: 0.2482 - val_loss: 2.1842 - val_accuracy: 0.2658\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1751 - accuracy: 0.2745 - val_loss: 2.1519 - val_accuracy: 0.2927\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1442 - accuracy: 0.2978 - val_loss: 2.1218 - val_accuracy: 0.3169\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1152 - accuracy: 0.3236 - val_loss: 2.0933 - val_accuracy: 0.3409\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0875 - accuracy: 0.3486 - val_loss: 2.0658 - val_accuracy: 0.3668\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0608 - accuracy: 0.3737 - val_loss: 2.0393 - val_accuracy: 0.3941\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 2.3292 - accuracy: 0.1103 - val_loss: 2.3005 - val_accuracy: 0.1181\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.2900 - accuracy: 0.1247 - val_loss: 2.2638 - val_accuracy: 0.1340\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.2543 - accuracy: 0.1385 - val_loss: 2.2303 - val_accuracy: 0.1495\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 3s 3ms/step - loss: 2.2216 - accuracy: 0.1533 - val_loss: 2.1995 - val_accuracy: 0.1688\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1915 - accuracy: 0.1706 - val_loss: 2.1709 - val_accuracy: 0.1867\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1635 - accuracy: 0.1930 - val_loss: 2.1443 - val_accuracy: 0.2119\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1374 - accuracy: 0.2195 - val_loss: 2.1193 - val_accuracy: 0.2387\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1125 - accuracy: 0.2481 - val_loss: 2.0953 - val_accuracy: 0.2694\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0887 - accuracy: 0.2810 - val_loss: 2.0722 - val_accuracy: 0.3014\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0658 - accuracy: 0.3157 - val_loss: 2.0500 - val_accuracy: 0.3388\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.2639 - accuracy: 0.1709 - val_loss: 2.2417 - val_accuracy: 0.1823\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 2.2305 - accuracy: 0.1949 - val_loss: 2.2090 - val_accuracy: 0.2064\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1984 - accuracy: 0.2162 - val_loss: 2.1776 - val_accuracy: 0.2271\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 2.1676 - accuracy: 0.2361 - val_loss: 2.1476 - val_accuracy: 0.2470\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1381 - accuracy: 0.2575 - val_loss: 2.1190 - val_accuracy: 0.2677\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 2.1099 - accuracy: 0.2772 - val_loss: 2.0913 - val_accuracy: 0.2884\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 2.0827 - accuracy: 0.2977 - val_loss: 2.0648 - val_accuracy: 0.3072\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 2.0566 - accuracy: 0.3132 - val_loss: 2.0391 - val_accuracy: 0.3229\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 2.0312 - accuracy: 0.3281 - val_loss: 2.0142 - val_accuracy: 0.3396\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 2.0067 - accuracy: 0.3444 - val_loss: 1.9901 - val_accuracy: 0.3594\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 2.2995 - accuracy: 0.0685 - val_loss: 2.2751 - val_accuracy: 0.0880\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.2638 - accuracy: 0.1009 - val_loss: 2.2407 - val_accuracy: 0.1235\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.2309 - accuracy: 0.1378 - val_loss: 2.2089 - val_accuracy: 0.1634\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.2002 - accuracy: 0.1760 - val_loss: 2.1787 - val_accuracy: 0.2005\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1707 - accuracy: 0.2140 - val_loss: 2.1494 - val_accuracy: 0.2410\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1422 - accuracy: 0.2509 - val_loss: 2.1211 - val_accuracy: 0.2798\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1144 - accuracy: 0.2866 - val_loss: 2.0935 - val_accuracy: 0.3161\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 2.0873 - accuracy: 0.3223 - val_loss: 2.0665 - val_accuracy: 0.3502\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0608 - accuracy: 0.3524 - val_loss: 2.0400 - val_accuracy: 0.3785\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 2.0349 - accuracy: 0.3798 - val_loss: 2.0141 - val_accuracy: 0.4007\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 2.3414 - accuracy: 0.0531 - val_loss: 2.3242 - val_accuracy: 0.0534\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.3012 - accuracy: 0.0684 - val_loss: 2.2854 - val_accuracy: 0.0719\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.2648 - accuracy: 0.0944 - val_loss: 2.2499 - val_accuracy: 0.1014\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.2313 - accuracy: 0.1222 - val_loss: 2.2171 - val_accuracy: 0.1245\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 4s 4ms/step - loss: 2.1999 - accuracy: 0.1432 - val_loss: 2.1863 - val_accuracy: 0.1404\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1704 - accuracy: 0.1587 - val_loss: 2.1570 - val_accuracy: 0.1574\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1422 - accuracy: 0.1770 - val_loss: 2.1292 - val_accuracy: 0.1783\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.1155 - accuracy: 0.1969 - val_loss: 2.1027 - val_accuracy: 0.2005\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0900 - accuracy: 0.2209 - val_loss: 2.0773 - val_accuracy: 0.2245\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 2.0653 - accuracy: 0.2460 - val_loss: 2.0525 - val_accuracy: 0.2544\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 2.3991 - accuracy: 0.1327 - val_loss: 2.3768 - val_accuracy: 0.1394\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.3691 - accuracy: 0.1371 - val_loss: 2.3470 - val_accuracy: 0.1444\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.3402 - accuracy: 0.1430 - val_loss: 2.3186 - val_accuracy: 0.1491\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.3126 - accuracy: 0.1485 - val_loss: 2.2915 - val_accuracy: 0.1552\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.2861 - accuracy: 0.1538 - val_loss: 2.2655 - val_accuracy: 0.1596\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.2611 - accuracy: 0.1593 - val_loss: 2.2411 - val_accuracy: 0.1666\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.2372 - accuracy: 0.1643 - val_loss: 2.2177 - val_accuracy: 0.1711\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.2143 - accuracy: 0.1696 - val_loss: 2.1951 - val_accuracy: 0.1770\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.1923 - accuracy: 0.1761 - val_loss: 2.1736 - val_accuracy: 0.1846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.1712 - accuracy: 0.1840 - val_loss: 2.1529 - val_accuracy: 0.1937\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.4037 - accuracy: 0.0532 - val_loss: 2.3924 - val_accuracy: 0.0555\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.3710 - accuracy: 0.0560 - val_loss: 2.3596 - val_accuracy: 0.0591\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.3397 - accuracy: 0.0638 - val_loss: 2.3279 - val_accuracy: 0.0705\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.3094 - accuracy: 0.0766 - val_loss: 2.2974 - val_accuracy: 0.0877\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.2805 - accuracy: 0.0952 - val_loss: 2.2685 - val_accuracy: 0.1064\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.2531 - accuracy: 0.1161 - val_loss: 2.2411 - val_accuracy: 0.1255\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.2270 - accuracy: 0.1365 - val_loss: 2.2150 - val_accuracy: 0.1467\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.2022 - accuracy: 0.1564 - val_loss: 2.1902 - val_accuracy: 0.1663\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.1785 - accuracy: 0.1760 - val_loss: 2.1664 - val_accuracy: 0.1871\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.1557 - accuracy: 0.1949 - val_loss: 2.1437 - val_accuracy: 0.2049\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 4s 5ms/step - loss: 2.4857 - accuracy: 0.0567 - val_loss: 2.4814 - val_accuracy: 0.0569\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.4562 - accuracy: 0.0597 - val_loss: 2.4510 - val_accuracy: 0.0608\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.4272 - accuracy: 0.0646 - val_loss: 2.4216 - val_accuracy: 0.0658\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.3990 - accuracy: 0.0706 - val_loss: 2.3932 - val_accuracy: 0.0705\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.3719 - accuracy: 0.0767 - val_loss: 2.3658 - val_accuracy: 0.0764\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.3460 - accuracy: 0.0831 - val_loss: 2.3400 - val_accuracy: 0.0833\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 2.3215 - accuracy: 0.0910 - val_loss: 2.3155 - val_accuracy: 0.0911\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.2983 - accuracy: 0.0993 - val_loss: 2.2924 - val_accuracy: 0.0990\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.2765 - accuracy: 0.1095 - val_loss: 2.2707 - val_accuracy: 0.1106\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.2558 - accuracy: 0.1219 - val_loss: 2.2500 - val_accuracy: 0.1221\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 2.3976 - accuracy: 0.1000 - val_loss: 2.3848 - val_accuracy: 0.0955\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.3695 - accuracy: 0.1032 - val_loss: 2.3569 - val_accuracy: 0.0994\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.3423 - accuracy: 0.1065 - val_loss: 2.3302 - val_accuracy: 0.1029\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.3164 - accuracy: 0.1115 - val_loss: 2.3049 - val_accuracy: 0.1095\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.2919 - accuracy: 0.1186 - val_loss: 2.2810 - val_accuracy: 0.1185\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.2686 - accuracy: 0.1293 - val_loss: 2.2583 - val_accuracy: 0.1292\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.2464 - accuracy: 0.1444 - val_loss: 2.2367 - val_accuracy: 0.1480\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.2252 - accuracy: 0.1620 - val_loss: 2.2159 - val_accuracy: 0.1710\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.2048 - accuracy: 0.1844 - val_loss: 2.1959 - val_accuracy: 0.1907\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.1851 - accuracy: 0.2073 - val_loss: 2.1765 - val_accuracy: 0.2149\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.3832 - accuracy: 0.1305 - val_loss: 2.3672 - val_accuracy: 0.1359\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.3440 - accuracy: 0.1440 - val_loss: 2.3273 - val_accuracy: 0.1519\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.3062 - accuracy: 0.1590 - val_loss: 2.2895 - val_accuracy: 0.1686\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.2708 - accuracy: 0.1754 - val_loss: 2.2545 - val_accuracy: 0.1855\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.2381 - accuracy: 0.1939 - val_loss: 2.2223 - val_accuracy: 0.2036\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.2078 - accuracy: 0.2152 - val_loss: 2.1925 - val_accuracy: 0.2250\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.1797 - accuracy: 0.2403 - val_loss: 2.1648 - val_accuracy: 0.2541\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.1535 - accuracy: 0.2655 - val_loss: 2.1389 - val_accuracy: 0.2795\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.1288 - accuracy: 0.2912 - val_loss: 2.1145 - val_accuracy: 0.3032\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 2.1055 - accuracy: 0.3149 - val_loss: 2.0915 - val_accuracy: 0.3257\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.3209 - accuracy: 0.1090 - val_loss: 2.3130 - val_accuracy: 0.1095\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.3051 - accuracy: 0.1164 - val_loss: 2.2968 - val_accuracy: 0.1155\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.2891 - accuracy: 0.1229 - val_loss: 2.2808 - val_accuracy: 0.1211\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.2732 - accuracy: 0.1302 - val_loss: 2.2648 - val_accuracy: 0.1284\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2575 - accuracy: 0.1388 - val_loss: 2.2491 - val_accuracy: 0.1369\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.2420 - accuracy: 0.1476 - val_loss: 2.2337 - val_accuracy: 0.1489\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2267 - accuracy: 0.1589 - val_loss: 2.2185 - val_accuracy: 0.1600\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.2117 - accuracy: 0.1712 - val_loss: 2.2035 - val_accuracy: 0.1727\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.1969 - accuracy: 0.1851 - val_loss: 2.1888 - val_accuracy: 0.1882\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.1823 - accuracy: 0.2001 - val_loss: 2.1743 - val_accuracy: 0.2030\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.3444 - accuracy: 0.0859 - val_loss: 2.3325 - val_accuracy: 0.0922\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.3283 - accuracy: 0.0941 - val_loss: 2.3161 - val_accuracy: 0.1017\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.3121 - accuracy: 0.1045 - val_loss: 2.2997 - val_accuracy: 0.1135\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.2959 - accuracy: 0.1183 - val_loss: 2.2835 - val_accuracy: 0.1292\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.2800 - accuracy: 0.1331 - val_loss: 2.2675 - val_accuracy: 0.1443\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2643 - accuracy: 0.1486 - val_loss: 2.2519 - val_accuracy: 0.1602\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 5ms/step - loss: 2.2490 - accuracy: 0.1664 - val_loss: 2.2366 - val_accuracy: 0.1768\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2339 - accuracy: 0.1837 - val_loss: 2.2216 - val_accuracy: 0.1947\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.2192 - accuracy: 0.2005 - val_loss: 2.2070 - val_accuracy: 0.2092\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.2049 - accuracy: 0.2160 - val_loss: 2.1927 - val_accuracy: 0.2248\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.4171 - accuracy: 0.0969 - val_loss: 2.4107 - val_accuracy: 0.0984\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.3958 - accuracy: 0.1013 - val_loss: 2.3886 - val_accuracy: 0.1041\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.3737 - accuracy: 0.1071 - val_loss: 2.3659 - val_accuracy: 0.1116\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.3512 - accuracy: 0.1152 - val_loss: 2.3429 - val_accuracy: 0.1207\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.3285 - accuracy: 0.1251 - val_loss: 2.3201 - val_accuracy: 0.1302\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.3060 - accuracy: 0.1367 - val_loss: 2.2974 - val_accuracy: 0.1423\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.2837 - accuracy: 0.1534 - val_loss: 2.2751 - val_accuracy: 0.1591\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.2619 - accuracy: 0.1716 - val_loss: 2.2534 - val_accuracy: 0.1772\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.2406 - accuracy: 0.1926 - val_loss: 2.2323 - val_accuracy: 0.2000\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.2200 - accuracy: 0.2172 - val_loss: 2.2119 - val_accuracy: 0.2243\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.4212 - accuracy: 0.0649 - val_loss: 2.4133 - val_accuracy: 0.0693\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.4037 - accuracy: 0.0718 - val_loss: 2.3953 - val_accuracy: 0.0768\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.3854 - accuracy: 0.0805 - val_loss: 2.3768 - val_accuracy: 0.0864\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.3669 - accuracy: 0.0908 - val_loss: 2.3581 - val_accuracy: 0.0984\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.3482 - accuracy: 0.1034 - val_loss: 2.3395 - val_accuracy: 0.1105\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.3297 - accuracy: 0.1188 - val_loss: 2.3209 - val_accuracy: 0.1270\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.3112 - accuracy: 0.1340 - val_loss: 2.3025 - val_accuracy: 0.1434\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.2930 - accuracy: 0.1504 - val_loss: 2.2843 - val_accuracy: 0.1608\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.2750 - accuracy: 0.1645 - val_loss: 2.2664 - val_accuracy: 0.1733\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.2574 - accuracy: 0.1793 - val_loss: 2.2489 - val_accuracy: 0.1870\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.4443 - accuracy: 0.1329 - val_loss: 2.4452 - val_accuracy: 0.1395\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.4215 - accuracy: 0.1388 - val_loss: 2.4205 - val_accuracy: 0.1466\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.3978 - accuracy: 0.1453 - val_loss: 2.3953 - val_accuracy: 0.1528\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.3739 - accuracy: 0.1513 - val_loss: 2.3701 - val_accuracy: 0.1609\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.3500 - accuracy: 0.1585 - val_loss: 2.3452 - val_accuracy: 0.1671\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.3268 - accuracy: 0.1667 - val_loss: 2.3213 - val_accuracy: 0.1735\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 2.3045 - accuracy: 0.1739 - val_loss: 2.2982 - val_accuracy: 0.1810\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2831 - accuracy: 0.1807 - val_loss: 2.2764 - val_accuracy: 0.1887\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2627 - accuracy: 0.1877 - val_loss: 2.2556 - val_accuracy: 0.1961\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 2.2433 - accuracy: 0.1939 - val_loss: 2.2359 - val_accuracy: 0.2017\n"
     ]
    }
   ],
   "source": [
    "results = []  # To store results for each hyperparameter combination\n",
    "\n",
    "for opt_name, opt_class in optimizers.items():\n",
    "    for lr in learning_rates:\n",
    "        for batch_size in batch_sizes:\n",
    "            best_train_accuracy = 0  # To store the best training accuracy across folds\n",
    "            best_val_accuracy = 0   # To store the best validation accuracy across folds\n",
    "            best_val_loss =0\n",
    "            avg_val_loss = 0  # To accumulate average validation loss across folds\n",
    "\n",
    "            for train_index, val_index in kf.split(X_train_scaled):\n",
    "                # Prepares training and validation sets for the current fold\n",
    "                x_train_fold, x_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "                y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "                # Selects the model (i.e v1, v2, or v3 as created in the FMM class)\n",
    "                model = fmm_module.FMM.create_model_v1()  # Using create_model_v1: 'this can be changed as needed or iterated over'\n",
    "\n",
    "                # Compiles and train the model\n",
    "                optimizer = opt_class(learning_rate=lr)\n",
    "                history = fmm_module.FMM.compile_and_train(\n",
    "                    model, x_train_fold, y_train_fold, optimizer, batch_size=batch_size, epochs=10)  # Reduced epochs for brevity\n",
    "\n",
    "                # Evaluate model on training data\n",
    "                train_loss, train_accuracy = model.evaluate(x_train_fold, y_train_fold, verbose=0)\n",
    "                # Update best training accuracy if current fold's accuracy is higher\n",
    "                if train_accuracy > best_train_accuracy:\n",
    "                    best_train_accuracy = train_accuracy\n",
    "\n",
    "                # Evaluate model on validation data\n",
    "                val_loss, val_accuracy = model.evaluate(x_val_fold, y_val_fold, verbose=0)\n",
    "                # Update best validation accuracy if current fold's accuracy is higher\n",
    "                if val_accuracy > best_val_accuracy:\n",
    "                    best_val_accuracy = val_accuracy\n",
    "            # Updates average validation loss\n",
    "                avg_val_loss += np.mean(history.history['val_loss']) / n_splits\n",
    "\n",
    "            # Appends results for this combination\n",
    "            results.append({'optimizer': opt_name, 'learning_rate': lr, 'batch_size': batch_size,\n",
    "                            'best_train_accuracy': best_train_accuracy, 'best_val_accuracy': best_val_accuracy,\n",
    "                            'best_val_loss': best_val_loss, 'avg_val_loss': avg_val_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d2e10e9",
   "metadata": {
    "id": "8d2e10e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Best Hyperparameters for loss based evaluation:\n",
      "     Adam\n",
      "   0.0005\n",
      "       32\n",
      " 0.351197\n",
      "\n",
      "Summary of All Combinations for loss based evaluation:\n",
      "optimizer  learning_rate  batch_size  best_train_accuracy  best_val_accuracy  best_val_loss  avg_val_loss\n",
      "     Adam         0.0005          32             0.918813           0.893750              0      0.351197\n",
      "     Adam         0.0010          32             0.914708           0.889167              0      0.356170\n",
      "     Adam         0.0010          64             0.914312           0.888750              0      0.356659\n",
      "     Adam         0.0010         128             0.906542           0.886833              0      0.358252\n",
      "     Adam         0.0005          64             0.914208           0.892917              0      0.361370\n",
      "  RMSprop         0.0005          64             0.909542           0.887833              0      0.364148\n",
      "     Adam         0.0005         128             0.909646           0.890833              0      0.368351\n",
      "  RMSprop         0.0010         128             0.912292           0.892000              0      0.368616\n",
      "  RMSprop         0.0005          32             0.909000           0.888500              0      0.370481\n",
      "  RMSprop         0.0010          64             0.909646           0.891000              0      0.370997\n",
      "  RMSprop         0.0005         128             0.909854           0.888417              0      0.382520\n",
      "     Adam         0.0001          32             0.893333           0.881750              0      0.392044\n",
      "  RMSprop         0.0001          32             0.893771           0.881417              0      0.398232\n",
      "  RMSprop         0.0010          32             0.901854           0.882500              0      0.402310\n",
      "     Adam         0.0001          64             0.888354           0.876250              0      0.413159\n",
      "  RMSprop         0.0001          64             0.885396           0.879083              0      0.422911\n",
      "     Adam         0.0001         128             0.878604           0.871167              0      0.441148\n",
      "  RMSprop         0.0001         128             0.875417           0.870750              0      0.449977\n",
      " Adadelta         0.0010          32             0.709521           0.704583              0      1.380394\n",
      " Adadelta         0.0010          64             0.688958           0.683750              0      1.588889\n",
      " Adadelta         0.0005          32             0.662625           0.659417              0      1.689500\n",
      " Adadelta         0.0010         128             0.654271           0.655417              0      1.778046\n",
      " Adadelta         0.0005          64             0.619708           0.621000              0      1.887204\n",
      " Adadelta         0.0005         128             0.564229           0.568917              0      2.026173\n",
      " Adadelta         0.0001          32             0.393833           0.391833              0      2.153639\n",
      " Adadelta         0.0001          64             0.325958           0.319333              0      2.273357\n",
      " Adadelta         0.0001         128             0.227563           0.226583              0      2.296012\n"
     ]
    }
   ],
   "source": [
    "# Converts the results list to a pandas DataFrame for easy tabular display\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sorts the DataFrame by average validation loss to see the best performers at the top\n",
    "results_df.sort_values(by='avg_val_loss', ascending=True, inplace=True)\n",
    "\n",
    "# Identifies the best parameters based on the lowest average validation loss\n",
    "best_params = results_df.iloc[results_df['avg_val_loss'].argmin()]\n",
    "\n",
    "# Displays the best hyperparameters in a tabular format\n",
    "print(\"Final Best Hyperparameters for loss based evaluation:\")\n",
    "print(best_params[['optimizer', 'learning_rate', 'batch_size', 'avg_val_loss']].to_string(index=False))\n",
    "\n",
    "# Displays summary of all combinations in a tabular format\n",
    "print(\"\\nSummary of All Combinations for loss based evaluation:\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "NO_EWWDojbpk",
   "metadata": {
    "id": "NO_EWWDojbpk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Best Hyperparameters for accuracy-based evaluation:\n",
      "     Adam\n",
      "   0.0005\n",
      "       32\n",
      " 0.918813\n",
      "  0.89375\n",
      "        0\n",
      "\n",
      "Summary of All Combinations:\n",
      "optimizer  learning_rate  batch_size  best_train_accuracy  best_val_accuracy  best_val_loss  avg_val_loss\n",
      "  RMSprop         0.0010          32             0.901854           0.882500              0      0.402310\n",
      "  RMSprop         0.0010          64             0.909646           0.891000              0      0.370997\n",
      "  RMSprop         0.0010         128             0.912292           0.892000              0      0.368616\n",
      "  RMSprop         0.0005          32             0.909000           0.888500              0      0.370481\n",
      "  RMSprop         0.0005          64             0.909542           0.887833              0      0.364148\n",
      "  RMSprop         0.0005         128             0.909854           0.888417              0      0.382520\n",
      "  RMSprop         0.0001          32             0.893771           0.881417              0      0.398232\n",
      "  RMSprop         0.0001          64             0.885396           0.879083              0      0.422911\n",
      "  RMSprop         0.0001         128             0.875417           0.870750              0      0.449977\n",
      "     Adam         0.0010          32             0.914708           0.889167              0      0.356170\n",
      "     Adam         0.0010          64             0.914312           0.888750              0      0.356659\n",
      "     Adam         0.0010         128             0.906542           0.886833              0      0.358252\n",
      "     Adam         0.0005          32             0.918813           0.893750              0      0.351197\n",
      "     Adam         0.0005          64             0.914208           0.892917              0      0.361370\n",
      "     Adam         0.0005         128             0.909646           0.890833              0      0.368351\n",
      "     Adam         0.0001          32             0.893333           0.881750              0      0.392044\n",
      "     Adam         0.0001          64             0.888354           0.876250              0      0.413159\n",
      "     Adam         0.0001         128             0.878604           0.871167              0      0.441148\n",
      " Adadelta         0.0010          32             0.709521           0.704583              0      1.380394\n",
      " Adadelta         0.0010          64             0.688958           0.683750              0      1.588889\n",
      " Adadelta         0.0010         128             0.654271           0.655417              0      1.778046\n",
      " Adadelta         0.0005          32             0.662625           0.659417              0      1.689500\n",
      " Adadelta         0.0005          64             0.619708           0.621000              0      1.887204\n",
      " Adadelta         0.0005         128             0.564229           0.568917              0      2.026173\n",
      " Adadelta         0.0001          32             0.393833           0.391833              0      2.153639\n",
      " Adadelta         0.0001          64             0.325958           0.319333              0      2.273357\n",
      " Adadelta         0.0001         128             0.227563           0.226583              0      2.296012\n"
     ]
    }
   ],
   "source": [
    "# Converts the results list to a pandas DataFrame for easy tabular display\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Identifies the best parameters based on the highest validation accuracy across all folds\n",
    "best_params = results_df.iloc[results_df['best_val_accuracy'].argmax()]\n",
    "\n",
    "# Displays the best hyperparameters in a tabular format\n",
    "print(\"Final Best Hyperparameters for accuracy-based evaluation:\")\n",
    "print(best_params[['optimizer', 'learning_rate', 'batch_size', 'best_train_accuracy', 'best_val_accuracy','best_val_loss']].to_string(index=False))\n",
    "\n",
    "# Displays summary of all combinations in a tabular format\n",
    "print(\"\\nSummary of All Combinations:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fGyo4G6ySNYK",
   "metadata": {
    "id": "fGyo4G6ySNYK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal Hyperparameters based on Highest Validation Accuracy:\n",
      "Optimizer: Adam\n",
      "Learning Rate: 0.0005\n",
      "Batch Size: 32\n",
      "Validation Accuracy: 0.8938\n"
     ]
    }
   ],
   "source": [
    "# Find the index of the combination with the highest validation accuracy\n",
    "best_index = np.argmax([result['best_val_accuracy'] for result in results])\n",
    "\n",
    "# Get the corresponding combination of hyperparameters\n",
    "best_params = results[best_index]\n",
    "\n",
    "# Print the hyperparameters along with the highest validation accuracy\n",
    "print(\"optimal Hyperparameters based on Highest Validation Accuracy:\")\n",
    "print(f\"Optimizer: {best_params['optimizer']}\")\n",
    "print(f\"Learning Rate: {best_params['learning_rate']}\")\n",
    "print(f\"Batch Size: {best_params['batch_size']}\")\n",
    "print(f\"Validation Accuracy: {best_params['best_val_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a12815d",
   "metadata": {
    "id": "1a12815d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# using a pivot table to prepare data for plotting\n",
    "pivot_df = results_df.pivot_table(values='avg_val_loss', index='optimizer', columns='learning_rate', aggfunc='mean')\n",
    "\n",
    "pivot_df.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Average Validation Loss by Optimizer and Learning Rate')\n",
    "ax.set_ylabel('Average Validation Loss')\n",
    "ax.set_xlabel('Optimizer')\n",
    "plt.legend(title='Learning Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76ee8e9e",
   "metadata": {
    "id": "76ee8e9e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIhCAYAAAB5deq6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7HUlEQVR4nO3deVxUZf//8fcwrC6gogIKgmkqbrnlGrmk5ppGpuaWW2WLgbaYWVm2aNmiZWimaIu55E3dZWaRuaDmrt2VpGYaqOAuqCTqcH5/+GO+joAzowOD+no+HvPIuc51zvnMzBnizXXOdUyGYRgCAAAAABTIw90FAAAAAEBxR3ACAAAAADsITgAAAABgB8EJAAAAAOwgOAEAAACAHQQnAAAAALCD4AQAAAAAdhCcAAAAAMAOghMAAAAA2EFwAoqZuXPnymQy2TwqVKigNm3aaMmSJVe93bi4OM2dO/eq1t23b59MJpPefvvtq95/cnKyBg4cqFtuuUW+vr4qX768GjVqpCeeeEKZmZnWfoMHD1ZERMRV7+d6UVifsz1ZWVl6+eWXtXLlSrt9p06dKpPJpGXLlhXY5+OPP5bJZFJCQoLDNbRp00Zt2rSxaTOZTHr55Zftrpv7vu3bt8/h/eVaunRpgfuIiIjQ4MGDnd6mK33zzTcymUwKDAxUdna2W2u5nrji55MzkpOTNXjwYFWpUkXe3t4qX768unTpou+///6atvvFF19oypQp+S5z9PvhjMLYJnCjIzgBxdScOXP0yy+/aN26dZo5c6bMZrO6d++ub7/99qq2dy3B6Vpt27ZNjRs31o4dO/TSSy9p2bJlmjFjhrp27aoffvhBx48ft/Z98cUX9dVXX7mlTndw9edsT1ZWll555RWHgtOAAQPk4+Oj+Pj4AvvMmTNHFSpUUPfu3a+prl9++UXDhw+/pm3Ys3TpUr3yyiv5Lvvqq6/04osvFur+7Zk9e7Yk6fjx4/r666/dWgvyl5CQoIYNG2rjxo168cUX9dNPP2n69OmSpC5duujZZ5+96m1fKTgVxvejKL5zwI3G090FAMhf3bp11aRJE+vzTp06qWzZspo/f/41/5Ja1KZMmSIPDw+tXLlSpUuXtrb36tVLr776qgzDsLZVq1bNHSW6TXH+nAMDA9WjRw99/fXXOnbsmAIDA22W//nnn/rll1/01FNPycvL65r21bx582ta/1o1bNjQrftPT0/X0qVL1a5dO61bt06zZ89Wnz593FpTQbKyslSiRAl3l1Hk9uzZo4EDB6pevXpauXKlSpYsaV12//3369FHH9XkyZPVqFEj9e3b16X7LozvR1F/586fPy+TySRPT371xPWLESfgOuHr6ytvb+88v6C+8soratasmcqVKyd/f381atRIs2fPtgkjERER+uOPP7Rq1SrraWGXng538uRJPfXUU7rlllvk4+OjihUrqkuXLvrzzz/z1PHuu++qatWqKlWqlFq0aKH169fbrf3YsWPy9/dXqVKl8l1uMpms/778VL2XX345zyltuY9LT606d+6cXnvtNdWqVUs+Pj6qUKGChgwZoiNHjlyxtilTpshkMumvv/7Ks2zMmDHy9vbW0aNHJV0cOevWrZsqVqwoHx8fVapUSV27dtX+/fvtvgeOKuhzdvT1/fzzz2rTpo0CAwPl5+enKlWq6L777lNWVpb27dunChUqSLp43OT3Pl5u2LBhOnfunL744os8y+bMmSNJGjp0qHWb9o7FguR32tD69evVqlUr+fr6qlKlSho7dqzOnz+fZ92FCxeqY8eOCgkJkZ+fnyIjI/Xcc8/pzJkz1j6DBw/Whx9+aN1X7iP3lL/8TtVLSUnRgAEDrJ93ZGSk3nnnHeXk5Fj7XHqa2NV8N3J98sknunDhgkaNGqXo6GgtX75c//zzT55+jnxXs7OzNWHCBEVGRsrX11eBgYFq27at1q1bZ1NzfiPQl38Oud+/rVu3qlevXipbtqz1jxubN29W3759FRERIT8/P0VEROiBBx7It+4DBw7o4YcfVlhYmLy9vVWpUiX16tVLhw4d0unTp1WmTBk98sgjedbbt2+fzGazJk+ebPc9zMnJ0euvv64qVarI19dXTZo00fLly63Lk5KSZDKZNH/+/DzrfvrppzKZTNq0aVOB23/vvfeUlZWlDz74wCY05XrnnXdUpkwZvf7669a23FNLExMTNWTIEJUrV04lS5ZU9+7d9ffff1v7tWnTRt99953++ecfm+Mz1+WfS+52f/75Zz300EMKDAyUv7+/Bg0apDNnzig9PV29e/dWmTJlFBISoqeffjrPd+fybUZERBT4s/bSEerdu3erX79+Nt+L3O9WrpUrV8pkMumzzz7TU089pcqVK8vHxyffn7PA9YTYDxRTFotFFy5ckGEYOnTokCZPnqwzZ86oX79+Nv327dunRx55RFWqVJF08ZfNkSNH6sCBA3rppZckXTwNqVevXgoICFBcXJwkycfHR5J06tQp3XHHHdq3b5/GjBmjZs2a6fTp01q9erXS0tJUq1Yt674+/PBD1apVy3o6yYsvvqguXbpo7969CggIKPC1tGjRQt9995369++vRx55RE2bNpWfn59D78Pw4cPVqVMnm7aEhARNnjxZderUkXTxF6YePXooKSlJzz77rFq2bKl//vlH48ePV5s2bbR58+YC9zdgwACNGTNGc+fO1WuvvWZtt1gs+vzzz9W9e3eVL19eZ86cUYcOHVS1alV9+OGHCgoKUnp6ulasWKFTp0459Fry48jn7Ojr27dvn7p27aqoqCjFx8erTJkyOnDggJYtW6Zz584pJCREy5YtU6dOnTRs2DDraTq5YSo/7du3V3h4uOLj4zVy5Eibuj/77DM1b95ctWvXluTYseioHTt26K677lJERITmzp2rEiVKKC4uLt8At3v3bnXp0kWxsbEqWbKk/vzzT7355pvauHGjfv75Z0kXj9UzZ85o8eLF+uWXX6zrhoSE5Lv/I0eOqGXLljp37pxeffVVRUREaMmSJXr66ae1Z88e6/co19V+N3LFx8crJCREnTt3lp+fn7744gvNnTtX48ePt/Zx5Lt64cIFde7cWUlJSYqNjVW7du104cIFrV+/XikpKWrZsqXdWvITHR2tvn37asSIEdZAum/fPtWsWVN9+/ZVuXLllJaWpunTp+v222/Xjh07VL58eUkXQ9Ptt9+u8+fP6/nnn1f9+vV17Ngx/fDDDzpx4oSCgoI0dOhQzZw5U2+99ZbN+xUXFydvb29rOL+SadOmKTw8XFOmTFFOTo7eeustde7cWatWrVKLFi0UFRWlhg0b6sMPP9QDDzyQZ93bb79dt99+e4HbT0xMVFBQUIEjNSVKlFDHjh21aNEipaenKzg42Lps2LBh6tChg7744gulpqbqhRdeUJs2bfS///1PZcqUUVxcnB5++GHt2bPHqVOVhw8frujoaC1YsEDbtm3T888/rwsXLmjnzp2Kjo7Www8/rJ9++klvvvmmKlWqpNGjRxe4ra+++srm2rqcnByNGDFCf//9t/U7vWPHDrVs2VJVqlTRO++8o+DgYP3www968skndfToUZvjVZLGjh2rFi1aaMaMGfLw8FDFihUdfm1AsWQAKFbmzJljSMrz8PHxMeLi4q64rsViMc6fP29MmDDBCAwMNHJycqzL6tSpY7Ru3TrPOhMmTDAkGYmJiQVud+/evYYko169esaFCxes7Rs3bjQkGfPnz79iXWfPnjV69uxpfS1ms9lo2LChMW7cOOPw4cM2fR988EEjPDy8wG0lJSUZvr6+Rv/+/a2vb/78+YYk4z//+Y9N302bNhmS7L5v0dHRRmhoqGGxWKxtS5cuNSQZ3377rWEYhrF582ZDkvH1119fcVuOcuZzdvT1LV682JBkbN++vcD9HjlyxJBkjB8/3uFax48fb0gytm7dam379ttvDUnGxx9/nO86VzoWW7dunedYvLymPn36GH5+fkZ6erq17cKFC0atWrUMScbevXvz3W9OTo5x/vx5Y9WqVYYk49dff7Uue/zxx42C/rcXHh5uPPjgg9bnzz33nCHJ2LBhg02/Rx991DCZTMbOnTsNw7j274ZhGMbq1asNScZzzz1nfQ1Vq1Y1wsPDbd43R76rn3766RU/l0trnjNnTp5ll38OuZ/9Sy+9ZPd1XLhwwTh9+rRRsmRJY+rUqdb2oUOHGl5eXsaOHTsKXHfPnj2Gh4eH8d5771nb/v33XyMwMNAYMmTIFfeb+3oqVapk/Pvvv9b2zMxMo1y5ckb79u2tbbnfu23btlnbcj+rTz755Ir78fX1NZo3b37FPmPGjLE5bnL3d++999r0W7t2rSHJeO2116xtXbt2LfBn3+WfS+52R44cadMv9+fsu+++a9PeoEEDo1GjRlfc5uWeeOIJw9PT01i6dKm17e677zZCQ0ONjIyMPH19fX2N48ePG4ZhGCtWrDAkGXfeeWeB2weuR5yqBxRTn376qTZt2qRNmzbp+++/14MPPqjHH39c06ZNs+n3888/q3379goICJDZbJaXl5deeuklHTt2TIcPH7a7n++//141atRQ+/bt7fbt2rWrzGaz9Xn9+vUlKd9Tcy7l4+Ojr776Sjt27NB7772nvn376siRI3r99dcVGRmpnTt32t23dHE2q3vuuUctW7ZUfHy89VSWJUuWqEyZMurevbsuXLhgfTRo0EDBwcF2J0IYMmSI9u/fr59++snaNmfOHAUHB6tz586SpOrVq6ts2bIaM2aMZsyYoR07djhUsz2OfM6Ovr4GDRrI29tbDz/8sD755BObU4GuxZAhQ+Th4WEzScScOXNUsmRJm+twrvVYvNSKFSt01113KSgoyNpmNpvzve7n77//Vr9+/RQcHGzdb+vWrSVdPGauxs8//6zatWuradOmNu2DBw+WYRjWkaxcV/vdkP5vUojcUZXc0yf/+ecfm1PNHPmufv/99/L19XVohMYZ9913X56206dPa8yYMapevbo8PT3l6empUqVK6cyZMzbv+/fff6+2bdsqMjKywO3fcsst6tatm+Li4qyndn7xxRc6duyYnnjiCYdqjI6Olq+vr/V56dKl1b17d61evVoWi0WS9MADD6hixYo2p5Z98MEHqlChgkuuKcut/dLT7CSpf//+Ns9btmyp8PBwrVix4pr2161bN5vnue9x165d87Q7cizmmjRpkqZNm6YZM2ZYfwaePXtWy5cv17333qsSJUrY/Czq0qWLzp49m+f01PyOG+B6RnACiqnIyEg1adJETZo0UadOnfTRRx+pY8eOevbZZ3Xy5ElJ0saNG9WxY0dJF6eFXrt2rTZt2qRx48ZJkv7991+7+zly5IhCQ0MdqunyyQFyT/dzZD+5ryk2Nlaff/65UlJS9O677+rYsWMOzWZ28OBBderUSaGhoUpISJC3t7d12aFDh3Ty5EnrtUGXPtLT063XKBWkc+fOCgkJsV6zc+LECX3zzTcaNGiQ9ZfhgIAArVq1Sg0aNNDzzz+vOnXqqFKlSho/fny+1904ypHP2dHXV61aNf3000+qWLGiHn/8cVWrVk3VqlXT1KlTr7o+SQoPD9ddd92lL774QtnZ2Tp69KiWLFmi+++/3zrZhyuOxUsdO3bM5lSnXJe3nT59WlFRUdqwYYNee+01rVy5Ups2bbJOj+7sfi/df36n8VWqVMm6/FJX+904deqUvvzySzVt2lQVKlTQyZMndfLkSd17770ymUzWUCU59l09cuSIKlWqJA8P1/7vPb/3ol+/fpo2bZqGDx+uH374QRs3btSmTZtUoUIFm9ft6M+YmJgY7d69W4mJiZIunv7YokULNWrUyKEaCzpezp07p9OnT0u6+Lk88sgj+uKLL3Ty5EkdOXJEixYt0vDhw62fWUGqVKmivXv3XrFP7jVzYWFhDtV2+XHkrHLlytk8z/25mF/72bNnHdrm559/rueff14vvfSShg0bZm0/duyYLly4oA8++CDPz6EuXbpIUp6ftQWdCgtcr7jGCbiO1K9fXz/88IN27dqlpk2basGCBfLy8tKSJUts/tLqzFTGFSpUcOnkBo4ymUwaNWqUJkyYoN9///2KfTMzM9WlSxfl5ORo6dKlea4ZKV++vAIDAwu839ClM/nlx2w2a+DAgXr//fd18uRJa0AYMmSITb969eppwYIFMgxD//vf/zR37lxNmDBBfn5+eu655xx41Y65/HN25vVFRUUpKipKFotFmzdv1gcffKDY2FgFBQVd00xfw4YNU2Jiov773//q4MGDOnfunM0vVa44Fi8VGBio9PT0PO2Xt/388886ePCgVq5caR1lkmQNnVcrMDBQaWlpedoPHjwoSdbrd67V/PnzlZWVpY0bN6ps2bJ5ln/11Vc6ceKEypYt69B3tUKFClqzZo1ycnIKDE+5n8/l94q60i/xl4+gZGRkaMmSJRo/frzNsZ+dnW1ze4Hcmhz5GdOuXTvVrVtX06ZNU6lSpbR161Z9/vnndtfLVdDx4u3tbTMxzaOPPqpJkyYpPj5eZ8+e1YULFzRixAi72+/QoYM+/PBDrV+/Pt/rnLKyspSYmKi6devmCUoF1Va9enVHXlqRSUxM1NChQzV48OA8U/eXLVvW+rPy8ccfz3f9qlWr2jy//LgBrneMOAHXke3bt0v6v4v5c6d2vfQUoX///VefffZZnnV9fHzy/et3586dtWvXrjynHrlSfr+AShd/Cc3MzLT+FT8/586d07333qt9+/bp+++/z/cv1926ddOxY8dksVisozeXPmrWrGm3xiFDhujs2bOaP3++5s6dqxYtWthMjHEpk8mk2267Te+9957KlCmjrVu32t2+My7/nK/m9ZnNZjVr1sx6SlJujc6OEubq2bOnAgMDFR8frzlz5qhGjRq64447rMudORYd0bZtWy1fvlyHDh2ytlksFi1cuNCmX+4vZpePFnz00Ud5tunMa7/rrru0Y8eOPJ9t7uxrbdu2deyF2DF79myVLl1ay5cv14oVK2wekydPVnZ2tubNmyfJse9q586ddfbs2Svesy0oKEi+vr763//+Z9P+3//+1+G6TSaTDMPI877PmjXLelrcpTWtWLHCoVNyn3zySX333XcaO3asgoKCdP/99ztcU0JCgs2oyqlTp/Ttt98qKirK5rgMCQnR/fffr7i4OM2YMUPdu3e3Tn5wJaNGjZKfn59GjhxpM2NjrqefflonTpzQCy+8kGdZ7meYa926dfrnn39sbgRd0M/oorJ9+3bdd999ateunWbOnJlneYkSJdS2bVtt27ZN9evXz/dn0eUjr8CNhhEnoJj6/fffdeHCBUkX/xKckJCgxMRE3Xvvvda/6nXt2lXvvvuu+vXrp4cffljHjh3T22+/ne8pJ7mjJQsXLtQtt9wiX19f1atXT7GxsVq4cKF69Oih5557Tk2bNtW///6rVatWqVu3bi75BfHhhx/WyZMndd9996lu3boym836888/9d5778nDw0NjxowpcN1Ro0bp559/1htvvKHTp0/bnENfoUIFVatWTX379tW8efPUpUsXxcTEqGnTpvLy8tL+/fu1YsUK9ejRQ/fee+8Va6xVq5ZatGihiRMnKjU1Nc8vDkuWLFFcXJx69uypW265RYZhKCEhQSdPnlSHDh2s/e666y6tWrXK+tnZ48jn7OjrmzFjhn7++Wd17dpVVapU0dmzZ63XJeVeF1O6dGmFh4frv//9r+666y6VK1dO5cuXt5kCPj8+Pj7q37+/PvjgAxmGoUmTJtksd+ZYdMQLL7ygb775Ru3atdNLL72kEiVK6MMPP8zzC2vLli1VtmxZjRgxQuPHj5eXl5fmzZunX3/9Nc8269WrJ0l688031blzZ5nNZtWvX9/mtM9co0aN0qeffqquXbtqwoQJCg8P13fffae4uDg9+uijqlGjxlW9rkv9/vvv2rhxox599FG1a9cuz/JWrVrpnXfe0ezZs/XEE0849F194IEHNGfOHI0YMUI7d+5U27ZtlZOTow0bNigyMlJ9+/aVyWTSgAEDFB8fr2rVqum2227Txo0b852xsCD+/v668847NXnyZOvxs2rVKs2ePVtlypSx6TthwgR9//33uvPOO/X888+rXr16OnnypJYtW6bRo0fb/IFiwIABGjt2rFavXq0XXngh38+mIGazWR06dNDo0aOVk5OjN998U5mZmfne9DgmJkbNmjWT9H/T6ttTrVo1ffbZZ+rfv79uv/12jR49WjVr1tShQ4cUHx+v77//Xk8//XS+10pt3rxZw4cP1/3336/U1FSNGzdOlStX1mOPPWbtU69ePSUkJGj69Olq3LixPDw8bO7xVphyR/X9/Pz09NNPa/PmzTbLa9euLX9/f02dOlV33HGHoqKi9OijjyoiIkKnTp3SX3/9pW+//bZQ/wAHFAtunJgCQD7ym20tICDAaNCggfHuu+8aZ8+etekfHx9v1KxZ0/Dx8TFuueUWY+LEicbs2bPzzDy2b98+o2PHjkbp0qUNSTazN504ccKIiYkxqlSpYnh5eRkVK1Y0unbtavz555+GYfzfrFWTJ0/OU68cmKHthx9+MIYOHWrUrl3bCAgIMDw9PY2QkBAjOjra+OWXX2z6Xj6rXuvWrfOdfU6SzSxo58+fN95++23jtttuM3x9fY1SpUoZtWrVMh555BFj9+7dV37T/7+ZM2cakgw/P788s0b9+eefxgMPPGBUq1bN8PPzMwICAoymTZsac+fOtemXW689zn7Ojry+X375xbj33nuN8PBww8fHxwgMDDRat25tfPPNNzbb+umnn4yGDRsaPj4+ed7HK/n111+tsyIePHgwz3JHj0VHZtUzjIszjzVv3tzw8fExgoODjWeeecb6GV26vXXr1hktWrQwSpQoYVSoUMEYPny4sXXr1jwzx2VnZxvDhw83KlSoYJhMJpvtXD6rnmEYxj///GP069fPCAwMNLy8vIyaNWsakydPtpl98Vq+G7GxsXZnQcyd3W/Lli2GYdj/rhrGxdnoXnrpJePWW281vL29jcDAQKNdu3bGunXrrH0yMjKM4cOHG0FBQUbJkiWN7t27G/v27StwVr0jR47kqW3//v3GfffdZ5QtW9YoXbq00alTJ+P333/P971MTU01hg4dagQHBxteXl5GpUqVjN69exuHDh3Ks93Bgwcbnp6exv79+wt8Xy6V+xm8+eabxiuvvGKEhoYa3t7eRsOGDY0ffvihwPUiIiKMyMhIh/ZxqT/++MN48MEHjdDQUMPLy8soV66c0alTJ+O7777L0zf3e/7jjz8aAwcONMqUKWP4+fkZXbp0yfNz6fjx40avXr2MMmXKWI/PXJd/Lrnb3bRpk802Cvq8HnzwQaNkyZI2bZduM/c9LOixYsUK63p79+41hg4dalSuXNnw8vIyKlSoYLRs2dJmhsDcWfW+/PJLh95T4HphMgwH7kwIAABQyM6dO6eIiAjdcccdWrRoUaHt53//+59uu+02ffjhhzajPq42d+5cDRkyRJs2bSqy0SMAhYdT9QAAgFsdOXJEO3fu1Jw5c3To0CGXTrZyqT179uiff/7R888/r5CQEA0ePLhQ9gPgxsTkEAAAwK2+++47RUVF6fvvv1dcXJzDU5A769VXX1WHDh10+vRpffnllypRokSh7AfAjYlT9QAAAADADkacAAAAAMAOghMAAAAA2EFwAgAAAAA7brpZ9XJycnTw4EGVLl3aesd5AAAAADcfwzB06tQpVapUSR4eVx5TuumC08GDBxUWFubuMgAAAAAUE6mpqQoNDb1in5suOJUuXVrSxTfH39/fzdUAAAAAcJfMzEyFhYVZM8KV3HTBKff0PH9/f4ITAAAAAIcu4WFyCAAAAACwg+AEAAAAAHYQnAAAAADADoITAAAAANhBcAIAAAAAOwhOAAAAAGAHwQkAAAAA7CA4AQAAAIAdBCcAAAAAsIPgBAAAAAB2uD04xcXFqWrVqvL19VXjxo2VlJR0xf4ffvihIiMj5efnp5o1a+rTTz8tokoBAAAA3Kw83bnzhQsXKjY2VnFxcWrVqpU++ugjde7cWTt27FCVKlXy9J8+fbrGjh2rjz/+WLfffrs2btyohx56SGXLllX37t3d8AoAAAAA3AxMhmEY7tp5s2bN1KhRI02fPt3aFhkZqZ49e2rixIl5+rds2VKtWrXS5MmTrW2xsbHavHmz1qxZ49A+MzMzFRAQoIyMDPn7+1/7iwAAAABwXXImG7htxOncuXPasmWLnnvuOZv2jh07at26dfmuk52dLV9fX5s2Pz8/bdy4UefPn5eXl1e+62RnZ1ufZ2ZmuqB617BYpKQkKS1NCgmRoqIks9ndVQG4FN9TAAAgufEap6NHj8pisSgoKMimPSgoSOnp6fmuc/fdd2vWrFnasmWLDMPQ5s2bFR8fr/Pnz+vo0aP5rjNx4kQFBARYH2FhYS5/LVcjIUGKiJDatpX69bv434iIi+0AioeL31Pjsu+pwfcUAICrZbFIK1dK8+df/K/F4u6KHOb2ySFMJpPNc8Mw8rTlevHFF9W5c2c1b95cXl5e6tGjhwYPHixJMhfwJ+CxY8cqIyPD+khNTXVp/VcjIUHq1Uvav9+2/cCBi+38Uga4X0KC1Os+Q/v3257NfGC/oV73EZ4AAHBaQoIs4bdoZduXNb/fN1rZ9mVZwm+5bn75dVtwKl++vMxmc57RpcOHD+cZhcrl5+en+Ph4ZWVlad++fUpJSVFERIRKly6t8uXL57uOj4+P/P39bR7uZLFIMTFSfleW5bbFxl5X4Ru44VgsUszDWTJk6PIfk4Y8JBmKfTiL7ykAAI5KSFDCffMUcWCN2mql+mm+2mqlIg6sUcJ9866L8OS24OTt7a3GjRsrMTHRpj0xMVEtW7a84rpeXl4KDQ2V2WzWggUL1K1bN3l4uH3wzCFJSXlHmi5lGFJq6sV+ANwjaaVF+4+VUEE/Ig15KPVYCSWtJDkBAGCXxaKEh79XL32p/apss+iAKquXvlTCw8uK/ciBW9PG6NGjNWvWLMXHxys5OVmjRo1SSkqKRowYIeniaXaDBg2y9t+1a5c+//xz7d69Wxs3blTfvn31+++/64033nDXS3BaWppr+wFwvbSVO13aDwCAm5llZZJijr0kQybldyaHISn22AuyrCzeIwduvY9Tnz59dOzYMU2YMEFpaWmqW7euli5dqvDwcElSWlqaUlJSrP0tFoveeecd7dy5U15eXmrbtq3WrVuniIgIN70C51Usb5Fkf0ouR/sBcL2KloOSarusHwAAN7Okn89rv640QZuHUlVFST/vVJu7iqwsp7k1OEnSY489psceeyzfZXPnzrV5HhkZqW3bthVBVYXot98kNXCsXwcH+gFwvZMnXdsPAICb2IF/Lri0n7tcHxcG3UAO781yaT8ArnfYFOzSfgAA3MyOqIJL+7kLwamIhVQr4dJ+AFwv5NZSLu0HAMDNrEK4Y7/XOtrPXQhORazlkJoy64KkfOYjlyQZMuuCWg6pWZRlAbhE1GP1FGo+KJNy8l1uUo7CzAcU9Vi9Iq4MAIDrT+V2jv1e62g/dyE4FbF1476TRZ6S8r/Jr2SSRZ5aN+67oiwLwCXM3mZN7fbT/392eXi6+HxKt+UyezOBCwAA9kS1MSs0MEt5/5+aK0dhgVmKalO8/79KcCpiabtPu7QfgEJgsSh6yzg9rckyX/ZD3qwcPa3Jit76QrG/3wQAAMWB2SxNnVlCJpmU3x8kTTJpyswSMhfv3ERwKmpcOwFcB5KSlLD/dr2tZ2S57Mdkjjz0tp5RQmoT7lQNAICDoqOlxf8xKTTU9qyrsFCTFv/HpOhoNxXmBJNhGAVdbHNDyszMVEBAgDIyMuTv71/k+7f8e04RJQ7pgCrLyCe3mpSjUO3X3qxgmf28i7w+AJJl3gJFDGj1/+9ufoXv6efrZO7ft+gLBADgOnXuX4vintmrPbtzVO1WDz02uaq8/dw31ORMNmDEqYiZ/bw1tccKScpz4Xnu8yk9VhKaADdKOlLr/9+oL/8fkUbujfqO1CrawgAAuI4lPLte1Uof0qgPq2vajzU06sPqqlb6kBKeXe/u0hxCcHKD6K8HaXGPz1VZB2zaQ7Vfi3t8ruivB7mpMgCSlFahvkv7AQBws0t4dr16TW6q/RbbeyAesASr1+Sm10V44lQ9N7L8e05Jz3yjtN2nFXJrKUVNvoeRJqAYWLlSatvWfr8VK6Q2bQq7GgAArm+WcxZFlDj0/0NTAafAm9MuXqpSxDPWOpMNPIuoJuTD7OetNtN6ubsMAJeJipJCQ6UD+w0Z+dw6wCRDoWEmRUW5oTgAAK4zSXG/ab+lQYHLDXko1VJZSXHb1Sa24H7uxql6AHAZs1maOlWSySSTyXZQ3mQyJJNJU6ao2E+bCgBAcZC2J8ul/dyF4AQA+YiOlhYvlipXth1xCg01afFiXRfTpgIAUByEVCvh0n7uwjVOAHAFFsvF2zWlpUkhIRdP42OkCQAAx+Ve43TAElzw7Xi4xgkArm9mMxNAAABwLczeZk0dnaJek4NlUo5NeLLejmd0qszeld1VokM4VQ8AAABAoYp+q7kWP7NRlc3pNu2h5jQtfmajot9q7qbKHMepegAAAACKhOWcRUlxvyltT5ZCqpVQ1GP1ivz0vEtxqh4AAACAYsfsbS7WU45fCafqAQAAAIAdBCcAAAAAsIPgBAAAAAB2EJwAAAAAwA6CEwAAAADYQXACAAAAADsITgAAAABgB8EJAAAAAOwgOAEAAACAHQQnAAAAALCD4AQAAAAAdhCcAAAAAMAOghMAAAAA2EFwAgAAAAA7CE4AAAAAYAfBCQAAAADsIDgBAAAAgB0EJwAAAACwg+AEAAAAAHYQnAAAAADADoITAAAAANhBcAIAAAAAOwhOAAAAAGAHwQkAAAAA7CA4AQAAAIAdBCcAAAAAsIPgBAAAAAB2EJwAAAAAwA6CEwAAAADYQXACAAAAADsITgAAAABgB8EJAAAAAOwgOAEAAACAHQQnAAAAALDD7cEpLi5OVatWla+vrxo3bqykpKQr9p83b55uu+02lShRQiEhIRoyZIiOHTtWRNUCAAAAuBm5NTgtXLhQsbGxGjdunLZt26aoqCh17txZKSkp+fZfs2aNBg0apGHDhumPP/7Ql19+qU2bNmn48OFFXDkAAACAm4lbg9O7776rYcOGafjw4YqMjNSUKVMUFham6dOn59t//fr1ioiI0JNPPqmqVavqjjvu0COPPKLNmzcXceUAAAAAbiZuC07nzp3Tli1b1LFjR5v2jh07at26dfmu07JlS+3fv19Lly6VYRg6dOiQFi9erK5duxa4n+zsbGVmZto8AAAAAMAZbgtOR48elcViUVBQkE17UFCQ0tPT812nZcuWmjdvnvr06SNvb28FBwerTJky+uCDDwrcz8SJExUQEGB9hIWFufR1AAAAALjxuX1yCJPJZPPcMIw8bbl27NihJ598Ui+99JK2bNmiZcuWae/evRoxYkSB2x87dqwyMjKsj9TUVJfWDwAAAODG5+muHZcvX15msznP6NLhw4fzjELlmjhxolq1aqVnnnlGklS/fn2VLFlSUVFReu211xQSEpJnHR8fH/n4+Lj+BQAAAAC4abhtxMnb21uNGzdWYmKiTXtiYqJatmyZ7zpZWVny8LAt2Ww2S7o4UgUAAAAAhcGtp+qNHj1as2bNUnx8vJKTkzVq1CilpKRYT70bO3asBg0aZO3fvXt3JSQkaPr06fr777+1du1aPfnkk2ratKkqVarkrpcBAAAA4AbntlP1JKlPnz46duyYJkyYoLS0NNWtW1dLly5VeHi4JCktLc3mnk6DBw/WqVOnNG3aND311FMqU6aM2rVrpzfffNNdLwEAAADATcBk3GTnuGVmZiogIEAZGRny9/d3dzkAAAAA3MSZbOD2WfUAAAAAoLgjOAEAAACAHQQnAAAAALCD4AQAAAAAdhCcAAAAAMAOghMAAAAA2EFwAgAAAAA7CE4AAAAAYAfBCQAAAADsIDgBAAAAgB0EJwAAAACwg+AEAAAAAHYQnAAAAADADoITAAAAANhBcAIAAAAAOwhOAAAAAGAHwQkAAAAA7CA4AQAAAIAdBCcAAAAAsIPgBAAAAAB2EJwAAAAAwA6CEwAAAADYQXACAAAAADsITgAAAABgB8EJAAAAAOwgOAEAAACAHQQnAAAAALCD4AQAAAAAdhCcAAAAAMAOghMAAAAA2EFwAgAAAAA7CE4AAAAAYAfBCQAAAADsIDgBAAAAgB0EJwAAAACwg+AEAAAAAHYQnAAAAADADoITAAAAANhBcAIAAAAAOwhOAAAAAGAHwQkAAAAA7CA4AQAAAIAdBCcAAAAAsIPgBAAAAAB2EJwAAAAAwA6CEwAAAADYQXACAAAAADsITgAAAABgh6e7C7iZWXIsSkpJUtqpNIWUDlFUlSiZPczuLgsAAADAZQhObpKQnKCYZTHan7nf2hbqH6qpnaYqOjLajZUBAAAAuByn6rlBQnKCei3qZROaJOlA5gH1WtRLCckJbqoMAAAAQH4ITkXMkmNRzLIYGTLyLMtti10WK0uOpahLAwAAAFAAtwenuLg4Va1aVb6+vmrcuLGSkpIK7Dt48GCZTKY8jzp16hRhxdcmKSUpz0jTpQwZSs1MVVJKwe8DAAAAgKLl1uC0cOFCxcbGaty4cdq2bZuioqLUuXNnpaSk5Nt/6tSpSktLsz5SU1NVrlw53X///UVc+dVLO5Xm0n4AAAAACp9bg9O7776rYcOGafjw4YqMjNSUKVMUFham6dOn59s/ICBAwcHB1sfmzZt14sQJDRkypIgrv3ohpUNc2g8AAABA4XNbcDp37py2bNmijh072rR37NhR69atc2gbs2fPVvv27RUeHl5gn+zsbGVmZto83CmqSpRC/UNlkinf5SaZFOYfpqgqUUVcGQAAAICCuC04HT16VBaLRUFBQTbtQUFBSk9Pt7t+Wlqavv/+ew0fPvyK/SZOnKiAgADrIyws7JrqvlZmD7OmdpoqSXnCU+7zKZ2mcD8nAAAAoBhx++QQJpNteDAMI09bfubOnasyZcqoZ8+eV+w3duxYZWRkWB+pqanXUq5LREdGa3HvxarsX9mmPdQ/VIt7L+Y+TgAAAEAx47Yb4JYvX15msznP6NLhw4fzjEJdzjAMxcfHa+DAgfL29r5iXx8fH/n4+Fxzva4WHRmtHjV7KCklSWmn0hRSOkRRVaIYaQIAAACKIadHnFauXOmSHXt7e6tx48ZKTEy0aU9MTFTLli2vuO6qVav0119/adiwYS6pxV3MHma1iWijB+o9oDYRbQhNAAAAQDHldHDq1KmTqlWrptdee+2aT3sbPXq0Zs2apfj4eCUnJ2vUqFFKSUnRiBEjJF08zW7QoEF51ps9e7aaNWumunXrXtP+AQAAAMARTgengwcPKiYmRgkJCapataruvvtuLVq0SOfOnXN653369NGUKVM0YcIENWjQQKtXr9bSpUuts+SlpaXluadTRkaG/vOf/1z3o00Arg+WHItW7lup+b/N18p9K2XJsbi7JAAA4AYmwzCMq115+/btio+P1/z585WTk6P+/ftr2LBhuu2221xZo0tlZmYqICBAGRkZ8vf3d3c5AIqxhOQExSyL0f7M/da2UP9QTe00lUlcAAC4ATiTDa4pOEkXR6BmzpypSZMmydPTU2fPnlWLFi00Y8YM1alT51o2XSgITgAckZCcoF6LesmQ7Y/I3NsGMAMmAADXP2eywVVNR37+/HktXrxYXbp0UXh4uH744QdNmzZNhw4d0t69exUWFqb777//qooHAHez5FgUsywmT2iSZG2LXRbLaXsAANxEnJ6OfOTIkZo/f74kacCAAXrrrbdsJmkoWbKkJk2apIiICJcVCQBFKSklyeb0vMsZMpSamaqklCS1iWhTdIUBAAC3cTo47dixQx988IHuu+++Au+hVKlSJa1YseKaiwMAd0g7lebSfgAA4PrndHBavny5/Y16eqp169ZXVRAAuFtI6RCX9gMAANc/p69xmjhxouLj4/O0x8fH680333RJUQDgTlFVohTqH2qdCOJyJpkU5h+mqCpRRVwZAABwF6eD00cffaRatWrlaa9Tp45mzJjhkqIAwJ3MHmZN7TRVkvKEp9znUzpNkdnDXOS1AQAA93A6OKWnpyskJO/pKRUqVFBaGuf7A7gxREdGa3HvxarsX9mmPdQ/lKnIAQC4CTl9jVNYWJjWrl2rqlWr2rSvXbtWlSpVcllhAOBu0ZHR6lGzh5JSkpR2Kk0hpUMUVSWKkSYAAG5CTgen4cOHKzY2VufPn1e7du0kXZww4tlnn9VTTz3l8gIBwJ3MHmamHAcAAM4Hp2effVbHjx/XY489pnPnzkmSfH19NWbMGI0dO9blBQIAAACAu5kMwzCuZsXTp08rOTlZfn5+uvXWW+Xj4+Pq2gpFZmamAgIClJGRIX9/f3eXAwAAAMBNnMkGTo845SpVqpRuv/32q10dAAAAAK4bVxWcNm3apC+//FIpKSnW0/VyJSQkuKSwm4Elx8JF5wAAAMB1wOnpyBcsWKBWrVppx44d+uqrr3T+/Hnt2LFDP//8swICAgqjxhtSQnKCIqZGqO0nbdUvoZ/aftJWEVMjlJBM8AQAAACKG6eD0xtvvKH33ntPS5Yskbe3t6ZOnark5GT17t1bVapUKYwabzgJyQnqtaiX9mfut2k/kHlAvRb1IjwBAAAAxYzTwWnPnj3q2rWrJMnHx0dnzpyRyWTSqFGjNHPmTJcXeKOx5FgUsyxGhvLOyZHbFrssVpYcS1GXBgAAABQqS45FK/et1Pzf5mvlvpXX1e+8Tl/jVK5cOZ06dUqSVLlyZf3++++qV6+eTp48qaysLJcXeKNJSknKM9J0KUOGUjNTlZSSxL1jAAAAcMNISE5QzLIYm9+FQ/1DNbXTVEVHRruxMsc4PeIUFRWlxMRESVLv3r0VExOjhx56SA888IDuuusulxd4o0k7lebSfgAAAEBxdyNcquL0iNO0adN09uxZSdLYsWPl5eWlNWvWKDo6Wi+++KLLC7zRhJQOcWk/AAAAoDizd6mKSSbFLotVj5o9ivUM006NOF24cEHffvutPDwurubh4aFnn31W33zzjd59912VLVu2UIq8kURViVKof6hMMuW73CSTwvzDFFUlqogrAwAAAFzPmUtVijOngpOnp6ceffRRZWdnF1Y9Nzyzh1lTO02VpDzhKff5lE5TinXaBgAAABx1o1yq4vQ1Ts2aNdO2bdsKo5abRnRktBb3XqzK/pVt2kP9Q7W49+Lr4uI4AAAAwBE3yqUqTl/j9Nhjj+mpp57S/v371bhxY5UsWdJmef369V1W3I0sOjJaPWr2UFJKktJOpSmkdIiiqkQx0gQAAIAbSu6lKgcyD+R7nZNJJoX6hxb7S1VMhmHkrf4Kcq9vstmIySTDMGQymWSxFO+52DMzMxUQEKCMjAz5+/u7uxwAAADghpc7q54km/CUe6mKu866ciYbOD3itHfv3qsuDAAAAMDNJ/dSlfzu4zSl05Tr4lIVp0ecrneMOAEAAADuYcmxFKtLVQp1xOnTTz+94vJBgwY5u0kAAAAANwGzh1ltItq4u4yr4vSI0+X3ajp//ryysrLk7e2tEiVK6Pjx4y4t0NUYcQIAAAAgOZcNnJ6O/MSJEzaP06dPa+fOnbrjjjs0f/78qy4aAAAAAIorp4NTfm699VZNmjRJMTExrtgcAAAAABQrLglOkmQ2m3Xw4EFXbQ4AAAAAig2nJ4f45ptvbJ4bhqG0tDRNmzZNrVq1cllhAAAAAFBcOB2cevbsafPcZDKpQoUKateund555x1X1QUAAAAAxYbTwSknJ6cw6gAAAACAYstl1zgBAAAAwI3K6eDUq1cvTZo0KU/75MmTdf/997ukKAAAAAAoTpwOTqtWrVLXrl3ztHfq1EmrV692SVEAUFxYcixauW+l5v82Xyv3rZQlx+LukgAAgBs4fY3T6dOn5e3tnafdy8tLmZmZLikKAIqDhOQExSyL0f7M/da2UP9QTe00VdGR0W6sDAAAFDWnR5zq1q2rhQsX5mlfsGCBateu7ZKiAMDdEpIT1GtRL5vQJEkHMg+o16JeSkhOcFNlAADAHZwecXrxxRd13333ac+ePWrXrp0kafny5Zo/f76+/PJLlxcIAEXNkmNRzLIYGTLyLDNkyCSTYpfFqkfNHjJ7mN1QIQAAKGpOjzjdc889+vrrr/XXX3/pscce01NPPaX9+/frp59+ynOPJwC4HiWlJOUZabqUIUOpmalKSkkqwqoAAIA7OT3iJEldu3bNd4IIALgRpJ1Kc2k/AABw/XN6xGnTpk3asGFDnvYNGzZo8+bNLikKANwppHSIS/sBAIDrn9PB6fHHH1dqamqe9gMHDujxxx93SVEA4E5RVaIU6h8qk0z5LjfJpDD/MEVViSriygAAgLs4HZx27NihRo0a5Wlv2LChduzY4ZKiAMCdzB5mTe00VZLyhKfc51M6TWFiCAAAbiJOBycfHx8dOnQoT3taWpo8Pa/qkikAKHaiI6O1uPdiVfavbNMe6h+qxb0Xcx8nAABuMibDMPLOt3sFffv2VXp6uv773/8qICBAknTy5En17NlTFStW1KJFiwqlUFfJzMxUQECAMjIy5O/v7+5yABRzlhyLklKSlHYqTSGlQxRVJYqRJgAAbhDOZAOng9OBAwd055136tixY2rYsKEkafv27QoKClJiYqLCwsKuvvIiQHACAAAAIDmXDZw+t65y5cr63//+p3nz5unXX3+Vn5+fhgwZogceeEBeXl5XXTQAAAAAFFdXdVFSyZIl9fDDD9u0/fbbb5o9e7amTJniiroAAAAAoNhwenKIS2VmZuqjjz5S06ZNddttt2nlypUuKgsAAAAAio+rCk6rVq3SoEGDFBISoscee0zt2rXTrl27tH37dqe3FRcXp6pVq8rX11eNGzdWUlLSFftnZ2dr3LhxCg8Pl4+Pj6pVq6b4+PireRkAAAAA4BCHg1NaWpreeOMNVa9eXX379lX58uW1atUqeXh4aNCgQapevbrTO1+4cKFiY2M1btw4bdu2TVFRUercubNSUlIKXKd3795avny5Zs+erZ07d2r+/PmqVauW0/sGAAAAAEc5PKuer6+v7r//fg0YMEAdOnSQh8fFzOXl5aVff/1VtWvXdnrnzZo1U6NGjTR9+nRrW2RkpHr27KmJEyfm6b9s2TL17dtXf//9t8qVK+f0/iRm1QMAAABwkTPZwOERp/DwcK1Zs0arV6/Wrl27rrnIc+fOacuWLerYsaNNe8eOHbVu3bp81/nmm2/UpEkTvfXWW6pcubJq1Kihp59+Wv/++2+B+8nOzlZmZqbNAwAAAACc4fCsejt37tTatWs1e/Zs3X777apRo4YGDBggSTKZTE7v+OjRo7JYLAoKCrJpDwoKUnp6er7r/P3331qzZo18fX311Vdf6ejRo3rsscd0/PjxAq9zmjhxol555RWn6wMAAACAXE5NDtGqVSvFx8crLS1NI0aM0KJFi2SxWPTYY4/p448/1pEjR5wu4PLQZRhGgUEsJydHJpNJ8+bNU9OmTdWlSxe9++67mjt3boGjTmPHjlVGRob1kZqa6nSNAAAAAG5uVzWrXqlSpfTQQw/pl19+0R9//KHGjRvrhRdeUKVKlRzeRvny5WU2m/OMLh0+fDjPKFSukJAQVa5cWQEBAda2yMhIGYah/fv357uOj4+P/P39bR4AAAAA4Ixruo+TdDG4vP322zpw4IAWLlzo8Hre3t5q3LixEhMTbdoTExPVsmXLfNdp1aqVDh48qNOnT1vbdu3aJQ8PD4WGhl7dCwAAAAAAO645OOXy9PRUdHS0U+uMHj1as2bNUnx8vJKTkzVq1CilpKRoxIgRki6eZjdo0CBr/379+ikwMFBDhgzRjh07tHr1aj3zzDMaOnSo/Pz8XPVSAAAAAMCGw5NDFIY+ffro2LFjmjBhgtLS0lS3bl0tXbpU4eHhki7eO+rSezqVKlVKiYmJGjlypJo0aaLAwED17t1br732mrteAgAAAICbgMP3cbpRcB8nAAAAAFIh3ccJAAAAAG5WBCcAAAAAsMPpa5zOnDmjSZMmafny5Tp8+LBycnJslv/9998uKw4AAAAAigOng9Pw4cO1atUqDRw4UCEhIQXerBYAAAAAbhROB6fvv/9e3333nVq1alUY9QAAAABAseP0NU5ly5ZVuXLlCqMWAAAAACiWnA5Or776ql566SVlZWUVRj0AAAAAUOw4fareO++8oz179igoKEgRERHy8vKyWb5161aXFQcAAADgxmHJsSgpJUlpp9IUUjpEUVWiZPYwu7sshzgdnHr27FkIZQAAAAC4kSUkJyhmWYz2Z+63toX6h2pqp6mKjox2Y2WOMRmGYbi7iKLkzN2BAQAAAFy7hOQE9VrUS4Zso4dJF2foXtx7sVvCkzPZwOkRp1xbtmxRcnKyTCaTateurYYNG17tpgAAAADcoCw5FsUsi8kTmiTJkCGTTIpdFqseNXsU69P2nA5Ohw8fVt++fbVy5UqVKVNGhmEoIyNDbdu21YIFC1ShQoXCqBMAAADAdSgpJcnm9LzLGTKUmpmqpJQktYloU3SFOcnpWfVGjhypzMxM/fHHHzp+/LhOnDih33//XZmZmXryyScLo0YAAAAA16m0U2ku7ecuTo84LVu2TD/99JMiIyOtbbVr19aHH36ojh07urQ4AAAAANe3kNIhLu3nLk6POOXk5OSZglySvLy8lJOT45KiAAAAANwYoqpEKdQ/1DoRxOVMMinMP0xRVaKKuDLnOB2c2rVrp5iYGB08eNDaduDAAY0aNUp33XWXS4sDAAAAcH0ze5g1tdNUScoTnnKfT+k0pVhPDCFdRXCaNm2aTp06pYiICFWrVk3Vq1dX1apVderUKX3wwQeFUSMAAACA61h0ZLQW916syv6VbdpD/UPdNhW5s676Pk6JiYn6888/ZRiGateurfbt27u6tkLBfZwAAAAA97DkWJSUkqS0U2kKKR2iqCpRbh1pciYbcANcAAAAADcll98A9/3339fDDz8sX19fvf/++1fsy5TkAAAAAG40Do04Va1aVZs3b1ZgYKCqVq1a8MZMJv39998uLdDVGHECAAAAIBXCiNPevXvz/TcAAAAA3AycnlVvwoQJysrKytP+77//asKECS4pCgAAAACKE6cnhzCbzUpLS1PFihVt2o8dO6aKFSvKYrG4tEBX41Q9AAAAAJJz2cDpESfDMGQy5b3r76+//qpy5co5uzkAAAAAKPYcusZJksqWLSuTySSTyaQaNWrYhCeLxaLTp09rxIgRhVIkAAAAALiTw8FpypQpMgxDQ4cO1SuvvKKAgADrMm9vb0VERKhFixaFUiQAAAAAuJPDwenBBx+UdHFq8pYtW8rLy6vQigIAAACA4sTh4JSrdevW1n//+++/On/+vM1yJlwAAAAAcKNxenKIrKwsPfHEE6pYsaJKlSqlsmXL2jwAAAAA4EbjdHB65pln9PPPPysuLk4+Pj6aNWuWXnnlFVWqVEmffvppYdQIAAAAAG7l9Kl63377rT799FO1adNGQ4cOVVRUlKpXr67w8HDNmzdP/fv3L4w6AQAAAMBtnB5xOn78uKpWrSrp4vVMx48flyTdcccdWr16tWurAwAAAIBiwOngdMstt2jfvn2SpNq1a2vRokWSLo5ElSlTxpW1AQAAAECx4HRwGjJkiH799VdJ0tixY63XOo0aNUrPPPOMywsEAAAAAHczGYZhXMsGUlJStHnzZlWrVk233Xabq+oqNJmZmQoICFBGRgZTpwMAAAA3MWeygdOTQ1yuSpUqqlKlyrVuBgAAAACKLYeC0/vvv+/wBp988smrLgYAAAAAiiOHTtXLnUUv15EjR5SVlWWdDOLkyZMqUaKEKlasqL///rtQCnUVTtUDAAAAIDmXDRyaHGLv3r3Wx+uvv64GDRooOTlZx48f1/Hjx5WcnKxGjRrp1VdfdckLAAAAAIDixOnJIapVq6bFixerYcOGNu1btmxRr169tHfvXpcW6GqMOAEAAACQCmHE6VJpaWk6f/58nnaLxaJDhw45uzkAAAAAKPacDk533XWXHnroIW3evFm5g1WbN2/WI488ovbt27u8QAAAAABwN6eDU3x8vCpXrqymTZvK19dXPj4+atasmUJCQjRr1qzCqBEAAAAA3Mrp+zhVqFBBS5cu1a5du/Tnn3/KMAxFRkaqRo0ahVEfAAAAALjdVd8At0aNGoQlAAAAADcFh4LT6NGj9eqrr6pkyZIaPXr0Ffu+++67LikMAAAAAIoLh4LTtm3brDPpbdu2rcB+JpPJNVUBAAAAQDHi9H2crnfcxwkAAACAVMj3cQIAAACAm41Dp+pFR0c7vMGEhISrLgYAAAAAiiOHglNAQEBh1wEAAAAAxZZDwWnOnDmFVkBcXJwmT56stLQ01alTR1OmTFFUVFS+fVeuXKm2bdvmaU9OTlatWrUKrUYAAAAANze3XuO0cOFCxcbGaty4cdq2bZuioqLUuXNnpaSkXHG9nTt3Ki0tzfq49dZbi6hiAAAAADejq5pVb/HixVq0aJFSUlJ07tw5m2Vbt251eDvNmjVTo0aNNH36dGtbZGSkevbsqYkTJ+bpnzvidOLECZUpU8bZsiUxqx4AAACAiwp1Vr33339fQ4YMUcWKFbVt2zY1bdpUgYGB+vvvv9W5c2eHt3Pu3Dlt2bJFHTt2tGnv2LGj1q1bd8V1GzZsqJCQEN11111asWLFFftmZ2crMzPT5gEAAAAAznA6OMXFxWnmzJmaNm2avL299eyzzyoxMVFPPvmkMjIyHN7O0aNHZbFYFBQUZNMeFBSk9PT0fNcJCQnRzJkz9Z///EcJCQmqWbOm7rrrLq1evbrA/UycOFEBAQHWR1hYmMM1AgAAAIDk4OQQl0pJSVHLli0lSX5+fjp16pQkaeDAgWrevLmmTZvm1PZMJpPNc8Mw8rTlqlmzpmrWrGl93qJFC6Wmpurtt9/WnXfeme86Y8eO1ejRo63PMzMzCU8AAAAAnOL0iFNwcLCOHTsmSQoPD9f69eslSXv37pUzl0uVL19eZrM5z+jS4cOH84xCXUnz5s21e/fuApf7+PjI39/f5gEAAAAAznA6OLVr107ffvutJGnYsGEaNWqUOnTooD59+ujee+91eDve3t5q3LixEhMTbdoTExOtI1qO2LZtm0JCQhzuDwAAAADOcvhUva+//lrdu3fXzJkzlZOTI0kaMWKEypUrpzVr1qh79+4aMWKEUzsfPXq0Bg4cqCZNmqhFixaaOXOmUlJSrNsZO3asDhw4oE8//VSSNGXKFEVERKhOnTo6d+6cPv/8c/3nP//Rf/7zH6f2CwAAAADOcDg49erVS+XLl9eDDz6ooUOHWq816t27t3r37n1VO+/Tp4+OHTumCRMmKC0tTXXr1tXSpUsVHh4uSUpLS7O5p9O5c+f09NNP68CBA/Lz81OdOnX03XffqUuXLle1fwAAAABwhMP3cTp48KDmzJmjTz75RHv27FGLFi00bNgw9e7dWyVLlizsOl2G+zgBAAAAkArpPk6VKlXSuHHjtGvXLv3888+qVq2annzySYWEhGj48OH65ZdfrrlwAAAAACiOnJ4cQpJat26tTz75RGlpaXr33XeVnJysO+64Q3Xq1HF1fQAAAADgdk7fx+lSpUqVUtu2bbVv3z79+eef2rVrl6vqAgAAAIBi46pGnLKysvTJJ5+odevWqlGjhhYuXKjRo0dr3759Li4PAAAAANzPqRGntWvXKj4+Xl9++aUuXLig6Oho/fTTT2rbtm1h1QcAAAAAbudwcKpRo4b27Nmjhg0b6s0331S/fv0UEBBQmLUBAAAAQLHgcHDq1KmThg0bpttuu60w6wEAAACAYsfh4PT+++8XZh0AAAAAUGxd1eQQAAAAAHAzITgBAAAAgB0EJwAAAACww+ng9Omnnyo7OztP+7lz5/Tpp5+6pCgAAAAAKE5MhmEYzqxgNpuVlpamihUr2rQfO3ZMFStWlMVicWmBrpaZmamAgABlZGTI39/f3eUAAAAAcBNnsoHTI06GYchkMuVp379/P/d1AgAAAHBDcng68oYNG8pkMslkMumuu+6Sp+f/rWqxWLR371516tSpUIoEAAAAAHdyODj17NlTkrR9+3bdfffdKlWqlHWZt7e3IiIidN9997m8QAAAAABwN4eD0/jx4yVJERER6tu3r3x8fAqtKAAAAAAoTpy+xqldu3Y6cuSI9fnGjRsVGxurmTNnurQwAAAAACgunA5O/fr104oVKyRJ6enpat++vTZu3Kjnn39eEyZMcHmBAAAAAOBuTgen33//XU2bNpUkLVq0SPXq1dO6dev0xRdfaO7cua6uDwAAAADczungdP78eev1TT/99JPuueceSVKtWrWUlpbm2uoAAAAAoBhwOjjVqVNHM2bMUFJSkhITE61TkB88eFCBgYEuLxAAAAAA3M3p4PTmm2/qo48+Ups2bfTAAw/otttukyR988031lP4AAAAAOBGYjIMw3B2JYvFoszMTJUtW9batm/fPpUoUUIVK1Z0aYGulpmZqYCAAGVkZMjf39/d5QAAAABwE2eygdMjTpJkGIa2bNmijz76SKdOnZJ08Sa4JUqUuJrNAQAAAECx5vANcHP9888/6tSpk1JSUpSdna0OHTqodOnSeuutt3T27FnNmDGjMOoEAAAAALdxesQpJiZGTZo00YkTJ+Tn52dtv/fee7V8+XKXFgcAAAAAxYHTI05r1qzR2rVr5e3tbdMeHh6uAwcOuKwwAAAAACgunB5xysnJkcViydO+f/9+lS5d2iVFAQAAAEBx4nRw6tChg6ZMmWJ9bjKZdPr0aY0fP15dunRxZW0AAAAAUCw4PR35wYMH1bZtW5nNZu3evVtNmjTR7t27Vb58ea1evZrpyAEAAABcF5zJBk5f41SpUiVt375dCxYs0JYtW5STk6Nhw4apf//+NpNFAAAAAMCN4qpugHs9Y8QJAAAAgFTII07Hjh1TYGCgJCk1NVUff/yx/v33X3Xv3l133nnn1VUMAAAAAMWYw5ND/Pbbb4qIiFDFihVVq1Ytbd++Xbfffrvee+89zZw5U+3atdPXX39diKUCAAAAgHs4HJyeffZZ1atXT6tWrVKbNm3UrVs3denSRRkZGTpx4oQeeeQRTZo0qTBrBQAAAAC3cPgap/Lly+vnn39W/fr1dfr0afn7+2vjxo1q0qSJJOnPP/9U8+bNdfLkycKs95pxjRMAAAAAybls4PCI0/HjxxUcHCxJKlWqlEqWLKly5cpZl5ctW1anTp26ypIBAAAAoPhy6ga4JpPpis8BAAAA4Ebk1Kx6gwcPlo+PjyTp7NmzGjFihEqWLClJys7Odn11AAAAAFAMOBycHnzwQZvnAwYMyNNn0KBB114RAAAAABQzDgenOXPmFGYdAAAAAFBsOXWNEwAAAADcjAhOAAAAAGAHwQkAAAAA7CA4AQAAAIAdBCcAAAAAsIPgBAAAAAB2EJwAAAAAwA6CEwAAAADYQXACAAAAADsITgAAAABgh9uDU1xcnKpWrSpfX181btxYSUlJDq23du1aeXp6qkGDBoVbIAAAAICbnluD08KFCxUbG6tx48Zp27ZtioqKUufOnZWSknLF9TIyMjRo0CDdddddRVQpAAAAgJuZyTAMw107b9asmRo1aqTp06db2yIjI9WzZ09NnDixwPX69u2rW2+9VWazWV9//bW2b9/u8D4zMzMVEBCgjIwM+fv7X0v5AAAAAK5jzmQDt404nTt3Tlu2bFHHjh1t2jt27Kh169YVuN6cOXO0Z88ejR8/3qH9ZGdnKzMz0+YBAAAAAM7wdNeOjx49KovFoqCgIJv2oKAgpaen57vO7t279dxzzykpKUmeno6VPnHiRL3yyivXXG9hsORYlJSSpLRTaQopHaKoKlEye5jdXRYAAACAy7gtOOUymUw2zw3DyNMmSRaLRf369dMrr7yiGjVqOLz9sWPHavTo0dbnmZmZCgsLu/qCXSQhOUExy2K0P3O/tS3UP1RTO01VdGS0GysDAAAAcDm3Bafy5cvLbDbnGV06fPhwnlEoSTp16pQ2b96sbdu26YknnpAk5eTkyDAMeXp66scff1S7du3yrOfj4yMfH5/CeRFXKSE5Qb0W9ZIh28vLDmQeUK9FvbS492LCEwAAAFCMuO0aJ29vbzVu3FiJiYk27YmJiWrZsmWe/v7+/vrtt9+0fft262PEiBGqWbOmtm/frmbNmhVV6dfEkmNRzLKYPKFJkrUtdlmsLDmWoi4NAAAAQAHceqre6NGjNXDgQDVp0kQtWrTQzJkzlZKSohEjRki6eJrdgQMH9Omnn8rDw0N169a1Wb9ixYry9fXN016cJaUk2ZyedzlDhlIzU5WUkqQ2EW2KrjAAAAAABXJrcOrTp4+OHTumCRMmKC0tTXXr1tXSpUsVHh4uSUpLS7N7T6frTdqpNJf2AwAAAFD43HofJ3dw932cVu5bqbaftLXbb8WDKxhxAgAAAArRdXEfp5tVVJUohfqHyqS8MwdKkkkmhfmHKapKVBFXBgAAAKAgBKciZvYwa2qnqZKUJzzlPp/SaQr3cwIAAACKEYKTG0RHRmtx78Wq7F/Zpj3UP5SpyAEAAIBiiGuc3MiSY1FSSpLSTqUppHSIoqpEMdIEAAAAFBFnsoFbZ9W72Zk9zEwAAQAAAFwHOFUPAAAAAOwgOAEAAACAHQQnAAAAALCD4AQAAAAAdhCcAAAAAMAOghMAAAAA2EFwAgAAAAA7CE4AAAAAYAfBCQAAAADsIDgBAAAAgB0EJwAAAACwg+AEAAAAAHYQnAAAAADADoITAAAAANhBcAIAAAAAOwhOAAAAAGAHwQkAAAAA7CA4AQAAAIAdBCcAAAAAsIPgBAAAAAB2EJwAAAAAwA6CEwAAAADY4enuAoori8Wi8+fPu7sMOMHLy0tms9ndZQAAAOAGRHC6jGEYSk9P18mTJ91dCq5CmTJlFBwcLJPJ5O5SAAAAcAMhOF0mNzRVrFhRJUqU4Bfw64RhGMrKytLhw4clSSEhIW6uCAAAADcSgtMlLBaLNTQFBga6uxw4yc/PT5J0+PBhVaxYkdP2AAAA4DJMDnGJ3GuaSpQo4eZKcLVyPzuuTwMAAIArEZzywel51y8+OwAAABQGghMAAAAA2EFwusG8/PLLatCgwTVtY9++fTKZTNq+fbtLagIAAACudwQnN0hNTdWwYcNUqVIleXt7Kzw8XDExMTp27JhT2zGZTPr6669t2p5++mktX778muoLCwtTWlqa6tate03bAQAAAG4UBKci9vfff6tJkybatWuX5s+fr7/++kszZszQ8uXL1aJFCx0/fvyatl+qVKlrnhHQbDYrODhYnp6FM+mixWJRTk5OoWwbAAAAKAwEpyL2+OOPy9vbWz/++KNat26tKlWqqHPnzvrpp5904MABjRs3TpIUERGhV199Vf369VOpUqVUqVIlffDBB9btRERESJLuvfdemUwm6/PLT9UbPHiwevbsqTfeeENBQUEqU6aMXnnlFV24cEHPPPOMypUrp9DQUMXHx1vXufxUvcGDB8tkMuV5rFy5UpJ07tw5Pfvss6pcubJKliypZs2aWZdJ0ty5c1WmTBktWbJEtWvXlo+Pj/755x+Xv7cAAABAYSE4FaHjx4/rhx9+0GOPPWa951Cu4OBg9e/fXwsXLpRhGJKkyZMnq379+tq6davGjh2rUaNGKTExUZK0adMmSdKcOXOUlpZmfZ6fn3/+WQcPHtTq1av17rvv6uWXX1a3bt1UtmxZbdiwQSNGjNCIESOUmpqa7/pTp05VWlqa9RETE6OKFSuqVq1akqQhQ4Zo7dq1WrBggf73v//p/vvvV6dOnbR7927rNrKysjRx4kTNmjVLf/zxhypWrHj1byRQhCw5Fq3ct1Lzf5uvlftWypJjcXdJAADADbgBbhHavXu3DMNQZGRkvssjIyN14sQJHTlyRJLUqlUrPffcc5KkGjVqaO3atXrvvffUoUMHVahQQZJUpkwZBQcHX3G/5cqV0/vvvy8PDw/VrFlTb731lrKysvT8889LksaOHatJkyZp7dq16tu3b571AwICFBAQIElKSEjQjBkz9NNPPyk4OFh79uzR/PnztX//flWqVEnSxeusli1bpjlz5uiNN96QdPG+SnFxcbrtttucfdsAt0lITlDMshjtz9xvbQv1D9XUTlMVHRntxsoAAEBRY8SpGMkdacq9F1GLFi1slrdo0ULJyclOb7dOnTry8Pi/jzooKEj16tWzPjebzQoMDNThw4evuJ1t27Zp0KBB+vDDD3XHHXdIkrZu3SrDMFSjRg2VKlXK+li1apX27NljXdfb21v169d3unbAXRKSE9RrUS+b0CRJBzIPqNeiXkpITnBTZQAAwB0YcSpC1atXl8lk0o4dO9SzZ888y//880+VLVtW5cuXL3AbV3ODVy8vrzzbyK/tShM2pKen65577tGwYcM0bNgwa3tOTo7MZrO2bNkis9lss06pUqWs//bz8+PmtLhuWHIsilkWI0NGnmWGDJlkUuyyWPWo2UNmD3M+WwAAADcaRpyKUGBgoDp06KC4uDj9+++/NsvS09M1b9489enTxxow1q9fb9Nn/fr11uuKpIuByGIp/Ostzp49qx49eqhWrVp69913bZY1bNhQFotFhw8fVvXq1W0e9k4hBIqrpJSkPCNNlzJkKDUzVUkpSUVYFQAAcCeCUxGbNm2asrOzdffdd2v16tVKTU3VsmXL1KFDB1WuXFmvv/66te/atWv11ltvadeuXfrwww/15ZdfKiYmxro8IiJCy5cvV3p6uk6cOFFoNT/yyCNKTU3V+++/ryNHjig9PV3p6ek6d+6catSoof79+2vQoEFKSEjQ3r17tWnTJr355ptaunRpodUEFKa0U2ku7QcAAK5/BKciduutt2rz5s2qVq2a+vTpo2rVqunhhx9W27Zt9csvv6hcuXLWvk899ZS2bNmihg0b6tVXX9U777yju+++27r8nXfeUWJiosLCwtSwYcNCq3nVqlVKS0tT7dq1FRISYn2sW7dO0sWZ/QYNGqSnnnpKNWvW1D333KMNGzYoLCys0GoCClNI6RCX9gMAANc/k5E7I8FNIjMzUwEBAcrIyJC/v7/NsrNnz2rv3r2qWrWqfH193VThRREREYqNjVVsbKxb67jeFKfPENcvS45FEVMjdCDzQL7XOZlkUqh/qPbG7OUaJwAArmNXygaXY8QJAC5j9jBraqepki6GpEvlPp/SaQqhCQCAmwjBCQDyER0ZrcW9F6uyf2Wb9lD/UC3uvZj7OAEAcJNhOvJiat++fe4uAbjpRUdGq0fNHkpKSVLaqTSFlA5RVJUoRpoAALgJEZwA4ArMHma1iWjj7jIAAICbcaoeAAAAANhBcAIAAAAAO9wenOLi4qxTRzdu3FhJSUkF9l2zZo1atWqlwMBA+fn5qVatWnrvvfeKsFoAAAAANyO3XuO0cOFCxcbGKi4uTq1atdJHH32kzp07a8eOHapSpUqe/iVLltQTTzyh+vXrq2TJklqzZo0eeeQRlSxZUg8//LAbXgEAAACAm4Fbb4DbrFkzNWrUSNOnT7e2RUZGqmfPnpo4caJD24iOjlbJkiX12WefOdT/erkBLq4OnyEAAAAcdV3cAPfcuXPasmWLOnbsaNPesWNHrVu3zqFtbNu2TevWrVPr1q0L7JOdna3MzEybBwAAAAA4w23B6ejRo7JYLAoKCrJpDwoKUnp6+hXXDQ0NlY+Pj5o0aaLHH39cw4cPL7DvxIkTFRAQYH2EhYW5pP7iZvDgwTKZTDKZTPL09FSVKlX06KOP6sSJE9Y+ERERMplMWrBgQZ7169SpI5PJpLlz51rbtm3bpm7duqlixYry9fVVRESE+vTpo6NHjxbFSwIAAACKDbdPDmEymWyeG4aRp+1ySUlJ2rx5s2bMmKEpU6Zo/vz5BfYdO3asMjIyrI/U1FSX1G2XxSKtXCnNn3/xvxZLoe+yU6dOSktL0759+zRr1ix9++23euyxx2z6hIWFac6cOTZt69evV3p6ukqWLGltO3z4sNq3b6/y5cvrhx9+UHJysuLj4xUSEqKsrKyrrtFisSgnJ+eq1wcAAADcwW3BqXz58jKbzXlGlw4fPpxnFOpyVatWVb169fTQQw9p1KhRevnllwvs6+PjI39/f5tHoUtIkCIipLZtpX79Lv43IuJieyHy8fFRcHCwQkND1bFjR/Xp00c//vijTZ/+/ftr1apVNgEyPj5e/fv3l6fn/80Vsm7dOmVmZmrWrFlq2LChqlatqnbt2mnKlCnWiTtWrlwpk8mk7777Trfddpt8fX3VrFkz/fbbb9btzJ07V2XKlNGSJUtUu3Zt+fj46J9//tGJEyc0aNAglS1bViVKlFDnzp21e/fuPOt9/fXXqlGjhnx9fdWhQ4eiC74AAADAJdwWnLy9vdW4cWMlJibatCcmJqply5YOb8cwDGVnZ7u6vKuXkCD16iXt32/bfuDAxfZCDk+5/v77by1btkxeXl427UFBQbr77rv1ySefSJKysrK0cOFCDR061KZfcHCwLly4oK+++kr25g955pln9Pbbb2vTpk2qWLGi7rnnHp0/f966PCsrSxMnTtSsWbP0xx9/qGLFiho8eLA2b96sb775Rr/88osMw1CXLl3yrPf666/rk08+0dq1a5WZmam+ffte61sDAAAAOM2tp+qNHj1as2bNUnx8vJKTkzVq1CilpKRoxIgRki6eZjdo0CBr/w8//FDffvutdu/erd27d2vOnDl6++23NWDAAHe9BFsWixQTI+UXNHLbYmML7bS9JUuWqFSpUvLz81O1atW0Y8cOjRkzJk+/oUOHau7cuTIMQ4sXL1a1atXUoEEDmz7NmzfX888/r379+ql8+fLq3LmzJk+erEOHDuXZ3vjx49WhQwfVq1dPn3zyiQ4dOqSvvvrKuvz8+fOKi4tTy5YtVbNmTR08eFDffPONZs2apaioKN12222aN2+eDhw4oK+//tpmvWnTpqlFixZq3LixPvnkE61bt04bN2502XsGAAAAOMKtwalPnz6aMmWKJkyYoAYNGmj16tVaunSpwsPDJUlpaWlKSUmx9s/JydHYsWPVoEEDNWnSRB988IEmTZqkCRMmuOsl2EpKyjvSdCnDkFJTL/YrBG3bttX27du1YcMGjRw5UnfffbdGjhyZp1/Xrl11+vRprV69WvHx8XlGm3K9/vrrSk9P14wZM1S7dm3NmDFDtWrVsjkVT5JatGhh/Xe5cuVUs2ZNJScnW9u8vb1Vv3596/Pk5GR5enqqWbNm1rbAwMA863l6eqpJkybW57Vq1VKZMmVs+gAAAABFwe2TQzz22GPat2+fsrOztWXLFt15553WZXPnztXKlSutz0eOHKnff/9dZ86cUUZGhrZu3apHH31UHh5ufxkXpaW5tp+TSpYsqerVq6t+/fp6//33lZ2drVdeeSVPP09PTw0cOFDjx4/Xhg0b1L9//wK3GRgYqPvvv1/vvPOOkpOTValSJb399tt2a7l0gg8/Pz+b5wWd+pffxCD5TRRib/IQAAAAwNWKSeK4QYSEuLbfNRo/frzefvttHTx4MM+yoUOHatWqVerRo4fKli3r0Pa8vb1VrVo1nTlzxqZ9/fr11n+fOHFCu3btUq1atQrcTu3atXXhwgVt2LDB2nbs2DHt2rVLkZGR1rYLFy5o8+bN1uc7d+7UyZMnr7htAAAAoDAQnFwpKkoKDZUKGhExmaSwsIv9ikCbNm1Up04dvfHGG3mWRUZG6ujRo3mmJs+1ZMkSDRgwQEuWLNGuXbu0c+dOvf3221q6dKl69Ohh03fChAlavny5fv/9dw0ePFjly5dXz549C6zr1ltvVY8ePfTQQw9pzZo1+vXXXzVgwABVrlzZZtteXl4aOXKkNmzYoK1bt2rIkCFq3ry5mjZtenVvCAAAAHCVCE6uZDZLU6de/Pfl4Sn3+ZQpF/sVkdGjR+vjjz/OdxrvwMBA+fn55bte7dq1VaJECT311FNq0KCBmjdvrkWLFmnWrFkaOHCgTd9JkyYpJiZGjRs3Vlpamr755ht5e3tfsa45c+aocePG6tatm1q0aCHDMLR06VKbWQBLlCihMWPGqF+/fmrRooX8/PzyvXkvAAAAUNhMhr25pm8wmZmZCggIUEZGRp57Op09e1Z79+5V1apV5evre/U7SUi4OLvepRNFhIVdDE3R0Ve/3WJm5cqVatu2rU6cOKEyZcq4dNtz585VbGysTp486dR6LvsMAQAAcMO7Uja4nOcVl+LqREdLPXpcnD0vLe3iNU1RUUU60gQAAADAdQhOhcVsltq0cXcVAAAAAFyAa5xw1dq0aSPDMFx+mp4kDR482OnT9AAAAIDCQnACAAAAADsITgAAAABgB8EJAAAAAOwgOAEAAACAHQQnAAAAALCD4AQAAAAAdhCcbmIvv/yyGjRo4O4yAAAAgGKP4HSDWbduncxmszp16uTuUgAAAIAbBsGpkFgs0sqV0vz5F/9rsRTNfuPj4zVy5EitWbNGKSkpRbNTAAAA4AZHcCoECQlSRITUtq3Ur9/F/0ZEXGwvTGfOnNGiRYv06KOPqlu3bpo7d67N8kmTJikoKEilS5fWsGHDdPbsWZvlmzZtUocOHVS+fHkFBASodevW2rp1q00fk8mkjz76SN26dVOJEiUUGRmpX375RX/99ZfatGmjkiVLqkWLFtqzZ0/hvlgAAACgCBGcXCwhQerVS9q/37b9wIGL7YUZnhYuXKiaNWuqZs2aGjBggObMmSPDMCRJixYt0vjx4/X6669r8+bNCgkJUVxcnM36p06d0oMPPqikpCStX79et956q7p06aJTp07Z9Hv11Vc1aNAgbd++XbVq1VK/fv30yCOPaOzYsdq8ebMk6Yknnii8FwoAAAAUMZOR+5v1TSIzM1MBAQHKyMiQv7+/zbKzZ89q7969qlq1qnx9fZ3etsVycWTp8tCUy2SSQkOlvXsls/kqirejVatW6t27t2JiYnThwgWFhIRo/vz5at++vVq2bKnbbrtN06dPt/Zv3ry5zp49q+3btxfweiwqW7asvvjiC3Xr1u3/vwaTXnjhBb366quSpPXr16tFixaaPXu2hg4dKklasGCBhgwZon///df1L9KOa/0MAQAAcPO4Uja4HCNOLpSUVHBokiTDkFJTL/ZztZ07d2rjxo3q27evJMnT01N9+vRRfHy8JCk5OVktWrSwWefy54cPH9aIESNUo0YNBQQEKCAgQKdPn85zrVT9+vWt/w4KCpIk1atXz6bt7NmzyszMdN0LBAAAANzI090F3EjS0lzbzxmzZ8/WhQsXVLlyZWubYRjy8vLSiRMnHNrG4MGDdeTIEU2ZMkXh4eHy8fFRixYtdO7cOZt+Xl5e1n+bTKYC23Jycq769QAAAADFCSNOLhQS4tp+jrpw4YI+/fRTvfPOO9q+fbv18euvvyo8PFzz5s1TZGSk1q9fb7Pe5c+TkpL05JNPqkuXLqpTp458fHx09OhR1xYLAAAAXIcYcXKhqKiL1zAdOHDxtLzL5V7jFBXl2v0uWbJEJ06c0LBhwxQQEGCzrFevXpo9e7aee+45Pfjgg2rSpInuuOMOzZs3T3/88YduueUWa9/q1avrs88+U5MmTZSZmalnnnlGfn5+ri0WAAAAuA4x4uRCZrM0derFf///s9Wscp9PmeL6iSFmz56t9u3b5wlNknTfffdp+/btuvXWW/XSSy9pzJgxaty4sf755x89+uijNn3j4+N14sQJNWzYUAMHDtSTTz6pihUrurZYAAAA4DrErHqXcNWMbAkJUkyM7UQRYWEXQ1N09FVvFg5gVj0AAAA4yplZ9ThVrxBER0s9elycPS8t7eI1TVFRhTMFOQAAAIDCR3AqJGaz1KaNu6sAAAAA4Apc4wQAAAAAdhCcAAAAAMAOghMAAAAA2EFwAgAAAAA7CE4AAAAAYAfBCQAAAADsIDgBAAAAgB0Ep5vYyy+/rAYNGlzzdkwmk77++muH+w8ePFg9e/a85v0CAADg+mLJsWjlvpWa/9t8rdy3UpYci7tLchjB6Qazbt06mc1mderUyd2lOKxNmzaKjY11dxkAAAAoRAnJCYqYGqG2n7RVv4R+avtJW0VMjVBCcoK7S3MIwamQuCtNx8fHa+TIkVqzZo1SUlKKZJ8AAADAlSQkJ6jXol7an7nfpv1A5gH1WtTrughPBKdC4K40febMGS1atEiPPvqounXrprlz59osnzRpkoKCglS6dGkNGzZMZ8+etVm+adMmdejQQeXLl1dAQIBat26trVu32vTZvXu37rzzTvn6+qp27dpKTEzMU8eBAwfUp08flS1bVoGBgerRo4f27duXb82DBw/WqlWrNHXqVJlMJplMJu3bt08Wi0XDhg1T1apV5efnp5o1a2rq1KnX9P4AAACg6FlyLIpZFiNDRp5luW2xy2KL/Wl7BCcXc2eaXrhwoWrWrKmaNWtqwIABmjNnjgzj4sG4aNEijR8/Xq+//ro2b96skJAQxcXF2ax/6tQpPfjgg0pKStL69et16623qkuXLjp16pQkKScnR9HR0TKbzVq/fr1mzJihMWPG2GwjKytLbdu2ValSpbR69WqtWbNGpUqVUqdOnXTu3Lk8NU+dOlUtWrTQQw89pLS0NKWlpSksLEw5OTkKDQ3VokWLtGPHDr300kt6/vnntWjRokJ69wAAAFAYklKS8vxufClDhlIzU5WUklSEVTnP090F3EjspWmTTIpdFqseNXvI7GF2+f5nz56tAQMGSJI6deqk06dPa/ny5Wrfvr2mTJmioUOHavjw4ZKk1157TT/99JPNqFO7du1stvfRRx+pbNmyWrVqlbp166affvpJycnJ2rdvn0JDQyVJb7zxhjp37mxdZ8GCBfLw8NCsWbNkMpkkSXPmzFGZMmW0cuVKdezY0WYfAQEB8vb2VokSJRQcHGxtN5vNeuWVV6zPq1atqnXr1mnRokXq3bu3K94uAAAAFIG0U2ku7ecujDi5kDvT9M6dO7Vx40b17dtXkuTp6ak+ffooPj5ekpScnKwWLVrYrHP588OHD2vEiBGqUaOGAgICFBAQoNOnT1uvlUpOTlaVKlWsoSm/bWzZskV//fWXSpcurVKlSqlUqVIqV66czp49qz179jj1mmbMmKEmTZqoQoUKKlWqlD7++GOu2wIAALjOhJQOcWk/d2HEyYXcmaZnz56tCxcuqHLlytY2wzDk5eWlEydOOLSNwYMH68iRI5oyZYrCw8Pl4+OjFi1aWE+xyz3t71K5o0q5cnJy1LhxY82bNy9P3woVKjj8ehYtWqRRo0bpnXfeUYsWLVS6dGlNnjxZGzZscHgbAAAAcL+oKlEK9Q/VgcwD+Z6ZZZJJof6hiqoS5YbqHEdwciF3pekLFy7o008/1TvvvJPnVLj77rtP8+bNU2RkpNavX69BgwZZl61fv96mb1JSkuLi4tSlSxdJUmpqqo4ePWpdXrt2baWkpOjgwYOqVKmSJOmXX36x2UajRo20cOFCVaxYUf7+/g7V7+3tLYvF9mLApKQktWzZUo899pi1zdkRKwAAALif2cOsqZ2mqteiXjLJZBOeTLr4R/gpnaYUyqUsrsSpei6Um6ZzD4DLmWRSmH+Yy9P0kiVLdOLECQ0bNkx169a1efTq1UuzZ89WTEyM4uPjFR8fr127dmn8+PH6448/bLZTvXp1ffbZZ0pOTtaGDRvUv39/+fn5WZe3b99eNWvW1KBBg/Trr78qKSlJ48aNs9lG//79Vb58efXo0UNJSUnau3evVq1apZiYGO3fn/9pjBEREdqwYYP27duno0ePKicnR9WrV9fmzZv1ww8/aNeuXXrxxRe1adMml75vAAAAKBrRkdFa3HuxKvtXtmkP9Q/V4t6LFR0Z7abKHEdwcqHcNC0pT3gqzDQ9e/ZstW/fXgEBAXmW3Xfffdq+fbtuvfVWvfTSSxozZowaN26sf/75R48++qhN3/j4eJ04cUINGzbUwIED9eSTT6pixYrW5R4eHvrqq6+UnZ2tpk2bavjw4Xr99ddttlGiRAmtXr1aVapUUXR0tCIjIzV06FD9+++/BY5APf300zKbzapdu7YqVKiglJQUjRgxQtHR0erTp4+aNWumY8eO2Yw+AQAA4PoSHRmtfTH7tOLBFfoi+guteHCF9sbsvS5CkySZjPwuXLmBZWZmKiAgQBkZGXl+kT979qz27t2rqlWrytfX96r3kZCcoJhlMTYTRYT5h2lKpynXzYFxvXLVZwgAAIAb35WyweW4xqkQREdGq0fNHkpKSVLaqTSFlA5RVJWoYn/eJgAAAID8EZwKidnDrDYRbdxdBgAAAAAX4BonAAAAALCD4AQAAAAAdhCc8nGTzZdxQ+GzAwAAQGEgOF3Cy8tLkpSVleXmSnC1cj+73M8SAAAAcAW3Tw4RFxenyZMnKy0tTXXq1NGUKVMUFZX/DWITEhI0ffp0bd++XdnZ2apTp45efvll3X333S6pxWw2q0yZMjp8+LCki/ckMpnyv5ktihfDMJSVlaXDhw+rTJkyMpuZwRAAAACu49bgtHDhQsXGxiouLk6tWrXSRx99pM6dO2vHjh2qUqVKnv6rV69Whw4d9MYbb6hMmTKaM2eOunfvrg0bNqhhw4YuqSk4OFiSrOEJ15cyZcpYP0MAAADAVdx6A9xmzZqpUaNGmj59urUtMjJSPXv21MSJEx3aRp06ddSnTx+99NJL+S7Pzs5Wdna29XlmZqbCwsLs3uTKYrHo/PnzDr4SFAdeXl6MNAEAAMBh18UNcM+dO6ctW7boueees2nv2LGj1q1b59A2cnJydOrUKZUrV67APhMnTtQrr7zidH1ms5lfwgEAAABIcuPkEEePHpXFYlFQUJBNe1BQkNLT0x3axjvvvKMzZ86od+/eBfYZO3asMjIyrI/U1NRrqhsAAADAzcftk0NcPvmCYRgOTcgwf/58vfzyy/rvf/+rihUrFtjPx8dHPj4+11wnAAAAgJuX24JT+fLlZTab84wuHT58OM8o1OUWLlyoYcOG6csvv1T79u0Ls0wAAAAAcF9w8vb2VuPGjZWYmKh7773X2p6YmKgePXoUuN78+fM1dOhQzZ8/X127dnV6v7lzYWRmZjpfNAAAAIAbRm4mcGS+PLeeqjd69GgNHDhQTZo0UYsWLTRz5kylpKRoxIgRki5en3TgwAF9+umnki6GpkGDBmnq1Klq3ry5dbTKz89PAQEBDu3z1KlTkqSwsLBCeEUAAAAArjenTp2ymyfcOh25dPEGuG+99ZbS0tJUt25dvffee7rzzjslSYMHD9a+ffu0cuVKSVKbNm20atWqPNt48MEHNXfuXIf2l5OTo4MHD6p06dLc3LYI5U4Dn5qaaneqR+BKOJbgKhxLcBWOJbgCx5F7GIahU6dOqVKlSvLwuPK8eW4PTrg5ODNHPnAlHEtwFY4luArHElyB46j4c9t05AAAAABwvSA4AQAAAIAdBCcUCR8fH40fP557auGacSzBVTiW4CocS3AFjqPij2ucAAAAAMAORpwAAAAAwA6CEwAAAADYQXACAAAAADsITgAAAABgB8EJhWbixIkymUyKjY21thmGoZdfflmVKlWSn5+f2rRpoz/++MN9RaLYOnDggAYMGKDAwECVKFFCDRo00JYtW6zLOZbgiAsXLuiFF15Q1apV5efnp1tuuUUTJkxQTk6OtQ/HEvKzevVqde/eXZUqVZLJZNLXX39ts9yR4yY7O1sjR45U+fLlVbJkSd1zzz3av39/Eb4KFAdXOpbOnz+vMWPGqF69eipZsqQqVaqkQYMG6eDBgzbb4FgqHghOKBSbNm3SzJkzVb9+fZv2t956S++++66mTZumTZs2KTg4WB06dNCpU6fcVCmKoxMnTqhVq1by8vLS999/rx07duidd95RmTJlrH04luCIN998UzNmzNC0adOUnJyst956S5MnT9YHH3xg7cOxhPycOXNGt912m6ZNm5bvckeOm9jYWH311VdasGCB1qxZo9OnT6tbt26yWCxF9TJQDFzpWMrKytLWrVv14osvauvWrUpISNCuXbt0zz332PTjWComDMDFTp06Zdx6661GYmKi0bp1ayMmJsYwDMPIyckxgoODjUmTJln7nj171ggICDBmzJjhpmpRHI0ZM8a44447ClzOsQRHde3a1Rg6dKhNW3R0tDFgwADDMDiW4BhJxldffWV97shxc/LkScPLy8tYsGCBtc+BAwcMDw8PY9myZUVWO4qXy4+l/GzcuNGQZPzzzz+GYXAsFSeMOMHlHn/8cXXt2lXt27e3ad+7d6/S09PVsWNHa5uPj49at26tdevWFXWZKMa++eYbNWnSRPfff78qVqyohg0b6uOPP7Yu51iCo+644w4tX75cu3btkiT9+uuvWrNmjbp06SKJYwlXx5HjZsuWLTp//rxNn0qVKqlu3bocW7iijIwMmUwm61kWHEvFh6e7C8CNZcGCBdq6das2bdqUZ1l6erokKSgoyKY9KChI//zzT5HUh+vD33//renTp2v06NF6/vnntXHjRj355JPy8fHRoEGDOJbgsDFjxigjI0O1atWS2WyWxWLR66+/rgceeEASP5dwdRw5btLT0+Xt7a2yZcvm6ZO7PnC5s2fP6rnnnlO/fv3k7+8viWOpOCE4wWVSU1MVExOjH3/8Ub6+vgX2M5lMNs8Nw8jThptbTk6OmjRpojfeeEOS1LBhQ/3xxx+aPn26Bg0aZO3HsQR7Fi5cqM8//1xffPGF6tSpo+3btys2NlaVKlXSgw8+aO3HsYSrcTXHDccWCnL+/Hn17dtXOTk5iouLs9ufY6nocaoeXGbLli06fPiwGjduLE9PT3l6emrVqlV6//335enpaf3L3OV/HTl8+HCev9rh5hYSEqLatWvbtEVGRiolJUWSFBwcLIljCfY988wzeu6559S3b1/Vq1dPAwcO1KhRozRx4kRJHEu4Oo4cN8HBwTp37pxOnDhRYB8g1/nz59W7d2/t3btXiYmJ1tEmiWOpOCE4wWXuuusu/fbbb9q+fbv10aRJE/Xv31/bt2/XLbfcouDgYCUmJlrXOXfunFatWqWWLVu6sXIUN61atdLOnTtt2nbt2qXw8HBJUtWqVTmW4JCsrCx5eNj+r85sNlunI+dYwtVw5Lhp3LixvLy8bPqkpaXp999/59iCjdzQtHv3bv30008KDAy0Wc6xVHxwqh5cpnTp0qpbt65NW8mSJRUYGGhtj42N1RtvvKFbb71Vt956q9544w2VKFFC/fr1c0fJKKZGjRqlli1b6o033lDv3r21ceNGzZw5UzNnzpQk6/3BOJZgT/fu3fX666+rSpUqqlOnjrZt26Z3331XQ4cOlcSxhIKdPn1af/31l/X53r17tX37dpUrV05VqlSxe9wEBARo2LBheuqppxQYGKhy5crp6aefVr169fJMnoQb25WOpUqVKqlXr17aunWrlixZIovFYh3JLFeunLy9vTmWihN3TumHG9+l05EbxsUpXMePH28EBwcbPj4+xp133mn89ttv7isQxda3335r1K1b1/Dx8TFq1aplzJw502Y5xxIckZmZacTExBhVqlQxfH19jVtuucUYN26ckZ2dbe3DsYT8rFixwpCU5/Hggw8ahuHYcfPvv/8aTzzxhFGuXDnDz8/P6Natm5GSkuKGVwN3utKxtHfv3nyXSTJWrFhh3QbHUvFgMgzDKPq4BgAAAADXD65xAgAAAAA7CE4AAAAAYAfBCQAAAADsIDgBAAAAgB0EJwAAAACwg+AEAAAAAHYQnAAAAADADoITAAAAANhBcAIA3BTmzp2rMmXKuHy7L7/8sho0aODy7QIAiheCEwCgyAwePFgmk8n6CAwMVKdOnfS///3Pqe0UZVj5z3/+o2bNmikgIEClS5dWnTp19NRTT1mXP/3001q+fHmR1AIAcB+CEwCgSHXq1ElpaWlKS0vT8uXL5enpqW7durm7rHz99NNP6tu3r3r16qWNGzdqy5Ytev3113Xu3Dlrn1KlSikwMNCNVQIAigLBCQBQpHx8fBQcHKzg4GA1aNBAY8aMUWpqqo4cOWLtM2bMGNWoUUMlSpTQLbfcohdffFHnz5+XdPGUu1deeUW//vqrdeRq7ty5kqSTJ0/q4YcfVlBQkHx9fVW3bl0tWbLEZv8//PCDIiMjVapUKWuIK8iSJUt0xx136JlnnlHNmjVVo0YN9ezZUx988IG1z+WjX5eOqOU+IiIirMt37NihLl26qFSpUgoKCtLAgQN19OjRa3hHAQBFgeAEAHCb06dPa968eapevbrNqE3p0qU1d+5c7dixQ1OnTtXHH3+s9957T5LUp08fPfXUU6pTp4515KpPnz7KyclR586dtW7dOn3++efasWOHJk2aJLPZbN1uVlaW3n77bX322WdavXq1UlJS9PTTTxdYX3BwsP744w/9/vvvDr+m3JrS0tL0119/qXr16rrzzjuty1q3bq0GDRpo8+bNWrZsmQ4dOqTevXs7+9YBAIqYp7sLAADcXJYsWaJSpUpJks6cOaOQkBAtWbJEHh7/97e8F154wfrviIgIPfXUU1q4cKGeffZZ+fn5qVSpUvL09FRwcLC1348//qiNGzcqOTlZNWrUkCTdcsstNvs+f/68ZsyYoWrVqkmSnnjiCU2YMKHAWkeOHKmkpCTVq1dP4eHhat68uTp27Kj+/fvLx8cn33VyazIMQ/fdd58CAgL00UcfSZKmT5+uRo0a6Y033rD2j4+PV1hYmHbt2mWtGwBQ/DDiBAAoUm3bttX27du1fft2bdiwQR07dlTnzp31zz//WPssXrxYd9xxh4KDg1WqVCm9+OKLSklJueJ2t2/frtDQ0CuGjxIlSlhDkySFhITo8OHDBfYvWbKkvvvuO/3111964YUXVKpUKT311FNq2rSpsrKyrljP888/r19++UVff/21/Pz8JElbtmzRihUrVKpUKeujVq1akqQ9e/ZccXsAAPciOAEAilTJkiVVvXp1Va9eXU2bNtXs2bN15swZffzxx5Kk9evXq2/fvurcubOWLFmibdu2ady4cTYTMuQnN5xciZeXl81zk8kkwzDsrletWjUNHz5cs2bN0tatW7Vjxw4tXLiwwP6ff/653nvvPX311VcKDQ21tufk5Kh79+7W4Jj72L17t/V0PgBA8cSpegAAtzKZTPLw8NC///4rSVq7dq3Cw8M1btw4a59LR6MkydvbWxaLxaatfv362r9/f6Gf8hYREaESJUrozJkz+S7/5ZdfNHz4cH300Udq3ry5zbJGjRrpP//5jyIiIuTpyf+CAeB6wogTAKBIZWdnKz09Xenp6UpOTtbIkSN1+vRpde/eXZJUvXp1paSkaMGCBdqzZ4/ef/99ffXVVzbbiIiI0N69e7V9+3YdPXpU2dnZat26te68807dd999SkxM1N69e/X9999r2bJlV13ryy+/rGeffVYrV67U3r17tW3bNg0dOlTnz59Xhw4d8vRPT0/Xvffeq759++ruu++2vs7cGQMff/xxHT9+XA888IA2btyov//+Wz/++KOGDh2aJwgCAIoXghMAoEgtW7ZMISEhCgkJUbNmzbRp0yZ9+eWXatOmjSSpR48eGjVqlJ544gk1aNBA69at04svvmizjfvuu0+dOnVS27ZtVaFCBc2fP1/SxZvV3n777XrggQdUu3ZtPfvss9cUSFq3bq2///5bgwYNUq1atdS5c2elp6frxx9/VM2aNfP0//PPP3Xo0CF98skn1tcYEhKi22+/XZJUqVIlrV27VhaLRXfffbfq1q2rmJgYBQQE2EyOAQAofkyGIyd3AwAAAMBNjD9vAQAAAIAdBCcAAAAAsIPgBAAAAAB2EJwAAAAAwA6CEwAAAADYQXACAAAAADsITgAAAABgB8EJAAAAAOwgOAEAAACAHQQnAAAAALCD4AQAAAAAdvw/VLXcqn+gBA4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = {'RMSprop': 'red', 'Adam': 'blue', 'Adadelta': 'green'}\n",
    "for optimizer in results_df['optimizer'].unique():\n",
    "    subset = results_df[results_df['optimizer'] == optimizer]\n",
    "    ax.scatter(subset['batch_size'], subset['best_val_accuracy'], color=colors[optimizer], label=optimizer)\n",
    "\n",
    "ax.set_title('Batch Size vs. Best Validation Accuracy by Optimizer')\n",
    "ax.set_xlabel('Batch Size')\n",
    "ax.set_ylabel('Best Validation Accuracy')\n",
    "plt.legend(title='Optimizer')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8fa35d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'results' is your DataFrame\n",
    "# Group by optimizer and calculate mean best_val_accuracy for simplicity\n",
    "accuracy_summary = results_df.groupby(['optimizer']).agg({'best_val_accuracy':'mean'}).reset_index()\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "accuracy_summary.plot(kind='bar', x='optimizer', y='best_val_accuracy', ax=ax, legend=False)\n",
    "ax.set_title('Best Validation Accuracy by Optimizer')\n",
    "ax.set_ylabel('Best Validation Accuracy')\n",
    "ax.set_xlabel('Optimizer')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb48b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
